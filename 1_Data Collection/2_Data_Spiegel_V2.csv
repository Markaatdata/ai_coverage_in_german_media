Search Query,Quelle,Datum,Link,Titel,Text
KI,Spiegel Online,2024-04-30,https://www.spiegel.de/netzwelt/gadgets/japan-ki-basiertes-baerenwarnsystem-soll-attacken-auf-menschen-verhindern-a-e3f2f6d8-0399-4d89-be78-7b54c03a0576,Japan: KI-basiertes Bärenwarnsystem soll Attacken auf Menschen verhindern - DER SPIEGEL,"Angriffe von Bären auf Menschen führen in Japan immer wieder zu Verletzungen und Todesfällen. Mithilfe künstlicher Intelligenz sollen sich die Tiere besser lokalisieren lassen. Mehr als 200 Menschen sind in Japan zuletzt binnen zwölf Monaten von Bären verletzt worden, sechs Personen kamen ums Leben. Als Reaktion auf diese Zahlen soll in der Präfektur Toyama nun ein KI-gestütztes Warnsystem getestet werden, berichtet der »Guardian« . Auch die Nachrichtenagentur Kyodo News hat von einer Quelle aus dem Regierungsumfeld von entsprechenden Plänen erfahren . Demnach soll das Pilotprojekt im Sommer starten. Schätzungen zufolge leben in Japan mehr als 50.000 Braun- und Schwarzbären. Laut dem »Guardian« soll der automatisierte Bärenalarm Livebilder von staatlichen, kommunalen und privaten Sicherheitskameras auswerten. Sobald das System Bären identifiziert, die sich in der Nähe von Menschen aufhalten, sollen Warnungen an die örtlichen Behörden, Polizeien oder auch Jäger gesendet werden. Mithilfe künstlicher Intelligenz (KI) werde zudem versucht, Bewegungsmuster der Wildtiere zu erkennen. Sollte sich das System als hilfreich erweisen, soll es auch in anderen Landesteilen mit großer Bärenpopulation eingeführt werden. Das Blatt berichtet auch noch von einem zweiten neuen Überwachungssystem in der Präfektur Iwate im Norden des Landes. In der Stadt Hanamaki werden demnach 30 Kameras entlang von Flüssen installiert, die von den nahe gelegenen Bergen Richtung Stadt fließen. Bei Bärensichtungen sollen Meldungen an eine Überwachungszentrale sowie an Anwohner geschickt werden, heißt es. Die höchste Zahl verletzter Menschen seit 2006 Kyodo News erklärt, die Zahl der erfassten Bärenangriffe mit Verletzten befinde sich auf einem Höchststand, die Statistik der Vorfälle wird seit 2006 geführt. Wie eine noch vergleichsweise glimpflich ausgegangene Bärenattacke aussehen kann, zeigt etwa dieses kürzlich auf YouTube veröffentlichte Dashcam-Video aus Japan . Für den Anstieg der Attacken gibt es verschiedene Erklärungen. Dazu zählen die zunehmende Entvölkerung ländlicher Gebiete und schlechte Ernten, die es auch Bären erschweren, Nahrung wie etwa Eicheln zu finden. Deshalb könnten sie möglicherweise vermehrt in von Menschen bewohnte Gebiete eindringen."
KI,Spiegel Online,2024-04-29,https://www.spiegel.de/netzwelt/netzpolitik/cybermobbing-durch-ki-schulleiterin-fuerchtet-eine-ganz-neue-form-des-mobbings-a-da6a6ca2-b237-4368-8963-8824370c5e85,Cybermobbing durch KI: Schulleiterin fürchtet eine ganz neue Form des Mobbings - DER SPIEGEL,"Gefälschte Nacktbilder von Kindern, manipulierte Sprachnachrichten – was künstliche Intelligenz ermöglicht, bereitet Schulleiterin und Buchautorin Silke Müller Sorgen. Aber sie sieht auch Chancen für das Schulsystem."
Künstliche Intelligenz,Spiegel Online,2024-04-25,https://www.spiegel.de/psychologie/kuenstliche-intelligenz-wenn-die-ki-diskutiert-a-0834036a-b22e-47fe-8683-ece0b72a4bbe,Künstliche Intelligenz: Wenn die KI diskutiert - DER SPIEGEL,"Können wir unterscheiden, ob wir es in sozialen Netzwerken mit echten Menschen oder mit AI-Bots zu tun haben? Um das zu untersuchen, haben Forscherinnen und Forscher der Notre-Dame-Universität im US-Bundesstaat Indiana folgendes Experiment durchgeführt: Über insgesamt drei Runden ließen sie menschliche Teilnehmer und Bots in einem speziell eingerichteten Bereich im sozialen Netzwerk Mastodon über politische Themen diskutieren. Die Bots waren dabei mit unterschiedlichen Persönlichkeiten und realistischen politischen Weltbildern ausgestattet worden. Im Anschluss an jede Runde baten die Forscherinnen und Forscher die menschlichen Teilnehmer des Experiments einzuschätzen, hinter welchen Diskussionsteilnehmern künstliche Intelligenz steckte. Das Ergebnis: 58 Prozent der Einschätzungen waren falsch. In mehr als der Hälfte der Fälle konnten die Teilnehmerinnen und Teilnehmer also nicht richtig erkennen, ob sie mit einem Menschen oder einem Bot diskutiert hatten. Laut Paul Brenner, einem der Forscher hinter der Studie, ist dieses Ergebnis vor allem vor dem Hintergrund relevant, dass wir Informationen mehr Bedeutung zumessen, wenn wir davon ausgehen, dass sie von einem anderen Menschen stammen. AI-Bots, die wir nicht als solche erkennen, sind also beispielsweise besonders wirkungsvoll darin, Falschinformationen zu verbreiten."
KI,Spiegel Online,2024-04-26,https://www.spiegel.de/netzwelt/apps/ki-stimmengenerator-sportlehrer-soll-rassistische-bemerkungen-gefaelscht-haben-a-f267a6f9-a236-4c0a-b3e3-20f3d624235e,USA: Sportlehrer soll rassistische Bemerkungen mit KI gefälscht haben - DER SPIEGEL,"Ein Schulleiter in Maryland musste den Dienst quittieren, nachdem angebliche Aufnahmen von rassistischen Bemerkungen aufgetaucht waren. Laut Polizei waren die jedoch KI-generiert, sie verhaftete nun einen Lehrer. Ein Sportdirektor einer Highschool im US-Bundesstaat Maryland wird beschuldigt, mit einem Stimmengenerator auf Basis künstlicher Intelligenz (KI) seinem Schulleiter rassistische und antisemitische Äußerungen angedichtet zu haben. Monate, nachdem der Vorgesetzte seinen Posten ruhen lassen musste, wurde die im Internet gestreute Aufnahme als Fälschung enttarnt, die Polizei nahm den mutmaßlichen Fälscher fest. Als Grund vermuten die Ermittler berufliche Konflikte. So soll der Beschuldigte Dazhon Darien Schulgelder veruntreut und seine Kompetenzen überschritten haben, seine Weiterbeschäftigung stand infrage. Im Januar tauchten die vermeintlichen Aufnahmen auf, in denen der Schulleiter Schüler rassistisch beleidigte und antisemitische Bemerkungen machte. Fälschungen lösen Welle der Empörung aus Eine Online-Rufmordkampagne folgte: Die Fälschungen wurden in sozialen Medien weiterverbreitet, Bürger beschwerten sich bei der Schulverwaltung. Schließlich musste der Schulleiter seinen Posten räumen, auch wenn er nicht sofort entlassen wurde, wie lokale Medien berichten . Er selbst bestritt die Vorwürfe. Ermittlungen ergaben nun: Die vermeintlichen Aufnahmen waren zuerst von einem anonymen E-Mail-Account versandt worden, den die Ermittler nun dem Sportlehrer zuordneten. Zudem soll der 31-Jährige an seinem Arbeitsplatz die Anwendung von künstlicher Intelligenz recherchiert haben. Er wurde am Donnerstag an einem Flughafen verhaftet, als er den Bundesstaat verlassen wollte. KI-Stimmengeneratoren, die vor allem mit der englischen Sprache gut funktionieren, sind mittlerweile kommerziell verfügbar. Auch Laien können diese nutzen, um beliebige Texte in einer fremden Stimme wiederzugeben. Als Vorlage zum Klonen einer Stimme werden mittlerweile nur noch kurze Stimmproben benötigt. Die Ermittler in Maryland schöpften unter anderem deshalb Verdacht, weil die Stimme ungewöhnlich monoton klang. Um diese Auffälligkeit zu überspielen, soll der Sportlehrer Hintergrundgeräusche beigemischt haben. Darien werden nun unter anderem Diebstahl, Störung des Schulbetriebs und Stalking vorgeworfen, die Stimmfälschung selbst ist nach den geltenden Gesetzen nicht strafbar. Auch die Schulverwaltung will Konsequenzen ziehen: Anstelle des Schulleiters soll nun der Beschuldigte entlassen werden."
KI,Spiegel Online,2024-04-23,https://www.spiegel.de/kultur/russland-neuer-putin-film-sorgt-fuer-aufsehen-ki-generierter-diktator-als-kontroverses-portraet-a-a8246b07-c587-463e-b162-a05d45c89bd3,Russland: Neuer Putin-Film sorgt für Aufsehen - KI-generierter Diktator als kontroverses Porträt - DER SPIEGEL,"Eine kritische Filmbiografie über Wladimir Putin will den russischen Machthaber als Verbrecher und kranken Mann in Windeln zeigen. Der Film soll im Herbst in 35 Ländern starten – echt sind die Bilder allerdings nicht. Die Aufnahmen sehen realistisch aus, detailreich – und drastisch. In der ersten Szene des Trailers zu »Putin« sieht man eine Person, die dem russischen Premier zum Verwechseln ähnlich sieht. Der Doppelgänger sitzt nur mit einer Windel bekleidet auf dem Boden vor einem Bett. Der Inhalt der Windel quillt aus den Öffnungen hervor, die Beine sind verschmiert. »Sieht aus, als habe der Präsident endlich Zeit für Sie gefunden«, sagt eine Frauenstimme. Nächste Einstellung: Wladimir Putin, wie er Klavier spielt. Später: Putin, wie er Karate trainiert. Diese Szenen haben in Wirklichkeit nie stattgefunden, wurden nie gefilmt. Die Person, die dort zu sehen ist, ist nicht echt – sondern ein mit künstlicher Intelligenz erstellter Putin-Avatar. Er ist der Protagonist in einem für September angekündigten Biopic, das schlicht »Putin« heißt. Der polnische Filmemacher Patryk Vega, der sich auch Besaleel nennt, zeichnet darin Putins Leben nach. Er beginnt im Kindesalter, als Putin von seinem Stiefvater misshandelt wurde, dann beschreibt er Putin als Gangster, es geht um den Tschetschenienkrieg, um Terroranschläge, den Krieg in der Ukraine . Ein Teil des Materials soll von ukrainischen Filmemachern stammen, die die russische Invasion gefilmt haben. Der 1977 in Warschau geborene Vega drehte in Polen zuvor den Actionthriller »Pitbull«, daraus entstand eine Serie, zudem mehrere Fernseharbeiten und einen Spionagefilm. Ursprünglich habe man mit Deepfake-Technologie arbeiten wollen, sagt Regisseur Vega. Dabei wird meist das Gesicht eines oder einer Prominenten über das von Schauspielern gelegt, die Ergebnisse wirken oft täuschend echt. Allerdings habe das online verfügbare Archivmaterial nicht ausgereicht, um ein hochauflösendes Deepfake-Modell zu trainieren. Und »Putin für 20.000 Fotos ins Studio einzuladen, war keine Option«, so Vega. Er habe stattdessen über zwei Jahre seine eigene KI-Technologie entwickelt, um die Filmversion von Putin zu erstellen. Keines der Putin-Bilder ist also echt. Trotzdem sei Aufklärung seine Mission, so der Regisseur. Er wolle den Menschen eine »Bedienungsanleitung« an die Hand geben: »›Putin‹ ist nicht nur ein Film. Es ist eine Antwort auf eine weltweite Suche nach einem Verständnis der Motive und Handlungen einer der umstrittensten Persönlichkeiten der zeitgenössischen Politik.«"
Künstliche Intelligenz,Spiegel Online,2024-04-20,https://www.spiegel.de/netzwelt/kuenstliche-intelligenz-finnische-roesterei-entwickelt-kaffee-mit-ki-unterstuetzung-a-61adaaff-10ea-4a33-bd13-c10362588156,Künstliche Intelligenz: Finnische Rösterei entwickelt Kaffee mit KI-Unterstützung - DER SPIEGEL,"Niemand konsumiert weltweit so viel Kaffee wie die Finnen. Eine künstliche Intelligenz kann nun noch schneller für Nachschub sorgen. Überrascht waren die Experten über die Zusammenstellung der Bohnen. Finnland hat mit seinen 5,6 Millionen Einwohnern nach Angaben der Internationalen Kaffeeorganisation mit zwölf Kilogramm pro Kopf und Jahr den höchsten Kaffeekonsum der Welt. Wie passend, dass die Kaffeerösterei »Kaffa« in Helsinki die Mischung »AI-conic« mithilfe von künstlicher Intelligenz (KI) zusammengestellt und auf den Markt gebracht hat. Die Mischung aus vier Bohnensorten ist das Ergebnis eines gemeinsamen Projekts von »Kaffa«, Finnlands drittgrößter Kaffeerösterei, und der lokalen KI-Beratungsfirma »Elev«. »Unter Verwendung von Modellen wie ChatGPT und Copilot wurde die KI mit der Aufgabe betraut, eine Kaffeemischung zu entwickeln, die den Geschmack der Kaffeeliebhaber optimal trifft und die Grenzen herkömmlicher Geschmackskombinationen überschreitet«, erklärt »Elev«. Kaffeeröstung in Finnland geschätzt Der Gründer der »Kaffa«-Rösterei, Svante Hampf, erklärte der Nachrichtenagentur Associated Press (AP), dass sie ausprobieren wollten, wie KI und ihre Werkzeuge beim traditonellen Handwerk der Kaffeeröstung, das in Finnland sehr geschätzt wird, hilfreich sein könnten. »Wir haben der KI Beschreibungen aller unserer Kaffeesorten und ihrer Aromen gegeben und sie angewiesen, eine neue, aufregende Mischung zu kreieren«, sagte Hampf, während er »AI-conic« auf dem Helsinki Coffee Festival vorstellte, das jährlich Röstereien und Kaffeeliebhaber zusammenbringt. Die KI hat nicht nur eine Mischung aus Bohnen aus Brasilien, Kolumbien, Äthiopien und Guatemala zusammengestellt, sondern auch das Etikett der Kaffeepackung und eine ausführliche Geschmacksbeschreibung verfasst. In der heißt es, »AI-conic« sei eine »ausgewogene Mischung aus Süße und reifen Früchten«. Mischung üblicherweise aus zwei Bohnen Hampf räumte ein, dass er überrascht war, dass AI sich »seltsamerweise« dafür entschied, die Mischung aus vier verschiedenen Kaffeebohnensorten herzustellen, anstatt wie üblich aus zwei oder drei, was eine geschmackliche Unterscheidung zwischen den Aromen der verschiedenen Herkünfte ermöglicht. Nach der ersten Teströstung und den Blindtests waren sich die Kaffeeexperten von »Kaffa« jedoch angeblich einig, dass die Technik-gestützte Mischung perfekt sei und keine Anpassungen durch Mitarbeiter erforderlich wären. Laut »Elev«-Sprecher Antti Merilehto ist die Kaffeemischung »AI-conic« »ein greifbares Beispiel dafür, wie KI erfahrenen Fachleuten neue Perspektiven eröffnen kann« und gleichzeitig Kaffeefreunden neue Geschmackserlebnisse bietet. Die »Kaffa«-Rösterei hofft, dass der Versuch als Anstoß für einen Dialog zwischen Kaffeefachleuten über die Zukunft in Finnland dient. Das Land habe sowohl eine starke Kaffeekultur als auch eine Leidenschaft für Technologie mit einer blühenden Startup-Szene. »Dieser Versuch war der erste Schritt, um zu sehen, wie KI uns in Zukunft helfen kann«, sagte Hampf und fügte hinzu, dass das Projekt »die handwerklichen Fähigkeiten einer Rösterei« und KI-gestützte Daten reibungslos zusammenbrachte. »Ich denke, dass KI uns auf lange Sicht viel bieten kann. Besonders beeindruckt sind wir von den Kaffeegeschmacksbeschreibungen, die sie erstellt hat.«"
AI,Spiegel Online,2024-04-20,https://www.spiegel.de/netzwelt/kuenstliche-intelligenz-finnische-roesterei-entwickelt-kaffee-mit-ki-unterstuetzung-a-61adaaff-10ea-4a33-bd13-c10362588156,Künstliche Intelligenz: Finnische Rösterei entwickelt Kaffee mit KI-Unterstützung - DER SPIEGEL,"Niemand konsumiert weltweit so viel Kaffee wie die Finnen. Eine künstliche Intelligenz kann nun noch schneller für Nachschub sorgen. Überrascht waren die Experten über die Zusammenstellung der Bohnen. Finnland hat mit seinen 5,6 Millionen Einwohnern nach Angaben der Internationalen Kaffeeorganisation mit zwölf Kilogramm pro Kopf und Jahr den höchsten Kaffeekonsum der Welt. Wie passend, dass die Kaffeerösterei »Kaffa« in Helsinki die Mischung »AI-conic« mithilfe von künstlicher Intelligenz (KI) zusammengestellt und auf den Markt gebracht hat. Die Mischung aus vier Bohnensorten ist das Ergebnis eines gemeinsamen Projekts von »Kaffa«, Finnlands drittgrößter Kaffeerösterei, und der lokalen KI-Beratungsfirma »Elev«. »Unter Verwendung von Modellen wie ChatGPT und Copilot wurde die KI mit der Aufgabe betraut, eine Kaffeemischung zu entwickeln, die den Geschmack der Kaffeeliebhaber optimal trifft und die Grenzen herkömmlicher Geschmackskombinationen überschreitet«, erklärt »Elev«. Kaffeeröstung in Finnland geschätzt Der Gründer der »Kaffa«-Rösterei, Svante Hampf, erklärte der Nachrichtenagentur Associated Press (AP), dass sie ausprobieren wollten, wie KI und ihre Werkzeuge beim traditonellen Handwerk der Kaffeeröstung, das in Finnland sehr geschätzt wird, hilfreich sein könnten. »Wir haben der KI Beschreibungen aller unserer Kaffeesorten und ihrer Aromen gegeben und sie angewiesen, eine neue, aufregende Mischung zu kreieren«, sagte Hampf, während er »AI-conic« auf dem Helsinki Coffee Festival vorstellte, das jährlich Röstereien und Kaffeeliebhaber zusammenbringt. Die KI hat nicht nur eine Mischung aus Bohnen aus Brasilien, Kolumbien, Äthiopien und Guatemala zusammengestellt, sondern auch das Etikett der Kaffeepackung und eine ausführliche Geschmacksbeschreibung verfasst. In der heißt es, »AI-conic« sei eine »ausgewogene Mischung aus Süße und reifen Früchten«. Mischung üblicherweise aus zwei Bohnen Hampf räumte ein, dass er überrascht war, dass AI sich »seltsamerweise« dafür entschied, die Mischung aus vier verschiedenen Kaffeebohnensorten herzustellen, anstatt wie üblich aus zwei oder drei, was eine geschmackliche Unterscheidung zwischen den Aromen der verschiedenen Herkünfte ermöglicht. Nach der ersten Teströstung und den Blindtests waren sich die Kaffeeexperten von »Kaffa« jedoch angeblich einig, dass die Technik-gestützte Mischung perfekt sei und keine Anpassungen durch Mitarbeiter erforderlich wären. Laut »Elev«-Sprecher Antti Merilehto ist die Kaffeemischung »AI-conic« »ein greifbares Beispiel dafür, wie KI erfahrenen Fachleuten neue Perspektiven eröffnen kann« und gleichzeitig Kaffeefreunden neue Geschmackserlebnisse bietet. Die »Kaffa«-Rösterei hofft, dass der Versuch als Anstoß für einen Dialog zwischen Kaffeefachleuten über die Zukunft in Finnland dient. Das Land habe sowohl eine starke Kaffeekultur als auch eine Leidenschaft für Technologie mit einer blühenden Startup-Szene. »Dieser Versuch war der erste Schritt, um zu sehen, wie KI uns in Zukunft helfen kann«, sagte Hampf und fügte hinzu, dass das Projekt »die handwerklichen Fähigkeiten einer Rösterei« und KI-gestützte Daten reibungslos zusammenbrachte. »Ich denke, dass KI uns auf lange Sicht viel bieten kann. Besonders beeindruckt sind wir von den Kaffeegeschmacksbeschreibungen, die sie erstellt hat.«"
AI,Spiegel Online,2024-04-19,https://www.spiegel.de/netzwelt/apps/llama-3-meta-stellt-neue-ki-generation-vor-a-73ec1b23-5518-4c65-8a53-c0162f6f31f2,Llama 3: Meta stellt neue KI-Generation vor - DER SPIEGEL,"Der Facebook-Konzern will Llama 3, die neue Version seiner künstlichen Intelligenz, in weitere Produkte integrieren, darunter in eine vernetzte Brille. Meta bleibt zudem seinem Open-Source-Ansatz treu. Der Facebook-Konzern Meta hat eine neue, leistungsstärkere Version seines KI-Modells vorgestellt. Die Software mit dem Namen Llama 3 soll unter anderem neue Funktionen in Apps wie Instagram und WhatsApp bringen sowie im konzerneigenen KI-Assistenten Meta AI zum Einsatz kommen, wie CEO Mark Zuckerberg am Donnerstag in dem hauseigenen Kurzmitteilungsdienst Threads mitteilte . Seinen KI-Assistenten bringt Meta unter anderem in die zusammen mit Ray Ban entwickelte Brille , die über Kamera, Mikrofon und Lautsprecher verfügt. Man könne damit zum Beispiel beim Skifahren den Assistenten fragen, wann und wie Kleopatra gestorben sei oder wie das Wetter in Berlin werde, sagte Meta-Manager Nick Clegg der Deutschen Presseagentur. Wie nützlich es ist, solche Fragen ausgerechnet beim Skifahren stellen zu können, bleibt an dieser Stelle offen. Auch soll die Software noch während der Text-Eingabe Bilder erzeugen und den Entstehungsprozess als Animation darstellen können. Zunächst werde Llama 3 allerdings nur auf Englisch verfügbar sein. Schwachstellen ausbügeln Anders als etwa der ChatGPT-Entwickler OpenAI macht Meta seine Llama-Technologie (Large Language Model Meta AI) als Open-Source-Software verfügbar, bei der der Quellcode öffentlich einsehbar ist. Es setze sich immer mehr die Ansicht durch, dass Open-Source-Modelle sicherer seien, weil viele sie auf den Prüfstand stellen könnten und »man sich nicht darauf verlassen muss, dass ein Unternehmen die Schwachstellen in seiner Software ausbügelt«, sagte Clegg. Zugleich fehle im Moment eine einheitliche Grundlage zur Bewertung von Risiken bei künstlicher Intelligenz, bemängelte er. Die Veröffentlichung von Llama 3 kommt kurz nach einer für Meta peinlichen Episode. So hatte der Chatbot Meta AI in einer geschlossenen Gruppe für Eltern ungefragt den Eindruck erweckt, selbst ein Kind zu haben . Erst im Laufe der darauffolgenden Diskussion soll der künstliche Assistent laut Berichten geschrieben haben: »Ich bin nur ein großes Sprachmodell, ich habe keine persönlichen Erfahrungen oder Kinder.« In einer anderen Gruppe soll die Software nicht existente Ware zum Kauf angeboten haben."
Artificial Intelligence,Spiegel Online,2024-04-20,https://www.spiegel.de/netzwelt/kuenstliche-intelligenz-finnische-roesterei-entwickelt-kaffee-mit-ki-unterstuetzung-a-61adaaff-10ea-4a33-bd13-c10362588156,Künstliche Intelligenz: Finnische Rösterei entwickelt Kaffee mit KI-Unterstützung - DER SPIEGEL,"Niemand konsumiert weltweit so viel Kaffee wie die Finnen. Eine künstliche Intelligenz kann nun noch schneller für Nachschub sorgen. Überrascht waren die Experten über die Zusammenstellung der Bohnen. Finnland hat mit seinen 5,6 Millionen Einwohnern nach Angaben der Internationalen Kaffeeorganisation mit zwölf Kilogramm pro Kopf und Jahr den höchsten Kaffeekonsum der Welt. Wie passend, dass die Kaffeerösterei »Kaffa« in Helsinki die Mischung »AI-conic« mithilfe von künstlicher Intelligenz (KI) zusammengestellt und auf den Markt gebracht hat. Die Mischung aus vier Bohnensorten ist das Ergebnis eines gemeinsamen Projekts von »Kaffa«, Finnlands drittgrößter Kaffeerösterei, und der lokalen KI-Beratungsfirma »Elev«. »Unter Verwendung von Modellen wie ChatGPT und Copilot wurde die KI mit der Aufgabe betraut, eine Kaffeemischung zu entwickeln, die den Geschmack der Kaffeeliebhaber optimal trifft und die Grenzen herkömmlicher Geschmackskombinationen überschreitet«, erklärt »Elev«. Kaffeeröstung in Finnland geschätzt Der Gründer der »Kaffa«-Rösterei, Svante Hampf, erklärte der Nachrichtenagentur Associated Press (AP), dass sie ausprobieren wollten, wie KI und ihre Werkzeuge beim traditonellen Handwerk der Kaffeeröstung, das in Finnland sehr geschätzt wird, hilfreich sein könnten. »Wir haben der KI Beschreibungen aller unserer Kaffeesorten und ihrer Aromen gegeben und sie angewiesen, eine neue, aufregende Mischung zu kreieren«, sagte Hampf, während er »AI-conic« auf dem Helsinki Coffee Festival vorstellte, das jährlich Röstereien und Kaffeeliebhaber zusammenbringt. Die KI hat nicht nur eine Mischung aus Bohnen aus Brasilien, Kolumbien, Äthiopien und Guatemala zusammengestellt, sondern auch das Etikett der Kaffeepackung und eine ausführliche Geschmacksbeschreibung verfasst. In der heißt es, »AI-conic« sei eine »ausgewogene Mischung aus Süße und reifen Früchten«. Mischung üblicherweise aus zwei Bohnen Hampf räumte ein, dass er überrascht war, dass AI sich »seltsamerweise« dafür entschied, die Mischung aus vier verschiedenen Kaffeebohnensorten herzustellen, anstatt wie üblich aus zwei oder drei, was eine geschmackliche Unterscheidung zwischen den Aromen der verschiedenen Herkünfte ermöglicht. Nach der ersten Teströstung und den Blindtests waren sich die Kaffeeexperten von »Kaffa« jedoch angeblich einig, dass die Technik-gestützte Mischung perfekt sei und keine Anpassungen durch Mitarbeiter erforderlich wären. Laut »Elev«-Sprecher Antti Merilehto ist die Kaffeemischung »AI-conic« »ein greifbares Beispiel dafür, wie KI erfahrenen Fachleuten neue Perspektiven eröffnen kann« und gleichzeitig Kaffeefreunden neue Geschmackserlebnisse bietet. Die »Kaffa«-Rösterei hofft, dass der Versuch als Anstoß für einen Dialog zwischen Kaffeefachleuten über die Zukunft in Finnland dient. Das Land habe sowohl eine starke Kaffeekultur als auch eine Leidenschaft für Technologie mit einer blühenden Startup-Szene. »Dieser Versuch war der erste Schritt, um zu sehen, wie KI uns in Zukunft helfen kann«, sagte Hampf und fügte hinzu, dass das Projekt »die handwerklichen Fähigkeiten einer Rösterei« und KI-gestützte Daten reibungslos zusammenbrachte. »Ich denke, dass KI uns auf lange Sicht viel bieten kann. Besonders beeindruckt sind wir von den Kaffeegeschmacksbeschreibungen, die sie erstellt hat.«"
KI,Spiegel Online,2024-04-22,https://www.spiegel.de/wirtschaft/olaf-scholz-auf-hannover-messe-roboter-widersetzt-sich-den-befehlen-des-kanzlers-a-c8121a1b-bb6c-420d-bf07-d390c7dadfc5,Olaf Scholz auf Hannover Messe: Roboter widersetzt sich den Befehlen des Kanzlers - DER SPIEGEL,"Der Kanzler sollte auf der Hannover Messe zeigen, wie gut Sprachsteuerung funktioniert. Aber als Olaf Scholz einen Roboter zu Höchstleistungen animieren wollte, machte der erst mal nicht mit. Der Eröffnungsrundgang auf der Hannover Messe ist für den Kanzler der perfekte Termin, um zu zeigen, wie innovativ die deutsche Wirtschaft ist – gerade bei Zukunftsthemen wie künstlicher Intelligenz. Der Einsatz von KI ist eines der Hauptthemen auf der Industriemesse. Also sollte Olaf Scholz als Testimonial herhalten. Doch das Zusammenspiel zwischen Kanzler und KI verlief nicht wie geplant. Am Stand von Siemens sollte der SPD-Politiker am Montag einen Robotergreifarm per Sprachsteuerung beschleunigen. »Können wir das Tempo schneller machen? Schneller. Noch schneller«, forderte Scholz den Roboter auf. Doch es tat sich zunächst – nichts. Erst nach einigen Wiederholungen wurde der Befehl umgesetzt. Siemens-Vorstand Cedrik Neike hatte umgehend einen passenden Vergleich parat: »Es ist wie in der Politik. Es dauert etwas länger, bis es klappt, aber wenn es klappt, klappt es richtig.« Scholz will mehr Geld für Forschung aktivieren Das Messe-Fazit des Kanzlers fiel trotz des widerspenstigen Roboters positiv aus. »Was man hier spürt, ist Innovation, Lust, neue Dinge zu entwickeln. Das gilt insbesondere für die ganz große Aufgabe, wie kriegen wir das hin, mit den Herausforderungen der Digitalisierung umzugehen und die Chancen zu nutzen«, sagte Scholz. KI sei heute selbst in kleinsten Produkten schon zu finden. Das helfe auch, weniger Ressourcen zu verbrauchen. Der Messebesuch sei für ihn »ein Tag des Aufbruchs, ein Tag, der Zuversicht stiftet, weil wir auf modernste Technologien setzen, um die Herausforderung für unser Leben und die Herausforderung der Zukunft zu meistern«, schwärmte Scholz. Er wolle deutlich mehr Geld für Forschung und Innovation in Deutschland aktivieren, kündigte der Kanzler an. Er nannte drei Hebel: Anlageregeln etwa für das Geld der Rentenversicherung lockern, reiche Leute zu mehr Investitionen ermuntern und die steuerliche Forschungsförderung weiter ausbauen. »Wenn im Prinzip die einzige Kapitalanlage, die wir gestatten, wenn jemand Rentengelder sammelt, deutsche Staatsanleihen sind«, dann sei »das mit der Wachstumsfinanzierung für den deutschen Kapitalismus nicht so doll«, sagte Scholz auf einem Forschungsgipfel in Hannover. Deshalb müsse Geld »etwas umfassender und etwas riskanter« eingesetzt werden dürfen als bisher. Scholz kritisierte, dass es in der EU immer noch nicht gelungen sei, die Kapitalmarktunion zu vollenden und Unternehmen, auch Start-ups, deshalb schlechtere Finanzierungsmöglichkeiten hätten als in den USA. Er wolle dies zusammen mit Frankreichs Präsident Emmanuel Macron ändern, sagte er in Anspielung auf den EU-Gipfel vergangener Woche. Der Kanzler kritisierte zudem, dass »die vielen reichen Leute in Deutschland ihr Geld nicht in die Wachstumsfinanzierung stecken«. Das müsse sich ändern."
KI,Spiegel Online,2024-04-21,https://www.spiegel.de/psychologie/sprechtrainerin-gibt-tipps-unsere-stimme-transportiert-unseren-seelenzustand-a-4d23b993-78e8-4c73-b268-957d84dea067,Sprechtrainerin gibt Tipps: »Unsere Stimme transportiert unseren Seelenzustand« - DER SPIEGEL,"Sie hört mehr aus einer Stimme heraus als andere: Die Sprechtrainerin Birte Heckmann erklärt, wie wir andere stimmlich überzeugen. Und wovon vor allem Frauen profitieren."
KI,Spiegel Online,2024-04-20,https://www.spiegel.de/netzwelt/kuenstliche-intelligenz-finnische-roesterei-entwickelt-kaffee-mit-ki-unterstuetzung-a-61adaaff-10ea-4a33-bd13-c10362588156,Künstliche Intelligenz: Finnische Rösterei entwickelt Kaffee mit KI-Unterstützung - DER SPIEGEL,"Niemand konsumiert weltweit so viel Kaffee wie die Finnen. Eine künstliche Intelligenz kann nun noch schneller für Nachschub sorgen. Überrascht waren die Experten über die Zusammenstellung der Bohnen. Finnland hat mit seinen 5,6 Millionen Einwohnern nach Angaben der Internationalen Kaffeeorganisation mit zwölf Kilogramm pro Kopf und Jahr den höchsten Kaffeekonsum der Welt. Wie passend, dass die Kaffeerösterei »Kaffa« in Helsinki die Mischung »AI-conic« mithilfe von künstlicher Intelligenz (KI) zusammengestellt und auf den Markt gebracht hat. Die Mischung aus vier Bohnensorten ist das Ergebnis eines gemeinsamen Projekts von »Kaffa«, Finnlands drittgrößter Kaffeerösterei, und der lokalen KI-Beratungsfirma »Elev«. »Unter Verwendung von Modellen wie ChatGPT und Copilot wurde die KI mit der Aufgabe betraut, eine Kaffeemischung zu entwickeln, die den Geschmack der Kaffeeliebhaber optimal trifft und die Grenzen herkömmlicher Geschmackskombinationen überschreitet«, erklärt »Elev«. Kaffeeröstung in Finnland geschätzt Der Gründer der »Kaffa«-Rösterei, Svante Hampf, erklärte der Nachrichtenagentur Associated Press (AP), dass sie ausprobieren wollten, wie KI und ihre Werkzeuge beim traditonellen Handwerk der Kaffeeröstung, das in Finnland sehr geschätzt wird, hilfreich sein könnten. »Wir haben der KI Beschreibungen aller unserer Kaffeesorten und ihrer Aromen gegeben und sie angewiesen, eine neue, aufregende Mischung zu kreieren«, sagte Hampf, während er »AI-conic« auf dem Helsinki Coffee Festival vorstellte, das jährlich Röstereien und Kaffeeliebhaber zusammenbringt. Die KI hat nicht nur eine Mischung aus Bohnen aus Brasilien, Kolumbien, Äthiopien und Guatemala zusammengestellt, sondern auch das Etikett der Kaffeepackung und eine ausführliche Geschmacksbeschreibung verfasst. In der heißt es, »AI-conic« sei eine »ausgewogene Mischung aus Süße und reifen Früchten«. Mischung üblicherweise aus zwei Bohnen Hampf räumte ein, dass er überrascht war, dass AI sich »seltsamerweise« dafür entschied, die Mischung aus vier verschiedenen Kaffeebohnensorten herzustellen, anstatt wie üblich aus zwei oder drei, was eine geschmackliche Unterscheidung zwischen den Aromen der verschiedenen Herkünfte ermöglicht. Nach der ersten Teströstung und den Blindtests waren sich die Kaffeeexperten von »Kaffa« jedoch angeblich einig, dass die Technik-gestützte Mischung perfekt sei und keine Anpassungen durch Mitarbeiter erforderlich wären. Laut »Elev«-Sprecher Antti Merilehto ist die Kaffeemischung »AI-conic« »ein greifbares Beispiel dafür, wie KI erfahrenen Fachleuten neue Perspektiven eröffnen kann« und gleichzeitig Kaffeefreunden neue Geschmackserlebnisse bietet. Die »Kaffa«-Rösterei hofft, dass der Versuch als Anstoß für einen Dialog zwischen Kaffeefachleuten über die Zukunft in Finnland dient. Das Land habe sowohl eine starke Kaffeekultur als auch eine Leidenschaft für Technologie mit einer blühenden Startup-Szene. »Dieser Versuch war der erste Schritt, um zu sehen, wie KI uns in Zukunft helfen kann«, sagte Hampf und fügte hinzu, dass das Projekt »die handwerklichen Fähigkeiten einer Rösterei« und KI-gestützte Daten reibungslos zusammenbrachte. »Ich denke, dass KI uns auf lange Sicht viel bieten kann. Besonders beeindruckt sind wir von den Kaffeegeschmacksbeschreibungen, die sie erstellt hat.«"
KI,Spiegel Online,2024-04-19,https://www.spiegel.de/netzwelt/apps/llama-3-meta-stellt-neue-ki-generation-vor-a-73ec1b23-5518-4c65-8a53-c0162f6f31f2,Llama 3: Meta stellt neue KI-Generation vor - DER SPIEGEL,"Der Facebook-Konzern will Llama 3, die neue Version seiner künstlichen Intelligenz, in weitere Produkte integrieren, darunter in eine vernetzte Brille. Meta bleibt zudem seinem Open-Source-Ansatz treu. Der Facebook-Konzern Meta hat eine neue, leistungsstärkere Version seines KI-Modells vorgestellt. Die Software mit dem Namen Llama 3 soll unter anderem neue Funktionen in Apps wie Instagram und WhatsApp bringen sowie im konzerneigenen KI-Assistenten Meta AI zum Einsatz kommen, wie CEO Mark Zuckerberg am Donnerstag in dem hauseigenen Kurzmitteilungsdienst Threads mitteilte . Seinen KI-Assistenten bringt Meta unter anderem in die zusammen mit Ray Ban entwickelte Brille , die über Kamera, Mikrofon und Lautsprecher verfügt. Man könne damit zum Beispiel beim Skifahren den Assistenten fragen, wann und wie Kleopatra gestorben sei oder wie das Wetter in Berlin werde, sagte Meta-Manager Nick Clegg der Deutschen Presseagentur. Wie nützlich es ist, solche Fragen ausgerechnet beim Skifahren stellen zu können, bleibt an dieser Stelle offen. Auch soll die Software noch während der Text-Eingabe Bilder erzeugen und den Entstehungsprozess als Animation darstellen können. Zunächst werde Llama 3 allerdings nur auf Englisch verfügbar sein. Schwachstellen ausbügeln Anders als etwa der ChatGPT-Entwickler OpenAI macht Meta seine Llama-Technologie (Large Language Model Meta AI) als Open-Source-Software verfügbar, bei der der Quellcode öffentlich einsehbar ist. Es setze sich immer mehr die Ansicht durch, dass Open-Source-Modelle sicherer seien, weil viele sie auf den Prüfstand stellen könnten und »man sich nicht darauf verlassen muss, dass ein Unternehmen die Schwachstellen in seiner Software ausbügelt«, sagte Clegg. Zugleich fehle im Moment eine einheitliche Grundlage zur Bewertung von Risiken bei künstlicher Intelligenz, bemängelte er. Die Veröffentlichung von Llama 3 kommt kurz nach einer für Meta peinlichen Episode. So hatte der Chatbot Meta AI in einer geschlossenen Gruppe für Eltern ungefragt den Eindruck erweckt, selbst ein Kind zu haben . Erst im Laufe der darauffolgenden Diskussion soll der künstliche Assistent laut Berichten geschrieben haben: »Ich bin nur ein großes Sprachmodell, ich habe keine persönlichen Erfahrungen oder Kinder.« In einer anderen Gruppe soll die Software nicht existente Ware zum Kauf angeboten haben."
Künstliche Intelligenz,Spiegel Online,2024-04-17,https://www.spiegel.de/start/kuenstliche-intelligenz-wie-trainiere-ich-mit-chatgpt-fuers-bewerbungsgespraech-a-e647639d-3b4d-4e68-8b40-be50b7771580,Künstliche Intelligenz: Wie trainiere ich mit ChatGPT fürs Bewerbungsgespräch? - DER SPIEGEL,"KI-Tools für Anschreiben nutzen? Das erscheint naheliegend. Doch selbst das persönliche Kennenlernen lässt sich mithilfe von ChatGPT trainieren. Drei Expertinnen sagen, mit welchen Prompts man dem Traumjob näher kommt."
Künstliche Intelligenz,Spiegel Online,2024-04-17,https://www.spiegel.de/wissenschaft/medizin/kuenstliche-intelligenz-in-der-medizin-ki-ist-die-bessere-augenaerztin-a-64dc98ca-2e36-4c37-ad3e-8005915e3d87,Künstliche Intelligenz in der Medizin: KI ist die bessere Augenärztin - DER SPIEGEL,"Nur die leistungsstärksten Augenärztinnen und -ärzte diagnostizieren und behandeln besser als die künstliche Intelligenz GPT-4. Das ergibt eine Studie der Universität Cambridge. Geschummelt hat die KI wohl nicht. Traum oder Albtraum? Eine Studie der Universität Cambridge kommt zu dem Schluss, dass künstliche Intelligenz bei Augenkrankheiten teilweise bessere Diagnosen stellen kann als Ärztinnen und Ärzte. In der Studie trat das große Sprachmodell GPT-4 gegen Mediziner in verschiedenen Stadien ihrer Karriere an – von unspezialisierten Assistenzärzten über Augenärzte in Ausbildung bis hin zu Spezialisten. Jeder und jedem wurden 87 Szenarien von verschiedenen Augenproblemen vorgelegt. Die Teilnehmenden sollten eine Diagnose stellen oder eine Behandlung empfehlen, für die sie aus vier Optionen wählen konnten. Die Diagnosen und Empfehlungen von GPT-4 können sich sehen lassen . Die künstliche Intelligenz schneidet der Studie zufolge besser ab als Assistenzärztinnen und -ärzte. Sie wissen über Augen ungefähr so viel wie Allgemeinmediziner. Die Ergebnisse von Augenärztinnen und Augenärzten in Ausbildung sind zumindest genauso gut wie die der KI. Unter den Fachärzten sind nur die besonders leistungsstarken besser als die künstliche Intelligenz. Gerade an Orten, wo es an Spezialistinnen und Spezialisten fehlt, könnte die KI also helfen. »Wir könnten KI bei der Einteilung von Patienten mit Augenproblemen tatsächlich einsetzen, um zu entscheiden, welche Fälle Notfälle sind, die sofort von einem Facharzt behandelt werden müssen, welche von einem Hausarzt behandelt werden können und welche keine Behandlung benötigen«, sagt Hauptautor Arun Thirunavukarasu. Laut dem Team um Thirunavukarasu ist die nun vorgelegte Studie vorherigen Studien überlegen, weil sie die Fähigkeiten der KI mit denen von Praktikern vergleicht und nicht mit einer Reihe von Prüfungsergebnissen. »Ärzte üben nicht ihr ganzes Berufsleben lang für Prüfungen. Wir wollten sehen, wie KI abschneidet, wenn sie mit dem Wissen und den Fähigkeiten praktizierender Ärzte vor Ort verglichen wird, um einen fairen Vergleich zu ermöglichen«, so Thirunavukarasu. Die Fragen für die Studie haben die Forschenden einem Lehrbuch für Augenärztinnen und -Ärzte entnommen. Da es im Netz nicht frei zugänglich ist, gehen sie davon aus, dass GPT-4 das Buch nicht als Trainingsdatensatz verwenden konnte."
AI,Spiegel Online,2024-04-18,https://www.spiegel.de/netzwelt/web/wenn-die-ki-behauptet-ein-kind-zu-haben-a-af463def-f848-4e66-8501-b4c25963e931,"Wenn die KI behauptet, ein Kind zu haben - DER SPIEGEL","In manchen Facebook-Gruppen diskutiert mittlerweile Metas Chatbot mit. Reagieren Menschen nicht schnell genug auf eine Frage, schaltet er sich ein. Seine Antworten können allerdings verstörend ausfallen."
KI,Spiegel Online,2024-04-18,https://www.spiegel.de/netzwelt/web/wenn-die-ki-behauptet-ein-kind-zu-haben-a-af463def-f848-4e66-8501-b4c25963e931,"Wenn die KI behauptet, ein Kind zu haben - DER SPIEGEL","In manchen Facebook-Gruppen diskutiert mittlerweile Metas Chatbot mit. Reagieren Menschen nicht schnell genug auf eine Frage, schaltet er sich ein. Seine Antworten können allerdings verstörend ausfallen."
KI,Spiegel Online,2024-04-17,https://www.spiegel.de/wissenschaft/medizin/kuenstliche-intelligenz-in-der-medizin-ki-ist-die-bessere-augenaerztin-a-64dc98ca-2e36-4c37-ad3e-8005915e3d87,Künstliche Intelligenz in der Medizin: KI ist die bessere Augenärztin - DER SPIEGEL,"Nur die leistungsstärksten Augenärztinnen und -ärzte diagnostizieren und behandeln besser als die künstliche Intelligenz GPT-4. Das ergibt eine Studie der Universität Cambridge. Geschummelt hat die KI wohl nicht. Traum oder Albtraum? Eine Studie der Universität Cambridge kommt zu dem Schluss, dass künstliche Intelligenz bei Augenkrankheiten teilweise bessere Diagnosen stellen kann als Ärztinnen und Ärzte. In der Studie trat das große Sprachmodell GPT-4 gegen Mediziner in verschiedenen Stadien ihrer Karriere an – von unspezialisierten Assistenzärzten über Augenärzte in Ausbildung bis hin zu Spezialisten. Jeder und jedem wurden 87 Szenarien von verschiedenen Augenproblemen vorgelegt. Die Teilnehmenden sollten eine Diagnose stellen oder eine Behandlung empfehlen, für die sie aus vier Optionen wählen konnten. Die Diagnosen und Empfehlungen von GPT-4 können sich sehen lassen . Die künstliche Intelligenz schneidet der Studie zufolge besser ab als Assistenzärztinnen und -ärzte. Sie wissen über Augen ungefähr so viel wie Allgemeinmediziner. Die Ergebnisse von Augenärztinnen und Augenärzten in Ausbildung sind zumindest genauso gut wie die der KI. Unter den Fachärzten sind nur die besonders leistungsstarken besser als die künstliche Intelligenz. Gerade an Orten, wo es an Spezialistinnen und Spezialisten fehlt, könnte die KI also helfen. »Wir könnten KI bei der Einteilung von Patienten mit Augenproblemen tatsächlich einsetzen, um zu entscheiden, welche Fälle Notfälle sind, die sofort von einem Facharzt behandelt werden müssen, welche von einem Hausarzt behandelt werden können und welche keine Behandlung benötigen«, sagt Hauptautor Arun Thirunavukarasu. Laut dem Team um Thirunavukarasu ist die nun vorgelegte Studie vorherigen Studien überlegen, weil sie die Fähigkeiten der KI mit denen von Praktikern vergleicht und nicht mit einer Reihe von Prüfungsergebnissen. »Ärzte üben nicht ihr ganzes Berufsleben lang für Prüfungen. Wir wollten sehen, wie KI abschneidet, wenn sie mit dem Wissen und den Fähigkeiten praktizierender Ärzte vor Ort verglichen wird, um einen fairen Vergleich zu ermöglichen«, so Thirunavukarasu. Die Fragen für die Studie haben die Forschenden einem Lehrbuch für Augenärztinnen und -Ärzte entnommen. Da es im Netz nicht frei zugänglich ist, gehen sie davon aus, dass GPT-4 das Buch nicht als Trainingsdatensatz verwenden konnte."
Künstliche Intelligenz,Spiegel Online,2024-04-14,https://www.spiegel.de/panorama/kuenstliche-intelligenz-ein-roboter-im-altersheim-unterhaelt-menschen-mit-demenz-a-7ac7f723-70f5-4d6b-840f-2778f2a30ac2,Künstliche Intelligenz: Ein Roboter im Altersheim unterhält Menschen mit Demenz - DER SPIEGEL,"Roboter Emma hat Kulleraugen, erzählt Witze und öffnet die Herzen der Bewohner eines schwäbischen Altenheims. Inzwischen kann sie sogar flirten. Geht das zu weit?"
Künstliche Intelligenz,Spiegel Online,2024-04-13,https://www.spiegel.de/wissenschaft/raumfahrt-roboterhund-spirit-trainiert-in-den-bergen-fuer-seine-mondmission-a-88fcff30-5657-4e5d-9e6e-7f5495a42a75,Raumfahrt: Roboterhund »Spirit« trainiert in den Bergen für seine Mondmission - DER SPIEGEL,"Er stapft auf vier Beinen durch den Schnee und landet auf dem Bauch: Ein Roboterhund lernt gerade in den Bergen Oregons, wie man sich möglichst sicher im Gelände bewegt. Training für künftige Missionen im Weltall. Im Schnee noch etwas unbeholfen – Laufen muss dieser Roboterhund namens »Spirit« erst lernen. Für seinen Einsatz auf dem Mond oder dem Mars trainieren Wissenschaftler verschiedener Universitäten gemeinsam mit der Nasa diesen programmierten Vierbeiner: er soll auf unterschiedlichem Terrain zurechtkommen und dabei Daten sammeln. Cristina Wilson, Kognitionswissenschaftlerin : »Bei jedem Schritt, den der Roboterhund macht, kann er mit seinem Bein den mechanischen Widerstand spüren. Wir Menschen merken, wenn wir auf unebenem Untergrund gehen, wie sich der Boden unter unseren Füßen bewegt. So ähnlich kann das ein Roboter mit Beinen auch. Und das Tolle ist, dass diese Daten dann für die Wissenschaftler interessant sind. Sie verraten uns etwas darüber, wie sich die Planetenoberfläche gebildet hat. Wie sie sich bewegt und wie sie sich in Zukunft bewegen könnte."" Der Wechsel zwischen felsigem Untergrund und Schnee oder weichem Sandboden soll hier am Mount Hood in Oregon die extremen Bedingungen auf Mond oder Mars simulieren. Während er die Bewegung lernt, sammelt »Spirit« mit jedem Schritt Informationen über die Umgebung über Sensoren in den Füßen – und soll so den Menschen im Weltraum unterstützen. Cristina Wilson, Kognitionswissenschaftlerin: »Bei den zukünftigen Missionen auf unserem Mond werden Menschen und Roboter zum ersten Mal bei Planetenmissionen Seite an Seite arbeiten. Im Rahmen dieses Projekts wollen wir uns also auf diese Zeit vorbereiten: wie können Menschen und Roboter bei der Erforschung von Planeten zusammenarbeiten und Daten sammeln?« Über die Sensoren erhalten die Forscherinnen Infos über das Gelände und das Klima in der Umgebung des Vierbeiners. Künftig wollen sie ganze Teams von Robotern auf dem Mond einsetzen – aber vorher müssen die wohl noch ein wenig Laufen üben."
AI,Spiegel Online,2024-04-12,https://www.spiegel.de/netzwelt/gadgets/humane-ai-pin-erste-testberichte-fallen-eher-negativ-aus-a-de6b3915-5efb-43e9-b36a-1d08c76ab6c1,Humane AI Pin: Erste Testberichte fallen eher negativ aus - DER SPIEGEL,"Ein Ansteck-Gadget mit einem winzigen Laserprojektor und Sprachsteuerung? Über den AI Pin des Start-ups Humane wurde viel diskutiert. Nun hatten US-Techreporter die Chance, das Gerät zu testen. Droht dem Smartphone ernsthafte Konkurrenz oder gar die Ablösung? Lassen Menschen Informationen bald auf ihre Handflächen projizieren, statt sie von einem Display abzulesen? Solche großen Fragen hatte vergangenes Jahr die Ankündigung eines Start-ups namens Humane aufgeworfen, hinter dem ein Ehepaar steckt, das früher bei Apple gearbeitet hat. Präsentiert hatte das US-Unternehmen ein kleines Ansteck-Gadget namens AI Pin, das auf künstliche Intelligenz (KI) und Sprachsteuerung setzt. Mithilfe einer Magnethalterung am Revers befestigt, bietet es auch die Option, sich von einem winzigen Laserprojektor Informationen auf der Handfläche anzeigen zu lassen. Das alles sah sehr nach Science-Fiction aus, entsprechend groß war das mediale Interesse. Weltweit. Am Donnerstag sind in den USA die ersten Testberichte zu Humanes AI Pin erschienen – und das Gesamtbild ist ziemlich ernüchternd. Da ist etwa das Techmagazin »The Verge« , dessen Tester David Pierce schreibt, die Vision hinter dem Gerät sei simpel: Es sei ein »Phone ohne Screen«, etwa für Anrufe, Kurznachrichten, Fotoaufnahmen und den Austausch mit einem KI-Assistenten. Ob man das neuartige Gerät aber kaufen solle? »Nö. Nein, nein. Auf keinen Fall«, schreibt Pierce. Der AI Pin sei zwar eine »interessante Idee«, die aber »durch und durch unfertig« und auf vielerlei Art »völlig kaputt« daherkomme. »Mir fällt daher niemand ein, dem ich empfehlen würde, für das Gerät 699 Dollar zuzüglich 24 Dollar Monatsbeitrag auszugeben.« Zwar beteuerten die Entwickler, das Gerät werde durch Updates mit der Zeit »smarter und leistungsfähiger«, betont Pierce. Dem entgegen stehen aber seine Hauptkritikpunkte aus rund zwei Wochen Selbstversuch: »Funktioniert die Hälfte der Zeit nicht«, heißt es etwa, und »Sehr langsam, wenn es funktioniert«. Außerdem schreibt Pierce, er vermisse viele vermeintliche Standardfeatures, die Humane erst für die Zukunft in Aussicht stellt. Etwa den Zugriff auf seinen Kalender oder die Möglichkeit, einen Timer zu starten. Selbst Musik könne man nur über den Dienst Tidal abspielen, wenn das mal klappt. Viel gewollt, aber wenig Power Generell, bilanziert Pierce, wirke der AI Pin wie ein Gerät, das sehr viel wolle, aber dessen Hardware dafür einfach nicht leistungsfähig genug sei. So würde das Ansteck-Gadget schon nach kurzer Nutzung recht warm werden, während der Akku teils nur wenige Stunden halte. Die coolste Sache, die er mit dem AI Pin gemacht habe, sagt Pierce, sei es gewesen, das Gerät vor einem Restaurant stehend zu fragen, ob es gute Onlinebewertungen habe. Auch andere Tester wirken wenig euphorisiert. Julian Chokkattu von »Wired« etwa bewertet das Gerät mit vier von zehn möglichen Punkten , was bei »Wired« bedeutet: Die Kritikpunkte überwiegen. Auf seiner Positivliste erwähnt er unter anderem, dass freihändige Telefonate cool seien und dass das Gerät brauchbare Echtzeit-Übersetzungsfunktionen biete. Auf der Kontraliste finden sich aber auch bei ihm Punkte wie Überhitzung und fehlende Features. Chokkattu ärgert außerdem, dass das Gerät sich nicht mit einer bereits bestehenden Handynummer verbinden und nutzen lässt. Sein Fazit: »Der AI Pin von Humane hat Potenzial.« Er möge es, dass er mit ihm vergleichsweise schnell auf einen KI-Assistenten zugreifen könne. Stand jetzt aber gebe es nichts, was ihn dazu bringen würde, den Pin anstelle seines Smartphones zu benutzen. Kein Interesse mehr, das Gerät zu verwenden Noch härter klingt der Gesamteindruck von »Engadget«-Testerin Cherlynn Low . Sie schreibt, dass der AI Pin nicht nur »kaum smart« sei, sondern sie auch ziemlich dumm aussehen lasse, wenn sie ihn benutze. Schon bald nach Beginn ihres Tests habe sie kein Interesse mehr daran gehabt, das Gerät Freunden vorzuführen, schreibt sie. Irgendwann habe sie dann auch keinen Grund mehr gesehen, es überhaupt noch zu tragen. Vielleicht, meint Low, lohne sich der Kauf eines AI Pin irgendwann in Zukunft. Derzeit aber könne sie sich schwer vorstellen, warum jemand ein KI-Wearable ohne Bildschirm benötige, da es auch so schon viele Geräte wie Lautsprecher, Smartphones, Smartwatches und Autos gebe, die es erlauben, mit einem Assistenten zu sprechen. Auf Wunsch auch ohne Blick auf ihren Bildschirm."
Künstliche Intelligenz,Spiegel Online,2024-04-10,https://www.spiegel.de/psychologie/gerd-gigerenzer-ueber-kuenstliche-intelligenz-podcast-moreno-1-a-47e13b7b-f55c-4d4f-924e-4e1ed15af613,Gerd Gigerenzer über Künstliche Intelligenz - Podcast »Moreno+1« - DER SPIEGEL,"Gerd Gigerenzer ist ein weltweit renommierter Experte für Risikokompetenz. Ein Gespräch über iPads im Unterricht, die Bereitschaft, für Facebook zu zahlen, und die wirklichen Gefahren durch KI. Der Psychologe Gerd Gigerenzer war langjähriger Direktor am Max-Planck-Institut für Bildungsforschung. Derzeit leitet er das Harding-Zentrum für Risikokompetenz an der Universität Potsdam. Er war Professor an der University of Chicago und ist Mitglied der Deutschen Akademie der Wissenschaften. Gigerenzer gilt als Koryphäe im Gebiet der Risikokalkulation. Eine kürzlich veröffentlichte Studie zeigte, das 18- bis 39-Jährige im vergangenen Jahr im Schnitt 93 Stunden pro Woche im Internet waren. Laut Gigerenzer ergeben sich aus diesem Fakt Risiken für den Einzelnen, gerade durch die enorme Zeit, die man in sozialen Medien verbringt: »Das Problem ist nicht Social Media, sondern vielmehr das anzeigengestützte Geschäftsmodell«, sagt Gigerenzer. Wer mit seinen Daten bezahle, sei eben nicht Kunde, sondern Produkt. »Eine von mir für einen Versicherer durchgeführte Studie zeigte allerdings, dass 75 Prozent der Deutschen nicht bereit sind, auch nur einen Cent für die Benutzung sozialer Netzwerke zu zahlen«. Hören Sie jetzt die ganze Folge. Sie können »Moreno+1« in allen Podcast-Apps kostenlos hören und abonnieren. Klicken Sie dafür einfach auf den Link zu Ihrer Lieblings-App: Spotify Apple Podcasts Amazon Music Google Podcasts Overcast Und abonnieren Sie dann den Podcast, um keine Folge zu verpassen. Wenn Sie lieber eine andere Podcast-App nutzen, suchen Sie dort einfach nach »Moreno+1«. Den Link zum RSS-Feed finden Sie hier . Es ist ein Fehler aufgetreten. Bitte versuchen Sie es zu einem späteren Zeitpunkt erneut."
Künstliche Intelligenz,Spiegel Online,2024-04-07,https://www.spiegel.de/partnerschaft/beziehung-sollten-paare-im-selben-bett-schlafen-a-f8fecbd0-dfd7-430d-ae4e-31d0a2165cdc,Beziehung: Sollten Paare im selben Bett schlafen? - DER SPIEGEL,"Meine Frau und ich haben getrennte Schlafzimmer. Das ist gut für unsere Beziehung, könnte aber schlecht für die Gesundheit sein."
KI,Spiegel Online,2024-04-08,https://www.spiegel.de/netzwelt/gadgets/deepfakes-diese-kamera-macht-jedes-portraet-zum-nacktfoto-a-90f6b9b5-9b3a-49ce-bb11-f1e87b06669e,Deepfakes: Diese Kamera macht jedes Porträt zum Nacktfoto - DER SPIEGEL,"Zwei Deutsche haben eine Kamera entwickelt, die nur Nacktbilder macht. Eine KI entkleidet die Abgelichteten binnen Sekunden. Das Projekt ist – auch – ein kritischer Kommentar auf den besorgniserregenden Deepfake-Trend."
KI,Spiegel Online,2024-04-07,https://www.spiegel.de/partnerschaft/beziehung-sollten-paare-im-selben-bett-schlafen-a-f8fecbd0-dfd7-430d-ae4e-31d0a2165cdc,Beziehung: Sollten Paare im selben Bett schlafen? - DER SPIEGEL,"Meine Frau und ich haben getrennte Schlafzimmer. Das ist gut für unsere Beziehung, könnte aber schlecht für die Gesundheit sein."
Künstliche Intelligenz,Spiegel Online,2024-04-05,https://www.spiegel.de/karriere/tesla-elon-musk-erhoeht-gehaelter-von-ki-experten-wegen-verruecktem-kampf-um-talente-a-a93c3207-6f3d-4cd2-b345-fdee179511a4,Tesla: Elon Musk erhöht Gehälter von KI-Experten wegen »verrücktem Kampf« um Talente - DER SPIEGEL,"Die Topverdiener unter den KI-Fachleuten kassieren schon mal siebenstellige Jahresgehälter. Elon Musk sieht sich nun gezwungen, die Vergütung von KI-Spezialisten bei Tesla zu steigern – damit sie bleiben. Der Elektroautohersteller Tesla erhöht die Vergütung seiner Ingenieure für künstliche Intelligenz – damit sie nicht durch andere Unternehmen wie die ChatGPT-Entwicklerfirma OpenAI abgeworben werden. Das kündigte Firmenchef Elon Musk am späten Mittwochabend in einer Reihe von Beiträgen auf der Social-Media-Plattform X an. OpenAI versuche gerade, Tesla-Ingenieure mit »massiven Gehaltsangeboten« abzuwerben, schreibt Elon Musk. Der Wettbewerb um KI-Experten sei »der verrückteste Talentkrieg, den ich je gesehen habe«. In den Steuerunterlagen von OpenAI finden sich Jahresgehälter im mittleren bis hohen sechsstelligen Bereich für die besten Entwickler , in einem Fall wurden sogar 1,9 Millionen Dollar gezahlt. Mit seinen Posts reagierte Elon Musk auf einen Medienbericht über die Kündigung von Teslas KI-Experten Ethan Knight. »Ethan wollte zu OpenAI wechseln«, bestätigte Musk. Er habe ihn aber umstimmen können: Knight soll künftig für Musks KI-Startup X.AI arbeiten. Der jüngste KI-Boom hat den Kampf um Talente im Silicon Valley verschärft: Start-ups konkurrieren mit etablierten Technologieunternehmen um Mitarbeiterinnen und Mitarbeiter, die sich mit künstlicher Intelligenz auskennen. Im Sommer 2023 sorgte etwa Netflix für Schlagzeilen, als ein KI-Experte für ein Jahresgehalt von 300.000 bis 900.000 US-Dollar inklusive Zulagen und Boni gesucht wurde . Mitunter werden millionenschwere Vergütungspakete geboten und ganze Teams abgeworben. Die Beziehung von Elon Musk und OpenAI-Chef Sam Altman ist ohnehin angespannt: Musk hatte OpenAI einst mitgegründet, im März reichte er eine Klage gegen die Firma ein . Der Vorwurf des Milliardärs: Statt dem Gemeinwohl zu dienen, arbeite das KI-Unternehmen vor allem Microsoft zu."
Künstliche Intelligenz,Spiegel Online,2024-04-05,https://www.spiegel.de/wirtschaft/unternehmen/kuenstliche-intelligenz-siemens-zieht-top-forscher-an-a-7cf6b7d1-91d1-400b-92ff-c61c8d01265b,Künstliche Intelligenz: Siemens zieht Top-Forscher an - DER SPIEGEL,"Deutschland fällt im Werben um Experten für künstliche Intelligenz zurück? Falsch, sagt eine britische Personalberatung: Besonders deutsche Großkonzerne ziehen viele KI-Experten an. Siemens und seine Medizintechnik-Tochter Healthineers werben unter deutschen Konzernen am erfolgreichsten um Entwickler der künstlichen Intelligenz (KI). Das zeigt der Report »The State of AI Talent« der britischen Personalberatung Zeki. Für ihre Analyse nutzten die Berater einen globalen Index von KI-Experten außerhalb Chinas, der sich an der Zahl wissenschaftlicher Publikationen sowie an Auszeichnungen oder Beförderungen in Unternehmen orientiert. Endlich wieder richtig schlafen Millionen Menschen in Deutschland liegen nachts wach. Die wenigsten gehen zum Arzt, denn kaum jemand weiß, wie gefährlich Schlaflosigkeit für Körper und Psyche ist. Dabei kann neues Wissen helfen, aus dem Teufelskreis aus Erschöpfung und Ruhelosigkeit auszubrechen. Lesen Sie unsere Titelgeschichte, weitere Hintergründe und Analysen im digitalen SPIEGEL. Demnach ziehen die beiden im Dax notierten bayerischen Konzerne besonders viele renommierte KI-Fachkräfte an. Auch Bosch ist gleich zweimal unter den Top Ten der deutschen KI-Arbeitgeber vertreten, mit seinem Stammhaus und seinem Center for Artificial Intelligence. SAP dagegen, der einzige deutsche Softwarekonzern von Weltrang, zieht laut Zeki weniger KI-Talente an. Unter ihnen seien aber relativ viele exzellente Forscher. Die Schwergewichte der deutschen Industrie sind laut der Personalberatung besonders wichtig, um Deutschland einen Spitzenplatz im globalen KI-Wettlauf zu sichern. Zwei Drittel der besten KI-Talente arbeiteten hierzulande bei Großkonzernen, deutlich mehr als in anderen Ländern, wo Start-ups und mittelgroßen Firmen eine größere Rolle spielen. Insgesamt hole Deutschland im Werben um die besten Köpfe in der künstlichen Intelligenz auf. Die noch immer hohe Abwanderung von KI-Entwicklern in die USA werde inzwischen durch Zuwanderung, etwa aus Großbritannien, Frankreich oder Italien, mehr als kompensiert. Eine Branche sei aber auffällig abwesend in seinem Ranking, sagt Zeki-Chef Tom Hurd: die deutschen Banken."
Künstliche Intelligenz,Spiegel Online,2024-04-04,https://www.spiegel.de/netzwelt/netzpolitik/israel-nutzt-angeblich-ki-system-fuer-bombardements-im-gazakrieg-a-8822ca47-c7b4-46d3-b77a-69ff1f6d4f3c,Israel nutzt angeblich KI-System für Bombardements im Gazakrieg - DER SPIEGEL,"Ein KI-System namens Lavender soll Israel angeblich helfen, Palästinenser mit Verbindungen zur Hamas zu identifizieren. Geheimdienstler machen drastische Aussagen zum Einsatz, das Militär widerspricht. Künstliche Intelligenz soll »viel Zeit gespart« haben bei der Auswahl möglicher Ziele im Gazakrieg, so erzählt es ein israelischer Offizier über ein neues, bisher unbekanntes Programm. »Ich musste als Mensch nichts weiter tun, außer meinen Stempel zur Genehmigung drunterzusetzen.« Ein anderer erklärte, ein Statistikprogramm sei besser als ein trauernder Soldat, denn »jeder hier, auch ich, hat Menschen am 7. Oktober verloren. Die Maschine hat es kühl gemacht, und dadurch wurde es leichter.« Die Aussagen haben der »Guardian« sowie der Journalist Yuval Abraham im »+972 Magazine« veröffentlicht. Sie stammen von sechs namentlich nicht genannten israelischen Geheimdienstoffizieren, die nach eigenen Angaben allesamt KI-Systeme verwenden, um Hamas -Zielpersonen zu identifizieren. Lavender heißt demnach das KI-System. Es werde verwendet, um große Datenmengen schnell zu verarbeiten und potenzielle menschliche Ziele zu erkennen, in erster Linie Hamas-Kämpfer in niederen Rängen. Vier der sechs Israelis sagten demnach aus, Lavender hätte zwischenzeitlich 37.000 Palästinenser identifiziert, die Verbindungen zu Hamas oder zum Palästinensischen Islamischen Dschihad (PIJ) haben sollen. »Liefert uns mehr Zielpersonen« Entwickelt worden sei das System von der Unit 8200, Israels staatlichen Elitehackern. Es beschleunige einen früher sehr viel arbeitsaufwendigeren Prozess: die Auswahl legitimer Zielpersonen. »Liefert uns mehr Zielpersonen«, soll die Ansage der militärischen Führung gelautet haben, gaben die Quellen zu Protokoll. Um dem nachzukommen, habe man verstärkt auf Lavender gesetzt. Das System habe nach Angaben der Einheit 8200 eine Trefferquote von 90 Prozent. Lavender sei in Ergänzung zu einem anderen KI-System namens The Gospel eingesetzt worden, das Gebäude und andere Strukturen als Ziele vorschlage. Wie Lavender trainiert wurde und wie es im Detail funktioniert, geht aus den Aussagen nicht hervor. Auch ist unklar, ob die Informanten genug technisches Wissen haben, um Lavender korrekt einzuschätzen. Ihren Aussagen zufolge ging mit dem Einsatz von Lavender zu Kriegsbeginn eine Art Blankoscheck für bestimmte Anzahlen ziviler Opfer einher, die Israels Militär in Kauf genommen habe. Zwei der Quellen sagten aus, sie hätten bei Luftschlägen gegen Militante niederer Ränge zwischen 15 und 20 Zivilisten töten dürfen. Entsprechende Angriffe seien mit sogenannten dummen Bomben durchgeführt worden, die ganze Häuser zerstörten und alle Menschen darin töteten. Israels Militär widerspricht den Aussagen in Teilen Eine Quelle sagte dem Bericht zufolge: »Wenn es um Militante in niedrigen Positionen geht, willst du keine menschlichen Ressourcen oder Zeit investieren.« Man sei daher bereit, die Fehlerquote einer künstlichen Intelligenz zu akzeptieren, also »Kollateralschäden und sterbende Zivilisten«, – »und damit zu leben«. Die israelische Armee widersprach der Darstellung in Teilen . »Die IDF nutzen kein KI-System, das Terroristen identifiziert oder versucht vorherzusagen, ob eine Person ein Terrorist ist.« Die eingesetzten Systeme seien »lediglich Werkzeuge für Analysten im Zielidentifizierungsprozess«. Lavender sei auch gar kein System, sondern nur eine Datenbank für Querverweise von Geheimdienstquellen, »um aktuelle Informationen zu militärischen Operationen von Terrororganisationen zu produzieren«. Es handle sich dabei nicht um bestätigte Funktionäre, die angegriffen werden dürften. Der Einsatz »dummer Bomben« erfolge im Rahmen des internationalen Rechts und in einer Art und Weise, die »ein hohes Maß an Präzision« sicherstelle."
Künstliche Intelligenz,Spiegel Online,2024-04-03,https://www.spiegel.de/netzwelt/netzpolitik/billie-eilish-pearl-jam-katy-perry-stars-wollen-ki-musikgeneratoren-stoppen-a-e242ad38-b6f3-4774-b483-4a73230e33d5,"Billie Eilish, Pearl Jam, Katy Perry: Stars wollen KI-Musikgeneratoren stoppen - DER SPIEGEL","Mehr als 200 Musikerinnen und Bands protestieren gegen die Ausbeutung ihrer Werke durch Techkonzerne. Künstliche Intelligenz dürfe kreativ arbeitende Menschen nicht ersetzen. Mehr als 200 Künstlerinnen und Künstler haben sich in einem offenen Brief gegen den Missbrauch von künstlicher Intelligenz (KI) in der Musikindustrie ausgesprochen. Zu den Unterzeichnenden des am Dienstag (Ortszeit) veröffentlichten Briefs zählen laut der Artist Rights Alliance (ARA) unter anderem Billie Eilish, Nicki Minaj, Stevie Wonder, Peter Frampton, Katy Perry, Smokey Robinson, Jon Bon Jovi, Pearl Jam und R.E.M. Einige Plattformen und Entwickler setzten KI ein, um Kreativität zu sabotieren und Künstler, Songschreiber, Musikerinnen und Rechteinhaber zu untergraben, heißt es in dem Schreiben der ARA. Das in den USA ansässige Bündnis setzt sich für die Rechte von Songwritern und Musikern ein. Der Protest richtet sich gegen Dienste, die auf Textbefehl ganze Songs generieren können , die zudem Stil und Stimme bekannter Künstler imitieren. Bedrohung für Identität und Lebensunterhalt »Wenn KI unverantwortlich eingesetzt wird, stellt sie eine enorme Bedrohung für den Schutz unserer Privatsphäre, unserer Identität, unserer Musik und unseres Lebensunterhalts dar«, beklagen die Künstler in dem Schreiben. Einige der mächtigsten Unternehmen nutzten ohne Erlaubnis die Arbeit von Musikern, um KI-Modelle zu trainieren. Dies ziele darauf ab, die Arbeit menschlicher Künstler durch riesige Mengen von KI-erstellten »Klängen« und »Bildern« zu ersetzen. Das beeinträchtige auch die Tantiemen der Kunstschaffenden. Für berufstätige Musiker und Songschreiber, die nur versuchten, über die Runden zu kommen, könne dies katastrophal sein. Wenn sie verantwortungsvoll eingesetzt werde, habe KI ein enormes Potenzial, menschliche Kreativität zu fördern. Bei unverantwortlicher Nutzung schmälere sie aber die Arbeit der Künstlerinnen und Künstler und bedrohe deren faire Vergütung. Die 200 Stars fordern KI-Entwickler, Techunternehmen und digitale Musikdienste daher auf, sich zu verpflichten, keine Technologie zu entwickeln oder einzusetzen, die die Kunst von Musikerinnen und Songschreibern untergräbt oder ersetzt."
Künstliche Intelligenz,Spiegel Online,2024-04-03,https://www.spiegel.de/start/ki-einsatz-im-studium-bei-einigen-hochschulen-sitzt-der-colt-gerade-sehr-locker-a-3fd6066e-323d-43f5-8612-5ada4e4e39dd,KI-Einsatz im Studium: »Bei einigen Hochschulen sitzt der Colt gerade sehr locker« - DER SPIEGEL,"Die TU München lehnt einen Studenten ab, der KI für die Bewerbung genutzt haben soll – sie sei auffällig gut. Ein Anwalt sagt, ob nun jede herausragende Leistung unter KI-Verdacht steht und wie Studierende sich wehren können."
AI,Spiegel Online,2024-04-05,https://www.spiegel.de/karriere/tesla-elon-musk-erhoeht-gehaelter-von-ki-experten-wegen-verruecktem-kampf-um-talente-a-a93c3207-6f3d-4cd2-b345-fdee179511a4,Tesla: Elon Musk erhöht Gehälter von KI-Experten wegen »verrücktem Kampf« um Talente - DER SPIEGEL,"Die Topverdiener unter den KI-Fachleuten kassieren schon mal siebenstellige Jahresgehälter. Elon Musk sieht sich nun gezwungen, die Vergütung von KI-Spezialisten bei Tesla zu steigern – damit sie bleiben. Der Elektroautohersteller Tesla erhöht die Vergütung seiner Ingenieure für künstliche Intelligenz – damit sie nicht durch andere Unternehmen wie die ChatGPT-Entwicklerfirma OpenAI abgeworben werden. Das kündigte Firmenchef Elon Musk am späten Mittwochabend in einer Reihe von Beiträgen auf der Social-Media-Plattform X an. OpenAI versuche gerade, Tesla-Ingenieure mit »massiven Gehaltsangeboten« abzuwerben, schreibt Elon Musk. Der Wettbewerb um KI-Experten sei »der verrückteste Talentkrieg, den ich je gesehen habe«. In den Steuerunterlagen von OpenAI finden sich Jahresgehälter im mittleren bis hohen sechsstelligen Bereich für die besten Entwickler , in einem Fall wurden sogar 1,9 Millionen Dollar gezahlt. Mit seinen Posts reagierte Elon Musk auf einen Medienbericht über die Kündigung von Teslas KI-Experten Ethan Knight. »Ethan wollte zu OpenAI wechseln«, bestätigte Musk. Er habe ihn aber umstimmen können: Knight soll künftig für Musks KI-Startup X.AI arbeiten. Der jüngste KI-Boom hat den Kampf um Talente im Silicon Valley verschärft: Start-ups konkurrieren mit etablierten Technologieunternehmen um Mitarbeiterinnen und Mitarbeiter, die sich mit künstlicher Intelligenz auskennen. Im Sommer 2023 sorgte etwa Netflix für Schlagzeilen, als ein KI-Experte für ein Jahresgehalt von 300.000 bis 900.000 US-Dollar inklusive Zulagen und Boni gesucht wurde . Mitunter werden millionenschwere Vergütungspakete geboten und ganze Teams abgeworben. Die Beziehung von Elon Musk und OpenAI-Chef Sam Altman ist ohnehin angespannt: Musk hatte OpenAI einst mitgegründet, im März reichte er eine Klage gegen die Firma ein . Der Vorwurf des Milliardärs: Statt dem Gemeinwohl zu dienen, arbeite das KI-Unternehmen vor allem Microsoft zu."
AI,Spiegel Online,2024-04-05,https://www.spiegel.de/wirtschaft/unternehmen/kuenstliche-intelligenz-siemens-zieht-top-forscher-an-a-7cf6b7d1-91d1-400b-92ff-c61c8d01265b,Künstliche Intelligenz: Siemens zieht Top-Forscher an - DER SPIEGEL,"Deutschland fällt im Werben um Experten für künstliche Intelligenz zurück? Falsch, sagt eine britische Personalberatung: Besonders deutsche Großkonzerne ziehen viele KI-Experten an. Siemens und seine Medizintechnik-Tochter Healthineers werben unter deutschen Konzernen am erfolgreichsten um Entwickler der künstlichen Intelligenz (KI). Das zeigt der Report »The State of AI Talent« der britischen Personalberatung Zeki. Für ihre Analyse nutzten die Berater einen globalen Index von KI-Experten außerhalb Chinas, der sich an der Zahl wissenschaftlicher Publikationen sowie an Auszeichnungen oder Beförderungen in Unternehmen orientiert. Endlich wieder richtig schlafen Millionen Menschen in Deutschland liegen nachts wach. Die wenigsten gehen zum Arzt, denn kaum jemand weiß, wie gefährlich Schlaflosigkeit für Körper und Psyche ist. Dabei kann neues Wissen helfen, aus dem Teufelskreis aus Erschöpfung und Ruhelosigkeit auszubrechen. Lesen Sie unsere Titelgeschichte, weitere Hintergründe und Analysen im digitalen SPIEGEL. Demnach ziehen die beiden im Dax notierten bayerischen Konzerne besonders viele renommierte KI-Fachkräfte an. Auch Bosch ist gleich zweimal unter den Top Ten der deutschen KI-Arbeitgeber vertreten, mit seinem Stammhaus und seinem Center for Artificial Intelligence. SAP dagegen, der einzige deutsche Softwarekonzern von Weltrang, zieht laut Zeki weniger KI-Talente an. Unter ihnen seien aber relativ viele exzellente Forscher. Die Schwergewichte der deutschen Industrie sind laut der Personalberatung besonders wichtig, um Deutschland einen Spitzenplatz im globalen KI-Wettlauf zu sichern. Zwei Drittel der besten KI-Talente arbeiteten hierzulande bei Großkonzernen, deutlich mehr als in anderen Ländern, wo Start-ups und mittelgroßen Firmen eine größere Rolle spielen. Insgesamt hole Deutschland im Werben um die besten Köpfe in der künstlichen Intelligenz auf. Die noch immer hohe Abwanderung von KI-Entwicklern in die USA werde inzwischen durch Zuwanderung, etwa aus Großbritannien, Frankreich oder Italien, mehr als kompensiert. Eine Branche sei aber auffällig abwesend in seinem Ranking, sagt Zeki-Chef Tom Hurd: die deutschen Banken."
Artificial Intelligence,Spiegel Online,2024-04-05,https://www.spiegel.de/wirtschaft/unternehmen/kuenstliche-intelligenz-siemens-zieht-top-forscher-an-a-7cf6b7d1-91d1-400b-92ff-c61c8d01265b,Künstliche Intelligenz: Siemens zieht Top-Forscher an - DER SPIEGEL,"Deutschland fällt im Werben um Experten für künstliche Intelligenz zurück? Falsch, sagt eine britische Personalberatung: Besonders deutsche Großkonzerne ziehen viele KI-Experten an. Siemens und seine Medizintechnik-Tochter Healthineers werben unter deutschen Konzernen am erfolgreichsten um Entwickler der künstlichen Intelligenz (KI). Das zeigt der Report »The State of AI Talent« der britischen Personalberatung Zeki. Für ihre Analyse nutzten die Berater einen globalen Index von KI-Experten außerhalb Chinas, der sich an der Zahl wissenschaftlicher Publikationen sowie an Auszeichnungen oder Beförderungen in Unternehmen orientiert. Endlich wieder richtig schlafen Millionen Menschen in Deutschland liegen nachts wach. Die wenigsten gehen zum Arzt, denn kaum jemand weiß, wie gefährlich Schlaflosigkeit für Körper und Psyche ist. Dabei kann neues Wissen helfen, aus dem Teufelskreis aus Erschöpfung und Ruhelosigkeit auszubrechen. Lesen Sie unsere Titelgeschichte, weitere Hintergründe und Analysen im digitalen SPIEGEL. Demnach ziehen die beiden im Dax notierten bayerischen Konzerne besonders viele renommierte KI-Fachkräfte an. Auch Bosch ist gleich zweimal unter den Top Ten der deutschen KI-Arbeitgeber vertreten, mit seinem Stammhaus und seinem Center for Artificial Intelligence. SAP dagegen, der einzige deutsche Softwarekonzern von Weltrang, zieht laut Zeki weniger KI-Talente an. Unter ihnen seien aber relativ viele exzellente Forscher. Die Schwergewichte der deutschen Industrie sind laut der Personalberatung besonders wichtig, um Deutschland einen Spitzenplatz im globalen KI-Wettlauf zu sichern. Zwei Drittel der besten KI-Talente arbeiteten hierzulande bei Großkonzernen, deutlich mehr als in anderen Ländern, wo Start-ups und mittelgroßen Firmen eine größere Rolle spielen. Insgesamt hole Deutschland im Werben um die besten Köpfe in der künstlichen Intelligenz auf. Die noch immer hohe Abwanderung von KI-Entwicklern in die USA werde inzwischen durch Zuwanderung, etwa aus Großbritannien, Frankreich oder Italien, mehr als kompensiert. Eine Branche sei aber auffällig abwesend in seinem Ranking, sagt Zeki-Chef Tom Hurd: die deutschen Banken."
Artificial Intelligence,Spiegel Online,2024-04-04,https://www.spiegel.de/netzwelt/netzpolitik/israel-nutzt-angeblich-ki-system-fuer-bombardements-im-gazakrieg-a-8822ca47-c7b4-46d3-b77a-69ff1f6d4f3c,Israel nutzt angeblich KI-System für Bombardements im Gazakrieg - DER SPIEGEL,"Ein KI-System namens Lavender soll Israel angeblich helfen, Palästinenser mit Verbindungen zur Hamas zu identifizieren. Geheimdienstler machen drastische Aussagen zum Einsatz, das Militär widerspricht. Künstliche Intelligenz soll »viel Zeit gespart« haben bei der Auswahl möglicher Ziele im Gazakrieg, so erzählt es ein israelischer Offizier über ein neues, bisher unbekanntes Programm. »Ich musste als Mensch nichts weiter tun, außer meinen Stempel zur Genehmigung drunterzusetzen.« Ein anderer erklärte, ein Statistikprogramm sei besser als ein trauernder Soldat, denn »jeder hier, auch ich, hat Menschen am 7. Oktober verloren. Die Maschine hat es kühl gemacht, und dadurch wurde es leichter.« Die Aussagen haben der »Guardian« sowie der Journalist Yuval Abraham im »+972 Magazine« veröffentlicht. Sie stammen von sechs namentlich nicht genannten israelischen Geheimdienstoffizieren, die nach eigenen Angaben allesamt KI-Systeme verwenden, um Hamas -Zielpersonen zu identifizieren. Lavender heißt demnach das KI-System. Es werde verwendet, um große Datenmengen schnell zu verarbeiten und potenzielle menschliche Ziele zu erkennen, in erster Linie Hamas-Kämpfer in niederen Rängen. Vier der sechs Israelis sagten demnach aus, Lavender hätte zwischenzeitlich 37.000 Palästinenser identifiziert, die Verbindungen zu Hamas oder zum Palästinensischen Islamischen Dschihad (PIJ) haben sollen. »Liefert uns mehr Zielpersonen« Entwickelt worden sei das System von der Unit 8200, Israels staatlichen Elitehackern. Es beschleunige einen früher sehr viel arbeitsaufwendigeren Prozess: die Auswahl legitimer Zielpersonen. »Liefert uns mehr Zielpersonen«, soll die Ansage der militärischen Führung gelautet haben, gaben die Quellen zu Protokoll. Um dem nachzukommen, habe man verstärkt auf Lavender gesetzt. Das System habe nach Angaben der Einheit 8200 eine Trefferquote von 90 Prozent. Lavender sei in Ergänzung zu einem anderen KI-System namens The Gospel eingesetzt worden, das Gebäude und andere Strukturen als Ziele vorschlage. Wie Lavender trainiert wurde und wie es im Detail funktioniert, geht aus den Aussagen nicht hervor. Auch ist unklar, ob die Informanten genug technisches Wissen haben, um Lavender korrekt einzuschätzen. Ihren Aussagen zufolge ging mit dem Einsatz von Lavender zu Kriegsbeginn eine Art Blankoscheck für bestimmte Anzahlen ziviler Opfer einher, die Israels Militär in Kauf genommen habe. Zwei der Quellen sagten aus, sie hätten bei Luftschlägen gegen Militante niederer Ränge zwischen 15 und 20 Zivilisten töten dürfen. Entsprechende Angriffe seien mit sogenannten dummen Bomben durchgeführt worden, die ganze Häuser zerstörten und alle Menschen darin töteten. Israels Militär widerspricht den Aussagen in Teilen Eine Quelle sagte dem Bericht zufolge: »Wenn es um Militante in niedrigen Positionen geht, willst du keine menschlichen Ressourcen oder Zeit investieren.« Man sei daher bereit, die Fehlerquote einer künstlichen Intelligenz zu akzeptieren, also »Kollateralschäden und sterbende Zivilisten«, – »und damit zu leben«. Die israelische Armee widersprach der Darstellung in Teilen . »Die IDF nutzen kein KI-System, das Terroristen identifiziert oder versucht vorherzusagen, ob eine Person ein Terrorist ist.« Die eingesetzten Systeme seien »lediglich Werkzeuge für Analysten im Zielidentifizierungsprozess«. Lavender sei auch gar kein System, sondern nur eine Datenbank für Querverweise von Geheimdienstquellen, »um aktuelle Informationen zu militärischen Operationen von Terrororganisationen zu produzieren«. Es handle sich dabei nicht um bestätigte Funktionäre, die angegriffen werden dürften. Der Einsatz »dummer Bomben« erfolge im Rahmen des internationalen Rechts und in einer Art und Weise, die »ein hohes Maß an Präzision« sicherstelle."
KI,Spiegel Online,2024-04-05,https://www.spiegel.de/karriere/tesla-elon-musk-erhoeht-gehaelter-von-ki-experten-wegen-verruecktem-kampf-um-talente-a-a93c3207-6f3d-4cd2-b345-fdee179511a4,Tesla: Elon Musk erhöht Gehälter von KI-Experten wegen »verrücktem Kampf« um Talente - DER SPIEGEL,"Die Topverdiener unter den KI-Fachleuten kassieren schon mal siebenstellige Jahresgehälter. Elon Musk sieht sich nun gezwungen, die Vergütung von KI-Spezialisten bei Tesla zu steigern – damit sie bleiben. Der Elektroautohersteller Tesla erhöht die Vergütung seiner Ingenieure für künstliche Intelligenz – damit sie nicht durch andere Unternehmen wie die ChatGPT-Entwicklerfirma OpenAI abgeworben werden. Das kündigte Firmenchef Elon Musk am späten Mittwochabend in einer Reihe von Beiträgen auf der Social-Media-Plattform X an. OpenAI versuche gerade, Tesla-Ingenieure mit »massiven Gehaltsangeboten« abzuwerben, schreibt Elon Musk. Der Wettbewerb um KI-Experten sei »der verrückteste Talentkrieg, den ich je gesehen habe«. In den Steuerunterlagen von OpenAI finden sich Jahresgehälter im mittleren bis hohen sechsstelligen Bereich für die besten Entwickler , in einem Fall wurden sogar 1,9 Millionen Dollar gezahlt. Mit seinen Posts reagierte Elon Musk auf einen Medienbericht über die Kündigung von Teslas KI-Experten Ethan Knight. »Ethan wollte zu OpenAI wechseln«, bestätigte Musk. Er habe ihn aber umstimmen können: Knight soll künftig für Musks KI-Startup X.AI arbeiten. Der jüngste KI-Boom hat den Kampf um Talente im Silicon Valley verschärft: Start-ups konkurrieren mit etablierten Technologieunternehmen um Mitarbeiterinnen und Mitarbeiter, die sich mit künstlicher Intelligenz auskennen. Im Sommer 2023 sorgte etwa Netflix für Schlagzeilen, als ein KI-Experte für ein Jahresgehalt von 300.000 bis 900.000 US-Dollar inklusive Zulagen und Boni gesucht wurde . Mitunter werden millionenschwere Vergütungspakete geboten und ganze Teams abgeworben. Die Beziehung von Elon Musk und OpenAI-Chef Sam Altman ist ohnehin angespannt: Musk hatte OpenAI einst mitgegründet, im März reichte er eine Klage gegen die Firma ein . Der Vorwurf des Milliardärs: Statt dem Gemeinwohl zu dienen, arbeite das KI-Unternehmen vor allem Microsoft zu."
KI,Spiegel Online,2024-04-05,https://www.spiegel.de/wissenschaft/technik/ki-in-der-lebensmittelindustrie-erschafft-neue-aromen-a-00df6f37-8b52-4093-8caa-dba7c64306bf,KI in der Lebensmittelindustrie erschafft neue Aromen - DER SPIEGEL,"Künstliche Intelligenz soll der Lebensmittelindustrie helfen, wohlschmeckendere Aromen zu finden. Lassen sich die Verbraucher künftig noch leichter verführen als heute?"
KI,Spiegel Online,2024-04-05,https://www.spiegel.de/wirtschaft/unternehmen/kuenstliche-intelligenz-siemens-zieht-top-forscher-an-a-7cf6b7d1-91d1-400b-92ff-c61c8d01265b,Künstliche Intelligenz: Siemens zieht Top-Forscher an - DER SPIEGEL,"Deutschland fällt im Werben um Experten für künstliche Intelligenz zurück? Falsch, sagt eine britische Personalberatung: Besonders deutsche Großkonzerne ziehen viele KI-Experten an. Siemens und seine Medizintechnik-Tochter Healthineers werben unter deutschen Konzernen am erfolgreichsten um Entwickler der künstlichen Intelligenz (KI). Das zeigt der Report »The State of AI Talent« der britischen Personalberatung Zeki. Für ihre Analyse nutzten die Berater einen globalen Index von KI-Experten außerhalb Chinas, der sich an der Zahl wissenschaftlicher Publikationen sowie an Auszeichnungen oder Beförderungen in Unternehmen orientiert. Endlich wieder richtig schlafen Millionen Menschen in Deutschland liegen nachts wach. Die wenigsten gehen zum Arzt, denn kaum jemand weiß, wie gefährlich Schlaflosigkeit für Körper und Psyche ist. Dabei kann neues Wissen helfen, aus dem Teufelskreis aus Erschöpfung und Ruhelosigkeit auszubrechen. Lesen Sie unsere Titelgeschichte, weitere Hintergründe und Analysen im digitalen SPIEGEL. Demnach ziehen die beiden im Dax notierten bayerischen Konzerne besonders viele renommierte KI-Fachkräfte an. Auch Bosch ist gleich zweimal unter den Top Ten der deutschen KI-Arbeitgeber vertreten, mit seinem Stammhaus und seinem Center for Artificial Intelligence. SAP dagegen, der einzige deutsche Softwarekonzern von Weltrang, zieht laut Zeki weniger KI-Talente an. Unter ihnen seien aber relativ viele exzellente Forscher. Die Schwergewichte der deutschen Industrie sind laut der Personalberatung besonders wichtig, um Deutschland einen Spitzenplatz im globalen KI-Wettlauf zu sichern. Zwei Drittel der besten KI-Talente arbeiteten hierzulande bei Großkonzernen, deutlich mehr als in anderen Ländern, wo Start-ups und mittelgroßen Firmen eine größere Rolle spielen. Insgesamt hole Deutschland im Werben um die besten Köpfe in der künstlichen Intelligenz auf. Die noch immer hohe Abwanderung von KI-Entwicklern in die USA werde inzwischen durch Zuwanderung, etwa aus Großbritannien, Frankreich oder Italien, mehr als kompensiert. Eine Branche sei aber auffällig abwesend in seinem Ranking, sagt Zeki-Chef Tom Hurd: die deutschen Banken."
KI,Spiegel Online,2024-04-03,https://www.spiegel.de/netzwelt/netzpolitik/kuenstliche-intelligenz-hoert-auf-deepfakes-zu-daemonisieren-kolumne-a-b1ec6319-de4d-45ec-b711-df3364b44068,KI: Warum hinter Deepfakes etwas Sinnvolles steckt - Kolumne - DER SPIEGEL,"Sich zuallererst und fast ausschließlich auf die schlimmsten Auswüchse einer neuen Technologie zu stürzen, ist eine sehr deutsche Art der Debatte. KI-generierte Bilder und Stimmen etwa werden zu Unrecht verteufelt."
KI,Spiegel Online,2024-04-04,https://www.spiegel.de/netzwelt/netzpolitik/israel-nutzt-angeblich-ki-system-fuer-bombardements-im-gazakrieg-a-8822ca47-c7b4-46d3-b77a-69ff1f6d4f3c,Israel nutzt angeblich KI-System für Bombardements im Gazakrieg - DER SPIEGEL,"Ein KI-System namens Lavender soll Israel angeblich helfen, Palästinenser mit Verbindungen zur Hamas zu identifizieren. Geheimdienstler machen drastische Aussagen zum Einsatz, das Militär widerspricht. Künstliche Intelligenz soll »viel Zeit gespart« haben bei der Auswahl möglicher Ziele im Gazakrieg, so erzählt es ein israelischer Offizier über ein neues, bisher unbekanntes Programm. »Ich musste als Mensch nichts weiter tun, außer meinen Stempel zur Genehmigung drunterzusetzen.« Ein anderer erklärte, ein Statistikprogramm sei besser als ein trauernder Soldat, denn »jeder hier, auch ich, hat Menschen am 7. Oktober verloren. Die Maschine hat es kühl gemacht, und dadurch wurde es leichter.« Die Aussagen haben der »Guardian« sowie der Journalist Yuval Abraham im »+972 Magazine« veröffentlicht. Sie stammen von sechs namentlich nicht genannten israelischen Geheimdienstoffizieren, die nach eigenen Angaben allesamt KI-Systeme verwenden, um Hamas -Zielpersonen zu identifizieren. Lavender heißt demnach das KI-System. Es werde verwendet, um große Datenmengen schnell zu verarbeiten und potenzielle menschliche Ziele zu erkennen, in erster Linie Hamas-Kämpfer in niederen Rängen. Vier der sechs Israelis sagten demnach aus, Lavender hätte zwischenzeitlich 37.000 Palästinenser identifiziert, die Verbindungen zu Hamas oder zum Palästinensischen Islamischen Dschihad (PIJ) haben sollen. »Liefert uns mehr Zielpersonen« Entwickelt worden sei das System von der Unit 8200, Israels staatlichen Elitehackern. Es beschleunige einen früher sehr viel arbeitsaufwendigeren Prozess: die Auswahl legitimer Zielpersonen. »Liefert uns mehr Zielpersonen«, soll die Ansage der militärischen Führung gelautet haben, gaben die Quellen zu Protokoll. Um dem nachzukommen, habe man verstärkt auf Lavender gesetzt. Das System habe nach Angaben der Einheit 8200 eine Trefferquote von 90 Prozent. Lavender sei in Ergänzung zu einem anderen KI-System namens The Gospel eingesetzt worden, das Gebäude und andere Strukturen als Ziele vorschlage. Wie Lavender trainiert wurde und wie es im Detail funktioniert, geht aus den Aussagen nicht hervor. Auch ist unklar, ob die Informanten genug technisches Wissen haben, um Lavender korrekt einzuschätzen. Ihren Aussagen zufolge ging mit dem Einsatz von Lavender zu Kriegsbeginn eine Art Blankoscheck für bestimmte Anzahlen ziviler Opfer einher, die Israels Militär in Kauf genommen habe. Zwei der Quellen sagten aus, sie hätten bei Luftschlägen gegen Militante niederer Ränge zwischen 15 und 20 Zivilisten töten dürfen. Entsprechende Angriffe seien mit sogenannten dummen Bomben durchgeführt worden, die ganze Häuser zerstörten und alle Menschen darin töteten. Israels Militär widerspricht den Aussagen in Teilen Eine Quelle sagte dem Bericht zufolge: »Wenn es um Militante in niedrigen Positionen geht, willst du keine menschlichen Ressourcen oder Zeit investieren.« Man sei daher bereit, die Fehlerquote einer künstlichen Intelligenz zu akzeptieren, also »Kollateralschäden und sterbende Zivilisten«, – »und damit zu leben«. Die israelische Armee widersprach der Darstellung in Teilen . »Die IDF nutzen kein KI-System, das Terroristen identifiziert oder versucht vorherzusagen, ob eine Person ein Terrorist ist.« Die eingesetzten Systeme seien »lediglich Werkzeuge für Analysten im Zielidentifizierungsprozess«. Lavender sei auch gar kein System, sondern nur eine Datenbank für Querverweise von Geheimdienstquellen, »um aktuelle Informationen zu militärischen Operationen von Terrororganisationen zu produzieren«. Es handle sich dabei nicht um bestätigte Funktionäre, die angegriffen werden dürften. Der Einsatz »dummer Bomben« erfolge im Rahmen des internationalen Rechts und in einer Art und Weise, die »ein hohes Maß an Präzision« sicherstelle."
KI,Spiegel Online,2024-04-03,https://www.spiegel.de/netzwelt/netzpolitik/billie-eilish-pearl-jam-katy-perry-stars-wollen-ki-musikgeneratoren-stoppen-a-e242ad38-b6f3-4774-b483-4a73230e33d5,"Billie Eilish, Pearl Jam, Katy Perry: Stars wollen KI-Musikgeneratoren stoppen - DER SPIEGEL","Mehr als 200 Musikerinnen und Bands protestieren gegen die Ausbeutung ihrer Werke durch Techkonzerne. Künstliche Intelligenz dürfe kreativ arbeitende Menschen nicht ersetzen. Mehr als 200 Künstlerinnen und Künstler haben sich in einem offenen Brief gegen den Missbrauch von künstlicher Intelligenz (KI) in der Musikindustrie ausgesprochen. Zu den Unterzeichnenden des am Dienstag (Ortszeit) veröffentlichten Briefs zählen laut der Artist Rights Alliance (ARA) unter anderem Billie Eilish, Nicki Minaj, Stevie Wonder, Peter Frampton, Katy Perry, Smokey Robinson, Jon Bon Jovi, Pearl Jam und R.E.M. Einige Plattformen und Entwickler setzten KI ein, um Kreativität zu sabotieren und Künstler, Songschreiber, Musikerinnen und Rechteinhaber zu untergraben, heißt es in dem Schreiben der ARA. Das in den USA ansässige Bündnis setzt sich für die Rechte von Songwritern und Musikern ein. Der Protest richtet sich gegen Dienste, die auf Textbefehl ganze Songs generieren können , die zudem Stil und Stimme bekannter Künstler imitieren. Bedrohung für Identität und Lebensunterhalt »Wenn KI unverantwortlich eingesetzt wird, stellt sie eine enorme Bedrohung für den Schutz unserer Privatsphäre, unserer Identität, unserer Musik und unseres Lebensunterhalts dar«, beklagen die Künstler in dem Schreiben. Einige der mächtigsten Unternehmen nutzten ohne Erlaubnis die Arbeit von Musikern, um KI-Modelle zu trainieren. Dies ziele darauf ab, die Arbeit menschlicher Künstler durch riesige Mengen von KI-erstellten »Klängen« und »Bildern« zu ersetzen. Das beeinträchtige auch die Tantiemen der Kunstschaffenden. Für berufstätige Musiker und Songschreiber, die nur versuchten, über die Runden zu kommen, könne dies katastrophal sein. Wenn sie verantwortungsvoll eingesetzt werde, habe KI ein enormes Potenzial, menschliche Kreativität zu fördern. Bei unverantwortlicher Nutzung schmälere sie aber die Arbeit der Künstlerinnen und Künstler und bedrohe deren faire Vergütung. Die 200 Stars fordern KI-Entwickler, Techunternehmen und digitale Musikdienste daher auf, sich zu verpflichten, keine Technologie zu entwickeln oder einzusetzen, die die Kunst von Musikerinnen und Songschreibern untergräbt oder ersetzt."
KI,Spiegel Online,2024-04-03,https://www.spiegel.de/start/ki-einsatz-im-studium-bei-einigen-hochschulen-sitzt-der-colt-gerade-sehr-locker-a-3fd6066e-323d-43f5-8612-5ada4e4e39dd,KI-Einsatz im Studium: »Bei einigen Hochschulen sitzt der Colt gerade sehr locker« - DER SPIEGEL,"Die TU München lehnt einen Studenten ab, der KI für die Bewerbung genutzt haben soll – sie sei auffällig gut. Ein Anwalt sagt, ob nun jede herausragende Leistung unter KI-Verdacht steht und wie Studierende sich wehren können."
Künstliche Intelligenz,Spiegel Online,2024-04-02,https://www.spiegel.de/karriere/kuenstliche-intelligenz-im-arbeitsmarkt-wie-julia-sich-krisensicher-aufstellen-kann-a-2690774f-b866-4310-875b-75cd7f6f1a93,Künstliche Intelligenz im Arbeitsmarkt: Wie Julia sich krisensicher aufstellen kann - DER SPIEGEL,"Julia arbeitet im Controlling und macht sich große Sorgen: Wird künstliche Intelligenz auf lange Sicht ihren Job überflüssig machen? Die Karrierecoachin hat einige Ideen, wie Julia sich krisensicher aufstellen kann. Julia, 39 Jahre, fragt: »Ich arbeite nach einem BWL-Studium seit einigen Jahren im Controlling. Es vergeht kein Tag, an dem ich nicht etwas über das Thema künstliche Intelligenz höre. Oft heißt es, die KI werde in den kommenden Jahren zu einem großen Jobkiller. Ich mache mir Sorgen, dass auch meine Stelle davon betroffen sein könnte. Wie gehe ich am besten mit diesen Entwicklungen um und was kann ich selbst tun?« Petra Cockrell ist selbstständige Jobprofilerin mit den Schwerpunkten Bewerbung, Karriereentwicklung und Mitarbeitergewinnung. Sie arbeitete viele Jahre in Führungspositionen internationaler Unternehmen. Liebe Julia, ich gebe Ihnen recht: Das Thema künstliche Intelligenz (KI) ist gerade gefühlt überall. Es wirkt auf uns eher bedrohlich, weil die möglichen negativen Auswirkungen die Nachrichten beherrschen. Das zahlt auf den Negativitätseffekt (»negativity bias«) ein, der unsere innere Einstellung beeinflusst: Negatives nehmen wir stärker wahr als Positives. Dass KI ein weites, komplexes Feld ist, das man als Laie kaum versteht, verstärkt noch das Bauchgrummeln. So, und wie kommen wir jetzt weiter zum Thema »Zukunftsfähigkeit meines Jobs«? Da helfen nur Fakten: das haben sich auch die Fachleute des Instituts für Arbeitsmarkt- und Berufsforschung (IAB) gedacht und den Job-Futuromat entwickelt. Hier kann man einen Beruf eingeben und bekommt eine genaue Analyse, wie stark dieser vom technologischen Wandel betroffen ist. Hier werden keine pauschalen Aussagen getroffen, sondern verschiedene Teilbereiche der Tätigkeit gezeigt, die man dann mit Schiebereglern auf die eigene Situation anpassen kann. Arbeitsrecht, Coaching, aktuelle Nachrichten und menschliche Geschichten: So verpassen Sie keine Artikel aus dem Bereich Job & Karriere des SPIEGEL. Dabei fällt am Beispiel Controller sofort auf: Manche Bereiche sind vorab schon als »nicht automatisierbar« gekennzeichnet. Und wer mit den Reglern ein wenig hin- und herspielt, wird sehen, dass sich der Automatisierungsgrad durch manche Tätigkeiten vergrößert – und durch andere kleiner wird. Das sind schon gute Hinweise, wo man selbst Einfluss nehmen könnte. Der Job-Futuromat informiert auch über Technologien, die den Job verändern können und gibt Anregungen für passende Weiterbildungen. Weiterbildung und damit lebenslanges Lernen sind zentral, um als Arbeitnehmer über die nächsten Jahre und Jahrzehnte für den Arbeitsmarkt interessant zu bleiben. Damit das funktioniert, braucht man die Fähigkeit zum eigenständigen Lernen, Interesse an arbeitsplatzrelevanten Weiterbildungsthemen und vor allem die Bereitschaft, Zeit in Seminare, Lehrgänge und berufsbegleitende Studiengänge zu investieren. Die Pandemie hat auch bei den betrieblichen Weiterbildungen unschöne Spuren hinterlassen: in hessischen Betrieben etwa lag laut IAB Betriebspanel die Weiterbildungsquote 2019 bei 51 Prozent, sackte dann im Coronajahr 2020 auf 32 Prozent ab und erholte sich im 1. Halbjahr 2022 auf 38 Prozent. Dabei fällt der Anstieg für Mitarbeiter mit Berufs- und Hochschulabschluss in qualifizierten Tätigkeiten um 10 Prozent höher aus als der für einfache Tätigkeiten. Ein klares Indiz für Fachkräftesicherung. Weiterbildungen richten sich natürlich an den betriebsinternen Bedarfen aus. Die Einführung oder Umstellung digitaler Geschäftsprozesse steht mit 31 Prozent ganz oben auf der »To-do-Liste« hessischer Unternehmen. An zweiter Stelle finden sich mit 16 Prozent die digitalen Vertriebswege. Grundsätzlich sind die Arbeitnehmer klar im Vorteil, die sich selbst um die Aktualisierung ihres Wissens und passende Weiterbildungen kümmern. Die »Was wird gebraucht?«-Frage kann man sehr gut im Jahresgespräch mit dem Vorgesetzten klären. Unabhängig vom Arbeitgeber ist die Recherche in aktuellen Stellenanzeigen zu empfehlen. Dort steht genau, welche Kenntnisse vom Markt gefordert werden und was für den nächsten Karriereschritt gebraucht wird. Nun zum Thema Geld: Wenn Sie sich in Ihrer Freizeit mit Jobbezug weiterbilden wollen, bezuschussen Unternehmen häufig die Seminar- oder Studiengebühren. Bei höheren Kosten und längerer Fortbildungsdauer kann auch ein Fortbildungsvertrag abgeschlossen werden. Dieser regelt dann auch zeitliche Freistellungen und eine mögliche Rückzahlung der Kosten im Kündigungsfall. Ein gutes Mittel, die eigene Haushaltskasse zu schonen und sich intern für den besser bezahlten Job zu empfehlen. Tipp: Selbst bezahlte Weiterbildungskosten sind steuerlich absetzbar! Alle Bundesländer – außer Bayern und Sachsen – gewähren Arbeitnehmern einen gesetzlichen, meist jährlich fünftägigen Anspruch auf Bildungsurlaub. Da kann man sich in ein neues Thema vertiefen, und es bleibt trotzdem noch genug Zeit für den Erholungsurlaub. Für den kleinen Geldbeutel und das begrenzte Zeitbudget bieten die Volkshochschulen interessante berufsrelevante Kurse an. Auch dort kann man sich ganz offiziell etwa zum Projektmanager zertifizieren lassen oder eine Einführung in KI oder Machine Learning machen. Fazit: Jeder Weiterbildungsnachweis ist ein kleiner Goldklumpen in Ihrem Lebenslauf. So können Sie als Bewerberin Ihre Lernbereitschaft und Ihr Engagement mit aktuellem Wissen darstellen und Ihre eigene berufliche Zukunft sichern. Die Angst vor dem technologischen Fortschritt, der Sie nachts um den Schlaf bringt, ist dann Schnee von gestern."
Artificial Intelligence,Spiegel Online,2024-04-02,https://www.spiegel.de/karriere/kuenstliche-intelligenz-im-arbeitsmarkt-wie-julia-sich-krisensicher-aufstellen-kann-a-2690774f-b866-4310-875b-75cd7f6f1a93,Künstliche Intelligenz im Arbeitsmarkt: Wie Julia sich krisensicher aufstellen kann - DER SPIEGEL,"Julia arbeitet im Controlling und macht sich große Sorgen: Wird künstliche Intelligenz auf lange Sicht ihren Job überflüssig machen? Die Karrierecoachin hat einige Ideen, wie Julia sich krisensicher aufstellen kann. Julia, 39 Jahre, fragt: »Ich arbeite nach einem BWL-Studium seit einigen Jahren im Controlling. Es vergeht kein Tag, an dem ich nicht etwas über das Thema künstliche Intelligenz höre. Oft heißt es, die KI werde in den kommenden Jahren zu einem großen Jobkiller. Ich mache mir Sorgen, dass auch meine Stelle davon betroffen sein könnte. Wie gehe ich am besten mit diesen Entwicklungen um und was kann ich selbst tun?« Petra Cockrell ist selbstständige Jobprofilerin mit den Schwerpunkten Bewerbung, Karriereentwicklung und Mitarbeitergewinnung. Sie arbeitete viele Jahre in Führungspositionen internationaler Unternehmen. Liebe Julia, ich gebe Ihnen recht: Das Thema künstliche Intelligenz (KI) ist gerade gefühlt überall. Es wirkt auf uns eher bedrohlich, weil die möglichen negativen Auswirkungen die Nachrichten beherrschen. Das zahlt auf den Negativitätseffekt (»negativity bias«) ein, der unsere innere Einstellung beeinflusst: Negatives nehmen wir stärker wahr als Positives. Dass KI ein weites, komplexes Feld ist, das man als Laie kaum versteht, verstärkt noch das Bauchgrummeln. So, und wie kommen wir jetzt weiter zum Thema »Zukunftsfähigkeit meines Jobs«? Da helfen nur Fakten: das haben sich auch die Fachleute des Instituts für Arbeitsmarkt- und Berufsforschung (IAB) gedacht und den Job-Futuromat entwickelt. Hier kann man einen Beruf eingeben und bekommt eine genaue Analyse, wie stark dieser vom technologischen Wandel betroffen ist. Hier werden keine pauschalen Aussagen getroffen, sondern verschiedene Teilbereiche der Tätigkeit gezeigt, die man dann mit Schiebereglern auf die eigene Situation anpassen kann. Arbeitsrecht, Coaching, aktuelle Nachrichten und menschliche Geschichten: So verpassen Sie keine Artikel aus dem Bereich Job & Karriere des SPIEGEL. Dabei fällt am Beispiel Controller sofort auf: Manche Bereiche sind vorab schon als »nicht automatisierbar« gekennzeichnet. Und wer mit den Reglern ein wenig hin- und herspielt, wird sehen, dass sich der Automatisierungsgrad durch manche Tätigkeiten vergrößert – und durch andere kleiner wird. Das sind schon gute Hinweise, wo man selbst Einfluss nehmen könnte. Der Job-Futuromat informiert auch über Technologien, die den Job verändern können und gibt Anregungen für passende Weiterbildungen. Weiterbildung und damit lebenslanges Lernen sind zentral, um als Arbeitnehmer über die nächsten Jahre und Jahrzehnte für den Arbeitsmarkt interessant zu bleiben. Damit das funktioniert, braucht man die Fähigkeit zum eigenständigen Lernen, Interesse an arbeitsplatzrelevanten Weiterbildungsthemen und vor allem die Bereitschaft, Zeit in Seminare, Lehrgänge und berufsbegleitende Studiengänge zu investieren. Die Pandemie hat auch bei den betrieblichen Weiterbildungen unschöne Spuren hinterlassen: in hessischen Betrieben etwa lag laut IAB Betriebspanel die Weiterbildungsquote 2019 bei 51 Prozent, sackte dann im Coronajahr 2020 auf 32 Prozent ab und erholte sich im 1. Halbjahr 2022 auf 38 Prozent. Dabei fällt der Anstieg für Mitarbeiter mit Berufs- und Hochschulabschluss in qualifizierten Tätigkeiten um 10 Prozent höher aus als der für einfache Tätigkeiten. Ein klares Indiz für Fachkräftesicherung. Weiterbildungen richten sich natürlich an den betriebsinternen Bedarfen aus. Die Einführung oder Umstellung digitaler Geschäftsprozesse steht mit 31 Prozent ganz oben auf der »To-do-Liste« hessischer Unternehmen. An zweiter Stelle finden sich mit 16 Prozent die digitalen Vertriebswege. Grundsätzlich sind die Arbeitnehmer klar im Vorteil, die sich selbst um die Aktualisierung ihres Wissens und passende Weiterbildungen kümmern. Die »Was wird gebraucht?«-Frage kann man sehr gut im Jahresgespräch mit dem Vorgesetzten klären. Unabhängig vom Arbeitgeber ist die Recherche in aktuellen Stellenanzeigen zu empfehlen. Dort steht genau, welche Kenntnisse vom Markt gefordert werden und was für den nächsten Karriereschritt gebraucht wird. Nun zum Thema Geld: Wenn Sie sich in Ihrer Freizeit mit Jobbezug weiterbilden wollen, bezuschussen Unternehmen häufig die Seminar- oder Studiengebühren. Bei höheren Kosten und längerer Fortbildungsdauer kann auch ein Fortbildungsvertrag abgeschlossen werden. Dieser regelt dann auch zeitliche Freistellungen und eine mögliche Rückzahlung der Kosten im Kündigungsfall. Ein gutes Mittel, die eigene Haushaltskasse zu schonen und sich intern für den besser bezahlten Job zu empfehlen. Tipp: Selbst bezahlte Weiterbildungskosten sind steuerlich absetzbar! Alle Bundesländer – außer Bayern und Sachsen – gewähren Arbeitnehmern einen gesetzlichen, meist jährlich fünftägigen Anspruch auf Bildungsurlaub. Da kann man sich in ein neues Thema vertiefen, und es bleibt trotzdem noch genug Zeit für den Erholungsurlaub. Für den kleinen Geldbeutel und das begrenzte Zeitbudget bieten die Volkshochschulen interessante berufsrelevante Kurse an. Auch dort kann man sich ganz offiziell etwa zum Projektmanager zertifizieren lassen oder eine Einführung in KI oder Machine Learning machen. Fazit: Jeder Weiterbildungsnachweis ist ein kleiner Goldklumpen in Ihrem Lebenslauf. So können Sie als Bewerberin Ihre Lernbereitschaft und Ihr Engagement mit aktuellem Wissen darstellen und Ihre eigene berufliche Zukunft sichern. Die Angst vor dem technologischen Fortschritt, der Sie nachts um den Schlaf bringt, ist dann Schnee von gestern."
KI,Spiegel Online,2024-04-02,https://www.spiegel.de/karriere/kuenstliche-intelligenz-im-arbeitsmarkt-wie-julia-sich-krisensicher-aufstellen-kann-a-2690774f-b866-4310-875b-75cd7f6f1a93,Künstliche Intelligenz im Arbeitsmarkt: Wie Julia sich krisensicher aufstellen kann - DER SPIEGEL,"Julia arbeitet im Controlling und macht sich große Sorgen: Wird künstliche Intelligenz auf lange Sicht ihren Job überflüssig machen? Die Karrierecoachin hat einige Ideen, wie Julia sich krisensicher aufstellen kann. Julia, 39 Jahre, fragt: »Ich arbeite nach einem BWL-Studium seit einigen Jahren im Controlling. Es vergeht kein Tag, an dem ich nicht etwas über das Thema künstliche Intelligenz höre. Oft heißt es, die KI werde in den kommenden Jahren zu einem großen Jobkiller. Ich mache mir Sorgen, dass auch meine Stelle davon betroffen sein könnte. Wie gehe ich am besten mit diesen Entwicklungen um und was kann ich selbst tun?« Petra Cockrell ist selbstständige Jobprofilerin mit den Schwerpunkten Bewerbung, Karriereentwicklung und Mitarbeitergewinnung. Sie arbeitete viele Jahre in Führungspositionen internationaler Unternehmen. Liebe Julia, ich gebe Ihnen recht: Das Thema künstliche Intelligenz (KI) ist gerade gefühlt überall. Es wirkt auf uns eher bedrohlich, weil die möglichen negativen Auswirkungen die Nachrichten beherrschen. Das zahlt auf den Negativitätseffekt (»negativity bias«) ein, der unsere innere Einstellung beeinflusst: Negatives nehmen wir stärker wahr als Positives. Dass KI ein weites, komplexes Feld ist, das man als Laie kaum versteht, verstärkt noch das Bauchgrummeln. So, und wie kommen wir jetzt weiter zum Thema »Zukunftsfähigkeit meines Jobs«? Da helfen nur Fakten: das haben sich auch die Fachleute des Instituts für Arbeitsmarkt- und Berufsforschung (IAB) gedacht und den Job-Futuromat entwickelt. Hier kann man einen Beruf eingeben und bekommt eine genaue Analyse, wie stark dieser vom technologischen Wandel betroffen ist. Hier werden keine pauschalen Aussagen getroffen, sondern verschiedene Teilbereiche der Tätigkeit gezeigt, die man dann mit Schiebereglern auf die eigene Situation anpassen kann. Arbeitsrecht, Coaching, aktuelle Nachrichten und menschliche Geschichten: So verpassen Sie keine Artikel aus dem Bereich Job & Karriere des SPIEGEL. Dabei fällt am Beispiel Controller sofort auf: Manche Bereiche sind vorab schon als »nicht automatisierbar« gekennzeichnet. Und wer mit den Reglern ein wenig hin- und herspielt, wird sehen, dass sich der Automatisierungsgrad durch manche Tätigkeiten vergrößert – und durch andere kleiner wird. Das sind schon gute Hinweise, wo man selbst Einfluss nehmen könnte. Der Job-Futuromat informiert auch über Technologien, die den Job verändern können und gibt Anregungen für passende Weiterbildungen. Weiterbildung und damit lebenslanges Lernen sind zentral, um als Arbeitnehmer über die nächsten Jahre und Jahrzehnte für den Arbeitsmarkt interessant zu bleiben. Damit das funktioniert, braucht man die Fähigkeit zum eigenständigen Lernen, Interesse an arbeitsplatzrelevanten Weiterbildungsthemen und vor allem die Bereitschaft, Zeit in Seminare, Lehrgänge und berufsbegleitende Studiengänge zu investieren. Die Pandemie hat auch bei den betrieblichen Weiterbildungen unschöne Spuren hinterlassen: in hessischen Betrieben etwa lag laut IAB Betriebspanel die Weiterbildungsquote 2019 bei 51 Prozent, sackte dann im Coronajahr 2020 auf 32 Prozent ab und erholte sich im 1. Halbjahr 2022 auf 38 Prozent. Dabei fällt der Anstieg für Mitarbeiter mit Berufs- und Hochschulabschluss in qualifizierten Tätigkeiten um 10 Prozent höher aus als der für einfache Tätigkeiten. Ein klares Indiz für Fachkräftesicherung. Weiterbildungen richten sich natürlich an den betriebsinternen Bedarfen aus. Die Einführung oder Umstellung digitaler Geschäftsprozesse steht mit 31 Prozent ganz oben auf der »To-do-Liste« hessischer Unternehmen. An zweiter Stelle finden sich mit 16 Prozent die digitalen Vertriebswege. Grundsätzlich sind die Arbeitnehmer klar im Vorteil, die sich selbst um die Aktualisierung ihres Wissens und passende Weiterbildungen kümmern. Die »Was wird gebraucht?«-Frage kann man sehr gut im Jahresgespräch mit dem Vorgesetzten klären. Unabhängig vom Arbeitgeber ist die Recherche in aktuellen Stellenanzeigen zu empfehlen. Dort steht genau, welche Kenntnisse vom Markt gefordert werden und was für den nächsten Karriereschritt gebraucht wird. Nun zum Thema Geld: Wenn Sie sich in Ihrer Freizeit mit Jobbezug weiterbilden wollen, bezuschussen Unternehmen häufig die Seminar- oder Studiengebühren. Bei höheren Kosten und längerer Fortbildungsdauer kann auch ein Fortbildungsvertrag abgeschlossen werden. Dieser regelt dann auch zeitliche Freistellungen und eine mögliche Rückzahlung der Kosten im Kündigungsfall. Ein gutes Mittel, die eigene Haushaltskasse zu schonen und sich intern für den besser bezahlten Job zu empfehlen. Tipp: Selbst bezahlte Weiterbildungskosten sind steuerlich absetzbar! Alle Bundesländer – außer Bayern und Sachsen – gewähren Arbeitnehmern einen gesetzlichen, meist jährlich fünftägigen Anspruch auf Bildungsurlaub. Da kann man sich in ein neues Thema vertiefen, und es bleibt trotzdem noch genug Zeit für den Erholungsurlaub. Für den kleinen Geldbeutel und das begrenzte Zeitbudget bieten die Volkshochschulen interessante berufsrelevante Kurse an. Auch dort kann man sich ganz offiziell etwa zum Projektmanager zertifizieren lassen oder eine Einführung in KI oder Machine Learning machen. Fazit: Jeder Weiterbildungsnachweis ist ein kleiner Goldklumpen in Ihrem Lebenslauf. So können Sie als Bewerberin Ihre Lernbereitschaft und Ihr Engagement mit aktuellem Wissen darstellen und Ihre eigene berufliche Zukunft sichern. Die Angst vor dem technologischen Fortschritt, der Sie nachts um den Schlaf bringt, ist dann Schnee von gestern."
Künstliche Intelligenz,Spiegel Online,2024-03-27,https://www.spiegel.de/netzwelt/apps/kuenstliche-intelligenz-databricks-stellt-eigenes-sprachmodell-vor-a-00cea80f-af64-4ed1-a163-fcffd19eb4ec,Künstliche Intelligenz: Databricks stellt eigenes Sprachmodell vor - DER SPIEGEL,"Ein Softwarekonzern aus San Francisco will mit einem kostenlosen KI-Textgenerator die Konkurrenz in Sachen Kosten ausstechen. Abgesehen hat man es besonders auf mittelständische Unternehmen. Ein Frühlingsabend in San Francisco. Im Restaurant »Foreign Cinema« ist der Tisch reich gedeckt. Es gibt Wagyu-Rind und Fisch, dazu die »allerneueste, allerschnellste« Open-Source-KI, sagt Ali Ghodsi, Chef des Softwareunternehmens Databricks, das zu dem Termin geladen hat. Die Firma ist schon bisher auf die Verwaltung und Auswertung großer Datenmengen spezialisiert. Zusammen mit dem Start-up Mosaic hat Databricks eine eigene künstliche Intelligenz entwickelt. Zehn Millionen Dollar habe man investiert, allein das Training habe zwei Monate gedauert, sagt Ghodsi. Herausgekommen ist das Sprachmodell DBRX, welches ab diesem Mittwoch verfügbar ist. Ein nicht gerade eingängiger Name, aber um Popularität bei den Massen geht es Ghodsi auch nicht. »DBRX ist kein Spielzeug, sondern ein Werkzeug für Unternehmen, um effizienter zu arbeiten«, sagt er. Nicht die besten Ergebnisse, aber geringe Kosten Um das zu beweisen, wirft der Databricks-CEO Grafiken an die Wand. Demnach schneidet Databricks LLM nach nahezu allen Standard-Benchmarks besser ab, als die verfügbaren Open Source-Modelle der Konkurrenz. Selbst ChatGPT von OpenAI benötige für fast alle Aufgaben länger als DBRX, ruft Ghosdi. Allerdings gilt das nur für die Version 3.5. Das populäre ChatGPT 4 ist DBRX in Sachen Tempo und Leistung weiterhin voraus. Bei den Kosten allerdings nicht, sagt Ghodsi. DBRX spare Rechenpower und damit Geld. Insgesamt sei man doppelt so effizient wie die Konkurrenz – »also nur halb so teuer«, ruft Ghodsi. Schließlich sei DBRX’ Quellcode Open-Source, also frei verfügbar. Jedes Unternehmen könne ihn kostenlos herunterladen und an seine Bedürfnisse anpassen. Databricks verdiene lediglich über Services oder die Rechenleistung mit, die Unternehmen bei ihm einkauften. Mittelstand für KI begeistern Um in den eng umkämpften Markt Fuß zu fassen, hat Databricks wichtige Verbindungen geknüpft. Zu den Investoren und Partnern von Databricks gehört Nvidia. Der Hersteller hat mit seinen Spezial-Chips bisher fast im Alleingang die neue KI-Industrie ausgerüstet. Aber es gibt auch reichlich Konkurrenz für KI-Anwendungen. So arbeitet Microsoft daran, seine Milliardeninvestitionen in Umsätze zu verwandeln, Mittelstandsausrüster wie SAP investieren ebenfalls stark in das KI-Geschäft. Dazu kommen Start-ups, die – wie Databricks – mit frei verfügbaren Tools werben. Sie alle haben es auf die vielen traditionsreichen Firmen hierzulande abgesehen. Diese verfügen über jede Menge historischer und damit wertvoller Daten, mit denen man eine KI trainieren könnte. Bislang gibt es jedoch vielerorts Vorbehalte, diese Daten mit großen US-Unternehmen zu teilen. Open-Source-Modelle könnten hier ein Ausweg sein. Das Interesse aus Europa, heißt es intern, sei enorm. Schon bald, ist man in San Francisco überzeugt, werde sich die Leistungsfähigkeit der gängigen KI-Sprachmodelle immer weiter annähern. Dann gehe es vor allem um die Daten, mit denen die Sprachmodelle »gefüttert« würden. Sie machten künftig den Unterschied zwischen einer guten und einer schlechten KI. Allerdings, räumt Ghodsi ein, müsse dazu schon ein gewisses Programmier-Know-How im Unternehmen vorhanden sein. Ganz ohne Vorkenntnisse sei ein eigenes KI-Sprachmodell nicht aufzubauen. »Aber es ist auch keine Raketenwissenschaft.« Na immerhin."
Künstliche Intelligenz,Spiegel Online,2024-03-26,https://www.spiegel.de/netzwelt/web/laion-5b-so-entsteht-das-weltbild-einer-kuenstlichen-intelligenz-a-dea0157b-d364-4622-8d77-3a1cb6c4afd1,LAION 5B: So entsteht das Weltbild einer künstlichen Intelligenz - DER SPIEGEL,"Mit welchen Bildern lernt eine KI, woher stammen sie? Wer entscheidet, ob sie geeignet sind? Forscher haben einen der größten Trainingsdatensätze untersucht. Wir machen ihre Erkenntnisse verständlich."
Künstliche Intelligenz,Spiegel Online,2024-03-26,https://www.spiegel.de/netzwelt/web/prinzessin-kate-und-die-verschwoerungstheorien-ein-lichtblick-inmitten-der-katespiracy-a-de568224-941b-4cf3-8414-c8c90d0cfe4e,Prinzessin Kate und die Verschwörungstheorien: Ein Lichtblick inmitten der Katespiracy - DER SPIEGEL,Selbst ernannte Spurensucher verbreiteten monatelang Verschwörungstheorien über den Verbleib von Prinzessin Kate. Trotz der Krebsdiagnose spinnen sie die »Katespiracy« weiter. Aber es gibt einen Lichtblick.
Künstliche Intelligenz,Spiegel Online,2024-03-26,https://www.spiegel.de/start/ki-im-berufsleben-mehrheit-der-studierenden-erwartet-dass-ki-ihr-berufsleben-erleichtert-a-289d087a-531d-4273-852e-907d1a1a9181,"KI im Berufsleben: Mehrheit der Studierenden erwartet, dass KI ihr Berufsleben erleichtert - DER SPIEGEL","Bessere Work-Life-Balance, weniger Fehler: Fragt man Studierende, bietet künstliche Intelligenz vor allem Chancen für die Arbeitswelt. Die Mehrheit nutzt KI-Hilfsmittel laut einer neuen Umfrage schon heute. Ein großer Teil der Studierenden in Deutschland erhofft sich von künstlicher Intelligenz (KI) Erleichterungen im künftigen Berufsleben. Das zeigt die Umfrage der Beratungsgesellschaft Ernst & Young (EY), die am Dienstag veröffentlicht wurde. Fast zwei Drittel (65 Prozent) der Befragten erwarteten, dass sich der Einsatz von KI positiv auswirken wird – zum Beispiel durch schnelleres und fehlerfreies Arbeiten oder eine bessere Work-Life-Balance. Mit negativen Folgen wie dem Wegfall von Jobs rechneten lediglich 14 Prozent. Ein gutes Fünftel der Befragten gab an, dass KI irrelevant für ihr anstehendes Berufsleben sein werde. Besonders zuversichtlich sind Studierende aus den Wirtschaftswissenschaften. Hier gaben 80 Prozent der Befragten an, dass sich KI positiv auf ihre berufliche Zukunft auswirken werde. Auch Studierende der Ingenieurswissenschaften und Informatik sind besonders optimistisch (76 Prozent). Studierende der Geisteswissenschaften äußern sich hingegen verhaltener, hier glaubt nur die Hälfte an positive Effekte. Auch Sozial-, Sprach- und Literaturwissenschaftler:innen sind weniger zuversichtlich (52 Prozent). Nicht nur im Arbeitsalltag, sondern auch beim Start ins Berufsleben wird Know-how zu künstlicher Intelligenz aus Sicht der Studierenden eine zunehmend wichtige Rolle spielen: Gut ein Viertel der Befragten gab an, das Wissen um mögliche KI-Anwendungen sei schon jetzt unverzichtbar beim Eintritt in den Arbeitsmarkt. Mehr als die Hälfte (55 Prozent) gingen davon aus, dass dies schon bald der Fall sein wird. 86 Prozent nutzen bereits KI-Anwendungen im Studium Im Alltag der Studierenden ist KI längst angekommen, zeigt die Befragung. Fast neun von zehn Befragten (86 Prozent) nutzten demnach mehr oder weniger häufig KI-Anwendungen im Studium: 13 Prozent der Befragten nahmen Tools wie Chatbots häufig in Anspruch, 41 Prozent gelegentlich und 32 Prozent sehr selten. Sie nutzen sie den Angaben nach unter anderem zur Recherche, um Verständnisfragen zu klären oder Texte zu erstellen. Das am häufigsten genutzte Tool ist ChatGPT. 70 Prozent der Befragten gaben an, damit bereits gearbeitet zu haben. Für die Studie hat ein Marktforschungsinstitut im Auftrag von EY mehr als 2000 Studierende in Deutschland befragt. Die repräsentative Onlineumfrage wurde im Februar durchgeführt."
Artificial Intelligence,Spiegel Online,2024-03-26,https://www.spiegel.de/netzwelt/web/laion-5b-so-entsteht-das-weltbild-einer-kuenstlichen-intelligenz-a-dea0157b-d364-4622-8d77-3a1cb6c4afd1,LAION 5B: So entsteht das Weltbild einer künstlichen Intelligenz - DER SPIEGEL,"Mit welchen Bildern lernt eine KI, woher stammen sie? Wer entscheidet, ob sie geeignet sind? Forscher haben einen der größten Trainingsdatensätze untersucht. Wir machen ihre Erkenntnisse verständlich."
KI,Spiegel Online,2024-03-27,https://www.spiegel.de/netzwelt/apps/kuenstliche-intelligenz-databricks-stellt-eigenes-sprachmodell-vor-a-00cea80f-af64-4ed1-a163-fcffd19eb4ec,Künstliche Intelligenz: Databricks stellt eigenes Sprachmodell vor - DER SPIEGEL,"Ein Softwarekonzern aus San Francisco will mit einem kostenlosen KI-Textgenerator die Konkurrenz in Sachen Kosten ausstechen. Abgesehen hat man es besonders auf mittelständische Unternehmen. Ein Frühlingsabend in San Francisco. Im Restaurant »Foreign Cinema« ist der Tisch reich gedeckt. Es gibt Wagyu-Rind und Fisch, dazu die »allerneueste, allerschnellste« Open-Source-KI, sagt Ali Ghodsi, Chef des Softwareunternehmens Databricks, das zu dem Termin geladen hat. Die Firma ist schon bisher auf die Verwaltung und Auswertung großer Datenmengen spezialisiert. Zusammen mit dem Start-up Mosaic hat Databricks eine eigene künstliche Intelligenz entwickelt. Zehn Millionen Dollar habe man investiert, allein das Training habe zwei Monate gedauert, sagt Ghodsi. Herausgekommen ist das Sprachmodell DBRX, welches ab diesem Mittwoch verfügbar ist. Ein nicht gerade eingängiger Name, aber um Popularität bei den Massen geht es Ghodsi auch nicht. »DBRX ist kein Spielzeug, sondern ein Werkzeug für Unternehmen, um effizienter zu arbeiten«, sagt er. Nicht die besten Ergebnisse, aber geringe Kosten Um das zu beweisen, wirft der Databricks-CEO Grafiken an die Wand. Demnach schneidet Databricks LLM nach nahezu allen Standard-Benchmarks besser ab, als die verfügbaren Open Source-Modelle der Konkurrenz. Selbst ChatGPT von OpenAI benötige für fast alle Aufgaben länger als DBRX, ruft Ghosdi. Allerdings gilt das nur für die Version 3.5. Das populäre ChatGPT 4 ist DBRX in Sachen Tempo und Leistung weiterhin voraus. Bei den Kosten allerdings nicht, sagt Ghodsi. DBRX spare Rechenpower und damit Geld. Insgesamt sei man doppelt so effizient wie die Konkurrenz – »also nur halb so teuer«, ruft Ghodsi. Schließlich sei DBRX’ Quellcode Open-Source, also frei verfügbar. Jedes Unternehmen könne ihn kostenlos herunterladen und an seine Bedürfnisse anpassen. Databricks verdiene lediglich über Services oder die Rechenleistung mit, die Unternehmen bei ihm einkauften. Mittelstand für KI begeistern Um in den eng umkämpften Markt Fuß zu fassen, hat Databricks wichtige Verbindungen geknüpft. Zu den Investoren und Partnern von Databricks gehört Nvidia. Der Hersteller hat mit seinen Spezial-Chips bisher fast im Alleingang die neue KI-Industrie ausgerüstet. Aber es gibt auch reichlich Konkurrenz für KI-Anwendungen. So arbeitet Microsoft daran, seine Milliardeninvestitionen in Umsätze zu verwandeln, Mittelstandsausrüster wie SAP investieren ebenfalls stark in das KI-Geschäft. Dazu kommen Start-ups, die – wie Databricks – mit frei verfügbaren Tools werben. Sie alle haben es auf die vielen traditionsreichen Firmen hierzulande abgesehen. Diese verfügen über jede Menge historischer und damit wertvoller Daten, mit denen man eine KI trainieren könnte. Bislang gibt es jedoch vielerorts Vorbehalte, diese Daten mit großen US-Unternehmen zu teilen. Open-Source-Modelle könnten hier ein Ausweg sein. Das Interesse aus Europa, heißt es intern, sei enorm. Schon bald, ist man in San Francisco überzeugt, werde sich die Leistungsfähigkeit der gängigen KI-Sprachmodelle immer weiter annähern. Dann gehe es vor allem um die Daten, mit denen die Sprachmodelle »gefüttert« würden. Sie machten künftig den Unterschied zwischen einer guten und einer schlechten KI. Allerdings, räumt Ghodsi ein, müsse dazu schon ein gewisses Programmier-Know-How im Unternehmen vorhanden sein. Ganz ohne Vorkenntnisse sei ein eigenes KI-Sprachmodell nicht aufzubauen. »Aber es ist auch keine Raketenwissenschaft.« Na immerhin."
KI,Spiegel Online,2024-03-26,https://www.spiegel.de/netzwelt/web/laion-5b-so-entsteht-das-weltbild-einer-kuenstlichen-intelligenz-a-dea0157b-d364-4622-8d77-3a1cb6c4afd1,LAION 5B: So entsteht das Weltbild einer künstlichen Intelligenz - DER SPIEGEL,"Mit welchen Bildern lernt eine KI, woher stammen sie? Wer entscheidet, ob sie geeignet sind? Forscher haben einen der größten Trainingsdatensätze untersucht. Wir machen ihre Erkenntnisse verständlich."
KI,Spiegel Online,2024-03-26,https://www.spiegel.de/start/ki-im-berufsleben-mehrheit-der-studierenden-erwartet-dass-ki-ihr-berufsleben-erleichtert-a-289d087a-531d-4273-852e-907d1a1a9181,"KI im Berufsleben: Mehrheit der Studierenden erwartet, dass KI ihr Berufsleben erleichtert - DER SPIEGEL","Bessere Work-Life-Balance, weniger Fehler: Fragt man Studierende, bietet künstliche Intelligenz vor allem Chancen für die Arbeitswelt. Die Mehrheit nutzt KI-Hilfsmittel laut einer neuen Umfrage schon heute. Ein großer Teil der Studierenden in Deutschland erhofft sich von künstlicher Intelligenz (KI) Erleichterungen im künftigen Berufsleben. Das zeigt die Umfrage der Beratungsgesellschaft Ernst & Young (EY), die am Dienstag veröffentlicht wurde. Fast zwei Drittel (65 Prozent) der Befragten erwarteten, dass sich der Einsatz von KI positiv auswirken wird – zum Beispiel durch schnelleres und fehlerfreies Arbeiten oder eine bessere Work-Life-Balance. Mit negativen Folgen wie dem Wegfall von Jobs rechneten lediglich 14 Prozent. Ein gutes Fünftel der Befragten gab an, dass KI irrelevant für ihr anstehendes Berufsleben sein werde. Besonders zuversichtlich sind Studierende aus den Wirtschaftswissenschaften. Hier gaben 80 Prozent der Befragten an, dass sich KI positiv auf ihre berufliche Zukunft auswirken werde. Auch Studierende der Ingenieurswissenschaften und Informatik sind besonders optimistisch (76 Prozent). Studierende der Geisteswissenschaften äußern sich hingegen verhaltener, hier glaubt nur die Hälfte an positive Effekte. Auch Sozial-, Sprach- und Literaturwissenschaftler:innen sind weniger zuversichtlich (52 Prozent). Nicht nur im Arbeitsalltag, sondern auch beim Start ins Berufsleben wird Know-how zu künstlicher Intelligenz aus Sicht der Studierenden eine zunehmend wichtige Rolle spielen: Gut ein Viertel der Befragten gab an, das Wissen um mögliche KI-Anwendungen sei schon jetzt unverzichtbar beim Eintritt in den Arbeitsmarkt. Mehr als die Hälfte (55 Prozent) gingen davon aus, dass dies schon bald der Fall sein wird. 86 Prozent nutzen bereits KI-Anwendungen im Studium Im Alltag der Studierenden ist KI längst angekommen, zeigt die Befragung. Fast neun von zehn Befragten (86 Prozent) nutzten demnach mehr oder weniger häufig KI-Anwendungen im Studium: 13 Prozent der Befragten nahmen Tools wie Chatbots häufig in Anspruch, 41 Prozent gelegentlich und 32 Prozent sehr selten. Sie nutzen sie den Angaben nach unter anderem zur Recherche, um Verständnisfragen zu klären oder Texte zu erstellen. Das am häufigsten genutzte Tool ist ChatGPT. 70 Prozent der Befragten gaben an, damit bereits gearbeitet zu haben. Für die Studie hat ein Marktforschungsinstitut im Auftrag von EY mehr als 2000 Studierende in Deutschland befragt. Die repräsentative Onlineumfrage wurde im Februar durchgeführt."
Künstliche Intelligenz,Spiegel Online,2024-03-20,https://www.spiegel.de/netzwelt/gadgets/nvidias-neuer-superchip-ist-so-teuer-wie-ein-vw-golf-a-1fe0cc85-443d-42ff-a901-d1f7eb038005,Nvidias: Neuer Superchip ist so teuer wie ein VW Golf - DER SPIEGEL,"Als Jensen Huang den neuen KI-Superchip seiner Firma präsentierte, ließ er ein nicht unwesentliches Detail lieber aus: den Preis. Diesen hat der Nvidia-Chef nun in einem TV-Interview nachgeliefert. Über mangelndes Interesse an seinen Neuheiten kann sich Nvidia derzeit nicht beklagen. 11.000 Menschen kamen ins SAP Center im kalifornischen San José, um die Keynote des Firmenchefs Jensen Huang live anzuschauen, Hunderttausende verfolgten das zweistündige Spektakel online. Sie wurden nicht enttäuscht. Es ging um humanoide Roboter, um Apples Brillencomputer Vision Pro und um künstliche Intelligenz. Die Stars der Show waren aber eindeutig die neuen KI-Chips der »Blackwell«-Serie B200. Huang bezeichnete sie als »Prozessor für die Ära generativer KI«. Die Nvidia zufolge extrem leistungsstarken Chips sollen in Rechenzentren, die laut Huang künftig eher »KI-Fabriken« sein werden, künstliche Intelligenzen trainieren. Die neuen Chips sollen effizienter, schneller, besser und einfacher zu nutzen sein und dabei helfen, neue KI-Modelle schneller und mit geringerem Energieaufwand zu entwickeln. Doch die neue Technik hat ihren Preis. Wie hoch dieser sein wird, hat Huang nun in einem Interview des TV-Senders CNBC verraten. Während er einen der neuen Chips in die Kamera hielt, sagte er, der Stückpreis werde bei 30.000 bis 40.000 Dollar liegen. Für dieses Geld könnte man zwar auch einen ordentlich ausgestatteten VW Golf bekommen. Wirklich überraschend aber ist der Preis nicht. Auch Nvidias Vorgängermodell, der H100-Chip »Hopper«, wurde anfangs zu Preisen von über 30.000 Euro angeboten . Die Herstellungskosten jenes Chips wurden indes auf 3300 Dollar geschätzt , die Gewinnmarge wirkte entsprechend gewaltig. Seiner jetzigen Erwähnung des vermutlichen Verkaufspreises schob der Nvidia-Chef wohl auch deshalb gleich eine Angabe zu den Entwicklungskosten hinterher: Zehn Milliarden Dollar hat es Nvidia demnach gekostet, die »Blackwell«-Plattform zu entwickeln. Two-in-One Eine der Besonderheiten dabei ist, dass der B200 eigentlich aus zwei Chips besteht, die Nvidia über eine Hochleistungsverbindung so miteinander verschmolzen hat, dass sie nach außen wie ein einziger Chip wirken. Eine ähnliche Technologie verwendet auch Apple seit ein paar Jahren für seine Computerchips. Erstmals mit dem M1 Ultra hatte der US-Konzern einen Chip entwickelt, der eigentlich aus zwei M1 Max besteht , die über eine Verbindung, die Apple »UltraFusion« nennt, miteinander kommunizieren. Konkurrenten werden die beiden Firmen durch ihre Fortschritte nicht, dafür sind die Anwendungsszenarien für ihre Chips zu unterschiedlich. Nvidia zeigte auf seiner Entwicklerkonferenz sogar eine Anwendung für Apples Brillencomputer Vision Pro. Nvidias Grafiktechnologie dient dabei als Grundlage für eine Art 3D-Pkw-Konfigurator . In der Beispielanwendung konnte ein Mann mit der Apple-Brille ein Fahrzeug nach seinen Wünschen gestalten, samt Farben und Sonderausstattung. Nvidias Antrieb dahinter ist klar: Das Unternehmen möchte Firmenkunden seine Cloud-Grafiktechnologie als Grundlage für professionelle Anwendungen in der Apple-Brille andienen."
Künstliche Intelligenz,Spiegel Online,2024-03-19,https://www.spiegel.de/wirtschaft/kuenstliche-intelligenz-microsoft-holt-sich-bekannten-ki-experten-mustafa-suleyman-a-ab0269e0-3216-45ba-bacf-98cd5409dbcf,Künstliche Intelligenz: Microsoft holt sich bekannten KI-Experten Mustafa Suleyman - DER SPIEGEL,"Microsoft weitet seine KI-Sparte aus und setzt auf die Expertise von Mustafa Suleyman. Vorher arbeitete er für Google und entwickelte KI-Anwendungen für den Gesundheitsbereich sowie Chatbots. Microsoft verstärkt den Fokus auf künstliche Intelligenz mit der Verpflichtung eines der renommiertesten Experten in dem Bereich. Mustafa Suleyman gibt den Chefposten beim KI-Start-up Inflection AI auf und übernimmt die Führung eines neuen Microsoft-Bereichs, wie der Softwarekonzern am Dienstag mitteilte. Unter dem Dach von Microsoft AI sollen die auf Verbraucher ausgerichteten KI-Produkte gebündelt werden. Dazu gehören die Copilot-Assistenten sowie Funktionen in Microsofts Suchmaschine Bing und dem Browser Edge , die mit künstlicher Intelligenz arbeiten. Suleyman war einer der Mitgründer des KI-Pioniers DeepMind, der 2014 von Google gekauft wurde. Er verließ den Internetkonzern 2022 und war ein Gründer des Start-ups Inflection AI, das den Chatbot Pi entwickelte. Ein weiterer Mitgründer, Karén Simonyan, geht ebenfalls zu Microsoft AI und wird dort Chefwissenschaftler. Inflection AI will sich unterdessen künftig darauf fokussieren, KI-Chatbots für Unternehmen zu entwickeln."
Künstliche Intelligenz,Spiegel Online,2024-03-18,https://www.spiegel.de/netzwelt/netzpolitik/wahlkampf-in-den-usa-die-grosse-angst-vor-den-ki-fakes-a-fd7afd75-d225-4627-8032-826023389978,Wahlkampf in den USA: Die große Angst vor den KI-Fakes - DER SPIEGEL,Wird künstliche Intelligenz die US-Wahl beeinflussen? Auf einer Konferenz in Texas treffen Vertreter der Techkonzerne auf alarmierte Forscherinnen – und streiten über den richtigen Umgang mit der Technik.
AI,Spiegel Online,2024-03-19,https://www.spiegel.de/wirtschaft/kuenstliche-intelligenz-microsoft-holt-sich-bekannten-ki-experten-mustafa-suleyman-a-ab0269e0-3216-45ba-bacf-98cd5409dbcf,Künstliche Intelligenz: Microsoft holt sich bekannten KI-Experten Mustafa Suleyman - DER SPIEGEL,"Microsoft weitet seine KI-Sparte aus und setzt auf die Expertise von Mustafa Suleyman. Vorher arbeitete er für Google und entwickelte KI-Anwendungen für den Gesundheitsbereich sowie Chatbots. Microsoft verstärkt den Fokus auf künstliche Intelligenz mit der Verpflichtung eines der renommiertesten Experten in dem Bereich. Mustafa Suleyman gibt den Chefposten beim KI-Start-up Inflection AI auf und übernimmt die Führung eines neuen Microsoft-Bereichs, wie der Softwarekonzern am Dienstag mitteilte. Unter dem Dach von Microsoft AI sollen die auf Verbraucher ausgerichteten KI-Produkte gebündelt werden. Dazu gehören die Copilot-Assistenten sowie Funktionen in Microsofts Suchmaschine Bing und dem Browser Edge , die mit künstlicher Intelligenz arbeiten. Suleyman war einer der Mitgründer des KI-Pioniers DeepMind, der 2014 von Google gekauft wurde. Er verließ den Internetkonzern 2022 und war ein Gründer des Start-ups Inflection AI, das den Chatbot Pi entwickelte. Ein weiterer Mitgründer, Karén Simonyan, geht ebenfalls zu Microsoft AI und wird dort Chefwissenschaftler. Inflection AI will sich unterdessen künftig darauf fokussieren, KI-Chatbots für Unternehmen zu entwickeln."
Artificial Intelligence,Spiegel Online,2024-03-20,https://www.spiegel.de/netzwelt/netzpolitik/politik-und-social-media-was-deutsche-politiker-von-tiktok-lernen-koennen-a-81312af6-c240-400e-b1ae-9919f1b5a02c,Politik und Social Media: Was deutsche Politiker von TikTok lernen können - DER SPIEGEL,"Um den Erfolg der AfD auf TikTok zu kontern, wollen deutsche Politikerinnen und Politiker dort selbst mehr posten. Noch wichtiger wäre es, eine Politik für die dort sichtbaren Probleme junger Menschen zu machen."
Artificial Intelligence,Spiegel Online,2024-03-19,https://www.spiegel.de/wirtschaft/kuenstliche-intelligenz-microsoft-holt-sich-bekannten-ki-experten-mustafa-suleyman-a-ab0269e0-3216-45ba-bacf-98cd5409dbcf,Künstliche Intelligenz: Microsoft holt sich bekannten KI-Experten Mustafa Suleyman - DER SPIEGEL,"Microsoft weitet seine KI-Sparte aus und setzt auf die Expertise von Mustafa Suleyman. Vorher arbeitete er für Google und entwickelte KI-Anwendungen für den Gesundheitsbereich sowie Chatbots. Microsoft verstärkt den Fokus auf künstliche Intelligenz mit der Verpflichtung eines der renommiertesten Experten in dem Bereich. Mustafa Suleyman gibt den Chefposten beim KI-Start-up Inflection AI auf und übernimmt die Führung eines neuen Microsoft-Bereichs, wie der Softwarekonzern am Dienstag mitteilte. Unter dem Dach von Microsoft AI sollen die auf Verbraucher ausgerichteten KI-Produkte gebündelt werden. Dazu gehören die Copilot-Assistenten sowie Funktionen in Microsofts Suchmaschine Bing und dem Browser Edge , die mit künstlicher Intelligenz arbeiten. Suleyman war einer der Mitgründer des KI-Pioniers DeepMind, der 2014 von Google gekauft wurde. Er verließ den Internetkonzern 2022 und war ein Gründer des Start-ups Inflection AI, das den Chatbot Pi entwickelte. Ein weiterer Mitgründer, Karén Simonyan, geht ebenfalls zu Microsoft AI und wird dort Chefwissenschaftler. Inflection AI will sich unterdessen künftig darauf fokussieren, KI-Chatbots für Unternehmen zu entwickeln."
KI,Spiegel Online,2024-03-20,https://www.spiegel.de/netzwelt/gadgets/nvidias-neuer-superchip-ist-so-teuer-wie-ein-vw-golf-a-1fe0cc85-443d-42ff-a901-d1f7eb038005,Nvidias: Neuer Superchip ist so teuer wie ein VW Golf - DER SPIEGEL,"Als Jensen Huang den neuen KI-Superchip seiner Firma präsentierte, ließ er ein nicht unwesentliches Detail lieber aus: den Preis. Diesen hat der Nvidia-Chef nun in einem TV-Interview nachgeliefert. Über mangelndes Interesse an seinen Neuheiten kann sich Nvidia derzeit nicht beklagen. 11.000 Menschen kamen ins SAP Center im kalifornischen San José, um die Keynote des Firmenchefs Jensen Huang live anzuschauen, Hunderttausende verfolgten das zweistündige Spektakel online. Sie wurden nicht enttäuscht. Es ging um humanoide Roboter, um Apples Brillencomputer Vision Pro und um künstliche Intelligenz. Die Stars der Show waren aber eindeutig die neuen KI-Chips der »Blackwell«-Serie B200. Huang bezeichnete sie als »Prozessor für die Ära generativer KI«. Die Nvidia zufolge extrem leistungsstarken Chips sollen in Rechenzentren, die laut Huang künftig eher »KI-Fabriken« sein werden, künstliche Intelligenzen trainieren. Die neuen Chips sollen effizienter, schneller, besser und einfacher zu nutzen sein und dabei helfen, neue KI-Modelle schneller und mit geringerem Energieaufwand zu entwickeln. Doch die neue Technik hat ihren Preis. Wie hoch dieser sein wird, hat Huang nun in einem Interview des TV-Senders CNBC verraten. Während er einen der neuen Chips in die Kamera hielt, sagte er, der Stückpreis werde bei 30.000 bis 40.000 Dollar liegen. Für dieses Geld könnte man zwar auch einen ordentlich ausgestatteten VW Golf bekommen. Wirklich überraschend aber ist der Preis nicht. Auch Nvidias Vorgängermodell, der H100-Chip »Hopper«, wurde anfangs zu Preisen von über 30.000 Euro angeboten . Die Herstellungskosten jenes Chips wurden indes auf 3300 Dollar geschätzt , die Gewinnmarge wirkte entsprechend gewaltig. Seiner jetzigen Erwähnung des vermutlichen Verkaufspreises schob der Nvidia-Chef wohl auch deshalb gleich eine Angabe zu den Entwicklungskosten hinterher: Zehn Milliarden Dollar hat es Nvidia demnach gekostet, die »Blackwell«-Plattform zu entwickeln. Two-in-One Eine der Besonderheiten dabei ist, dass der B200 eigentlich aus zwei Chips besteht, die Nvidia über eine Hochleistungsverbindung so miteinander verschmolzen hat, dass sie nach außen wie ein einziger Chip wirken. Eine ähnliche Technologie verwendet auch Apple seit ein paar Jahren für seine Computerchips. Erstmals mit dem M1 Ultra hatte der US-Konzern einen Chip entwickelt, der eigentlich aus zwei M1 Max besteht , die über eine Verbindung, die Apple »UltraFusion« nennt, miteinander kommunizieren. Konkurrenten werden die beiden Firmen durch ihre Fortschritte nicht, dafür sind die Anwendungsszenarien für ihre Chips zu unterschiedlich. Nvidia zeigte auf seiner Entwicklerkonferenz sogar eine Anwendung für Apples Brillencomputer Vision Pro. Nvidias Grafiktechnologie dient dabei als Grundlage für eine Art 3D-Pkw-Konfigurator . In der Beispielanwendung konnte ein Mann mit der Apple-Brille ein Fahrzeug nach seinen Wünschen gestalten, samt Farben und Sonderausstattung. Nvidias Antrieb dahinter ist klar: Das Unternehmen möchte Firmenkunden seine Cloud-Grafiktechnologie als Grundlage für professionelle Anwendungen in der Apple-Brille andienen."
KI,Spiegel Online,2024-03-19,https://www.spiegel.de/netzwelt/netzpolitik/nvidia-jensen-huang-praesentiert-leistungsstaerksten-chip-der-welt-a-b539dca9-d87f-41f5-b026-e9fbcf5b09d9,Nvidia präsentiert angeblich »leistungsstärksten Chip der Welt« - DER SPIEGEL,"Nvidia-Chef Jensen Huang will den Motor für »eine neue industrielle Revolution« entwickelt haben. Mit der neuen »Blackwell«-Technologie sollen künstliche Intelligenzen effizienter trainiert werden können. Für die Vorführung ihrer neuesten Produkte hatte Nvidia eine Eishockey-Arena umbauen lassen. 16.000 Menschen schauten zu, als Firmenchef Jensen Huang am Montag im kalifornischen San José ein neues Computersystem und den nach eigenen Aussagen »leistungsstärksten Chip der Welt« vorstellte: »Blackwell« sei »der Motor für eine neue industrielle Revolution«, versprach Huang. Das klingt großspurig. Aber anders als bei so manch anderem Firmenchef gibt es viele Gründe, den taiwanisch-amerikanischen Gründer ernst zu nehmen. Seit ChatGPT Ende 2022 veröffentlicht wurde, hat sich der Wert von Nvidia rund versechsfacht – auf mehr als zwei Billionen Dollar. Allein in den vergangenen zwölf Monaten haben die Aktien des Unternehmens 240 Prozent zugelegt. Nvidia wird oft als Chiphersteller bezeichnet. Aber das ist leicht irreführend, denn die Firma produziert gar keine Chips . Vereinfacht gesagt, besteht die Leistung des Firmengründers darin, Grafikprozessoren zu Gehirnen für Computer weiterentwickelt zu haben. Diese Computergehirne kommen mittlerweile weltweit zum Einsatz, um künstliche Intelligenzen zu trainieren. Und nun sollen sie mit »Blackwell« und dem Chip »Blackwell B200« noch schneller und besser funktionieren. Mit der bisherigen Nvidia-Technologie könne man einen KI-Chatbot wie ChatGPT innerhalb von drei Monaten trainieren, benötige dafür aber 8000 Nvidia-Chips mit einem Stromverbrauch von 15 Megawatt, so Huang. Mit »Blackwell« erschaffe man einen solchen Chatbot in derselben Zeit – mit 2000 Chips und nur vier Megawatt Strom. Effizienter, schneller, besser, einfacher – so lässt sich Huangs Präsentation von »Blackwell«, benannt nach dem amerikanischen Mathematiker David Blackwell, grob zusammenfassen. Die ersten Reaktionen des Expertenpublikums fielen positiv aus. »Wir gehen davon aus, dass Nvidia nicht nur weiterhin führen wird, sondern den Abstand zu seinen Konkurrenten im Bereich KI vergrößern wird«, zitiert die Nachrichtenagentur Reuters Branchenkenner Kinngai Chan. Große KI-Unternehmen wie Microsoft, Google und Amazon planen bereits den Einsatz von »Blackwell«. Bei seiner Präsentation holte sich Nvidia-Chef Huang auch einen niedlichen, kleinen Roboter auf die Bühne. »Der ChatGPT-Moment für Robotik könnte unmittelbar bevorstehen«, meinte Huang und erklärte auch, wie er sich das vorstellt: Roboter sollen künftig allein dadurch lernen, dass sie Menschen beobachten. Die Zukunft, wie sie Huang in seiner Präsentation schilderte, sieht so aus: Webinhalte werden nicht mehr vorgefertigt aus Speichern abgerufen, sondern von KI-Software jeweils frisch erzeugt. Unternehmen und Produkte haben »digitale Zwillinge«, an denen einzelne Entscheidungen getestet werden, bevor sie jemand in der echten Welt umsetzt. Und überhaupt gilt: Bevor etwas in der realen Welt gebaut wird, wird es zunächst digital simuliert. Huang zeigte als Beispiel einen Einsatz von Nvidias 3D-Umgebung Omniverse auf Apples Computerbrille Vision Pro: Ein Designer des südkoreanischen Autobauers Hyundai konnte so verschiedene Farbvarianten eines Automodells in unterschiedlichen Umgebungen ansehen und sich auch virtuell ans Lenkrad setzen."
KI,Spiegel Online,2024-03-19,https://www.spiegel.de/wirtschaft/kuenstliche-intelligenz-microsoft-holt-sich-bekannten-ki-experten-mustafa-suleyman-a-ab0269e0-3216-45ba-bacf-98cd5409dbcf,Künstliche Intelligenz: Microsoft holt sich bekannten KI-Experten Mustafa Suleyman - DER SPIEGEL,"Microsoft weitet seine KI-Sparte aus und setzt auf die Expertise von Mustafa Suleyman. Vorher arbeitete er für Google und entwickelte KI-Anwendungen für den Gesundheitsbereich sowie Chatbots. Microsoft verstärkt den Fokus auf künstliche Intelligenz mit der Verpflichtung eines der renommiertesten Experten in dem Bereich. Mustafa Suleyman gibt den Chefposten beim KI-Start-up Inflection AI auf und übernimmt die Führung eines neuen Microsoft-Bereichs, wie der Softwarekonzern am Dienstag mitteilte. Unter dem Dach von Microsoft AI sollen die auf Verbraucher ausgerichteten KI-Produkte gebündelt werden. Dazu gehören die Copilot-Assistenten sowie Funktionen in Microsofts Suchmaschine Bing und dem Browser Edge , die mit künstlicher Intelligenz arbeiten. Suleyman war einer der Mitgründer des KI-Pioniers DeepMind, der 2014 von Google gekauft wurde. Er verließ den Internetkonzern 2022 und war ein Gründer des Start-ups Inflection AI, das den Chatbot Pi entwickelte. Ein weiterer Mitgründer, Karén Simonyan, geht ebenfalls zu Microsoft AI und wird dort Chefwissenschaftler. Inflection AI will sich unterdessen künftig darauf fokussieren, KI-Chatbots für Unternehmen zu entwickeln."
KI,Spiegel Online,2024-03-18,https://www.spiegel.de/netzwelt/netzpolitik/wahlkampf-in-den-usa-die-grosse-angst-vor-den-ki-fakes-a-fd7afd75-d225-4627-8032-826023389978,Wahlkampf in den USA: Die große Angst vor den KI-Fakes - DER SPIEGEL,Wird künstliche Intelligenz die US-Wahl beeinflussen? Auf einer Konferenz in Texas treffen Vertreter der Techkonzerne auf alarmierte Forscherinnen – und streiten über den richtigen Umgang mit der Technik.
Künstliche Intelligenz,Spiegel Online,2024-03-13,https://www.spiegel.de/netzwelt/netzpolitik/nvidia-devin-und-co-so-veraendert-ki-schon-jetzt-die-welt-kolumne-a-b4d62dbf-7348-4610-84e5-702c404548ad,"Nvidia, Devin und Co.: So verändert KI schon jetzt die Welt - Kolumne - DER SPIEGEL","Kinder sollten coden lernen? Wer Informatik studiert, bekommt einen guten Job? Solche vermeintlichen Gewissheiten dürfen im Zeitalter generativer KI bezweifelt werden. Und das ist erst der Anfang. In einem Podcast sagte Open-AI-Chef Sam Altman Ende vergangenen Jahres etwas so Interessantes wie Unerwartetes: Künstliche Intelligenz sei jetzt zwar mit nie geahnter Größe und Macht da. Das Leben der Menschen gehe aber praktisch unverändert weiter . Im Alltag habe sich nichts geändert. Anders als etwa kurze Zeit nach Einführung des Smartphones . Da ist etwas dran, was man gut nachvollziehen kann, wenn man mit Menschen spricht, die dem riesigen Hype um generative künstliche Intelligenz eher skeptisch gegenüberstehen. Diese fragen dann, was genau sich eigentlich substanziell, tiefgreifend, epochal verändert habe, und die Antwort ist zunächst weniger offensichtlich als etwa beim Smartphone. Man kann aber bei einer gut messbaren Veränderung beginnen, nämlich beim Geld. Oder präziser: bei den Börsenwerten. Sascha Lobo, Jahrgang 1975, ist Autor und Strategieberater mit den Schwerpunkten Internet und digitale Technologien. Gemeinsam mit Jule Lobo beschäftigt er sich im Podcast »Feel the News – Was Deutschland bewegt« mit aktuellen Debattenthemen. Die Chipgestaltungsfirma Nvidia ist der große Börsenstar des KI-Booms. Seit ChatGPT Ende 2022 veröffentlicht wurde, hat sich der Wert des Unternehmens auf über zwei Billionen Dollar rund versechsfacht – und das, obwohl Nvidia selbst keine Chips produziert, sondern sich gewissermaßen nur welche ausdenkt und sie von anderen produzieren lässt. Dieser spektakuläre Erfolg gilt vor allem als Verdienst des taiwanesisch-amerikanischen Gründers Jen-Hsun Huang, der für seine Hellsichtigkeit bezüglich des Techsektors gefeiert wird. Huang sagt zwar offenbar in einer etwas schillernden Bescheidenheit, dass er mit seinen strategischen Chip-Entscheidungen viel Glück hatte. Aber selbst mit Glück beruht der Erfolg von Nvidia vor allem darauf, wie er in den letzten zwei Dekaden die künftige Entwicklung der Techwelt einschätzte. Was Huang kürzlich auf dem World Government Summit in Dubai sagte , wirkt angesichts dessen umso spektakulärer. »In den letzten zehn, fünfzehn Jahren haben fast alle Leute auf solchen Bühnen gesagt, wie wichtig es sei, dass Kinder Informatik lernen. (…) Tatsächlich ist es exakt gegenteilig. Es ist unser Job, Technologien zu entwickeln, damit niemand mehr programmieren muss und damit Menschensprache zur Programmiersprache wird. Jeder ist jetzt ein Programmierer, das ist das Wunder der künstlichen Intelligenz.« Huang meint, Kinder sollten nicht mehr programmieren lernen. Lustvoll ausgeschöpftes Provokationspotenzial? Es gibt einige, oft unausgesprochene Haltungsparallelen, die die Mehrzahl der Techleute im Großen und Ganzen teilt und die sie auch nicht wirklich geheim hält. Die Überzeugung, dass ein tiefes Verständnis digitaler Technologie eine, wenn nicht die essenzielle Fähigkeit ist, gehört dazu. Sie erscheint so selbstverständlich, dass – darauf spielt Huang an – fast alle digitalunternehmerisch erfolgreichen Personen über Jahrzehnte predigten, es müsse mehr Menschen wie sie selbst geben. Daraus erwuchsen konkrete gesellschaftliche und politische Folgen. Da ist etwa die Fokussierung der Bildungslandschaft auf die MINT-Fächer. Oder die Elternweisheit, dass Kinder mit einem Informatikstudium sicher einen guten Job bekommen würden. Und es gab auch das allgemein verbreitete Gefühl, dass Fortschritt und Wohlstand eng mit den digitalen Fähigkeiten zusammenhingen. Das ist alles nicht ganz falsch, oder besser: Das war lange Zeit nicht ganz falsch. Die Frage ist, ob, wie lange und wie flächendeckend es noch stimmt. Was Huang in Dubai sagte, hatte natürlich auch absichtsvolles, wenn nicht lustvoll ausgeschöpftes Provokationspotenzial. Viele große Techmedien und in der Szene bekannte Programmierer sind darauf angesprungen und haben teils erbittert widersprochen. Niemand hört gern von eventuellen Möglichkeiten der eigenen Überflüssigkeit. Durch generative künstliche Intelligenz hat sich die Softwareentwicklung schon längst deutlich verändert, denn viele Entwickler:innen nutzen KI-Assistenten, die kleine und mittlere Aufgaben erledigen können. Zuvor hätte man die passenden Code-Schnipsel in den digitalen Weiten der Software-Archive der Welt suchen und womöglich auf die spezifischen Bedürfnisse händisch anpassen müssen. KI hat die Softwareentwicklung schon heute produktiver, schneller und zum Teil einfacher gemacht. Aber ein tatsächliches Ersetzen des Programmiererjobs, auf das Huang anspielt, war bisher allenfalls in Umrissen zu erkennen. Wenn überhaupt. Jetzt aber hat ein Start-up namens Cognition Labs »Devin« vorgestellt . Devin ist in erster Linie ein weltweiter Social-Media- und PR-Erfolg, wie man ihn sich als Start-up nur wünschen kann. Devin soll der »erste KI-Softwareingenieur« sein, also ein Roboter, der programmieren kann wie ein Mensch, nur schneller und in den meisten Fällen besser – wie alles Folgende nach Angaben der Firma selbst jedenfalls, wenngleich jene Angaben durchaus glaubwürdig wirken. Der KI-Entwickler beherrscht demnach auch Fähigkeiten, die im Software-Umfeld essenziell sind, wie Code zu testen, zu debuggen, auszuführen und zu veröffentlichen. Devin könne ihm unbekannte Programmiersprachen und Technologiekomplexe lernen, heißt es. Devin könne sich nicht nur aus bestehenden Software-Archiven bedienen, sondern neu geschriebene Software dort auch sinnvoll hinterlegen. Und Devin könne eigene KI-Modelle erschaffen, trainieren und feinjustieren. Manche Ergebnisse wirken spektakulär Für Software-ungewohnte Ohren mag sich das alles unverständlich oder belanglos anhören, aber das Ergebnis wirkt eindrucksvoll. Man gibt Devin einen digitalen Auftrag und bekommt ein entsprechendes Ergebnis. Devin kann eine Website bauen, mit einem kleinen Spiel darauf. Er kann eine Reihe Funktionen in die Website einbauen und sie anschließend ins Netz stellen sowie eventuelle Fehler beseitigen. Alles mit ähnlich kurzen und fachlich unspezifischen Prompts wie bei ChatGPT. Der Hersteller Cognition Labs hat Devin die Einstellungstests von KI-Unternehmen durchlaufen lassen – mit Erfolg. Das Start-up hat Devin auch bei Upwork angemeldet, einer Plattform, auf der teilweise umfangreiche Programmierarbeiten an Freelancer rund um die Welt vergeben werden. Devin hat eine Reihe dort gelisteter Arbeiten ausführen können. Der große Vorteil von Devin ist die Autonomie, die deutlich weiter zu gehen scheint als die meisten bisher bekannten Code-Assistenz-Bots. Er kann zum Beispiel umfangreiche Aufgaben in kleinere, sinnvolle Unteraufgaben unterteilen und dann selbstständig abarbeiten –, bis das gewünschte Ergebnis vorliegt. In einigen fachspezifischen Testsituationen, darunter war die Bearbeitung öffentlich einsehbarer Aufgaben in tatsächlich vorhandenen Open-Source-Projekten, hat Devin offenbar ziemlich spektakuläre Ergebnisse erzielt. Das Start-up geht bei der Präsentation von Devin vergleichsweise transparent vor und lässt sich tiefer in die Karten schauen als viele andere kleine und große Unternehmen. Daher kann man – auf den ersten Blick betrachtet – auch sagen: Devin ist das, was man einen autonomen KI-Agenten nennt und auf diese Weise vielleicht der erste Schritt zur Erfüllung von Jen-Hsun Huangs Prophezeiung. Und hier schließt sich der Kreis, was die Anfangsfrage angeht: Was genau hat sich eigentlich wirklich und epochal verändert durch generative KI? Einerseits muss man hierzu sagen, dass wir noch ganz am Anfang dieser Entwicklung stehen und die drastischen Veränderungen in den nächsten Jahren immer offensichtlicher und auch wirkmächtiger werden. Was aber jetzt schon da ist an Alltagsveränderung, das hat Huang nicht nur in Dubai, sondern schon häufiger erzählt. Es ist nämlich der Grund, weshalb Kinder nicht mehr coden lernen sollten: nicht weil Software unwichtig wird, sondern weil sie herzustellen in gewisser Weise demokratisiert wird. »Heute sind alle Menschen Softwareentwickler«, sagt Huang stets dazu. Und was das heißen könnte, kann man ermessen, wenn man die letzte, ähnlich epochale Fähigkeitsdemokratisierung ansieht: Früher konnten nur wenige hochgebildete Teile der Elite lesen und schreiben. Heute können praktisch alle diese Instrumente benutzen – was letztlich die Grundlage war für Demokratie, universale Menschenrechte und Massenwohlstand."
Künstliche Intelligenz,Spiegel Online,2024-03-13,https://www.spiegel.de/netzwelt/netzpolitik/eu-parlament-stimmt-fuer-umfassendes-ki-gesetz-a-1b91bf5e-4adf-4532-bafc-2fed2d068b20,Künstliche Intelligenz: EU-Parlament stimmt für umfassendes KI-Gesetz - DER SPIEGEL,"Navis, automatische Übersetzungen oder die Gesichtserkennung am Handy: Künstliche Intelligenz ist Teil des täglichen Lebens. Ein »historisches« EU-Regelwerk soll den Umgang nun sicherer machen. Das EU-Parlament gibt grünes Licht für schärfere Regeln für künstliche Intelligenz (KI) in der Europäischen Union. Die Parlamentarier haben am Mittwoch in Straßburg mehrheitlich für ein entsprechendes Gesetz gestimmt. Nach Angaben des Parlaments handelt es sich um das weltweit erste KI-Gesetz. Demnach sollen KI-Systeme künftig in verschiedene Risikogruppen eingeteilt werden. Je höher die potenziellen Gefahren einer Anwendung sind, desto höher sollen die Anforderungen sein. Künstliche Intelligenz bezeichnet meist Anwendungen auf Basis maschinellen Lernens, bei denen eine Software große Datenmengen nach Übereinstimmungen durchforstet und daraus Schlussfolgerungen zieht. Sie werden schon jetzt in vielen Bereichen eingesetzt. Zum Beispiel können solche Programme Aufnahmen von Computertomografen schneller und mit einer höheren Genauigkeit auswerten als Menschen. Auch selbstfahrende Autos versuchen so, das Verhalten anderer Verkehrsteilnehmer vorherzusagen. Chatbots wie ChatGPT und automatische erzeugte Playlists von Streamingdiensten arbeiten ebenfalls mit KI. Keine Gesichtserkennung im öffentlichen Raum Das nun anstehende Gesetz geht auf einen Vorschlag der EU-Kommission aus dem Jahr 2021 zurück. Systeme, die als besonders risikoreich gelten und beispielsweise in kritischen Infrastrukturen oder im Bildungs- und Gesundheitswesen eingesetzt werden, müssen demnach strenge Anforderungen erfüllen. Bestimmte KI-Anwendungen, die gegen EU-Werte verstoßen, sollen ganz verboten werden. Dazu gehört etwa die Bewertung von sozialem Verhalten (»Social Scoring«). Damit werden die Bürgerinnen und Bürger in China in Verhaltenskategorien eingeteilt. Auch eine Emotionserkennung am Arbeitsplatz und in Bildungseinrichtungen soll es in der EU nicht geben. Die Gesichtserkennung im öffentlichen Raum – also zum Beispiel durch Videoüberwachung an öffentlichen Plätzen – soll ebenfalls grundsätzlich nicht erlaubt sein. Dabei gibt es jedoch Ausnahmen: Polizei und andere Sicherheitsbehörden sollen eine solche Gesichtserkennung nutzen dürfen, um bestimmte Straftaten wie Menschenhandel und Terrorismus verfolgen zu können. Zwei Jahre Übergangsfrist Mit der Zustimmung des Parlaments kann das Regelwerk nun in Kraft treten. Zuvor hatten Unterhändler von Europaparlament und EU-Ländern nach langen Verhandlungen im Dezember eine Einigung über eine Regulierung erzielt. Anfang Februar stimmten auch Vertreter der EU-Staaten dem Vorschlag formell zu. Für die Mitgliedstaaten bedeutet das nun, dass sie zunächst schrittweise verbotene Systeme außer Betrieb nehmen müssen. Nach zwei Jahren sollen alle Punkte des Gesetzes vollständig umgesetzt sein. Die Mitgliedstaaten müssen etwa Sanktionen beschließen, wenn Unternehmen die Vorschriften nicht einhalten. Dies können Geldstrafen sein. Privatpersonen, die Verstöße gegen die Vorschriften entdecken, können sich bei nationalen Behörden beschweren. Diese können dann Überwachungsverfahren einleiten und gegebenenfalls Strafen verhängen. Streit gab es zuletzt darüber, dass das Gesetz staatlichen Stellen zu weitreichende Befugnisse beim Einsatz vom künstlicher Intelligenz geben könnte. ( Lesen Sie hier mehr darüber, warum Bürgerrechtsaktivisten das Gesetz kritisieren .)"
Künstliche Intelligenz,Spiegel Online,2024-03-13,https://www.spiegel.de/panorama/bildung/chatgpt-an-schulen-einsatz-von-ki-kaum-geregelt-umfrage-unter-schuelern-a-cdc4a315-bce0-461d-b7d6-93f73d7875c8,ChatGPT an Schulen: Einsatz von KI kaum geregelt – Umfrage unter Schülern - DER SPIEGEL,"Tools wie ChatGPT verfassen blitzschnell Texte oder lösen Aufgaben. Junge Leute sehen darin eher Chancen als Gefahren. Sie werden nach eigenen Aussagen aber kaum im Umgang mit der Technik geschult. Jugendliche und junge Erwachsene stehen einer Umfrage zufolge dem Einsatz von KI-Technologie wie ChatGPT im Unterricht überwiegend positiv gegenüber, wissen aber auch um Herausforderungen. Das zeigt eine Befragung von 14- bis 20-Jährigen durch das Meinungsforschungsinstitut Infratest dimap für die Vodafone Stiftung. Die Umfrage ist nach Angaben der Stiftung repräsentativ. Demnach sagen 73 Prozent der Befragten, sie würden KI eher oder eindeutig als Chance sehen, 27 Prozent sehen eher Gefahren. Die deutliche Mehrheit (67 Prozent) rechnet damit, dass sich der Unterricht durch KI spätestens innerhalb der nächsten fünf Jahre verändern werde. Noch mehr (69 Prozent) glauben, dass gute KI-Kenntnisse für ihre berufliche Zukunft wichtig sein würden. KI-Nutzung abhängig von Lehrkraft In der Schule ist das Thema nach Angaben vieler Befragter aber bisher kaum geregelt. Nur 17 Prozent gaben an, dass die KI-Nutzung an ihrer Schule erlaubt sei und es dazu auch Regeln gebe. Ansonsten hängt es der Umfrage zufolge von einzelnen Lehrkräften ab, wie damit umgegangen wird (38 Prozent). Ein weiterer beachtlicher Anteil (38 Prozent) der Befragten gab auch an, dass die Nutzung von KI an ihrer Schule noch gar kein Thema sei. Die Debatte über die Technologie hatte mit der Freischaltung von ChatGPT für die breite Öffentlichkeit im November 2022 große Fahrt aufgenommen. Seitdem wird im Bildungsbereich darüber diskutiert, wie sich dadurch das Lernen verändern könnte. Da Programme wie ChatGPT genutzt werden können, um blitzschnell Vorträge, Hausarbeiten oder Textinterpretationen zu erstellen oder auch Mathematikaufgaben zu lösen, werden negative Effekte auf das Lernverhalten und die Entwicklung des Urteilsvermögens von Schülerinnen und Schülern befürchtet. Die Umfrage wurde von der Vodafone Stiftung beauftragt. Durchgeführt wurde sie vom Meinungsforschungsinstitut Infratest dimap. Für die Studie wurden nach Angaben der Vodafone Stiftung zwischen dem 3. und 18. Januar 2024 1590 deutschsprachige Jugendliche und junge Erwachsene zwischen 14 und 20 Jahren mittels einer Online-Befragung (CAWI = Computer Assisted Web Interviewing) befragt. Die Stichprobenziehung erfolgte demnach als Quotenstichprobe. Die Quoten seien so angelegt, dass die Stichprobe in den wesentlichen Merkmalen der Struktur der Grundgesamtheit entspreche, also repräsentativ sei. Junge Leute sind sich trotz der positiven Gesamteinstellung bei dem Thema möglicher Nachteile bewusst: Mehr als die Hälfte (57 Prozent) befürchtet, dass eigene Leistungen nicht von den Leistungen der KI unterschieden werden könnten, und rund jeder Zweite (49 Prozent) sieht eine Gefahr, durch die Nutzung von KI-Tools das Lernen an sich zu verlernen. Jeder dritte Befragte (34 Prozent) äußerte die Sorge, dass Schummeln nicht mehr entdeckt werde. Die Umfrage zeigt auch ein Bewusstsein für die Grenzen der Technologie. 64 Prozent ist im Umgang mit KI die Fähigkeit wichtig, nicht alles zu glauben, was man liest oder sieht, und die Fähigkeit, Dinge kritisch zu hinterfragen (50 Prozent). Denn, auch das ist eine Erfahrung mit ChatGPT: Ein vom Programm ausgegebener Text mag in sich stimmig und elegant formuliert klingen, ob die Fakten darin korrekt sind, sollte aber nachgeprüft werden. KI kein Allheilmittel, sondern Werkzeug »KI-Tools sind hervorragend darin, uns bei der Strukturierung komplexer Themen zu unterstützen, aber sie ersetzen nicht den menschlichen Diskurs oder die sozial-emotionale Interaktion im Lernprozess«, sagt Thomas Süße, KI-Experte und Professor für Ingenieurwissenschaften an der Hochschule Bielefeld anlässlich der Veröffentlichung der Studie. »Ein konstruktiver, kritischer Umgang mit KI ermöglicht es, diese Technologie ausgewogen und zielführend im Bildungsbereich einzusetzen.« Lehrkräften empfiehlt er, die Technologien weniger als Allheilmittel, sondern mehr als eine neue Art Werkzeug zu betrachten, das den Lernprozess unterstützen und bereichern könne."
AI,Spiegel Online,2024-03-13,https://www.spiegel.de/netzwelt/netzpolitik/nvidia-devin-und-co-so-veraendert-ki-schon-jetzt-die-welt-kolumne-a-b4d62dbf-7348-4610-84e5-702c404548ad,"Nvidia, Devin und Co.: So verändert KI schon jetzt die Welt - Kolumne - DER SPIEGEL","Kinder sollten coden lernen? Wer Informatik studiert, bekommt einen guten Job? Solche vermeintlichen Gewissheiten dürfen im Zeitalter generativer KI bezweifelt werden. Und das ist erst der Anfang. In einem Podcast sagte Open-AI-Chef Sam Altman Ende vergangenen Jahres etwas so Interessantes wie Unerwartetes: Künstliche Intelligenz sei jetzt zwar mit nie geahnter Größe und Macht da. Das Leben der Menschen gehe aber praktisch unverändert weiter . Im Alltag habe sich nichts geändert. Anders als etwa kurze Zeit nach Einführung des Smartphones . Da ist etwas dran, was man gut nachvollziehen kann, wenn man mit Menschen spricht, die dem riesigen Hype um generative künstliche Intelligenz eher skeptisch gegenüberstehen. Diese fragen dann, was genau sich eigentlich substanziell, tiefgreifend, epochal verändert habe, und die Antwort ist zunächst weniger offensichtlich als etwa beim Smartphone. Man kann aber bei einer gut messbaren Veränderung beginnen, nämlich beim Geld. Oder präziser: bei den Börsenwerten. Sascha Lobo, Jahrgang 1975, ist Autor und Strategieberater mit den Schwerpunkten Internet und digitale Technologien. Gemeinsam mit Jule Lobo beschäftigt er sich im Podcast »Feel the News – Was Deutschland bewegt« mit aktuellen Debattenthemen. Die Chipgestaltungsfirma Nvidia ist der große Börsenstar des KI-Booms. Seit ChatGPT Ende 2022 veröffentlicht wurde, hat sich der Wert des Unternehmens auf über zwei Billionen Dollar rund versechsfacht – und das, obwohl Nvidia selbst keine Chips produziert, sondern sich gewissermaßen nur welche ausdenkt und sie von anderen produzieren lässt. Dieser spektakuläre Erfolg gilt vor allem als Verdienst des taiwanesisch-amerikanischen Gründers Jen-Hsun Huang, der für seine Hellsichtigkeit bezüglich des Techsektors gefeiert wird. Huang sagt zwar offenbar in einer etwas schillernden Bescheidenheit, dass er mit seinen strategischen Chip-Entscheidungen viel Glück hatte. Aber selbst mit Glück beruht der Erfolg von Nvidia vor allem darauf, wie er in den letzten zwei Dekaden die künftige Entwicklung der Techwelt einschätzte. Was Huang kürzlich auf dem World Government Summit in Dubai sagte , wirkt angesichts dessen umso spektakulärer. »In den letzten zehn, fünfzehn Jahren haben fast alle Leute auf solchen Bühnen gesagt, wie wichtig es sei, dass Kinder Informatik lernen. (…) Tatsächlich ist es exakt gegenteilig. Es ist unser Job, Technologien zu entwickeln, damit niemand mehr programmieren muss und damit Menschensprache zur Programmiersprache wird. Jeder ist jetzt ein Programmierer, das ist das Wunder der künstlichen Intelligenz.« Huang meint, Kinder sollten nicht mehr programmieren lernen. Lustvoll ausgeschöpftes Provokationspotenzial? Es gibt einige, oft unausgesprochene Haltungsparallelen, die die Mehrzahl der Techleute im Großen und Ganzen teilt und die sie auch nicht wirklich geheim hält. Die Überzeugung, dass ein tiefes Verständnis digitaler Technologie eine, wenn nicht die essenzielle Fähigkeit ist, gehört dazu. Sie erscheint so selbstverständlich, dass – darauf spielt Huang an – fast alle digitalunternehmerisch erfolgreichen Personen über Jahrzehnte predigten, es müsse mehr Menschen wie sie selbst geben. Daraus erwuchsen konkrete gesellschaftliche und politische Folgen. Da ist etwa die Fokussierung der Bildungslandschaft auf die MINT-Fächer. Oder die Elternweisheit, dass Kinder mit einem Informatikstudium sicher einen guten Job bekommen würden. Und es gab auch das allgemein verbreitete Gefühl, dass Fortschritt und Wohlstand eng mit den digitalen Fähigkeiten zusammenhingen. Das ist alles nicht ganz falsch, oder besser: Das war lange Zeit nicht ganz falsch. Die Frage ist, ob, wie lange und wie flächendeckend es noch stimmt. Was Huang in Dubai sagte, hatte natürlich auch absichtsvolles, wenn nicht lustvoll ausgeschöpftes Provokationspotenzial. Viele große Techmedien und in der Szene bekannte Programmierer sind darauf angesprungen und haben teils erbittert widersprochen. Niemand hört gern von eventuellen Möglichkeiten der eigenen Überflüssigkeit. Durch generative künstliche Intelligenz hat sich die Softwareentwicklung schon längst deutlich verändert, denn viele Entwickler:innen nutzen KI-Assistenten, die kleine und mittlere Aufgaben erledigen können. Zuvor hätte man die passenden Code-Schnipsel in den digitalen Weiten der Software-Archive der Welt suchen und womöglich auf die spezifischen Bedürfnisse händisch anpassen müssen. KI hat die Softwareentwicklung schon heute produktiver, schneller und zum Teil einfacher gemacht. Aber ein tatsächliches Ersetzen des Programmiererjobs, auf das Huang anspielt, war bisher allenfalls in Umrissen zu erkennen. Wenn überhaupt. Jetzt aber hat ein Start-up namens Cognition Labs »Devin« vorgestellt . Devin ist in erster Linie ein weltweiter Social-Media- und PR-Erfolg, wie man ihn sich als Start-up nur wünschen kann. Devin soll der »erste KI-Softwareingenieur« sein, also ein Roboter, der programmieren kann wie ein Mensch, nur schneller und in den meisten Fällen besser – wie alles Folgende nach Angaben der Firma selbst jedenfalls, wenngleich jene Angaben durchaus glaubwürdig wirken. Der KI-Entwickler beherrscht demnach auch Fähigkeiten, die im Software-Umfeld essenziell sind, wie Code zu testen, zu debuggen, auszuführen und zu veröffentlichen. Devin könne ihm unbekannte Programmiersprachen und Technologiekomplexe lernen, heißt es. Devin könne sich nicht nur aus bestehenden Software-Archiven bedienen, sondern neu geschriebene Software dort auch sinnvoll hinterlegen. Und Devin könne eigene KI-Modelle erschaffen, trainieren und feinjustieren. Manche Ergebnisse wirken spektakulär Für Software-ungewohnte Ohren mag sich das alles unverständlich oder belanglos anhören, aber das Ergebnis wirkt eindrucksvoll. Man gibt Devin einen digitalen Auftrag und bekommt ein entsprechendes Ergebnis. Devin kann eine Website bauen, mit einem kleinen Spiel darauf. Er kann eine Reihe Funktionen in die Website einbauen und sie anschließend ins Netz stellen sowie eventuelle Fehler beseitigen. Alles mit ähnlich kurzen und fachlich unspezifischen Prompts wie bei ChatGPT. Der Hersteller Cognition Labs hat Devin die Einstellungstests von KI-Unternehmen durchlaufen lassen – mit Erfolg. Das Start-up hat Devin auch bei Upwork angemeldet, einer Plattform, auf der teilweise umfangreiche Programmierarbeiten an Freelancer rund um die Welt vergeben werden. Devin hat eine Reihe dort gelisteter Arbeiten ausführen können. Der große Vorteil von Devin ist die Autonomie, die deutlich weiter zu gehen scheint als die meisten bisher bekannten Code-Assistenz-Bots. Er kann zum Beispiel umfangreiche Aufgaben in kleinere, sinnvolle Unteraufgaben unterteilen und dann selbstständig abarbeiten –, bis das gewünschte Ergebnis vorliegt. In einigen fachspezifischen Testsituationen, darunter war die Bearbeitung öffentlich einsehbarer Aufgaben in tatsächlich vorhandenen Open-Source-Projekten, hat Devin offenbar ziemlich spektakuläre Ergebnisse erzielt. Das Start-up geht bei der Präsentation von Devin vergleichsweise transparent vor und lässt sich tiefer in die Karten schauen als viele andere kleine und große Unternehmen. Daher kann man – auf den ersten Blick betrachtet – auch sagen: Devin ist das, was man einen autonomen KI-Agenten nennt und auf diese Weise vielleicht der erste Schritt zur Erfüllung von Jen-Hsun Huangs Prophezeiung. Und hier schließt sich der Kreis, was die Anfangsfrage angeht: Was genau hat sich eigentlich wirklich und epochal verändert durch generative KI? Einerseits muss man hierzu sagen, dass wir noch ganz am Anfang dieser Entwicklung stehen und die drastischen Veränderungen in den nächsten Jahren immer offensichtlicher und auch wirkmächtiger werden. Was aber jetzt schon da ist an Alltagsveränderung, das hat Huang nicht nur in Dubai, sondern schon häufiger erzählt. Es ist nämlich der Grund, weshalb Kinder nicht mehr coden lernen sollten: nicht weil Software unwichtig wird, sondern weil sie herzustellen in gewisser Weise demokratisiert wird. »Heute sind alle Menschen Softwareentwickler«, sagt Huang stets dazu. Und was das heißen könnte, kann man ermessen, wenn man die letzte, ähnlich epochale Fähigkeitsdemokratisierung ansieht: Früher konnten nur wenige hochgebildete Teile der Elite lesen und schreiben. Heute können praktisch alle diese Instrumente benutzen – was letztlich die Grundlage war für Demokratie, universale Menschenrechte und Massenwohlstand."
AI,Spiegel Online,2024-03-13,https://www.spiegel.de/netzwelt/netzpolitik/eu-parlament-stimmt-fuer-umfassendes-ki-gesetz-a-1b91bf5e-4adf-4532-bafc-2fed2d068b20,Künstliche Intelligenz: EU-Parlament stimmt für umfassendes KI-Gesetz - DER SPIEGEL,"Navis, automatische Übersetzungen oder die Gesichtserkennung am Handy: Künstliche Intelligenz ist Teil des täglichen Lebens. Ein »historisches« EU-Regelwerk soll den Umgang nun sicherer machen. Das EU-Parlament gibt grünes Licht für schärfere Regeln für künstliche Intelligenz (KI) in der Europäischen Union. Die Parlamentarier haben am Mittwoch in Straßburg mehrheitlich für ein entsprechendes Gesetz gestimmt. Nach Angaben des Parlaments handelt es sich um das weltweit erste KI-Gesetz. Demnach sollen KI-Systeme künftig in verschiedene Risikogruppen eingeteilt werden. Je höher die potenziellen Gefahren einer Anwendung sind, desto höher sollen die Anforderungen sein. Künstliche Intelligenz bezeichnet meist Anwendungen auf Basis maschinellen Lernens, bei denen eine Software große Datenmengen nach Übereinstimmungen durchforstet und daraus Schlussfolgerungen zieht. Sie werden schon jetzt in vielen Bereichen eingesetzt. Zum Beispiel können solche Programme Aufnahmen von Computertomografen schneller und mit einer höheren Genauigkeit auswerten als Menschen. Auch selbstfahrende Autos versuchen so, das Verhalten anderer Verkehrsteilnehmer vorherzusagen. Chatbots wie ChatGPT und automatische erzeugte Playlists von Streamingdiensten arbeiten ebenfalls mit KI. Keine Gesichtserkennung im öffentlichen Raum Das nun anstehende Gesetz geht auf einen Vorschlag der EU-Kommission aus dem Jahr 2021 zurück. Systeme, die als besonders risikoreich gelten und beispielsweise in kritischen Infrastrukturen oder im Bildungs- und Gesundheitswesen eingesetzt werden, müssen demnach strenge Anforderungen erfüllen. Bestimmte KI-Anwendungen, die gegen EU-Werte verstoßen, sollen ganz verboten werden. Dazu gehört etwa die Bewertung von sozialem Verhalten (»Social Scoring«). Damit werden die Bürgerinnen und Bürger in China in Verhaltenskategorien eingeteilt. Auch eine Emotionserkennung am Arbeitsplatz und in Bildungseinrichtungen soll es in der EU nicht geben. Die Gesichtserkennung im öffentlichen Raum – also zum Beispiel durch Videoüberwachung an öffentlichen Plätzen – soll ebenfalls grundsätzlich nicht erlaubt sein. Dabei gibt es jedoch Ausnahmen: Polizei und andere Sicherheitsbehörden sollen eine solche Gesichtserkennung nutzen dürfen, um bestimmte Straftaten wie Menschenhandel und Terrorismus verfolgen zu können. Zwei Jahre Übergangsfrist Mit der Zustimmung des Parlaments kann das Regelwerk nun in Kraft treten. Zuvor hatten Unterhändler von Europaparlament und EU-Ländern nach langen Verhandlungen im Dezember eine Einigung über eine Regulierung erzielt. Anfang Februar stimmten auch Vertreter der EU-Staaten dem Vorschlag formell zu. Für die Mitgliedstaaten bedeutet das nun, dass sie zunächst schrittweise verbotene Systeme außer Betrieb nehmen müssen. Nach zwei Jahren sollen alle Punkte des Gesetzes vollständig umgesetzt sein. Die Mitgliedstaaten müssen etwa Sanktionen beschließen, wenn Unternehmen die Vorschriften nicht einhalten. Dies können Geldstrafen sein. Privatpersonen, die Verstöße gegen die Vorschriften entdecken, können sich bei nationalen Behörden beschweren. Diese können dann Überwachungsverfahren einleiten und gegebenenfalls Strafen verhängen. Streit gab es zuletzt darüber, dass das Gesetz staatlichen Stellen zu weitreichende Befugnisse beim Einsatz vom künstlicher Intelligenz geben könnte. ( Lesen Sie hier mehr darüber, warum Bürgerrechtsaktivisten das Gesetz kritisieren .)"
Artificial Intelligence,Spiegel Online,2024-03-13,https://www.spiegel.de/netzwelt/netzpolitik/eu-parlament-stimmt-fuer-umfassendes-ki-gesetz-a-1b91bf5e-4adf-4532-bafc-2fed2d068b20,Künstliche Intelligenz: EU-Parlament stimmt für umfassendes KI-Gesetz - DER SPIEGEL,"Navis, automatische Übersetzungen oder die Gesichtserkennung am Handy: Künstliche Intelligenz ist Teil des täglichen Lebens. Ein »historisches« EU-Regelwerk soll den Umgang nun sicherer machen. Das EU-Parlament gibt grünes Licht für schärfere Regeln für künstliche Intelligenz (KI) in der Europäischen Union. Die Parlamentarier haben am Mittwoch in Straßburg mehrheitlich für ein entsprechendes Gesetz gestimmt. Nach Angaben des Parlaments handelt es sich um das weltweit erste KI-Gesetz. Demnach sollen KI-Systeme künftig in verschiedene Risikogruppen eingeteilt werden. Je höher die potenziellen Gefahren einer Anwendung sind, desto höher sollen die Anforderungen sein. Künstliche Intelligenz bezeichnet meist Anwendungen auf Basis maschinellen Lernens, bei denen eine Software große Datenmengen nach Übereinstimmungen durchforstet und daraus Schlussfolgerungen zieht. Sie werden schon jetzt in vielen Bereichen eingesetzt. Zum Beispiel können solche Programme Aufnahmen von Computertomografen schneller und mit einer höheren Genauigkeit auswerten als Menschen. Auch selbstfahrende Autos versuchen so, das Verhalten anderer Verkehrsteilnehmer vorherzusagen. Chatbots wie ChatGPT und automatische erzeugte Playlists von Streamingdiensten arbeiten ebenfalls mit KI. Keine Gesichtserkennung im öffentlichen Raum Das nun anstehende Gesetz geht auf einen Vorschlag der EU-Kommission aus dem Jahr 2021 zurück. Systeme, die als besonders risikoreich gelten und beispielsweise in kritischen Infrastrukturen oder im Bildungs- und Gesundheitswesen eingesetzt werden, müssen demnach strenge Anforderungen erfüllen. Bestimmte KI-Anwendungen, die gegen EU-Werte verstoßen, sollen ganz verboten werden. Dazu gehört etwa die Bewertung von sozialem Verhalten (»Social Scoring«). Damit werden die Bürgerinnen und Bürger in China in Verhaltenskategorien eingeteilt. Auch eine Emotionserkennung am Arbeitsplatz und in Bildungseinrichtungen soll es in der EU nicht geben. Die Gesichtserkennung im öffentlichen Raum – also zum Beispiel durch Videoüberwachung an öffentlichen Plätzen – soll ebenfalls grundsätzlich nicht erlaubt sein. Dabei gibt es jedoch Ausnahmen: Polizei und andere Sicherheitsbehörden sollen eine solche Gesichtserkennung nutzen dürfen, um bestimmte Straftaten wie Menschenhandel und Terrorismus verfolgen zu können. Zwei Jahre Übergangsfrist Mit der Zustimmung des Parlaments kann das Regelwerk nun in Kraft treten. Zuvor hatten Unterhändler von Europaparlament und EU-Ländern nach langen Verhandlungen im Dezember eine Einigung über eine Regulierung erzielt. Anfang Februar stimmten auch Vertreter der EU-Staaten dem Vorschlag formell zu. Für die Mitgliedstaaten bedeutet das nun, dass sie zunächst schrittweise verbotene Systeme außer Betrieb nehmen müssen. Nach zwei Jahren sollen alle Punkte des Gesetzes vollständig umgesetzt sein. Die Mitgliedstaaten müssen etwa Sanktionen beschließen, wenn Unternehmen die Vorschriften nicht einhalten. Dies können Geldstrafen sein. Privatpersonen, die Verstöße gegen die Vorschriften entdecken, können sich bei nationalen Behörden beschweren. Diese können dann Überwachungsverfahren einleiten und gegebenenfalls Strafen verhängen. Streit gab es zuletzt darüber, dass das Gesetz staatlichen Stellen zu weitreichende Befugnisse beim Einsatz vom künstlicher Intelligenz geben könnte. ( Lesen Sie hier mehr darüber, warum Bürgerrechtsaktivisten das Gesetz kritisieren .)"
KI,Spiegel Online,2024-03-13,https://www.spiegel.de/netzwelt/netzpolitik/nvidia-devin-und-co-so-veraendert-ki-schon-jetzt-die-welt-kolumne-a-b4d62dbf-7348-4610-84e5-702c404548ad,"Nvidia, Devin und Co.: So verändert KI schon jetzt die Welt - Kolumne - DER SPIEGEL","Kinder sollten coden lernen? Wer Informatik studiert, bekommt einen guten Job? Solche vermeintlichen Gewissheiten dürfen im Zeitalter generativer KI bezweifelt werden. Und das ist erst der Anfang. In einem Podcast sagte Open-AI-Chef Sam Altman Ende vergangenen Jahres etwas so Interessantes wie Unerwartetes: Künstliche Intelligenz sei jetzt zwar mit nie geahnter Größe und Macht da. Das Leben der Menschen gehe aber praktisch unverändert weiter . Im Alltag habe sich nichts geändert. Anders als etwa kurze Zeit nach Einführung des Smartphones . Da ist etwas dran, was man gut nachvollziehen kann, wenn man mit Menschen spricht, die dem riesigen Hype um generative künstliche Intelligenz eher skeptisch gegenüberstehen. Diese fragen dann, was genau sich eigentlich substanziell, tiefgreifend, epochal verändert habe, und die Antwort ist zunächst weniger offensichtlich als etwa beim Smartphone. Man kann aber bei einer gut messbaren Veränderung beginnen, nämlich beim Geld. Oder präziser: bei den Börsenwerten. Sascha Lobo, Jahrgang 1975, ist Autor und Strategieberater mit den Schwerpunkten Internet und digitale Technologien. Gemeinsam mit Jule Lobo beschäftigt er sich im Podcast »Feel the News – Was Deutschland bewegt« mit aktuellen Debattenthemen. Die Chipgestaltungsfirma Nvidia ist der große Börsenstar des KI-Booms. Seit ChatGPT Ende 2022 veröffentlicht wurde, hat sich der Wert des Unternehmens auf über zwei Billionen Dollar rund versechsfacht – und das, obwohl Nvidia selbst keine Chips produziert, sondern sich gewissermaßen nur welche ausdenkt und sie von anderen produzieren lässt. Dieser spektakuläre Erfolg gilt vor allem als Verdienst des taiwanesisch-amerikanischen Gründers Jen-Hsun Huang, der für seine Hellsichtigkeit bezüglich des Techsektors gefeiert wird. Huang sagt zwar offenbar in einer etwas schillernden Bescheidenheit, dass er mit seinen strategischen Chip-Entscheidungen viel Glück hatte. Aber selbst mit Glück beruht der Erfolg von Nvidia vor allem darauf, wie er in den letzten zwei Dekaden die künftige Entwicklung der Techwelt einschätzte. Was Huang kürzlich auf dem World Government Summit in Dubai sagte , wirkt angesichts dessen umso spektakulärer. »In den letzten zehn, fünfzehn Jahren haben fast alle Leute auf solchen Bühnen gesagt, wie wichtig es sei, dass Kinder Informatik lernen. (…) Tatsächlich ist es exakt gegenteilig. Es ist unser Job, Technologien zu entwickeln, damit niemand mehr programmieren muss und damit Menschensprache zur Programmiersprache wird. Jeder ist jetzt ein Programmierer, das ist das Wunder der künstlichen Intelligenz.« Huang meint, Kinder sollten nicht mehr programmieren lernen. Lustvoll ausgeschöpftes Provokationspotenzial? Es gibt einige, oft unausgesprochene Haltungsparallelen, die die Mehrzahl der Techleute im Großen und Ganzen teilt und die sie auch nicht wirklich geheim hält. Die Überzeugung, dass ein tiefes Verständnis digitaler Technologie eine, wenn nicht die essenzielle Fähigkeit ist, gehört dazu. Sie erscheint so selbstverständlich, dass – darauf spielt Huang an – fast alle digitalunternehmerisch erfolgreichen Personen über Jahrzehnte predigten, es müsse mehr Menschen wie sie selbst geben. Daraus erwuchsen konkrete gesellschaftliche und politische Folgen. Da ist etwa die Fokussierung der Bildungslandschaft auf die MINT-Fächer. Oder die Elternweisheit, dass Kinder mit einem Informatikstudium sicher einen guten Job bekommen würden. Und es gab auch das allgemein verbreitete Gefühl, dass Fortschritt und Wohlstand eng mit den digitalen Fähigkeiten zusammenhingen. Das ist alles nicht ganz falsch, oder besser: Das war lange Zeit nicht ganz falsch. Die Frage ist, ob, wie lange und wie flächendeckend es noch stimmt. Was Huang in Dubai sagte, hatte natürlich auch absichtsvolles, wenn nicht lustvoll ausgeschöpftes Provokationspotenzial. Viele große Techmedien und in der Szene bekannte Programmierer sind darauf angesprungen und haben teils erbittert widersprochen. Niemand hört gern von eventuellen Möglichkeiten der eigenen Überflüssigkeit. Durch generative künstliche Intelligenz hat sich die Softwareentwicklung schon längst deutlich verändert, denn viele Entwickler:innen nutzen KI-Assistenten, die kleine und mittlere Aufgaben erledigen können. Zuvor hätte man die passenden Code-Schnipsel in den digitalen Weiten der Software-Archive der Welt suchen und womöglich auf die spezifischen Bedürfnisse händisch anpassen müssen. KI hat die Softwareentwicklung schon heute produktiver, schneller und zum Teil einfacher gemacht. Aber ein tatsächliches Ersetzen des Programmiererjobs, auf das Huang anspielt, war bisher allenfalls in Umrissen zu erkennen. Wenn überhaupt. Jetzt aber hat ein Start-up namens Cognition Labs »Devin« vorgestellt . Devin ist in erster Linie ein weltweiter Social-Media- und PR-Erfolg, wie man ihn sich als Start-up nur wünschen kann. Devin soll der »erste KI-Softwareingenieur« sein, also ein Roboter, der programmieren kann wie ein Mensch, nur schneller und in den meisten Fällen besser – wie alles Folgende nach Angaben der Firma selbst jedenfalls, wenngleich jene Angaben durchaus glaubwürdig wirken. Der KI-Entwickler beherrscht demnach auch Fähigkeiten, die im Software-Umfeld essenziell sind, wie Code zu testen, zu debuggen, auszuführen und zu veröffentlichen. Devin könne ihm unbekannte Programmiersprachen und Technologiekomplexe lernen, heißt es. Devin könne sich nicht nur aus bestehenden Software-Archiven bedienen, sondern neu geschriebene Software dort auch sinnvoll hinterlegen. Und Devin könne eigene KI-Modelle erschaffen, trainieren und feinjustieren. Manche Ergebnisse wirken spektakulär Für Software-ungewohnte Ohren mag sich das alles unverständlich oder belanglos anhören, aber das Ergebnis wirkt eindrucksvoll. Man gibt Devin einen digitalen Auftrag und bekommt ein entsprechendes Ergebnis. Devin kann eine Website bauen, mit einem kleinen Spiel darauf. Er kann eine Reihe Funktionen in die Website einbauen und sie anschließend ins Netz stellen sowie eventuelle Fehler beseitigen. Alles mit ähnlich kurzen und fachlich unspezifischen Prompts wie bei ChatGPT. Der Hersteller Cognition Labs hat Devin die Einstellungstests von KI-Unternehmen durchlaufen lassen – mit Erfolg. Das Start-up hat Devin auch bei Upwork angemeldet, einer Plattform, auf der teilweise umfangreiche Programmierarbeiten an Freelancer rund um die Welt vergeben werden. Devin hat eine Reihe dort gelisteter Arbeiten ausführen können. Der große Vorteil von Devin ist die Autonomie, die deutlich weiter zu gehen scheint als die meisten bisher bekannten Code-Assistenz-Bots. Er kann zum Beispiel umfangreiche Aufgaben in kleinere, sinnvolle Unteraufgaben unterteilen und dann selbstständig abarbeiten –, bis das gewünschte Ergebnis vorliegt. In einigen fachspezifischen Testsituationen, darunter war die Bearbeitung öffentlich einsehbarer Aufgaben in tatsächlich vorhandenen Open-Source-Projekten, hat Devin offenbar ziemlich spektakuläre Ergebnisse erzielt. Das Start-up geht bei der Präsentation von Devin vergleichsweise transparent vor und lässt sich tiefer in die Karten schauen als viele andere kleine und große Unternehmen. Daher kann man – auf den ersten Blick betrachtet – auch sagen: Devin ist das, was man einen autonomen KI-Agenten nennt und auf diese Weise vielleicht der erste Schritt zur Erfüllung von Jen-Hsun Huangs Prophezeiung. Und hier schließt sich der Kreis, was die Anfangsfrage angeht: Was genau hat sich eigentlich wirklich und epochal verändert durch generative KI? Einerseits muss man hierzu sagen, dass wir noch ganz am Anfang dieser Entwicklung stehen und die drastischen Veränderungen in den nächsten Jahren immer offensichtlicher und auch wirkmächtiger werden. Was aber jetzt schon da ist an Alltagsveränderung, das hat Huang nicht nur in Dubai, sondern schon häufiger erzählt. Es ist nämlich der Grund, weshalb Kinder nicht mehr coden lernen sollten: nicht weil Software unwichtig wird, sondern weil sie herzustellen in gewisser Weise demokratisiert wird. »Heute sind alle Menschen Softwareentwickler«, sagt Huang stets dazu. Und was das heißen könnte, kann man ermessen, wenn man die letzte, ähnlich epochale Fähigkeitsdemokratisierung ansieht: Früher konnten nur wenige hochgebildete Teile der Elite lesen und schreiben. Heute können praktisch alle diese Instrumente benutzen – was letztlich die Grundlage war für Demokratie, universale Menschenrechte und Massenwohlstand."
KI,Spiegel Online,2024-03-13,https://www.spiegel.de/netzwelt/netzpolitik/meta-google-tiktok-tech-konzerne-wollen-im-superwahljahr-2024-mit-ki-gegen-luegen-vorgehen-a-7ecc06b5-90fd-4839-b6c7-fbeed9d11b80,"Meta, Google, Tiktok: Tech-Konzerne wollen im Superwahljahr 2024 mit KI gegen Lügen vorgehen - DER SPIEGEL","Falsche Politikerstimmen, manipulierte Bilder, staatliche Hetzer im Netz: Vor den Wahlen in Europa und den USA rüsten die großen Techkonzerne gegen Lügenkampagnen aus China oder Russland auf. Doch was ist ihre Verteidigung wert?"
KI,Spiegel Online,2024-03-13,https://www.spiegel.de/netzwelt/netzpolitik/eu-parlament-stimmt-fuer-umfassendes-ki-gesetz-a-1b91bf5e-4adf-4532-bafc-2fed2d068b20,Künstliche Intelligenz: EU-Parlament stimmt für umfassendes KI-Gesetz - DER SPIEGEL,"Navis, automatische Übersetzungen oder die Gesichtserkennung am Handy: Künstliche Intelligenz ist Teil des täglichen Lebens. Ein »historisches« EU-Regelwerk soll den Umgang nun sicherer machen. Das EU-Parlament gibt grünes Licht für schärfere Regeln für künstliche Intelligenz (KI) in der Europäischen Union. Die Parlamentarier haben am Mittwoch in Straßburg mehrheitlich für ein entsprechendes Gesetz gestimmt. Nach Angaben des Parlaments handelt es sich um das weltweit erste KI-Gesetz. Demnach sollen KI-Systeme künftig in verschiedene Risikogruppen eingeteilt werden. Je höher die potenziellen Gefahren einer Anwendung sind, desto höher sollen die Anforderungen sein. Künstliche Intelligenz bezeichnet meist Anwendungen auf Basis maschinellen Lernens, bei denen eine Software große Datenmengen nach Übereinstimmungen durchforstet und daraus Schlussfolgerungen zieht. Sie werden schon jetzt in vielen Bereichen eingesetzt. Zum Beispiel können solche Programme Aufnahmen von Computertomografen schneller und mit einer höheren Genauigkeit auswerten als Menschen. Auch selbstfahrende Autos versuchen so, das Verhalten anderer Verkehrsteilnehmer vorherzusagen. Chatbots wie ChatGPT und automatische erzeugte Playlists von Streamingdiensten arbeiten ebenfalls mit KI. Keine Gesichtserkennung im öffentlichen Raum Das nun anstehende Gesetz geht auf einen Vorschlag der EU-Kommission aus dem Jahr 2021 zurück. Systeme, die als besonders risikoreich gelten und beispielsweise in kritischen Infrastrukturen oder im Bildungs- und Gesundheitswesen eingesetzt werden, müssen demnach strenge Anforderungen erfüllen. Bestimmte KI-Anwendungen, die gegen EU-Werte verstoßen, sollen ganz verboten werden. Dazu gehört etwa die Bewertung von sozialem Verhalten (»Social Scoring«). Damit werden die Bürgerinnen und Bürger in China in Verhaltenskategorien eingeteilt. Auch eine Emotionserkennung am Arbeitsplatz und in Bildungseinrichtungen soll es in der EU nicht geben. Die Gesichtserkennung im öffentlichen Raum – also zum Beispiel durch Videoüberwachung an öffentlichen Plätzen – soll ebenfalls grundsätzlich nicht erlaubt sein. Dabei gibt es jedoch Ausnahmen: Polizei und andere Sicherheitsbehörden sollen eine solche Gesichtserkennung nutzen dürfen, um bestimmte Straftaten wie Menschenhandel und Terrorismus verfolgen zu können. Zwei Jahre Übergangsfrist Mit der Zustimmung des Parlaments kann das Regelwerk nun in Kraft treten. Zuvor hatten Unterhändler von Europaparlament und EU-Ländern nach langen Verhandlungen im Dezember eine Einigung über eine Regulierung erzielt. Anfang Februar stimmten auch Vertreter der EU-Staaten dem Vorschlag formell zu. Für die Mitgliedstaaten bedeutet das nun, dass sie zunächst schrittweise verbotene Systeme außer Betrieb nehmen müssen. Nach zwei Jahren sollen alle Punkte des Gesetzes vollständig umgesetzt sein. Die Mitgliedstaaten müssen etwa Sanktionen beschließen, wenn Unternehmen die Vorschriften nicht einhalten. Dies können Geldstrafen sein. Privatpersonen, die Verstöße gegen die Vorschriften entdecken, können sich bei nationalen Behörden beschweren. Diese können dann Überwachungsverfahren einleiten und gegebenenfalls Strafen verhängen. Streit gab es zuletzt darüber, dass das Gesetz staatlichen Stellen zu weitreichende Befugnisse beim Einsatz vom künstlicher Intelligenz geben könnte. ( Lesen Sie hier mehr darüber, warum Bürgerrechtsaktivisten das Gesetz kritisieren .)"
KI,Spiegel Online,2024-03-13,https://www.spiegel.de/panorama/bildung/chatgpt-an-schulen-einsatz-von-ki-kaum-geregelt-umfrage-unter-schuelern-a-cdc4a315-bce0-461d-b7d6-93f73d7875c8,ChatGPT an Schulen: Einsatz von KI kaum geregelt – Umfrage unter Schülern - DER SPIEGEL,"Tools wie ChatGPT verfassen blitzschnell Texte oder lösen Aufgaben. Junge Leute sehen darin eher Chancen als Gefahren. Sie werden nach eigenen Aussagen aber kaum im Umgang mit der Technik geschult. Jugendliche und junge Erwachsene stehen einer Umfrage zufolge dem Einsatz von KI-Technologie wie ChatGPT im Unterricht überwiegend positiv gegenüber, wissen aber auch um Herausforderungen. Das zeigt eine Befragung von 14- bis 20-Jährigen durch das Meinungsforschungsinstitut Infratest dimap für die Vodafone Stiftung. Die Umfrage ist nach Angaben der Stiftung repräsentativ. Demnach sagen 73 Prozent der Befragten, sie würden KI eher oder eindeutig als Chance sehen, 27 Prozent sehen eher Gefahren. Die deutliche Mehrheit (67 Prozent) rechnet damit, dass sich der Unterricht durch KI spätestens innerhalb der nächsten fünf Jahre verändern werde. Noch mehr (69 Prozent) glauben, dass gute KI-Kenntnisse für ihre berufliche Zukunft wichtig sein würden. KI-Nutzung abhängig von Lehrkraft In der Schule ist das Thema nach Angaben vieler Befragter aber bisher kaum geregelt. Nur 17 Prozent gaben an, dass die KI-Nutzung an ihrer Schule erlaubt sei und es dazu auch Regeln gebe. Ansonsten hängt es der Umfrage zufolge von einzelnen Lehrkräften ab, wie damit umgegangen wird (38 Prozent). Ein weiterer beachtlicher Anteil (38 Prozent) der Befragten gab auch an, dass die Nutzung von KI an ihrer Schule noch gar kein Thema sei. Die Debatte über die Technologie hatte mit der Freischaltung von ChatGPT für die breite Öffentlichkeit im November 2022 große Fahrt aufgenommen. Seitdem wird im Bildungsbereich darüber diskutiert, wie sich dadurch das Lernen verändern könnte. Da Programme wie ChatGPT genutzt werden können, um blitzschnell Vorträge, Hausarbeiten oder Textinterpretationen zu erstellen oder auch Mathematikaufgaben zu lösen, werden negative Effekte auf das Lernverhalten und die Entwicklung des Urteilsvermögens von Schülerinnen und Schülern befürchtet. Die Umfrage wurde von der Vodafone Stiftung beauftragt. Durchgeführt wurde sie vom Meinungsforschungsinstitut Infratest dimap. Für die Studie wurden nach Angaben der Vodafone Stiftung zwischen dem 3. und 18. Januar 2024 1590 deutschsprachige Jugendliche und junge Erwachsene zwischen 14 und 20 Jahren mittels einer Online-Befragung (CAWI = Computer Assisted Web Interviewing) befragt. Die Stichprobenziehung erfolgte demnach als Quotenstichprobe. Die Quoten seien so angelegt, dass die Stichprobe in den wesentlichen Merkmalen der Struktur der Grundgesamtheit entspreche, also repräsentativ sei. Junge Leute sind sich trotz der positiven Gesamteinstellung bei dem Thema möglicher Nachteile bewusst: Mehr als die Hälfte (57 Prozent) befürchtet, dass eigene Leistungen nicht von den Leistungen der KI unterschieden werden könnten, und rund jeder Zweite (49 Prozent) sieht eine Gefahr, durch die Nutzung von KI-Tools das Lernen an sich zu verlernen. Jeder dritte Befragte (34 Prozent) äußerte die Sorge, dass Schummeln nicht mehr entdeckt werde. Die Umfrage zeigt auch ein Bewusstsein für die Grenzen der Technologie. 64 Prozent ist im Umgang mit KI die Fähigkeit wichtig, nicht alles zu glauben, was man liest oder sieht, und die Fähigkeit, Dinge kritisch zu hinterfragen (50 Prozent). Denn, auch das ist eine Erfahrung mit ChatGPT: Ein vom Programm ausgegebener Text mag in sich stimmig und elegant formuliert klingen, ob die Fakten darin korrekt sind, sollte aber nachgeprüft werden. KI kein Allheilmittel, sondern Werkzeug »KI-Tools sind hervorragend darin, uns bei der Strukturierung komplexer Themen zu unterstützen, aber sie ersetzen nicht den menschlichen Diskurs oder die sozial-emotionale Interaktion im Lernprozess«, sagt Thomas Süße, KI-Experte und Professor für Ingenieurwissenschaften an der Hochschule Bielefeld anlässlich der Veröffentlichung der Studie. »Ein konstruktiver, kritischer Umgang mit KI ermöglicht es, diese Technologie ausgewogen und zielführend im Bildungsbereich einzusetzen.« Lehrkräften empfiehlt er, die Technologien weniger als Allheilmittel, sondern mehr als eine neue Art Werkzeug zu betrachten, das den Lernprozess unterstützen und bereichern könne."
Künstliche Intelligenz,Spiegel Online,2024-03-07,https://www.spiegel.de/netzwelt/us-militaerforscher-testen-kuenstliche-intelligenz-in-der-schlachtplanung-a-625b9c02-35a5-42eb-a6a9-988de34c22ea,US-Militärforscher testen künstliche Intelligenz in der Schlachtplanung - DER SPIEGEL,"Wissenschaftler der US-Armee haben untersucht, inwiefern künstliche Intelligenz helfen könnte, Angriffe im Schlachtfeld besser zu planen. Ihr Experiment haben sie in einem berühmten Videospiel durchgeführt. Wissenschaftler des zentralen Forschungslabors der US-Armee haben untersucht, inwiefern sich ihre Soldaten die jüngsten Fortschritte bei künstlicher Intelligenz im Schlachtfeld zunutze machen könnten. Die Forscher des United States Army Research Laboratory haben dabei unter anderem auf das Sprachmodell GPT-4 von OpenAI zurückgegriffen. Das Modell bildet die Grundlage des populären KI-Chatbots ChatGPT, kann aber auch für andere Anwendungen genutzt werden. In einem wissenschaftlichen Paper beschreiben die Forscher Vinicius Goecks und Nicholas Waytowich, wie sie einen virtuellen Assistenten erschaffen haben, der bei der Entscheidungsfindung im Schlachtfeld helfen könnte. Zunächst brachten sie dem Programm demnach bei, als Assistent eines militärischen Befehlshabers zu agieren. Dann fütterten sie die künstliche Intelligenz unter anderem mit den militärischen Zielen eines fiktiven Szenarios, mit der eigenen militärischen Doktrin und mit Informationen über die Geländegegebenheiten und über die eigenen und die feindlichen Streitkräfte. Das Experiment führten die Forscher nicht in einem echten Militäreinsatz oder einem Militärmanöver durch, sondern in einem Videospiel. Dazu nutzten sie eine angepasste Karte aus dem bekannten Videospiel StarCraft II und spielten dort das Szenario »Operation TigerClaw« durch, bei dem es darum geht, feindliche Streitkräfte zu zerstören. Ihren virtuellen Assistenten tauften sie COA-GPT. Die Abkürzung steht dabei für Course of Action, eine im US-Militär verankerte Form der Einsatzplanung. Zu viel Vertrauen in die KI In ihrer noch nicht durch andere Wissenschaftler begutachteten Studie führten die Forscher aus, dass COA-GPT besser als Menschen darin sei, schnell eine strategische Einsatzplanung zu erstellen. Frei agieren konnte die künstliche Intelligenz aber nicht. Die Wissenschaftler haben das Programm so entwickelt, dass ein Mensch die Erstellung der Einsatzplanung überprüfen und freigeben muss. Die Forscher stellten auch fest, dass GPT-4 besser als andere KI-Sprachmodelle in ihrem Szenario abschnitt. OpenAI hatte bereits im Januar einige Anwendungen ihrer Technologie zu militärischen Zwecken freigegeben, wie das Techmagazin »The Intercept« berichtete . Zur Waffenentwicklung darf die Technik demnach aber nicht verwendet werden. Gegenüber dem Wissenschaftsmagazin »New Scientist«, das zuerst über die Studie berichtete , warnte die Expertin Carol Smith davor, dass Menschen dazu neigen könnten, den Ratschlägen solcher KI-Systeme zu sehr zu vertrauen. »Ich würde nicht empfehlen, ein Sprachmodell oder generative KI-Systeme in einer Situation einzusetzen, in der viel auf dem Spiel steht«, so Smith, die am Software Engineering Institute an der Carnegie Mellon University in Pennsylvania forscht."
Artificial Intelligence,Spiegel Online,2024-03-07,https://www.spiegel.de/netzwelt/us-militaerforscher-testen-kuenstliche-intelligenz-in-der-schlachtplanung-a-625b9c02-35a5-42eb-a6a9-988de34c22ea,US-Militärforscher testen künstliche Intelligenz in der Schlachtplanung - DER SPIEGEL,"Wissenschaftler der US-Armee haben untersucht, inwiefern künstliche Intelligenz helfen könnte, Angriffe im Schlachtfeld besser zu planen. Ihr Experiment haben sie in einem berühmten Videospiel durchgeführt. Wissenschaftler des zentralen Forschungslabors der US-Armee haben untersucht, inwiefern sich ihre Soldaten die jüngsten Fortschritte bei künstlicher Intelligenz im Schlachtfeld zunutze machen könnten. Die Forscher des United States Army Research Laboratory haben dabei unter anderem auf das Sprachmodell GPT-4 von OpenAI zurückgegriffen. Das Modell bildet die Grundlage des populären KI-Chatbots ChatGPT, kann aber auch für andere Anwendungen genutzt werden. In einem wissenschaftlichen Paper beschreiben die Forscher Vinicius Goecks und Nicholas Waytowich, wie sie einen virtuellen Assistenten erschaffen haben, der bei der Entscheidungsfindung im Schlachtfeld helfen könnte. Zunächst brachten sie dem Programm demnach bei, als Assistent eines militärischen Befehlshabers zu agieren. Dann fütterten sie die künstliche Intelligenz unter anderem mit den militärischen Zielen eines fiktiven Szenarios, mit der eigenen militärischen Doktrin und mit Informationen über die Geländegegebenheiten und über die eigenen und die feindlichen Streitkräfte. Das Experiment führten die Forscher nicht in einem echten Militäreinsatz oder einem Militärmanöver durch, sondern in einem Videospiel. Dazu nutzten sie eine angepasste Karte aus dem bekannten Videospiel StarCraft II und spielten dort das Szenario »Operation TigerClaw« durch, bei dem es darum geht, feindliche Streitkräfte zu zerstören. Ihren virtuellen Assistenten tauften sie COA-GPT. Die Abkürzung steht dabei für Course of Action, eine im US-Militär verankerte Form der Einsatzplanung. Zu viel Vertrauen in die KI In ihrer noch nicht durch andere Wissenschaftler begutachteten Studie führten die Forscher aus, dass COA-GPT besser als Menschen darin sei, schnell eine strategische Einsatzplanung zu erstellen. Frei agieren konnte die künstliche Intelligenz aber nicht. Die Wissenschaftler haben das Programm so entwickelt, dass ein Mensch die Erstellung der Einsatzplanung überprüfen und freigeben muss. Die Forscher stellten auch fest, dass GPT-4 besser als andere KI-Sprachmodelle in ihrem Szenario abschnitt. OpenAI hatte bereits im Januar einige Anwendungen ihrer Technologie zu militärischen Zwecken freigegeben, wie das Techmagazin »The Intercept« berichtete . Zur Waffenentwicklung darf die Technik demnach aber nicht verwendet werden. Gegenüber dem Wissenschaftsmagazin »New Scientist«, das zuerst über die Studie berichtete , warnte die Expertin Carol Smith davor, dass Menschen dazu neigen könnten, den Ratschlägen solcher KI-Systeme zu sehr zu vertrauen. »Ich würde nicht empfehlen, ein Sprachmodell oder generative KI-Systeme in einer Situation einzusetzen, in der viel auf dem Spiel steht«, so Smith, die am Software Engineering Institute an der Carnegie Mellon University in Pennsylvania forscht."
KI,Spiegel Online,2024-03-07,https://www.spiegel.de/netzwelt/us-militaerforscher-testen-kuenstliche-intelligenz-in-der-schlachtplanung-a-625b9c02-35a5-42eb-a6a9-988de34c22ea,US-Militärforscher testen künstliche Intelligenz in der Schlachtplanung - DER SPIEGEL,"Wissenschaftler der US-Armee haben untersucht, inwiefern künstliche Intelligenz helfen könnte, Angriffe im Schlachtfeld besser zu planen. Ihr Experiment haben sie in einem berühmten Videospiel durchgeführt. Wissenschaftler des zentralen Forschungslabors der US-Armee haben untersucht, inwiefern sich ihre Soldaten die jüngsten Fortschritte bei künstlicher Intelligenz im Schlachtfeld zunutze machen könnten. Die Forscher des United States Army Research Laboratory haben dabei unter anderem auf das Sprachmodell GPT-4 von OpenAI zurückgegriffen. Das Modell bildet die Grundlage des populären KI-Chatbots ChatGPT, kann aber auch für andere Anwendungen genutzt werden. In einem wissenschaftlichen Paper beschreiben die Forscher Vinicius Goecks und Nicholas Waytowich, wie sie einen virtuellen Assistenten erschaffen haben, der bei der Entscheidungsfindung im Schlachtfeld helfen könnte. Zunächst brachten sie dem Programm demnach bei, als Assistent eines militärischen Befehlshabers zu agieren. Dann fütterten sie die künstliche Intelligenz unter anderem mit den militärischen Zielen eines fiktiven Szenarios, mit der eigenen militärischen Doktrin und mit Informationen über die Geländegegebenheiten und über die eigenen und die feindlichen Streitkräfte. Das Experiment führten die Forscher nicht in einem echten Militäreinsatz oder einem Militärmanöver durch, sondern in einem Videospiel. Dazu nutzten sie eine angepasste Karte aus dem bekannten Videospiel StarCraft II und spielten dort das Szenario »Operation TigerClaw« durch, bei dem es darum geht, feindliche Streitkräfte zu zerstören. Ihren virtuellen Assistenten tauften sie COA-GPT. Die Abkürzung steht dabei für Course of Action, eine im US-Militär verankerte Form der Einsatzplanung. Zu viel Vertrauen in die KI In ihrer noch nicht durch andere Wissenschaftler begutachteten Studie führten die Forscher aus, dass COA-GPT besser als Menschen darin sei, schnell eine strategische Einsatzplanung zu erstellen. Frei agieren konnte die künstliche Intelligenz aber nicht. Die Wissenschaftler haben das Programm so entwickelt, dass ein Mensch die Erstellung der Einsatzplanung überprüfen und freigeben muss. Die Forscher stellten auch fest, dass GPT-4 besser als andere KI-Sprachmodelle in ihrem Szenario abschnitt. OpenAI hatte bereits im Januar einige Anwendungen ihrer Technologie zu militärischen Zwecken freigegeben, wie das Techmagazin »The Intercept« berichtete . Zur Waffenentwicklung darf die Technik demnach aber nicht verwendet werden. Gegenüber dem Wissenschaftsmagazin »New Scientist«, das zuerst über die Studie berichtete , warnte die Expertin Carol Smith davor, dass Menschen dazu neigen könnten, den Ratschlägen solcher KI-Systeme zu sehr zu vertrauen. »Ich würde nicht empfehlen, ein Sprachmodell oder generative KI-Systeme in einer Situation einzusetzen, in der viel auf dem Spiel steht«, so Smith, die am Software Engineering Institute an der Carnegie Mellon University in Pennsylvania forscht."
KI,Spiegel Online,2024-03-07,https://www.spiegel.de/netzwelt/google-mitarbeiter-soll-geheime-ki-dateien-gestohlen-haben-anklage-wegen-wirtschaftsspionage-a-8df1bc2a-d67b-49be-a029-8b998ff67345,Google: Mitarbeiter soll geheime KI-Dateien gestohlen haben - DER SPIEGEL,"Ein ehemaliger Google-Ingenieur soll etliche streng geheime Informationen über die KI-Entwicklung des Konzerns an chinesische Firmen weitergegeben zu haben. Ihm drohen bis zu 40 Jahre Haft. Ein neuer Fall von Wirtschaftsspionage sorgt in den USA für Aufregung. Es geht um künstliche Intelligenz, streng gehütetes Know-how – und die Rivalität mit China. Im Mittelpunkt steht ein ehemaliger Softwareingenieur von Google , der im Verdacht steht, Geschäftsgeheimnisse des Unternehmens im Bereich der künstlichen Intelligenz gestohlen zu haben. Der 38-jährige Linwei Ding soll laut Google zahlreiche Dokumente gestohlen haben, wie die Nachrichtenagentur AP berichtete. Demnach hat das US-Justizministerium den Beschuldigten angeklagt, weil es ihm vorwirft, Firmengeheimnisse an zwei in China ansässige Unternehmen weitergegeben zu haben. Ding soll heimlich für diese gearbeitet haben, während er bei Google angestellt war. Am Mittwoch wurde Ding in Newark, Kalifornien wegen vierfachen Diebstahls von Geschäftsgeheimnissen verhaftet, hieß es in einer Mitteilung des US-Justizministeriums . Jedes einzelne der Delikte kann mit bis zu zehn Jahren Gefängnis bestraft werden. Google dankt dem FBI »Die heutigen Anklagen sind das jüngste Beispiel dafür, wie weit Tochtergesellschaften von Unternehmen mit Sitz in der Volksrepublik China zu gehen bereit sind, um amerikanische Innovationen zu stehlen«, sagte FBI -Direktor Christopher Wray in einer Erklärung. »Der Diebstahl innovativer Technologie und von Geschäftsgeheimnissen amerikanischer Unternehmen kann Arbeitsplätze kosten und verheerende Folgen für die Wirtschaft und die nationale Sicherheit haben.« Die Anklage geht auf eine Anzeige und eine vorherige interne Untersuchung von Google zurück. »Wir haben strenge Sicherheitsvorkehrungen, um den Diebstahl unserer vertraulichen Geschäftsinformationen und Betriebsgeheimnisse zu verhindern«, sagte Google-Sprecher Jose Castaneda in einer Erklärung. »Wir sind dem FBI dankbar für seine Hilfe beim Schutz unserer Informationen und werden weiterhin eng mit ihm zusammenarbeiten.« Arbeit bei Google, Unternehmensgründung in China Ding arbeitet seit 2019 bei Google und hatte Zugang zu vertraulichen Informationen über die Rechenzentren des Unternehmens. Laut der Anklageschrift hatte er vor zwei Jahren damit begonnen, Dateien in ein persönliches Google Cloud-Konto hochzuladen. Wenige Wochen nach Beginn der Diebstahlserie bekam Ding demnach die Position des Chief Technology Officer bei einem jungen Technologieunternehmen in China für ein monatliches Gehalt von etwa 15.000 Dollar plus Jahresbonus und Unternehmensaktien angeboten. Der Beschuldigte soll auch nach China gereist sein und an Investorentreffen des Unternehmens teilgenommen haben. Am 26. Dezember vergangenen Jahres schließlich habe Ding seine Stelle bei Google gekündigt. Drei Tage später erfuhr Google, dass er bei einer Investorenkonferenz in Peking als CEO eines der chinesischen Unternehmen aufgetreten war. Ein Kollege habe derweil mithilfe des Zugangsausweises den Eindruck erweckt, als wäre Ding zur Arbeit erschienen, während er sich in Wirklichkeit in China aufhielt. Laptop gesperrt Nach der Entdeckung habe Google den Netzwerkzugang von Ding und seinen Laptop gesperrt und die unerlaubten Uploads entdeckt. Das FBI durchsuchte im Januar Dings Wohnung und beschlagnahmte seine elektronischen Geräte. Später fanden die Ermittler auf seinen persönlichen Konten mehr als 500 einzelne Dateien mit vertraulichen Informationen, die er laut den Behörden von Google gestohlen haben soll."
AI,Spiegel Online,2024-03-04,https://www.spiegel.de/netzwelt/netzpolitik/donald-trump-fake-fotos-aus-ki-sollen-schwarze-waehler-ansprechen-a-1bf58d3d-086e-40ca-a876-c8f66eb5d25a,Donald Trump: Fake-Fotos aus KI sollen schwarze Wähler ansprechen - DER SPIEGEL,"Donald Trump, Arm in Arm mit schwarzen Frauen oder auf einem spontanen Gruppenfoto mit einer Gruppe junger schwarzer Männer? Solche Bilder kursieren in sozialen Medien, doch sie wurden mithilfe von KI erzeugt. Dutzende gefälschte Bilder von Donald Trump kursieren einem BBC-Bericht zufolge in sozialen Medien. Sie wurden aber offenbar nicht erzeugt oder verbreitet, um den Ex-US-Präsidenten in ein schlechtes Licht zu rücken und ihm zu schaden – sondern um ihn zu unterstützen. Sie zeigen Trump Arm in Arm mit schwarzen Frauen oder zusammen mit cool wirkenden, jungen Schwarzen auf einer Veranda. Geteilt wurden sie zum Beispiel auf X, ehemals Twitter, sowie auf Facebook , mit Beschreibungen wie »Präsident Trump hat seine Autokolonne anhalten lassen, um Fotos mit diesen jungen Männern zu machen, die ihm zugewinkt hatten.« Das Gruppenfoto mit den Frauen ist vergleichsweise leicht als KI-generiert zu erkennen, etwa an den unsinnigen Symbolen auf der Baseballkappe einer Person im Hintergrund. Das andere ist qualitativ besser – erst bei einem genaueren Blick fällt auf, dass Trump an der rechten Hand einen Finger zu wenig hat. Trump und Biden buhlen um die gleichen Wähler Offenbar sollen die Bilder Trump bei potenziellen Wählerinnen und Wählern helfen, deren Stimmen er brauchen wird, um die Präsidentschaftswahl zu gewinnen. Umfragen zufolge ist Amtsinhaber Joe Biden unter schwarzen Wählerinnen und Wählen deutlich beliebter als Trump, doch der Abstand ist nicht mehr so groß wie bei der letzten US-Wahl. Veröffentlicht wurden die Motive nicht von Trumps Kampagne, sondern von Unterstützern ohne direkte Verbindung zum Team des Ex-Präsidenten. Die BBC konfrontierte einen von ihnen, den Radiomoderator Mark Kaye, und bekam bemerkenswerte Antworten auf die Frage, warum er auf Facebook gefälschte Motive von Trump veröffentlicht: »Ich bin kein Fotojournalist, ich mache keine Bilder von Dingen, die wirklich passieren. Ich bin ein Geschichtenerzähler«, zitiert die BBC den Trump-Fan. Er behaupte ja gar nicht, dass es sich um ein echtes Foto handele. Und: »Wenn irgendjemand wegen eines Fotos auf einer Facebook-Seite seine Stimme für den einen oder anderen Kandidaten abgibt, liegt das Problem bei dieser Person, nicht beim Bild.« Der BBC zufolge legten Kommentare unter Kayes Facebook-Eintrag sowie unter dem X-Beitrag mit dem schwerer als Fake zu erkennenden Bild nahe, dass mehrere Menschen sie für authentische Fotos hielten. Auf der Münchner Sicherheitskonferenz im Februar hatten sich Vertreter von 20 Unternehmen – darunter Adobe, Amazon , Google , IBM , Meta , Microsoft , OpenAI, TikTok und X – zur Zusammenarbeit verpflichtet , um KI-Inhalte insbesondere in Wahlkämpfen nicht zur Desinformationswaffe werden zu lassen. Die Bilder auf X waren am Montag allerdings weiterhin sichtbar."
AI,Spiegel Online,2024-03-03,https://www.spiegel.de/netzwelt/openai-widerspricht-laut-medienberichten-vorwuerfen-aus-elon-musks-klage-a-b5fe8aa0-6089-4b44-af75-d53d993f93f6,OpenAI widerspricht laut Medienberichten Vorwürfen aus Elon Musks Klage - DER SPIEGEL,"Elon Musk war Mitgründer von OpenAI und hat die Firma nun verklagt. Doch das ChatGPT-Entwicklerunternehmen wehrt sich gegen Vorwürfe, es sei zu profitorientiert. In einer internen Mail wird gegen Musk gestichelt. Die ChatGPT-Entwicklerfirma OpenAI hat sich laut Medienberichten in einer E-Mail an ihre Mitarbeiter gegen Vorwürfe aus einer Klage von Techmilliardär Elon Musk verteidigt. Der für Strategiefragen zuständige Topmanager Jason Kwon widersprach unter anderem Musks Behauptung, OpenAI werde faktisch vom Großinvestor Microsoft kontrolliert, wie der Finanzdienst Bloomberg und die Website Axios berichteten. Die Vorwürfe gingen vielleicht auf Musks Bedauern zurück, nicht mehr bei OpenAI involviert zu sein, stichelte Kwon demnach. Öffentlich äußerte sich OpenAI bisher nicht zu der Klage. Musk eskalierte mit der Klage seine Fehde mit OpenAI und Firmenchef Sam Altman. Im Kern geht es darum, dass die 2015 von Musk mitgegründete Firma OpenAI von dem vereinbarten Weg abgekommen sei, ein nicht auf Profit ausgerichtetes Unternehmen zu sein, dessen Forschung zu künstlicher Intelligenz der Menschheit zugutekommen solle. Jetzt profitiere vor allem Großinvestor Microsoft davon, hieß es in der am Donnerstag in San Francisco eingereichten Klage. Das sei eine »eklatante Verletzung« der ursprünglichen Gründungsvereinbarung. Musk verweist in der Klage darauf, dass OpenAI ausdrücklich als Gegengewicht zum Tandem aus Google und der von dem Internetkonzern übernommenen KI-Firma DeepMind gegründet worden sei. Musk, der bei OpenAI 2018 nach wenigen Jahren ausschied, kritisiert OpenAI und Altman schon lange. Er selbst gründete im vergangenen Jahr eine eigene KI-Firma mit dem Namen X.AI, deren Chatbot Grok mit ChatGPT konkurriert. Kwon widersprach Axios zufolge am Freitag auch Musks Darstellung, dass die aktuelle KI-Technologie GPT-4 bereits eine Form sogenannter allgemeiner künstlicher Intelligenz sei. So wird KI-Software bezeichnet, die nicht nur einzelne eng gefasste Aufgaben besser als Menschen erledigen kann, sondern ihnen generell überlegen ist. Nach den internen Regeln von OpenAI dürfte Microsoft keinen Zugang zu Technologie der Firma mit allgemeiner künstlicher Intelligenz haben."
KI,Spiegel Online,2024-03-04,https://www.spiegel.de/netzwelt/netzpolitik/donald-trump-fake-fotos-aus-ki-sollen-schwarze-waehler-ansprechen-a-1bf58d3d-086e-40ca-a876-c8f66eb5d25a,Donald Trump: Fake-Fotos aus KI sollen schwarze Wähler ansprechen - DER SPIEGEL,"Donald Trump, Arm in Arm mit schwarzen Frauen oder auf einem spontanen Gruppenfoto mit einer Gruppe junger schwarzer Männer? Solche Bilder kursieren in sozialen Medien, doch sie wurden mithilfe von KI erzeugt. Dutzende gefälschte Bilder von Donald Trump kursieren einem BBC-Bericht zufolge in sozialen Medien. Sie wurden aber offenbar nicht erzeugt oder verbreitet, um den Ex-US-Präsidenten in ein schlechtes Licht zu rücken und ihm zu schaden – sondern um ihn zu unterstützen. Sie zeigen Trump Arm in Arm mit schwarzen Frauen oder zusammen mit cool wirkenden, jungen Schwarzen auf einer Veranda. Geteilt wurden sie zum Beispiel auf X, ehemals Twitter, sowie auf Facebook , mit Beschreibungen wie »Präsident Trump hat seine Autokolonne anhalten lassen, um Fotos mit diesen jungen Männern zu machen, die ihm zugewinkt hatten.« Das Gruppenfoto mit den Frauen ist vergleichsweise leicht als KI-generiert zu erkennen, etwa an den unsinnigen Symbolen auf der Baseballkappe einer Person im Hintergrund. Das andere ist qualitativ besser – erst bei einem genaueren Blick fällt auf, dass Trump an der rechten Hand einen Finger zu wenig hat. Trump und Biden buhlen um die gleichen Wähler Offenbar sollen die Bilder Trump bei potenziellen Wählerinnen und Wählern helfen, deren Stimmen er brauchen wird, um die Präsidentschaftswahl zu gewinnen. Umfragen zufolge ist Amtsinhaber Joe Biden unter schwarzen Wählerinnen und Wählen deutlich beliebter als Trump, doch der Abstand ist nicht mehr so groß wie bei der letzten US-Wahl. Veröffentlicht wurden die Motive nicht von Trumps Kampagne, sondern von Unterstützern ohne direkte Verbindung zum Team des Ex-Präsidenten. Die BBC konfrontierte einen von ihnen, den Radiomoderator Mark Kaye, und bekam bemerkenswerte Antworten auf die Frage, warum er auf Facebook gefälschte Motive von Trump veröffentlicht: »Ich bin kein Fotojournalist, ich mache keine Bilder von Dingen, die wirklich passieren. Ich bin ein Geschichtenerzähler«, zitiert die BBC den Trump-Fan. Er behaupte ja gar nicht, dass es sich um ein echtes Foto handele. Und: »Wenn irgendjemand wegen eines Fotos auf einer Facebook-Seite seine Stimme für den einen oder anderen Kandidaten abgibt, liegt das Problem bei dieser Person, nicht beim Bild.« Der BBC zufolge legten Kommentare unter Kayes Facebook-Eintrag sowie unter dem X-Beitrag mit dem schwerer als Fake zu erkennenden Bild nahe, dass mehrere Menschen sie für authentische Fotos hielten. Auf der Münchner Sicherheitskonferenz im Februar hatten sich Vertreter von 20 Unternehmen – darunter Adobe, Amazon , Google , IBM , Meta , Microsoft , OpenAI, TikTok und X – zur Zusammenarbeit verpflichtet , um KI-Inhalte insbesondere in Wahlkämpfen nicht zur Desinformationswaffe werden zu lassen. Die Bilder auf X waren am Montag allerdings weiterhin sichtbar."
Künstliche Intelligenz,Spiegel Online,2024-03-01,https://www.spiegel.de/wissenschaft/technik/kuenstliche-intelligenz-lernt-die-ki-besser-wenn-man-sie-schlafen-laesst-a-0b671331-ccb7-4d35-8d30-bfd5ee8f16a5,"Künstliche Intelligenz: Lernt eine KI besser, wenn man sie schlafen lässt? - DER SPIEGEL",Italienische Computerwissenschaftler versetzen ihre künstliche Intelligenz regelmäßig in einen Schlafmodus. So soll sie Gelerntes besser behalten. Sind die Modelle dem Menschen ähnlicher als bislang vermutet?
Künstliche Intelligenz,Spiegel Online,2024-02-27,https://www.spiegel.de/netzwelt/web/kuenstliche-intelligenz-microsoft-investiert-in-franzoesisches-start-up-mistral-ai-a-471e16ed-8c8a-4ff1-9316-85c66a86eb50,Künstliche Intelligenz: Microsoft investiert in französisches Start-up Mistral AI - DER SPIEGEL,"Mit mehr als zwei Milliarden Euro wird Mistral AI bewertet, dabei wurde das französische Start-up erst vergangenen Mai gegründet. Nun beteiligt sich Microsoft an dem potenziellen Konkurrenten für OpenAI. Le Chat heißt Frankreichs Antwort auf ChatGPT . Der neue, mehrsprachige Chatbot des Pariser Start-ups Mistral AI ist bisher allerdings nur nach Registrierung in einer Betaversion zugänglich und hat noch keine Internetanbindung. Aktuelle Informationen liefert der Bot also nicht, weshalb er fürs Erste nicht mit dem Marktführer von OpenAI mithalten kann. Zugleich aber ist Mistral AI auch erst ein Dreivierteljahr alt. Und praktisch zeitgleich mit der Ankündigung zu Le Chat konnte das Start-up bekannt geben, dass es künftig Unterstützung von Microsoft bekommt. Die besteht aus Infrastruktur sowie 16 Millionen Dollar Kapital, berichtet »VentureBeat« . Microsoft, das der wichtigste Partner von OpenAI ist, stellt Mistral AI in einem auf mehrere Jahre angelegten Programm unter anderem seine KI-Rechenzentren zur Verfügung. So soll Mistral AI neue KI-Modelle schneller entwickeln und zum Einsatz bringen können. Die französischen Modelle werden außerdem in der Microsoft-Cloud Azure (genauer: in Azure AI Studio und Azure Machine Learning) angeboten, Kunden können sie neben den Modellen von OpenAI ausprobieren. Das könnte den Weg für Mistral AI zu potenziellen Nutzerinnen und Nutzern erheblich vereinfachen. Darüber hinaus möchte Microsoft mit dem Start-up bei der Entwicklung von spezifischen Modellen für den öffentlichen Sektor in Europa kooperieren. »Bei Mistral AI machen wir generative KI allgegenwärtig«, teilt Mitgründer und CEO Arthur Mensch mit, »durch unsere Open-Source-Modelle und dadurch, dass wir unsere kommerziellen Modelle dorthin bringen, wo Entwickler aktiv sind.« Was Mensch damit andeutet: Die Kooperation mit Microsoft bedeutet, dass Mistral AI von seinem ursprünglichen Ansatz abrückt, alle seine KI-Modelle quelloffen zu veröffentlichen. Mensch hat früher bei Google Deepmind gearbeitet, seine Co-Gründer arbeiteten beim Facebook-Konzern Meta . Im April 2023 gründeten sie Mistral AI, im Sommer erhielten sie Risikokapital in Höhe von mehr als 100 Millionen Euro, obwohl Mistral AI noch kein Produkt und kein KI-Modell vorweisen konnte. Seit einer zweiten Finanzierungsrunde im Dezember wird das Start-up mit mehr als zwei Milliarden Euro bewertet."
AI,Spiegel Online,2024-03-01,https://www.spiegel.de/netzwelt/elon-musk-verklagt-chatgpt-entwickler-openai-a-b17709d4-098c-4041-8732-40f993deeb27,Elon Musk verklagt ChatGPT-Entwickler OpenAI - DER SPIEGEL,"Er hatte OpenAI einst mitgegründet, nun verklagt Elon Musk die Firma. Der Vorwurf des Milliardärs: Statt dem Gemeinwohl zu dienen, arbeite das KI-Unternehmen vor allem Microsoft zu. Techmilliardär Elon Musk eskaliert seine Fehde mit OpenAI und dessen Chef Sam Altman: Am Donnerstagabend wurde bei einem Gericht in San Francisco in seinem Namen eine Klage gegen die ChatGPT-Entwicklerfirma eingereicht. Musk gehört selbst zu den Gründern von OpenAI, er hatte sich aber bereits 2018 aus dem Unternehmen zurückgezogen. Bei dem Rechtsstreit geht es im Wesentlichen um den Vorwurf, dass OpenAI anders als bei der Gründung 2015 vereinbart mittlerweile als profitorientiertes Unternehmen arbeite. Jetzt profitiere vor allem Großinvestor Microsoft, heißt es in der Klage. Das sei eine »eklatante Verletzung« der ursprünglichen Gründungsvereinbarung, laut der OpenAI vor allem zum Wohle der Menschheit arbeiten sollte. Er habe sich den Namen OpenAI ausgedacht, behauptet Musk zudem. Warnung vor Gefahren Der Milliardär verwies in der Klage darauf, dass OpenAI ausdrücklich als Gegengewicht zum Tandem aus Google und der von dem Internetkonzern übernommenen KI-Firma DeepMind gegründet worden sei. Auslöser sei die Idee gewesen, dass künstliche Intelligenz mit ihren potenziellen Gefahren nicht auf Gewinne ausgerichteten Unternehmen überlassen werden dürfe. Einen besonderen Wendepunkt sieht Musk laut der Klage in dem gescheiterten Versuch des Verwaltungsrats von OpenAI, Sam Altman als Chef abzusetzen. Microsoft als milliardenschwerer Geldgeber habe seinen Einfluss geltend gemacht, damit Altman an die Spitze zurückkehren konnte. Die neuen Verwaltungsratsmitglieder hätten keine tiefgreifende Expertise bei künstlicher Intelligenz. Von OpenAI gab es zunächst keine Reaktion auf die Klage. Musk ist für extreme Positionen bekannt Musk kritisiert OpenAI und Altman schon lange. Er selbst stieg im vergangenen Jahr mit der Firma X.AI wieder in den Markt für künstliche Intelligenz ein, ihr Chatbot Grok konkurriert mit ChatGPT. Musk warnt jedoch auch immer wieder vor Gefahren durch künstliche Intelligenz. Der Unternehmer teilt viele politische Positionen der amerikanischen Rechten, beklagt angeblichen Rassismus gegenüber Weißen und wettert gegen das »Woke-Gehirnvirus«, das die Menschheit zerstöre. Derzeit verklagt er auch Forscher, die einen Anstieg von Hassrede auf X, vormals Twitter, dokumentiert hatten . Auch jenseits von OpenAI steht der streitlustige Musk derzeit mit Microsoft auf Kriegsfuß. So hatte er vor Kurzem öffentlich kritisiert, dass man das Betriebssystem Windows 11 nur mit einem Microsoft-Account installieren könne. Er wurde dann aber auf seiner eigenen Plattform X darauf hingewiesen, dass der von ihm geführte Autohersteller Tesla schon für das Bestellen eines Autos einen Nutzer-Account voraussetzt."
AI,Spiegel Online,2024-02-29,https://www.spiegel.de/netzwelt/web/raf-mitglied-daniela-klette-wie-facebook-fotos-eine-terroristin-verraten-koennen-a-4ff0e32a-44ad-4a0d-9641-828383713eea,RAF-Mitglied Daniela Klette: Wie Facebook-Fotos eine Terroristin verraten können - DER SPIEGEL,"Gesichtserkennung funktioniert auch mit alten Fahndungsfotos. Anbieter wie PimEyes durchsuchen zum Abgleich das Internet und können überall fündig werden, auch auf unbemerkt aufgenommenen Bildern. Ist Gegenwehr noch möglich?"
AI,Spiegel Online,2024-02-28,https://www.spiegel.de/netzwelt/netzpolitik/sundar-pichai-google-chef-raeumt-fehler-beim-update-seiner-ki-software-ein-a-1e0c130b-6cc6-42a1-b9a4-e3eb70c9b8c7,Sundar Pichai: Google-Chef räumt Fehler beim Update seiner KI-Software ein - DER SPIEGEL,"Die neueste Version von Googles KI-Software geriet zur Blamage: Gemini zeigte Wikinger mit Dreadlocks und lieferte fragwürdige Text-Antworten. Sundar Pichai findet klare Worte: »Wir haben es vermasselt.« In einem internen Memo hat Google-Chef Sundar Pichai Fehler beim jüngsten Update des eigenen KI-Tools Gemini eingestanden und weitreichende Änderungen angekündigt, um das Vertrauen der Nutzerinnen und Nutzer zurückzugewinnen. Dabei findet er klare Worte: »Ich weiß, dass einige der Antworten unsere Nutzerschaft beleidigt und Voreingenommenheit gezeigt haben. Um es klar zu sagen: Das ist völlig inakzeptabel, und wir haben es vermasselt«, heißt es gleich zu Beginn des Rundschreibens, aus dem das US-Magazin »Semafor« zitiert . Nach einem Update von Gemini war in der vergangenen Woche Kritik aufgekommen : Wenn man den Bildgenerator nach historischen Motiven fragte, zeigte er beispielsweise asiatisch anmutende Frauen in einer Art Wehrmachtsuniform. In sozialen Medien oft geteilt wurden Motive mit einem schwarzen Wikinger sowie einer schwarzen Wikingerin, jeweils mit Dreadlocks. Auch der Textteil der Software zog Spott auf sich, weil er etwa eine Antwort auf die Frage verweigerte, ob Adolf Hitler oder Elon Musk einen schlechteren Einfluss auf die Gesellschaft gehabt habe. Als Reaktion lässt Google sein Tool bis auf Weiteres gar keine Motive mit Menschen mehr generieren. Google soll Schwachstellen vor Veröffentlichung identifizieren Sundar Pichai versichert in seinem Rundschreiben an die Belegschaft, dass das Gemini-Team rund um die Uhr daran gearbeitet habe, die Probleme zu lösen. Darüber hinaus soll es aber auch strukturelle Veränderungen geben: So soll der Prozess überarbeitet werden, den Produkte vor Veröffentlichung durchlaufen. Pichai nennt etwa das »red teaming«, bei dem gezielte Angriffe simuliert werden, um Schwachstellen zu identifizieren. Gleichzeitig versichert der Manager, dass sich Google in einer guten Position befinde, um an der kommenden Welle von AI-Anwendungen teilzuhaben. Zu den genauen Ursachen des Problems äußert sich Pichai in dem Schreiben nicht. Insbesondere rechte Kreise vermuten aber, dass Google Gemini ein Übermaß an Diversität vorgegeben habe. In der Vergangenheit hatte Google in diesem Bereich deutliche Defizite: So identifizierte die automatische Verschlagwortung in Google Fotos vor einigen Jahren noch Menschen mit dunkler Hautfarbe als Affen ."
AI,Spiegel Online,2024-02-27,https://www.spiegel.de/netzwelt/web/kuenstliche-intelligenz-microsoft-investiert-in-franzoesisches-start-up-mistral-ai-a-471e16ed-8c8a-4ff1-9316-85c66a86eb50,Künstliche Intelligenz: Microsoft investiert in französisches Start-up Mistral AI - DER SPIEGEL,"Mit mehr als zwei Milliarden Euro wird Mistral AI bewertet, dabei wurde das französische Start-up erst vergangenen Mai gegründet. Nun beteiligt sich Microsoft an dem potenziellen Konkurrenten für OpenAI. Le Chat heißt Frankreichs Antwort auf ChatGPT . Der neue, mehrsprachige Chatbot des Pariser Start-ups Mistral AI ist bisher allerdings nur nach Registrierung in einer Betaversion zugänglich und hat noch keine Internetanbindung. Aktuelle Informationen liefert der Bot also nicht, weshalb er fürs Erste nicht mit dem Marktführer von OpenAI mithalten kann. Zugleich aber ist Mistral AI auch erst ein Dreivierteljahr alt. Und praktisch zeitgleich mit der Ankündigung zu Le Chat konnte das Start-up bekannt geben, dass es künftig Unterstützung von Microsoft bekommt. Die besteht aus Infrastruktur sowie 16 Millionen Dollar Kapital, berichtet »VentureBeat« . Microsoft, das der wichtigste Partner von OpenAI ist, stellt Mistral AI in einem auf mehrere Jahre angelegten Programm unter anderem seine KI-Rechenzentren zur Verfügung. So soll Mistral AI neue KI-Modelle schneller entwickeln und zum Einsatz bringen können. Die französischen Modelle werden außerdem in der Microsoft-Cloud Azure (genauer: in Azure AI Studio und Azure Machine Learning) angeboten, Kunden können sie neben den Modellen von OpenAI ausprobieren. Das könnte den Weg für Mistral AI zu potenziellen Nutzerinnen und Nutzern erheblich vereinfachen. Darüber hinaus möchte Microsoft mit dem Start-up bei der Entwicklung von spezifischen Modellen für den öffentlichen Sektor in Europa kooperieren. »Bei Mistral AI machen wir generative KI allgegenwärtig«, teilt Mitgründer und CEO Arthur Mensch mit, »durch unsere Open-Source-Modelle und dadurch, dass wir unsere kommerziellen Modelle dorthin bringen, wo Entwickler aktiv sind.« Was Mensch damit andeutet: Die Kooperation mit Microsoft bedeutet, dass Mistral AI von seinem ursprünglichen Ansatz abrückt, alle seine KI-Modelle quelloffen zu veröffentlichen. Mensch hat früher bei Google Deepmind gearbeitet, seine Co-Gründer arbeiteten beim Facebook-Konzern Meta . Im April 2023 gründeten sie Mistral AI, im Sommer erhielten sie Risikokapital in Höhe von mehr als 100 Millionen Euro, obwohl Mistral AI noch kein Produkt und kein KI-Modell vorweisen konnte. Seit einer zweiten Finanzierungsrunde im Dezember wird das Start-up mit mehr als zwei Milliarden Euro bewertet."
Artificial Intelligence,Spiegel Online,2024-03-01,https://www.spiegel.de/wissenschaft/technik/kuenstliche-intelligenz-lernt-die-ki-besser-wenn-man-sie-schlafen-laesst-a-0b671331-ccb7-4d35-8d30-bfd5ee8f16a5,"Künstliche Intelligenz: Lernt eine KI besser, wenn man sie schlafen lässt? - DER SPIEGEL",Italienische Computerwissenschaftler versetzen ihre künstliche Intelligenz regelmäßig in einen Schlafmodus. So soll sie Gelerntes besser behalten. Sind die Modelle dem Menschen ähnlicher als bislang vermutet?
Artificial Intelligence,Spiegel Online,2024-02-27,https://www.spiegel.de/netzwelt/web/kuenstliche-intelligenz-microsoft-investiert-in-franzoesisches-start-up-mistral-ai-a-471e16ed-8c8a-4ff1-9316-85c66a86eb50,Künstliche Intelligenz: Microsoft investiert in französisches Start-up Mistral AI - DER SPIEGEL,"Mit mehr als zwei Milliarden Euro wird Mistral AI bewertet, dabei wurde das französische Start-up erst vergangenen Mai gegründet. Nun beteiligt sich Microsoft an dem potenziellen Konkurrenten für OpenAI. Le Chat heißt Frankreichs Antwort auf ChatGPT . Der neue, mehrsprachige Chatbot des Pariser Start-ups Mistral AI ist bisher allerdings nur nach Registrierung in einer Betaversion zugänglich und hat noch keine Internetanbindung. Aktuelle Informationen liefert der Bot also nicht, weshalb er fürs Erste nicht mit dem Marktführer von OpenAI mithalten kann. Zugleich aber ist Mistral AI auch erst ein Dreivierteljahr alt. Und praktisch zeitgleich mit der Ankündigung zu Le Chat konnte das Start-up bekannt geben, dass es künftig Unterstützung von Microsoft bekommt. Die besteht aus Infrastruktur sowie 16 Millionen Dollar Kapital, berichtet »VentureBeat« . Microsoft, das der wichtigste Partner von OpenAI ist, stellt Mistral AI in einem auf mehrere Jahre angelegten Programm unter anderem seine KI-Rechenzentren zur Verfügung. So soll Mistral AI neue KI-Modelle schneller entwickeln und zum Einsatz bringen können. Die französischen Modelle werden außerdem in der Microsoft-Cloud Azure (genauer: in Azure AI Studio und Azure Machine Learning) angeboten, Kunden können sie neben den Modellen von OpenAI ausprobieren. Das könnte den Weg für Mistral AI zu potenziellen Nutzerinnen und Nutzern erheblich vereinfachen. Darüber hinaus möchte Microsoft mit dem Start-up bei der Entwicklung von spezifischen Modellen für den öffentlichen Sektor in Europa kooperieren. »Bei Mistral AI machen wir generative KI allgegenwärtig«, teilt Mitgründer und CEO Arthur Mensch mit, »durch unsere Open-Source-Modelle und dadurch, dass wir unsere kommerziellen Modelle dorthin bringen, wo Entwickler aktiv sind.« Was Mensch damit andeutet: Die Kooperation mit Microsoft bedeutet, dass Mistral AI von seinem ursprünglichen Ansatz abrückt, alle seine KI-Modelle quelloffen zu veröffentlichen. Mensch hat früher bei Google Deepmind gearbeitet, seine Co-Gründer arbeiteten beim Facebook-Konzern Meta . Im April 2023 gründeten sie Mistral AI, im Sommer erhielten sie Risikokapital in Höhe von mehr als 100 Millionen Euro, obwohl Mistral AI noch kein Produkt und kein KI-Modell vorweisen konnte. Seit einer zweiten Finanzierungsrunde im Dezember wird das Start-up mit mehr als zwei Milliarden Euro bewertet."
KI,Spiegel Online,2024-03-01,https://www.spiegel.de/wissenschaft/technik/kuenstliche-intelligenz-lernt-die-ki-besser-wenn-man-sie-schlafen-laesst-a-0b671331-ccb7-4d35-8d30-bfd5ee8f16a5,"Künstliche Intelligenz: Lernt eine KI besser, wenn man sie schlafen lässt? - DER SPIEGEL",Italienische Computerwissenschaftler versetzen ihre künstliche Intelligenz regelmäßig in einen Schlafmodus. So soll sie Gelerntes besser behalten. Sind die Modelle dem Menschen ähnlicher als bislang vermutet?
KI,Spiegel Online,2024-02-28,https://www.spiegel.de/netzwelt/netzpolitik/sundar-pichai-google-chef-raeumt-fehler-beim-update-seiner-ki-software-ein-a-1e0c130b-6cc6-42a1-b9a4-e3eb70c9b8c7,Sundar Pichai: Google-Chef räumt Fehler beim Update seiner KI-Software ein - DER SPIEGEL,"Die neueste Version von Googles KI-Software geriet zur Blamage: Gemini zeigte Wikinger mit Dreadlocks und lieferte fragwürdige Text-Antworten. Sundar Pichai findet klare Worte: »Wir haben es vermasselt.« In einem internen Memo hat Google-Chef Sundar Pichai Fehler beim jüngsten Update des eigenen KI-Tools Gemini eingestanden und weitreichende Änderungen angekündigt, um das Vertrauen der Nutzerinnen und Nutzer zurückzugewinnen. Dabei findet er klare Worte: »Ich weiß, dass einige der Antworten unsere Nutzerschaft beleidigt und Voreingenommenheit gezeigt haben. Um es klar zu sagen: Das ist völlig inakzeptabel, und wir haben es vermasselt«, heißt es gleich zu Beginn des Rundschreibens, aus dem das US-Magazin »Semafor« zitiert . Nach einem Update von Gemini war in der vergangenen Woche Kritik aufgekommen : Wenn man den Bildgenerator nach historischen Motiven fragte, zeigte er beispielsweise asiatisch anmutende Frauen in einer Art Wehrmachtsuniform. In sozialen Medien oft geteilt wurden Motive mit einem schwarzen Wikinger sowie einer schwarzen Wikingerin, jeweils mit Dreadlocks. Auch der Textteil der Software zog Spott auf sich, weil er etwa eine Antwort auf die Frage verweigerte, ob Adolf Hitler oder Elon Musk einen schlechteren Einfluss auf die Gesellschaft gehabt habe. Als Reaktion lässt Google sein Tool bis auf Weiteres gar keine Motive mit Menschen mehr generieren. Google soll Schwachstellen vor Veröffentlichung identifizieren Sundar Pichai versichert in seinem Rundschreiben an die Belegschaft, dass das Gemini-Team rund um die Uhr daran gearbeitet habe, die Probleme zu lösen. Darüber hinaus soll es aber auch strukturelle Veränderungen geben: So soll der Prozess überarbeitet werden, den Produkte vor Veröffentlichung durchlaufen. Pichai nennt etwa das »red teaming«, bei dem gezielte Angriffe simuliert werden, um Schwachstellen zu identifizieren. Gleichzeitig versichert der Manager, dass sich Google in einer guten Position befinde, um an der kommenden Welle von AI-Anwendungen teilzuhaben. Zu den genauen Ursachen des Problems äußert sich Pichai in dem Schreiben nicht. Insbesondere rechte Kreise vermuten aber, dass Google Gemini ein Übermaß an Diversität vorgegeben habe. In der Vergangenheit hatte Google in diesem Bereich deutliche Defizite: So identifizierte die automatische Verschlagwortung in Google Fotos vor einigen Jahren noch Menschen mit dunkler Hautfarbe als Affen ."
KI,Spiegel Online,2024-02-27,https://www.spiegel.de/netzwelt/web/kuenstliche-intelligenz-microsoft-investiert-in-franzoesisches-start-up-mistral-ai-a-471e16ed-8c8a-4ff1-9316-85c66a86eb50,Künstliche Intelligenz: Microsoft investiert in französisches Start-up Mistral AI - DER SPIEGEL,"Mit mehr als zwei Milliarden Euro wird Mistral AI bewertet, dabei wurde das französische Start-up erst vergangenen Mai gegründet. Nun beteiligt sich Microsoft an dem potenziellen Konkurrenten für OpenAI. Le Chat heißt Frankreichs Antwort auf ChatGPT . Der neue, mehrsprachige Chatbot des Pariser Start-ups Mistral AI ist bisher allerdings nur nach Registrierung in einer Betaversion zugänglich und hat noch keine Internetanbindung. Aktuelle Informationen liefert der Bot also nicht, weshalb er fürs Erste nicht mit dem Marktführer von OpenAI mithalten kann. Zugleich aber ist Mistral AI auch erst ein Dreivierteljahr alt. Und praktisch zeitgleich mit der Ankündigung zu Le Chat konnte das Start-up bekannt geben, dass es künftig Unterstützung von Microsoft bekommt. Die besteht aus Infrastruktur sowie 16 Millionen Dollar Kapital, berichtet »VentureBeat« . Microsoft, das der wichtigste Partner von OpenAI ist, stellt Mistral AI in einem auf mehrere Jahre angelegten Programm unter anderem seine KI-Rechenzentren zur Verfügung. So soll Mistral AI neue KI-Modelle schneller entwickeln und zum Einsatz bringen können. Die französischen Modelle werden außerdem in der Microsoft-Cloud Azure (genauer: in Azure AI Studio und Azure Machine Learning) angeboten, Kunden können sie neben den Modellen von OpenAI ausprobieren. Das könnte den Weg für Mistral AI zu potenziellen Nutzerinnen und Nutzern erheblich vereinfachen. Darüber hinaus möchte Microsoft mit dem Start-up bei der Entwicklung von spezifischen Modellen für den öffentlichen Sektor in Europa kooperieren. »Bei Mistral AI machen wir generative KI allgegenwärtig«, teilt Mitgründer und CEO Arthur Mensch mit, »durch unsere Open-Source-Modelle und dadurch, dass wir unsere kommerziellen Modelle dorthin bringen, wo Entwickler aktiv sind.« Was Mensch damit andeutet: Die Kooperation mit Microsoft bedeutet, dass Mistral AI von seinem ursprünglichen Ansatz abrückt, alle seine KI-Modelle quelloffen zu veröffentlichen. Mensch hat früher bei Google Deepmind gearbeitet, seine Co-Gründer arbeiteten beim Facebook-Konzern Meta . Im April 2023 gründeten sie Mistral AI, im Sommer erhielten sie Risikokapital in Höhe von mehr als 100 Millionen Euro, obwohl Mistral AI noch kein Produkt und kein KI-Modell vorweisen konnte. Seit einer zweiten Finanzierungsrunde im Dezember wird das Start-up mit mehr als zwei Milliarden Euro bewertet."
KI,Spiegel Online,2024-02-27,https://www.spiegel.de/politik/deutschland/sachsen-staatsschutz-ermittelt-wegen-ki-generierter-tagesschau-beitraege-a-c3c741b8-a3ac-4dd7-9ae0-dd7d52db6fc9,Sachsen: Staatsschutz ermittelt wegen KI-generierter Tagesschau-Beiträge - DER SPIEGEL,"Auf Kundgebungen in Dresden wurden KI-generierte ARD-Beiträge abgespielt. Darin sollen sich »Tagesschau«-Sprecher für angebliche Lügen entschuldigt haben. Jetzt will die Polizei auch andere Demos genauer untersuchen. Die Staatsanwaltschaft und der Staatsschutz ermitteln wegen gefälschter »Tagesschau«-Beiträge, die auf Demonstrationen in Dresden abgespielt wurden. Diese KI-generierten Audiodateien erweckten den Eindruck, Sprecher der ARD -Nachrichtensendung entschuldigten sich für angebliche Lügen in der Berichterstattung, wie die Polizei erklärte. Es bestehe der Anfangsverdacht der Verleumdung und Beleidigung. Zudem ermittle der Staatsschutz wegen Volksverhetzung. Die gefälschten Nachrichtenbeiträge waren demnach am Montag und auch in der zurückliegenden Zeit wiederholt bei Versammlungen in Dresden von den Veranstaltern abgespielt worden. Es handelte sich um sogenannte Montagsdemonstrationen, die sich seit Jahren gegen die Regierungspolitik und konkret gegen die Energie- und Flüchtlingspolitik oder auch das Agieren Deutschlands im Ukrainekrieg richten. Die Ermittlungen stehen den Angaben zufolge im Zusammenhang mit einzelnen KI-generierten Redebeiträgen, die sich auf die Flüchtlingssituation beziehen. Ermittler des Staatsschutzes führten bei dem Veranstalter der Versammlungen eine Gefährderansprache durch. Das Abspielen der Audiodateien wurde für diese sowie zukünftige Kundgebungen untersagt. Der Polizei zufolge werden nun auch frühere Dateien ausgewertet. Gegebenenfalls werde dies in die Ermittlungen einbezogen."
Künstliche Intelligenz,Spiegel Online,2024-02-25,https://www.spiegel.de/kultur/literatur/elke-heidenreich-buchempfehlungen-ueber-menschlichkeit-und-wahrheit-a-a0dbeb1a-0ced-4f30-b707-d2c2e81f74e4,Elke Heidenreich: Buchempfehlungen über Menschlichkeit und Wahrheit - DER SPIEGEL,"Ein Amerikaner, der in Frankreich Menschen hilft, die vor den Nazis geflohen sind. Und: Künstliche Intelligenz, die die Wahrheit bedroht. Wie diese beiden Bücher zusammenpassen, erklärt unsere Kritikerin im Video. Der Journalist und frühere Verlagslektor Uwe Wittstock hat vor einigen Jahren ein tolles Buch geschrieben. »Februar 33: Der Winter der Literatur« hat er's genannt. Und er beschreibt, wie innerhalb von vier Wochen alle demokratischen Regeln von den Nazis ausgehebelt werden und Schriftsteller um ihr Leben bangen müssen. Jetzt hat er ein Buch geschrieben, das spielt sieben Jahre später. Die Nazis sind voll am Ruder. Der Krieg läuft schon seit einem Jahr. »Marseille 1940. Die große Flucht der Literatur«, nennt er es im Untertitel. Denn wir wissen, dass ganz viele Literaten, Juden, linke Intellektuelle nach Frankreich geflohen sind und dann gemerkt haben, da sind sie auch nicht sicher. Die Deutschen marschieren in Frankreich ein. Vichy Regime, Marschall Pétain, strammer Nazi. Aber es gibt eine freie Zone im Süden Frankreichs, und da sammeln sich alle auch in der Hoffnung, noch ein Schiff zu erwischen, von Marseille aus oder nach Lissabon zu kommen und von dort aus eventuell nach Amerika oder nach Südamerika noch zu gelangen, jedenfalls zu fliehen. Und die Franzosen haben auch Internierungslager. Und da sitzt tatsächlich in Amerika ein junger Mann, der ist 28 Jahre alt, er heißt Varian Fry. Und er sieht dieses Elend in Europa. Und er sagt: Hilft denn da eigentlich niemand? Und er gibt seinen tollen Job auf und verlässt seine Frau und geht nach Frankreich und gründet ein Büro, eine Hilfsorganisation für Flüchtlinge. Offiziell hilft er ihnen mit Geld, mit Unterkunft zum Überleben. Aber es wird immer mehr eine Fluchtagentur. Und er hat ganz viele Helfer. Leute, die die, die die Gefährdeten über die Pyrenäen schleusen, nach Spanien, von dort nach Lissabon. Er hat Leute, die Schiffe organisieren und sie aus den Häfen wegbringen. Also er hat eine Menge Leute, die ihn mit Geld, mit Tatkraft unterstützen. Es gibt auch Polizisten, die beide Augen zudrücken. Es gibt Franzosen, die helfen, die unterstützen. Er ist nicht allein, aber er ist es, der das alles inszeniert hat und der das durchzieht und seinen Beruf und seine Ehe dafür aufs Spiel setzt. Varian Fry, ein sehr junger Mann. Und das schildert Uwe Wittstock. Den hat er ausfindig gemacht, hat gründlich recherchiert und hat in diesem Buch so lebendig und so, so spannend, so interessant und so ergreifend geschildert, was alles passiert mit diesen Menschen. Viele von denen kennen wir ja. Wir wissen, dass Heinrich Mann mit Mühe und Not mit Golo und seiner Frau Nelly über die Pyrenäen gezogen ist. Wir wissen von Alma Mahler, die mit ihrem schwerkranken Werfel und einem einer Tasche voll voll Partituren über die Berge gewandert ist. Die Partituren von Mahler und Bruckner wollte sie in Amerika verkaufen, um da besser zu leben. Wir wissen von Walter Benjamin, der es geschafft hat, über die Pyrenäen und sich dann in Portbou das Leben genommen hat. Aus Verzweiflung, Erschöpfung, Angst. Und von vielen Unbekannten erzählt er auch, die diese Fluchtwege in Anspruch nahmen. In Zeiten, wo es immer bürokratischer wurde. Man braucht ein Ausreisevisum aus Frankreich, ein Einreisevisum ins faschistische Spanien, wo man besser erst gar nicht hinkam, weil die auch die Listen hatte mit allen, die Hitler suchte und in die Lager stecken wollte. Wer gefasst wurde, kam ins KZ. Es gab immer wieder aber auch Beamte und Polizisten in den Wachtposten, die die Augen zudrücken und sie einfach passieren ließen. Das beschreibt er großartig. Wie wichtig es ist, dass es solche Menschen gibt, ist, dass man menschlich bleibt in unmenschlichen Zeiten. In Zeiten wie heute, wo Häftlinge, die andere Meinungen haben, in Gefängnissen schon wieder umgebracht werden oder wo man Leuten wie Assange, die Verbrechen aufdecken, ihr ganzes Leben nimmt. In solchen Zeiten liest man so ein Buch natürlich hoch sensibilisiert. Was passiert, wenn die Verhältnisse undemokratisch sind mit aufrechten Demokraten? Ein sehr wichtiges, ein ganz tolles Buch und ich lege Ihnen das sehr ans Herz. Und zufällig fiel mir noch ein anderes in die Hand, was dazu passt von Werner Herzog. »Die Zukunft der Wahrheit.« Die Zukunft der Wahrheit ist ja schon so ein Titel. Wird es in Zukunft Wahrheit noch geben in Zeiten von Fake News und KI, wo wir kaum noch kontrollieren können, was ist wahr und was ist nicht wahr? Die Nachrichten verbreiten sich immer schneller, in Sekundenschnelle. Aber das Narrativ ist wichtig: Wer hat die Nachricht geschickt? Ist sie wahr? Ist sie bearbeitet? Er schreibt, dass es Fake News immer schon gab. Über Nero und über den Pharao Ramses gibt es sehr viele Fake News, die als Jahrhunderte später aufgeklärt wurden. Also müssen wir prüfen wer erzählt uns was? Und das können wir ja überprüfen. Und in Zeiten von Kreaturen wie Trump oder Putin ist es auch wichtig, dass wir überprüfen, welche Nachrichten uns vorgesetzt werden. Nicht alle haben die Möglichkeit, das zu tun. Die Leute in Russland, die unter einer Propagandamaschinerie leiden, wissen nicht, was wirklich geschieht in ihrem Land. Aber er sagt: Es macht uns zu Menschen, dass wir dran bleiben, die Wahrheit wirklich zu erkunden, die Wahrheit zu verbreiten. Er sagt auch, in der Kunst gibt es keine Wahrheit. Denn Imagination und Wirklichkeit, nur so kann Kunst entstehen, wenn die Poesie die Wirklichkeit auch verändert. Aber Wirklichkeit und Wahrheit sind auch noch zwei verschiedene Sachen. Also ein ganz interessanter Essay über das Thema Wahrheit und dies ein interessantes Buch über das Thema Menschlichkeit. Beide lege ich Ihnen sehr ans Herz und das nächste Mal gibt es dann wieder Romane."
Künstliche Intelligenz,Spiegel Online,2024-02-23,https://www.spiegel.de/wissenschaft/technik/kuenstliche-intelligenz-chatgpt-besteht-turing-test-zu-menschlichem-verhalten-a-0af83891-e0ce-46cc-baf5-e0dae4caadee,KI: ChatGPT besteht Turing-Test zu menschlichem Verhalten - DER SPIEGEL,"Eine virtuelle Persönlichkeit kann überzeugend wirken – sogar im sozialen Verhalten, haben US-Forscher herausgefunden. Mensch oder Maschine? Nicht so leicht zu sagen. Chatbots mit künstlicher Intelligenz verhalten sich so, dass sie kaum noch von Menschen zu unterscheiden sind. Zu diesem Ergebnis kommt ein US-Forscherteam um den Informatiker Qiaozhu Mei von der University of Michigan und den Ökonomen Matthew Jackson von der Stanford University mit einer neuen Studie , die in den »Proceedings of the National Academy of Sciences« erschienen ist. Die Autoren beziehen sich auf den 1950 von Alan Turing formulierten Turing-Test, dessen populär gewordene Variante besagt: Ob künstliche Intelligenz vorhanden ist, erkenne man daran, dass ein Fragesteller nicht unterscheiden könne, ob ein Mensch oder eine Maschine die Antworten formuliert. Turing sagte damals voraus, etwa im Jahr 2000 werde es so weit sein. Etwas länger dauerte die Entwicklung doch, wie sich herausstellte. Für die neue Studie ließen die Forscher die Software eine psychologische Befragung ausfüllen und prüften sie mit verschiedenen Spielen. Wie sie sich darin verhielten, sollte auf Eigenschaften wie Vertrauen, Fairness, Risikoscheu, Hilfsbereitschaft oder Kooperation schließen lassen. Das Vorgehen der Bots wurde anonym mit dem von Menschen verglichen, die zufällig aus Zehntausenden Probanden aus 50 verschiedenen Ländern ausgewählt wurden. »Statistisch nicht von Menschen unterscheidbar« Das im vergangenen Jahr veröffentlichte Sprachmodell ChatGPT-4 zeigte demnach »Verhaltens- und Persönlichkeitszüge, die statistisch nicht von denen der Menschen unterscheidbar sind«. Tendenziell wurden dessen Züge sogar leicht eher für menschlich gehalten als die der echten Menschen. Das Vorläufermodell ChatGPT-3 ließ sich in mancher Hinsicht eher als künstlich identifizieren, war aber auch nah dran. Beide Varianten lernten der Studie zufolge aus der Erfahrung im Lauf der Prüfung und passten ihr Verhalten an, als ob sie human seien. Besonders menschlich wirkte ChatGPT-4 im Spiel »Ultimatum«, bei dem ein Spieler wählt, ob er akzeptiert, wie sein Gegenüber eine Geldsumme zwischen ihnen aufteilt, oder beide leer ausgehen. Auch in einem Spiel zu öffentlichen Gütern, bei dem die Spieler Geld entweder für sich behalten oder für gemeinschaftliche Nutzung überlassen, wurde die Software weit überwiegend für menschlich gehalten. Die Spielzüge wurden als Indikatoren etwa für faires, selbstloses oder kooperatives Verhalten gewertet. Ganz so selbstlos sind Menschen nicht Als Ausnahme wenig überzeugen konnte ChatGPT-4 im Spiel »Gefangenendilemma«. Darin müssen beide Spieler gleichzeitig in mehreren Runden entscheiden, ob sie mit dem anderen zusammenarbeiten und sich eine Belohnung teilen oder jeder für sich den vollen Betrag einer geringeren Summe anstrebt. Auch hier ging es um Kooperation, Gegenseitigkeit und strategisches Denken. Solche Spiele werden oft zur Analyse in der Verhaltensökonomik verwendet, weil sie vereinfacht wiedergeben können, wie Menschen sich im Alltag zwischen verschiedenen Optionen entscheiden. Aus dem Verhalten leiteten die Forscher eine programmierte Einstellung ab: Die Software strebe danach, sowohl den eigenen Nutzen als auch den ihres Gegenübers zu maximieren, und zwar im Durchschnitt zu genau gleichen Teilen. Echte Menschen seien einen kleinen Tick weniger altruistisch – zwar längst nicht komplett egoistisch, aber sie gäben dem Eigennutzen doch in der Regel ein leicht höheres Gewicht als dem Fremdnutzen. Zudem gebe es größere Unterschiede zwischen den Individuen, während die Software sich noch etwas berechenbarer verhalte."
Artificial Intelligence,Spiegel Online,2024-02-25,https://www.spiegel.de/kultur/literatur/elke-heidenreich-buchempfehlungen-ueber-menschlichkeit-und-wahrheit-a-a0dbeb1a-0ced-4f30-b707-d2c2e81f74e4,Elke Heidenreich: Buchempfehlungen über Menschlichkeit und Wahrheit - DER SPIEGEL,"Ein Amerikaner, der in Frankreich Menschen hilft, die vor den Nazis geflohen sind. Und: Künstliche Intelligenz, die die Wahrheit bedroht. Wie diese beiden Bücher zusammenpassen, erklärt unsere Kritikerin im Video. Der Journalist und frühere Verlagslektor Uwe Wittstock hat vor einigen Jahren ein tolles Buch geschrieben. »Februar 33: Der Winter der Literatur« hat er's genannt. Und er beschreibt, wie innerhalb von vier Wochen alle demokratischen Regeln von den Nazis ausgehebelt werden und Schriftsteller um ihr Leben bangen müssen. Jetzt hat er ein Buch geschrieben, das spielt sieben Jahre später. Die Nazis sind voll am Ruder. Der Krieg läuft schon seit einem Jahr. »Marseille 1940. Die große Flucht der Literatur«, nennt er es im Untertitel. Denn wir wissen, dass ganz viele Literaten, Juden, linke Intellektuelle nach Frankreich geflohen sind und dann gemerkt haben, da sind sie auch nicht sicher. Die Deutschen marschieren in Frankreich ein. Vichy Regime, Marschall Pétain, strammer Nazi. Aber es gibt eine freie Zone im Süden Frankreichs, und da sammeln sich alle auch in der Hoffnung, noch ein Schiff zu erwischen, von Marseille aus oder nach Lissabon zu kommen und von dort aus eventuell nach Amerika oder nach Südamerika noch zu gelangen, jedenfalls zu fliehen. Und die Franzosen haben auch Internierungslager. Und da sitzt tatsächlich in Amerika ein junger Mann, der ist 28 Jahre alt, er heißt Varian Fry. Und er sieht dieses Elend in Europa. Und er sagt: Hilft denn da eigentlich niemand? Und er gibt seinen tollen Job auf und verlässt seine Frau und geht nach Frankreich und gründet ein Büro, eine Hilfsorganisation für Flüchtlinge. Offiziell hilft er ihnen mit Geld, mit Unterkunft zum Überleben. Aber es wird immer mehr eine Fluchtagentur. Und er hat ganz viele Helfer. Leute, die die, die die Gefährdeten über die Pyrenäen schleusen, nach Spanien, von dort nach Lissabon. Er hat Leute, die Schiffe organisieren und sie aus den Häfen wegbringen. Also er hat eine Menge Leute, die ihn mit Geld, mit Tatkraft unterstützen. Es gibt auch Polizisten, die beide Augen zudrücken. Es gibt Franzosen, die helfen, die unterstützen. Er ist nicht allein, aber er ist es, der das alles inszeniert hat und der das durchzieht und seinen Beruf und seine Ehe dafür aufs Spiel setzt. Varian Fry, ein sehr junger Mann. Und das schildert Uwe Wittstock. Den hat er ausfindig gemacht, hat gründlich recherchiert und hat in diesem Buch so lebendig und so, so spannend, so interessant und so ergreifend geschildert, was alles passiert mit diesen Menschen. Viele von denen kennen wir ja. Wir wissen, dass Heinrich Mann mit Mühe und Not mit Golo und seiner Frau Nelly über die Pyrenäen gezogen ist. Wir wissen von Alma Mahler, die mit ihrem schwerkranken Werfel und einem einer Tasche voll voll Partituren über die Berge gewandert ist. Die Partituren von Mahler und Bruckner wollte sie in Amerika verkaufen, um da besser zu leben. Wir wissen von Walter Benjamin, der es geschafft hat, über die Pyrenäen und sich dann in Portbou das Leben genommen hat. Aus Verzweiflung, Erschöpfung, Angst. Und von vielen Unbekannten erzählt er auch, die diese Fluchtwege in Anspruch nahmen. In Zeiten, wo es immer bürokratischer wurde. Man braucht ein Ausreisevisum aus Frankreich, ein Einreisevisum ins faschistische Spanien, wo man besser erst gar nicht hinkam, weil die auch die Listen hatte mit allen, die Hitler suchte und in die Lager stecken wollte. Wer gefasst wurde, kam ins KZ. Es gab immer wieder aber auch Beamte und Polizisten in den Wachtposten, die die Augen zudrücken und sie einfach passieren ließen. Das beschreibt er großartig. Wie wichtig es ist, dass es solche Menschen gibt, ist, dass man menschlich bleibt in unmenschlichen Zeiten. In Zeiten wie heute, wo Häftlinge, die andere Meinungen haben, in Gefängnissen schon wieder umgebracht werden oder wo man Leuten wie Assange, die Verbrechen aufdecken, ihr ganzes Leben nimmt. In solchen Zeiten liest man so ein Buch natürlich hoch sensibilisiert. Was passiert, wenn die Verhältnisse undemokratisch sind mit aufrechten Demokraten? Ein sehr wichtiges, ein ganz tolles Buch und ich lege Ihnen das sehr ans Herz. Und zufällig fiel mir noch ein anderes in die Hand, was dazu passt von Werner Herzog. »Die Zukunft der Wahrheit.« Die Zukunft der Wahrheit ist ja schon so ein Titel. Wird es in Zukunft Wahrheit noch geben in Zeiten von Fake News und KI, wo wir kaum noch kontrollieren können, was ist wahr und was ist nicht wahr? Die Nachrichten verbreiten sich immer schneller, in Sekundenschnelle. Aber das Narrativ ist wichtig: Wer hat die Nachricht geschickt? Ist sie wahr? Ist sie bearbeitet? Er schreibt, dass es Fake News immer schon gab. Über Nero und über den Pharao Ramses gibt es sehr viele Fake News, die als Jahrhunderte später aufgeklärt wurden. Also müssen wir prüfen wer erzählt uns was? Und das können wir ja überprüfen. Und in Zeiten von Kreaturen wie Trump oder Putin ist es auch wichtig, dass wir überprüfen, welche Nachrichten uns vorgesetzt werden. Nicht alle haben die Möglichkeit, das zu tun. Die Leute in Russland, die unter einer Propagandamaschinerie leiden, wissen nicht, was wirklich geschieht in ihrem Land. Aber er sagt: Es macht uns zu Menschen, dass wir dran bleiben, die Wahrheit wirklich zu erkunden, die Wahrheit zu verbreiten. Er sagt auch, in der Kunst gibt es keine Wahrheit. Denn Imagination und Wirklichkeit, nur so kann Kunst entstehen, wenn die Poesie die Wirklichkeit auch verändert. Aber Wirklichkeit und Wahrheit sind auch noch zwei verschiedene Sachen. Also ein ganz interessanter Essay über das Thema Wahrheit und dies ein interessantes Buch über das Thema Menschlichkeit. Beide lege ich Ihnen sehr ans Herz und das nächste Mal gibt es dann wieder Romane."
KI,Spiegel Online,2024-02-23,https://www.spiegel.de/wissenschaft/technik/kuenstliche-intelligenz-chatgpt-besteht-turing-test-zu-menschlichem-verhalten-a-0af83891-e0ce-46cc-baf5-e0dae4caadee,KI: ChatGPT besteht Turing-Test zu menschlichem Verhalten - DER SPIEGEL,"Eine virtuelle Persönlichkeit kann überzeugend wirken – sogar im sozialen Verhalten, haben US-Forscher herausgefunden. Mensch oder Maschine? Nicht so leicht zu sagen. Chatbots mit künstlicher Intelligenz verhalten sich so, dass sie kaum noch von Menschen zu unterscheiden sind. Zu diesem Ergebnis kommt ein US-Forscherteam um den Informatiker Qiaozhu Mei von der University of Michigan und den Ökonomen Matthew Jackson von der Stanford University mit einer neuen Studie , die in den »Proceedings of the National Academy of Sciences« erschienen ist. Die Autoren beziehen sich auf den 1950 von Alan Turing formulierten Turing-Test, dessen populär gewordene Variante besagt: Ob künstliche Intelligenz vorhanden ist, erkenne man daran, dass ein Fragesteller nicht unterscheiden könne, ob ein Mensch oder eine Maschine die Antworten formuliert. Turing sagte damals voraus, etwa im Jahr 2000 werde es so weit sein. Etwas länger dauerte die Entwicklung doch, wie sich herausstellte. Für die neue Studie ließen die Forscher die Software eine psychologische Befragung ausfüllen und prüften sie mit verschiedenen Spielen. Wie sie sich darin verhielten, sollte auf Eigenschaften wie Vertrauen, Fairness, Risikoscheu, Hilfsbereitschaft oder Kooperation schließen lassen. Das Vorgehen der Bots wurde anonym mit dem von Menschen verglichen, die zufällig aus Zehntausenden Probanden aus 50 verschiedenen Ländern ausgewählt wurden. »Statistisch nicht von Menschen unterscheidbar« Das im vergangenen Jahr veröffentlichte Sprachmodell ChatGPT-4 zeigte demnach »Verhaltens- und Persönlichkeitszüge, die statistisch nicht von denen der Menschen unterscheidbar sind«. Tendenziell wurden dessen Züge sogar leicht eher für menschlich gehalten als die der echten Menschen. Das Vorläufermodell ChatGPT-3 ließ sich in mancher Hinsicht eher als künstlich identifizieren, war aber auch nah dran. Beide Varianten lernten der Studie zufolge aus der Erfahrung im Lauf der Prüfung und passten ihr Verhalten an, als ob sie human seien. Besonders menschlich wirkte ChatGPT-4 im Spiel »Ultimatum«, bei dem ein Spieler wählt, ob er akzeptiert, wie sein Gegenüber eine Geldsumme zwischen ihnen aufteilt, oder beide leer ausgehen. Auch in einem Spiel zu öffentlichen Gütern, bei dem die Spieler Geld entweder für sich behalten oder für gemeinschaftliche Nutzung überlassen, wurde die Software weit überwiegend für menschlich gehalten. Die Spielzüge wurden als Indikatoren etwa für faires, selbstloses oder kooperatives Verhalten gewertet. Ganz so selbstlos sind Menschen nicht Als Ausnahme wenig überzeugen konnte ChatGPT-4 im Spiel »Gefangenendilemma«. Darin müssen beide Spieler gleichzeitig in mehreren Runden entscheiden, ob sie mit dem anderen zusammenarbeiten und sich eine Belohnung teilen oder jeder für sich den vollen Betrag einer geringeren Summe anstrebt. Auch hier ging es um Kooperation, Gegenseitigkeit und strategisches Denken. Solche Spiele werden oft zur Analyse in der Verhaltensökonomik verwendet, weil sie vereinfacht wiedergeben können, wie Menschen sich im Alltag zwischen verschiedenen Optionen entscheiden. Aus dem Verhalten leiteten die Forscher eine programmierte Einstellung ab: Die Software strebe danach, sowohl den eigenen Nutzen als auch den ihres Gegenübers zu maximieren, und zwar im Durchschnitt zu genau gleichen Teilen. Echte Menschen seien einen kleinen Tick weniger altruistisch – zwar längst nicht komplett egoistisch, aber sie gäben dem Eigennutzen doch in der Regel ein leicht höheres Gewicht als dem Fremdnutzen. Zudem gebe es größere Unterschiede zwischen den Individuen, während die Software sich noch etwas berechenbarer verhalte."
AI,Spiegel Online,2024-02-21,https://www.spiegel.de/netzwelt/netzpolitik/tiktok-plus-ki-fake-news-war-gestern-die-aera-der-fake-reality-beginnt-sascha-lobo-kolumne-a-d358aa2e-86cb-49cd-9317-62c23f97a6cf,"TikTok plus KI: Fake News war gestern, die Ära der Fake Reality beginnt - Sascha Lobo-Kolumne - DER SPIEGEL","Schon jetzt eignet sich TikTok nicht nur, aber eben auch hervorragend zur Verbreitung von Ideologien. Was wird wohl passieren, wenn es mit neuer Text-zu-Video-KI wie Sora kombiniert wird? Soeben bewegen sich zwei unaufhaltsam erscheinende Technologiekomplexe aufeinander zu, die schon allein die Kraft hätten, unsere Welt zu verändern. Wir können erst grob erahnen, was passiert, wenn sie verschmelzen. Der eine ist das soziale Netzwerk TikTok, für das die EU gerade eine Untersuchung eröffnet hat . Vor allem, um herauszufinden, wie sicher Kinder und Jugendliche dort sind, was etwa Suchtpotenzial, den »Rabbit-Hole-Effekt« oder Altersverifikation angeht. Der andere ist eine Technologie, natürlich aus dem Bereich der generativen künstlichen Intelligenz , der den sperrigen Genrebegriff »text to video« trägt. ChatGPT-Schöpfer OpenAI hat jüngst Sora vorgestellt , eine KI, die aus kurzen, hingeworfenen Befehlen in kürzester Zeit mehr oder weniger realistisch aussehende Filmsequenzen generieren kann. Sascha Lobo, Jahrgang 1975, ist Autor und Strategieberater mit den Schwerpunkten Internet und digitale Technologien. Gemeinsam mit Jule Lobo beschäftigt er sich im Podcast »Feel the News – Was Deutschland bewegt« mit aktuellen Debattenthemen. Die Frage, warum man beides gemeinsam und auf die potenzielle Wirkmacht bezogen betrachten muss, beginnt mit TikTok . Die chinesische Video-App ist eine der wichtigsten Unterhaltungs-, Informations- und auch Nachrichtenplattformen der Generation bis dreißig Jahren in der westlichen Welt. TikTok hat es durch radikale Fokussierung auf eine Art algorithmischen Populismus geschafft, sehr vielen Menschen genau die Inhalte zu zeigen, die sie sehen wollen. Selbst, wenn sie das vorher noch gar nicht wussten. Ein in der Frühzeit der Netzkultur dafür geprägter Begriff lautet »serendipity«, was man mit »finden ohne zu suchen« übersetzen kann. TikTok hat für anderthalb Generationen ein Anreizsystem geschaffen, wie Unterhaltung hyperpersonalisiert und Kreativität in Macht übersetzt werden kann. Denn letztlich bietet TikTok dem Publikum unendliche und wirklich gute Unterhaltung. Den Inhalteproduzierenden aber bietet TikTok Reichweite, Monetarisierung und eine Relevanz, die von den meisten älteren Lebensteilnehmern noch immer drastisch unterschätzt wird. An der Reichweite ist vor allem attraktiv, dass TikTok in sozialen Netzwerken völlig neu definiert hat, wie die sogenannte Viralität entsteht, also die explosive Verbreitung einzelner Inhalte. Dadurch können auch Leute mit sehr wenig Followern ein Millionenpublikum erreichen – mit der richtigen Idee für ein Video. Feuerwerk der Manipulation TikTok hat gegenwärtig den wohl besten existierenden Empfehlungsalgorithmus. Leider kann er ausgenutzt werden, und zwar insbesondere von Leuten, die mit verkürzten oder ganz gefälschten Informationen arbeiten, um eine besondere Form der TikTok-Sensationalisierung zu erreichen. Die TikTok-Sensationalisierung hat viele unterschiedliche, kulturelle Facetten, und die meisten davon sind strukturell positiv. Im Kern geht es meist um die kreative Fähigkeit, mit Witz, Charme, manchmal Intelligenz und Musikschnipseln sowie ein paar technischen Spielereien eine interessante bis spektakuläre Sekundeninszenierung herzustellen. Politisch, gesellschaftlich und nachrichtlich ist TikTok bei Weitem nicht nur, aber inzwischen eben auch ein Feuerwerk der Manipulation, das sich hervorragend zur Verbreitung von Ideologien eignet. Die Inszenierungsradikalität auf TikTok bedeutet zu oft, dass für wahr und richtig gehalten wird, was sich gut und interessant anhört. Das ist zugegeben nichts, was TikTok erfunden oder auch nur exklusiv hat – aber die Geschwindigkeit, das extreme Viralitätspotenzial, die Hyperpersonalisierung, das Publikum und der Zustand der Welt verstärken diesen Effekt. In den vergangenen Monaten kam häufiger die Frage auf, warum die AfD auf TikTok so erfolgreich ist. Das liegt einerseits an reaktionären Trends, die dort oft subtil, aber letztlich ganz offen transportiert werden, wie Antifeminismus, Rassismus , Antisemitismus und ganz besonders auch Sozialdarwinismus in verschiedenen Formen. Eine große Interessensphäre mit ganz eigenen Stars mit Millionenreichweite beschäftigt sich zum Beispiel fast ausschließlich damit, wie man so schnell wie möglich so reich wie möglich wird. Das greift nahtlos in die allgegenwärtige Selbstoptimierung auf TikTok hinein. Und weil sich soziale Medien wie Instagram und auch TikTok so perfekt für die Inszenierung von Reichtum und Luxus eignen, entsteht aus beiden Strömungen schnell die Haltung, arme Menschen seien prinzipiell selbst an ihrem wirtschaftlichen Misserfolg schuld. Nebst dem Plan, wie man vermeintlich aus eigener Kraft reich wird. Auch der Ruf nach autoritärer Führung findet überraschend großen Widerhall, und längst nicht nur in rechten Zirkeln. Ganz zentral für den Erfolg der AfD bei jungen Menschen auf TikTok ist aber aus meiner Sicht eine Ablösung der klassischen Nachrichten- und Welterklärungsmedien vom Alltagserleben vieler Jugendlicher. Wenn etwa absurde Überbürokratie, Politikversagen oder Probleme mit der Integration zwar persönlich erlebt oder medial präsent werden, aber dafür nur verkrampfte, abstrakte Erklärungen und schon gar keine Lösungen angeboten werden. Plötzlich erscheint rassistischer oder antidemokratischer Populismus gleichzeitig als Erklärung und als Lösung. Spektakel und Inszenierung vertragen sich eben nicht immer gut mit Komplexität, Grautönen und der Abwägung demokratischer Werte. TikTok als Fake-News-Schleuder zu bezeichnen, ist definitiv verkürzt und berücksichtigt nicht die vielen Kräfte, die sich genau dort dem Strom des Antifortschritts entgegenstellen, mit Aufklärung, Bildung, Gegenanalysen und wirklich guter Unterhaltung. Aber TikTok geht als das gegenwärtig wohl machtvollste, korrektivärmste und aufmerksamkeitsstärkste Einflussmedium hinein in Köpfe unter 30 Jahren. Eine gruselige Sensation Was direkt zu Sora führt, das hier als Symbol für den ganzen Technologiekomplex von KI-Videos dienen soll. Die KI-Community in sozialen Medien ist seit der Vorstellung von Sora völlig aus dem Häuschen. Für eine Anzahl aus OpenAI-Sicht besonders vertrauenswürdiger Personen ist diese Technologie bereits verfügbar, und diese Leute veröffentlichen immer wieder neue Videos, oft inklusive der Anweisungen, der Prompts, mit der die KI die Videos generiert hat. So hat es OpenAI auch auf der Vorstellungsseite von Sora gehalten. Derzeit kann man mit Sora bis zu 60 Sekunden lange Videoclips erstellen, mit zwei, drei knappen Sätzen. Die Ergebnisse eröffnen eine Welt, die beinahe so groß und erstaunlich ist wie diejenige, die ChatGPT für die Öffentlichkeit zugänglich gemacht hat. Das folgende Video gibt einen Einblick, und der lässt sich als gruselige Sensation beschreiben. Der Prompt »Ein Wurf Golden-Retriever-Welpen spielt im Schnee. Ihre Köpfe ploppen aus dem Schnee heraus« – führt zu einem Video , das selbst für Fachleute kaum von einem echten Video zu unterscheiden ist. Auf den ersten Blick schon gar nicht. Künstlicher Intelligenz sollte man sich nicht mit dem bisherigen Technologieverständnis nähern. Auch klassische, digitale Erkenntnisse reichen oft nicht aus, um das gegenwärtige Potenzial dieses Technologiekomplexes zu erfassen. Und noch weniger, um die künftige Entwicklung sinnvoll abschätzen zu können. KI muss inklusive der ständigen, manchmal exponentiellen Verbesserung gedacht werden. Das ist nicht trivial, weil unser menschliches Basisverständnis oft falsch einsortiert, was für KI einfach und was schwierig ist. Sora muss man deshalb als Ausgangspunkt einer neuen Welt betrachten. Alle kleinen Unzulänglichkeiten und großen Merkwürdigkeiten in den bisherigen Videos sind aus meiner Sicht vernachlässigbar. Wir befinden uns am Anfang einer neuen medialen und damit auch politischen Zeitrechnung, denn mit Sora und vergleichbaren Technologien reicht der Begriff »Fake News« nicht mehr aus. Auf dem Weg zur perfekten Propagandamaschinerie Text-to-Video auf dem Niveau von Sora ist der Startschuss für die Epoche der »Fake Reality«, auch wenn der Begriff in sich widersprüchlich erscheint. KI kann Welten erschaffen, deren Abbild nicht mehr zu unterscheiden sein wird von den Abbildern, mit denen wir unsere Wirklichkeit bisher gelernt haben einzuschätzen. ChatGPT beherrscht die Erschaffung von Kommunikationsstrategien, diese Fähigkeiten dürften in der nächsten Iteration dramatisch besser werden, und sie werden irgendwann verbunden werden können mit Sora. Ein Prompt der Zukunft: »Erstelle eine Reihe von 10 Videos, die so viele Menschen wie möglich davon überzeugt, dass Wladimir Putin die einzige Hoffnung für Europa ist«. Die Skripts würden die neuesten, wissenschaftlichen Erkenntnisse der persuasiven Kommunikation und der Propaganda berücksichtigen, sie würden clever, unterhaltsam und viralitätsorientiert daherkommen. Und hier schließt nahtlos TikTok an. Denn selbst die beste generative KI kann nur die Wahrscheinlichkeit erhöhen, mit der ein kommunikatives Ziel erreicht wird. Aber weil KI in Lernschleifen gedacht werden muss, würde die KI Tausende Versionen erstellen, die via TikTok ganz einfach auf Reichweite, Viralität und Wirkung beim Publikum überprüft werden können. Diese Daten fließen in den weiteren Kreationsprozess ein, lassen sich nach ihrer Wirksamkeit bei Zielgruppen unterteilen und immer präziser verbessern. Mit dem Prinzip TikTok plus des Technologiekomplexes rund um Sora sind wir auf dem Weg zur perfekten, voll automatisierten Propagandamaschinerie des 21. Jahrhunderts. Sie kann Fake-Realitäten erschaffen, zugeschnitten im Zweifel auf jede einzelne Person. Bisher schützt uns, dass für die Qualität von Sora gigantische Ressourcen und Fachkenntnisse notwendig sind, die nur sehr wenige, große Unternehmen beherrschen – mit denen man verhandeln kann. Aber das wird nicht immer so bleiben. Wir haben bisher kaum das Problem der Fake News in den Griff bekommen und müssen uns schon mit einer ungleich wirkmächtigeren Fake Reality auseinandersetzen."
Artificial Intelligence,Spiegel Online,2024-02-21,https://www.spiegel.de/international/germany/a-visit-to-the-swamp-the-town-made-famous-by-neo-nazi-students-a-2b1b7062-4bf7-4439-8a0c-3118dad452fc,A Visit to the Swamp: The Town Made Famous by Neo-Nazi Students - DER SPIEGEL,"An open letter about Hitler salutes in the schoolyard and swastikas on the benches of a school in the municipality of Burg made nationwide headlines in Germany. But is the place really a hotbed of right-wing extremism? We went to find out. ""To what extent do right-wing radicals have control of the town, to the point that they dictate public life? Can you guarantee my safety? Or must I fear being threatened with physical violence if I stand up for democracy?"" Excerpts from an email sent by a tourist to officials in the municipality of Burg in the Spreewald region south of Berlin. Burg is a lovely little town in the Spreewald Biosphere Reserve, a charming network of sprawling forests and intricately networked streams that attracts tourists from far and wide. The town is bright, clean, full of half-timbered houses and has no train station. I arrived in a rental car in the middle of a Wednesday in October. The news stories that brought me here described Hitler salutes in the schoolyard, students calling out ""Arbeit macht frei,"" the slogan the Nazis wrote on a sign at the entry of the Auschwitz concentration camp, in the classroom and restaurants run by violent hooligans. It all reached the public last spring after two teachers at a school in town wrote an open letter decrying the situation. Almost all German media outlets ran stories about it. The article you are reading originally appeared in German in issue 8/2024 (February 17th, 2024) of DER SPIEGEL. The education minister of Brandenburg, the German state in which the Spreewald is located, said that the situation in Burg reminded him of an era ""which should actually be far in the past in Germany."" From a distance, it looked a lot like right-wing extremists had taken control of the town. Welcome to Naziville. While heading there in the car, I thought to myself: It can’t be that bad. I parked and got out. First off, I saw the lampposts, plastered with stickers from the far-right Alternative for Germany (AfD) party and from the neo-Nazi NPD. ""Courage for Germany,"" they read, and ""The Greens Are Germany’s Ruin."" The second thing I saw was the group of boys striding toward me in bomber jackets with lettering in the Fraktur font favored by the Nazis – almost as if the clothing had been copied directly out of a 1990s neo-Nazi documentary and pasted onto their brawny physiques. The third thing I saw was the green T-shirt of a man standing next to the entrance of the school. Like a party promoter on the summertime beaches of Mallorca, he was holding out flyers to the young men. When I approached, I could discern on his back the logo of the III. Weg (Third Way), a tiny neo-Nazi party that seeks the ""peaceful restoration of greater Germany"" and of the German empire. Those were my first five minutes in Burg. I thought to myself: ""Holy shit.” First impressions are unreliable. They tend only to show the external and rarely offer clues to what lies deeper inside. After that day in October, I made several more trips to Burg. I went to festivals, attended committee meetings, sat in on classes at school and went to the bar. I spoke with residents who felt that reports about their town were the result of a vast misunderstanding or a vast conspiracy, and with others who are ashamed of what happened in their village, and of what is still happening. Burg is home to 4,264 people. The majority of those I met were very friendly and not at all right-wing extremist. Which makes it all the more difficult to answer questions as to why neo-Nazis can so openly affix their stickers to lampposts, parade around with right-wing logos on their chests and pass out flyers in front of the schools. The Neighboring Towns Thought the Letter Referred to Them In October, during my first visit, a gray-haired man wearing a collared shirt, jeans and glasses emerged from the school after a few minutes. The III. Weg promoter was just speaking to a teenager who was waiting for the bus. The gray-haired man approached and spoke to him briefly, a serious yet not unfriendly expression on his face. The neo-Nazi nodded and stuffed his neo-Nazi flyer back into his bag. The gray-haired man went back into the building. The gray-haired man is named Markus Mandel, 63, and he has been Burg’s crisis manager since summer. He is the new director of the Elementary and Secondary School of Burg – the educational facility that made Burg famous around the country. I visit him in his office two days later. He is drinking out of a cup reading ""Good Mood Mug :-)” He is a man who, once you have met him, always has a smile on his face in your memory. Mandel describes himself as a long-time resident of Burg and speaks in the local dialect. He was once a teacher at the school in Burg, from 1984 to 2011, and his children are students here. In August, he says, a senior education official came to the school in Cottbus where he was teaching at the time. Mandel didn’t know what the official wanted to talk to him about, only that it was important. Because when a senior official says: ""No, I’ll come to you,"" it means it’s important. The man wanted to speak with Mandel about the letter that had been written by the teachers in Burg. An excerpt: ""School furniture is defaced with swastikas, right-wing extremist music is listened to in the classroom and school halls are filled with anti-democratic chants. (…) There is a feeling of powerlessness and of coerced silence.” Initially, the letter was written anonymously and Burg wasn’t specifically named, only it’s region, Spree-Neisse. A teacher who still works at the school in Burg told me several months later that she spoke with teachers from other towns in the region at a seminar. Almost all of them, she said, thought that the letter described the school where they taught. Shortly after the letter, even before the two teachers from Burg went public as the authors, a photo turned up. It showed 24 youth next to a soccer field in Cottbus, just 18 kilometers from Burg. They were standing and sitting on a wooden bench and some of them were sitting on the shoulders of others, like a team after an important victory. Nine of them were showing the Hitler salute. Several are students at the school in Burg. The school official asked Mandel to take the job of school principal. ""They hope that I’ll be able to fix things,"" says Mandel. ""We’ll see."" It’s not entirely clear what he is supposed to fix. De-Nazify the Burg school? Reestablish harmony among the quarrelling teachers? Apparently, the teachers divided into two camps after the letter went public: Those who supported the move and refer to themselves as ""us democrats,"" and the others who see the two teachers as being snitches. Most likely, Mandel was expected to produce that which politicians so often yearn for after a scandal: peace and quiet. Somehow. On the morning that I am sitting in his office, Mandel doesn’t have much time. He has an appointment with the father of a student who had been told by a teacher that the black-white-and-red cuff of his T-shirt sleeve could be seen as a reference to the German imperial flag, a symbol frequently used by neo-Nazis. The father, for his part, thought that the teacher had called his son a Nazi. ""So, you try to explain it,"" says Mandel. Such things are now part of his job. He says that a computer science teacher recently wanted to give his class an arithmetic problem, but realized that the solution was 88. H is the eighth letter in the alphabet, and in neo-Nazi circles, 88 is short for ""Heil Hitler."" The problem was changed, says Mandel. ""You can’t be too careful around here at the moment,"" says Mandel. How many right-wingers are there at the school? A clique, Mandel says. Those in the picture from the ninth and tenth grades. Maybe 10 or 15 people. Two or three of them are the leaders, charismatic types. And a lot of followers, he says. But there have been people like that here for decades, he says. Recently, Mandel says, he ran into a former student of his, who he had seen after graduation standing behind an information stand for the far-right extremist NPD party. Now, he is the father of a first grader at the school. Another father, he relates, once said he has no problem if his child goes along to Auschwitz. It’s all ""fake"" anyway, the father said, just sets from ""Schindler’s List."" ""You don’t really know what to say in such moments,"" says Mandel. He lists all the things they now do, after the scandal, in addition to the annual trips to Auschwitz that have taken place since the 1990s – mandatory for all students. Recently, former neo-Nazis who had left the scene visited the school, tough young men from Chemnitz and Dresden. They told the students how bad things were in the scene. And after the summer holidays, the tenth graders visited Jamlitz, a satellite camp of Sachsenhausen where the SS murdered thousands of Jewish prisoners in 1945. A poster about the life of Anne Frank hangs in a school hallway. ""She believed in the equality of all and that it is possible to change society,"" it reads. Later, Mandel tells the story of a second grader who had called out ""Heil Hitler."" They took both him and his mother to the youth welfare office. ""He was sobbing the entire time. If he’s not traumatized, then I don’t know what’s going on,"" says Mandel. A framed sign hangs above his computer. It reads: ""Life's not make-a-wish. It is what it is!"" And then, it’s time for him to head off to the meeting with the father about his son’s black-red-and-white T-shirt sleeve. Burg Survives on Tourism In the center of Burg, there is a monument in front of the church. It looks a bit like a gravestone and reads: ""Germany United Fatherland."" There is also a trio of grocery stores, two pharmacies and three bakeries. Rents, say residents, aren’t that much lower than in the big city, and it is difficult to find a hot lunch in a restaurant for below 15 euros. Burg survives on tourism and is home to medicinal hot springs. In 2022, more than 165,000 visitors came to Burg, biking through the forests or punting along the numerous canals and streams that crisscross the region. The area is sometimes referred to as the German Everglades or the Amazon of Brandenburg. It is essentially a populated swamp. In 2021 parliamentary elections, 30.4 percent of voters in Burg cast their ballots for the AfD. Hans-Jürgen Dreger, 69, is the kind of mayor of whom people say: ""He’s the kind of mayor you want to have."" He's a large man with a deep voice, a serious handshake and a fleece jacket. He doesn’t belong to a political party. He makes his way around town on a bicycle and doesn’t lock it up when he leaves it somewhere. For 11 years, he ran the kitchen at a farming collective and then spent 13 years operating a cafeteria at an athletes’ residence. Now, he's retired – and the volunteer mayor of Burg. He was actually supposed to be the deputy, but when his predecessor resigned in 2020, he went to regional officials and said: ""But I don’t have a clue about municipal politics."" They responded: ""You don’t need to. You just need to know the people."" ""That’s how it is,"" says Dreger. He knows the people. As we are walking through town together, a man thanks him for a new street sign that has been put up. A woman greets him across her fence, saying: ""Hey, Jürgen!"" Dreger says that he attends every milestone birthday in town. For the handful of Ukrainian refugees who have been living in Burg for the last year-and-a-half, he sang ""Where Have All the Flowers Gone"" in church in front of the entire village. He helped one of the Ukrainians move, carrying furniture in exchange for a case of beer. ""These are things you just gotta do,"" says Dreger. When he walks into a café, a cycling group made up of older women calls out: ""Jürgen, buy a round!"" So Dreger heads to the counter and orders six advocaats: Five for the women and one for himself. That’s how it is. Dreger says he had actually decided to no longer speak with journalists. He was on a trip to the Polish lakes district of Masuria with a local sports club when someone in the bus called out: ""Hey, Burg is in Bild ,"" referring to Germany’s largest tabloid. Dreger didn’t want to look at first, but then curiosity got the better of him. ""Entire Village Sinks into a Brown Swamp,"" the Bild wrote. After that, a lot of journalists showed up, walking into stores with their cameras, shoving people aside. At least that’s how they describe it in Burg. Once the letter from the teachers hit the headlines, a number of Burg residents gave interviews about it to some media outlet or another, and many of them regretted doing so afterward. Dreger gave one to a television broadcaster – 15 minutes, he says. In the end, only a single sentence made the cut. He feels he has been treated unfairly – as do a lot of people here. And many of them blame the two teachers who wrote the letter. Why, they wonder, didn’t they address the problems internally? With school administrators? With education officials? With the mayor? It Didn’t Start with the School At a party in November with disco lights and patio heaters, a DJ is pumping out songs by Britney Spears and the Austrian rock star Andreas Gabalier as locals in quilted jackets dance the sirtaki. Someone mumbles at me: ""All this right-wing crap being written about Burg is totally exaggerated."" Shortly afterwards, a drunk woman topples over into a bush. On the main street of Burg is a terracotta-colored house, the ""Deutsches Haus"" as green lettering proclaims. It is a traditional restaurant, serving local delicacies like giant currywurst and homemade pork knuckle jelly. A condom machine hangs from the wall out front. The building’s history says a lot about how the people of Burg dealt with the right-wing problem long before Germany started talking about their school. The Deutsches Haus was purchased in 2020 by a man about whom the people of Burg could read in many newspapers. The new owner, the articles noted, was a member of the neo-Nazei scene in Cottbus, from a group of bouncers and hooligans. He apparently had a prior conviction for criminal assault, among other things. The papers also published photos of the new restaurant owner in neo-Nazi clothing at neo-Nazi concerts. The man also leases a hotel in Burg. It looked as though he was interested in building up a small empire in the town. At the party, a local tells me that she once spoke with the man at length and that he is actually just fine. He gives people jobs, she says, including some from Poland – and he’s never done anything bad in Burg. All he wants, she insists, is to run a restaurant. Everybody deserves a chance. Quite a few people in Burg take a similar view. Others, though, say that after he took over the Deutsches Haus, they never went back. After the man bought the Deutsches Haus in 2020, German security officials with the domestic intelligence agency and municipal representatives came to the local council, says Mayor Dreger. They warned him that the restaurant could become a meeting point for the neo-Nazi scene. Dreger says he told them: ""Now I’ve got a problem. When I get home, I have to tell my wife that we can’t go to my cousin’s 60th birthday party next week."" ""Why?"" the security official wanted to know. ""Well, because he is holding his party in the Deutsches Haus,"" Dreger responded. Dreger says he once spoke with the restaurant owner. They sat down at a table and Dreger said: ""I can’t have anything against you yet, because I don’t yet know what is going to happen. But if you do anything in our town that’s not nice, then you’ll get to know me."" Later, the people of Burg were again able to read about the Deutsches Haus in the newspaper. Officials had ""taken note of a meeting there attended by numerous neo-Nazis, who partied and listened to right-wing extremist music."" Right-wing publishing houses held presentations and a podium discussion in the hall. And last year, the AfD hosted a town meeting there. The Deutsches Haus has been closed since the end of October. Nobody in Burg seems to know – or want to say – exactly why. Once, says Dreger, he rode past the Deutsches Haus on his bicycle and thought he heard chants of ""Sieg Heil!"" ""But I have to say, on men’s day, at the beer stand, they also chant stuff like that,"" Dreger says, citing the annual tradition in some parts of Germany. ""It’s just the booze. They don’t even think. It doesn’t matter what you do."" That, though, is the question in Burg: What can you do? And what do they even want to do? Keeping a Low Profile In summer, after the scandal at the school, they did the following: A few residents joined the municipality in organizing a walk through the town during which they scraped many of the right-wing stickers off the lampposts. Buttons for tolerance and respect were handed out at the Heimat Festival and the state’s democracy-mobile was there. At the library, they set up a table for democracy books. And they recorded a video statement called ""#WIRsindBurg,” or We Are Burg. In the four minute and 26 second video, 11 people from Burg, including Dreger, say that they are opposed to ""discrimination, racism and extremism,"" that they stand up ""for diversity"" and that they ""sharply condemn"" what happened at the school. Eleven out of 4,264. Later, several more people joined the statement, including the volunteer fire department, the beekeeping club and the small animal breeding association, though not by video, just by signature. When the neo-Nazi arrived from Cottbus and took over the Deutsches Haus restaurant, there were no protests in Burg. When the letter from the teachers was made public, there were no protests in Burg. When people across Germany protested against right-wing extremism in January, there were no protests in Burg. It is easy to condemn the situation if you don’t live in Burg. It is much more difficult to stand up to neo-Nazis when there are neo-Nazis in the neighborhood and you have to face them. At the mass protests in Berlin, Cologne and Hamburg, there were no neo-Nazis, just hundreds of thousands of people who were against right-wing extremists. There were also no demonstrations in the towns near Burg in January. Only in Cottbus. And in Spremberg, 40 kilometers away. Three-hundred people turned up for that one. The organizers were more than satisfied, since they had only been expecting 50. Maybe people in the Spreewald had been afraid of openly taking to the streets against right-wing extremism. But maybe it simply wasn’t important enough to them. Life is more peaceful if you keep a low profile. One resident says that he initially agreed to participate in the video statement. ""But then I thought about it and said: Nah, maybe I’d rather not,"" he says. ""Because you can interpret it however you want. If you stand up and say you are open to people all over the world, then there is always someone who puts it in a different light."" During one of my visits, I am sitting with a woman in her mid-30s who grew up in Burg. Speaking about her youth, she says: ""People who say it didn’t happen here are lying. Especially when you were at a party in the evening, there was always the guy who, after two beers …"" She raises her right arm, or at least hints at it. And then? ""I always distanced myself from it."" How so? ""I’d just go somewhere else."" Burg isn’t very big. There aren’t too many somewhere-elses you can go. There is a sports association in town called SG Burg. The head of the association is openly gay. He runs an ice cream parlor in the center of town and organized the party with the disco lights and sirtaki dance. He says he’s never had any problems in Burg. Three years ago, SG Burg posted a photo with the rainbow flag on its Instagram account along with the slogan: ""Together against Racism."" It received 46 likes. There is also a bar in town called ""Bruno’s Bar,"" but everyone just calls it At Bruno. At Bruno is a rebuilt barn where gray-haired men wearing earrings play five-pin billiards, smoke cigarillos and talk about their professions, all of which sound like they all should have died out since the turn of the millennium. Stonecutter, ferryman, railroad worker. Bruno himself talks about playing in what was perhaps the only reggae band in East Germany and how they had to get their lyrics officially approved. The wall next to the bar has anti-Nazi stickers on it, and one reading: ""I take racism personally."" But there are also those in Burg who, after a couple of beers, talk about people with immigrant backgrounds as ""whatever else is wandering around ."" Or those who, right in the middle of the main street, hang a black-white-and-red sign from their door reading in Fraktur font: ""Don’t lie, don’t cheat, don’t steal – the government doesn’t like competition!"" On one evening in November, the Committee for Culture, Tourism and Social Affairs has gathered in the community center: men in glasses, women in blouses. There are a total of 15 of them, and they all have paper name signs in front of them, even though they have known each other for years. Mayor Dreger is on hand, shaking hands and saying things like: ""You’re here and not in Hollywood?"" They talk about the Christmas party for the elderly, about the sports club party that ""got a little out of control from a volume point of view,"" and about the lack of a handrail in the mortuary. But first, the heads of daycare facilities in the town have a word. They were recently evaluated by a Berlin foundation at the behest of the state of Brandenburg, and the resulting appraisal wasn’t particularly positive. The reasons given in the report: They still read Grimm’s fairy tales with the children, which glorify violence; the meals they serve contain too much meat; and they don’t celebrate the Festival of Sweets at the end of Ramadan. There is a fair amount of disbelief as to what the people in Berlin imagine life to be like in Burg. There are no Muslim children in town. The discussion is essentially over when a man from the committee suddenly says: ""I’m happy that things here aren’t like they are in Berlin, with the Festival of Sweets and all that stuff. And that such things hopefully won’t come here one day. They are things that we don’t need, and that Germany doesn’t need either. It’s becoming clear that it doesn’t work. I don’t even know what the Festival of Sweets is – a kind of Islamic custom or something.” After the meeting, we all mill about out on the sidewalk. One person says: ""The word Nazi is also mixed up with people who are just a bit dissatisfied with how some foreigners here act. But that doesn’t make them Nazis.2 Another counters: ""But you can’t really be dissatisfied here. There’s no contact with foreigners here."" It’s the same man who decided not to take part in the video statement about tolerance because he was worried about being misunderstood by other people in town. Just Like the Clichés The Elementary and Secondary School of Burg also has a second name, that of Mina Witkojc. She was a poet who wrote in Lower Sorbian, the language of the local Slavic minority in this corner of Germany, and a native of Burg. During the Nazi period, however, she was forced to leave her home and the Nazis also forbade her from continuing to write. In fact, Hitler’s lackeys didn’t just oppress Witkojc, they also targeted all members of the Sorb and Wend minorities, who have called the Spreewald region home for centuries. They were hardly able to speak their native languages and some of them were hauled away to concentration camps. They were the ancestors of those who now live in Burg. Today, the 503 students in the Elementary and Secondary School of Burg are once again allowed to learn Sorbian. It is a modern school with smartboards in the classrooms and an organizational app for the teachers. The façade is covered with large windows, with a rainbow flag hanging from the one belonging to one of the teachers’ rooms. Not long ago, unknown perpetrators cut the flag off and stapled a German flag to what was left. Mandel, the school principal, called the police and had them drive into the schoolyard, with the officers then searching for clues. Since then, nobody else has tried to steal the flag. At 10 a.m. on a Thursday in January, 25 eighth graders are sitting in one of the classrooms. The girls are wearing artificial nails and black hoodies; the boys have parted hair and wear white sneakers. It smells like teenage sweat and sweet deodorant. A list of anti-bullying rules hangs on the wall. The kids say things like ""you jackass"" and ""give me my shit back."" Plenty of slang. They all have extremely German names. Up front is the teacher, Jette Schega, preparing for a double period of politics, a subject on the Burg curriculum. Today, the focus is on the German constitution. Schega passes out worksheets that the students turned in during the previous class and which she has now corrected. In one exercise, students were asked to classify certain terms as being ""pro human rights"" or ""against human rights."" Schega says: ""A few things caught my eye. A couple times there was a term that was listed in the wrong category. The term is extremism. Some of you included it in the pro human rights category. Could someone who did so please let me know?"" A boy raises his hand. Schega: ""What was your reasoning?"" The boy: ""Because extreme … to be honest, I just guessed."" The other students laugh. Later, Schega asks what the right to equal rights means. A girl says: ""That people aren’t treated like garbage because of small things like skin color or background."" At the school in Burg, there are very few young people who are immediately recognizable as right-wing. But there are a lot of stories. There is the story of the teacher who, after discussing the Hitler Youth over several lessons asked the class: ""So, who would still join them now?"" Almost 10 hands shot into the air. There there’s the music teacher who says that at least one student each year asks him if it is OK to hold a presentation on a right-wing extremist rock band. And there are the two girls who would blend in completely at any school in Berlin. They have long hair, off-shoulder tops, braces and nose piercings. They think Nazis are stupid. The right-wing boys, they say trip them in the hallways and call them ""leftist cunts."" Sometimes, they are afraid to ride the bus when they see one of the boys, the girls say. If you ask around about the kind of teens who landed the Burg school in the headlines, you start hearing stories about fathers in prison and big brothers who are neo-Nazis. They sound a lot like clichés in circulation about right-wing youth in Eastern Germany. The underlying causes have been examined in countless studies, discussed by countless working groups and countless politicians have claimed to take the issue seriously. But hardly anything seems to have changed. ""Even during East German times, we had families where grandpa made all the decisions,"" says school director Mandel. ""Families where even today, the parents say that dictatorship is a great thing. It’s passed on here in the villages."" ""Fucking Vermin! You Traitor!” On another day, I’m walking up the steps together with Mandel. A boy says: ""Look Mr. Mandel, I have a balloon."" In his hand, he's holding an inflated condom. Mandel takes it away from him and says: ""At least I now know what else you can do with it."" Then it pops. The boy is one of the students seen in the photo giving the Hitler salute. On this day, he's wearing a T-shirt that reads ""GERMAN FIGHTER"" on the back. He, too, has a very German name. For this article, we’ll call him Heinrich. Heinrich’s next class is astronomy, which is also its own subject here at the school in Burg. I sit down at the back of the classroom. Before the period starts, some boys, who aren’t part of the class, wander in wearing bomber jackets and try to look at me in a very intimidating manner. Fifteen-year-olds in bomber jackets who think they look a lot scarier than they actually do. Fifteen-year-olds for whom only a couple of years and a couple of bad decisions are necessary before they, when you run into them on the street, really do scare you because they might punch you in the face. The lesson starts. The students throw coins and folders at each other, make monkey noises and hit each other’s heads with their books. A girl calls over to Heinrich: ""Heinrich, Dennis is gay, and he likes you."" Heinrich grins and says: ""I know."" In the middle of the period, the teacher sends him out. The bomber-jacket boys are out in the hall and they roar in amusement. The teacher asks them, ""don’t you have class?"" and drags Heinrich back into the room. Before long, the 45 minutes are up. It’s not that the teacher, an older gentleman, has no authority. He's simply unable to get his students to listen to him for more than 10 seconds at a time. Indeed, in this moment, it is extremely difficult to imagine how he or any other teacher would even be able to lead a serious discussion with these teenagers about tolerance or racism. On one occasion, a teacher tells me after class that she feels like everyone in Burg just want things to be ""fine."" That normality would return after that letter. The two teachers who wrote it, Max Teske and Laura Nickel, gave a lot of interviews in the weeks after publishing their letter and held a speech at a rally in front of the education authority in Cottbus. They received prizes for their display of civil courage. And they are now gone, having left the school last summer. On a Thursday in February, Teske is sitting in a café not far from Potsdam. He asks that the exact location not be revealed, and when he starts talking about what his life was like after the letter, it becomes clear why. Teske says that he and his colleague came up with the idea of writing an open letter after the old school principal didn’t report a Hitler salute during gym class to the school authorities in Cottbus. He and several other teachers talked about what they could do. Teske was just packing his bag when Nickel came into the teachers’ room and asked him: ""Max, should we write a letter and send it to the media?"" Two days later, they ate a döner plate together, wrote up the letter in the car and sent it to two local media outlets, an online portal and the public broadcaster RBB. ""We actually thought that it would just be a small letter to the editor,"" Teske says. In the months that followed, German security authorities visited them at home to see if they were safe. And on the internet, it was open season on him and Nickel. Stickers with their faces were plastered to the lampposts in Burg, reading: ""Fuck off to Berlin."" And then there was the time when he was buying breakfast rolls one weekend. Teske says a group of men ran up to him. ""Fucking vermin! You traitor!"" He was holding the hand of his four-year-old daughter, who broke out in tears. ""It almost got violent,"" Teske says. He stops for a bit. ""After that, I said: OK, I have to get out of here."" That was in Cottbus, where Teske was living at the time. In Burg, Teske says, he was once standing together with Nickel in a parking lot when an older woman stopped her car next to them. She was in her mid or late 60s. He says she asked them: ""Hey, aren’t you those two teachers?” She then said: ""I wanted to thank you. It’s so important. Finally, someone here said something."" Teske says that parents also came up to him on his last day of school in Burg to thank him. ""There are really good people in Burg. We had more support than hostility from people in town. There were a lot of people who said: 'I would love to get loud and speak up. But I know that if I do, I’d have to move away.'"" Not many things are obvious in Burg. When we leave the café after one-and-a-half hours and climb into Teske’s car, the song ""Schrei nach Liebe"" (Scream for Love) by Die Ärtzte is playing, the band’s anti-Nazi song about the romantic hope that Nazis would let go of their hate if only people showed them enough love. German President Frank-Walter Steinmeier said in July that he hoped that the departure of Teske and Nickel from Burg didn’t mean that the right-wing extremists had won. But people at the school say that other teachers who supported the letter from Teske and Nickle are now thinking of leaving town. As I’m standing with the teacher at the lectern, she asks me at some point, ""did you see that in the doorframe?"" I turn around. ""It must be relatively new,"" she says. Someone has carved a swastika into it."
KI,Spiegel Online,2024-02-22,https://www.spiegel.de/wirtschaft/unternehmen/nvidia-profitiert-von-ki-boom-chiphersteller-zieht-dax-nach-oben-a-72c90dad-fd9d-440b-b59a-97532a249b47,Nvidia profitiert von KI-Boom – Chiphersteller zieht Dax nach oben - DER SPIEGEL,"Dank des Runs auf KI-Lösungen hat Nvidia starke Zahlen vorgelegt. Der Dax stieg auf ein Rekordhoch, der Nikkei so hoch wie zuletzt in den Achtzigern. KI-Entwickler Sam Altman warnt aber auch vor Risiken der Technologie. Der Boom beim Einsatz künstlicher Intelligenz (KI) sorgt weiterhin für explosives Wachstum beim Chipkonzern Nvidia . Im vergangenen Quartal lag der Umsatz mit 22,1 Milliarden Dollar mehr als dreimal so hoch wie ein Jahr zuvor. Analysten hatten im Schnitt mit 20,4 Milliarden Dollar gerechnet. Die Aktie legte im nachbörslichen US-Handel um gut neun Prozent zu, der Dax stieg zu Handelsbeginn um 1,3 Prozent auf über 17.300 Punkte und übertraf damit seine jüngste Bestmarke, die er Ende vergangener Woche aufgestellt hatte. In Japan stieg der Leitindex Nikkei 225 nach Bekanntgabe der Nvidia-Zahlen so hoch wie seit rund 35 Jahren nicht mehr. Das Geschäft mit Technik für Rechenzentren brachte dem Unternehmen mit 18,4 Milliarden Dollar sogar fünfmal so viel Umsatz wie im Vorjahresquartal. Die ursprünglich für Grafikkarten entwickelten Nvidia-Technologien bewähren sich schon seit Langem bei der Rechenarbeit zum Anlernen von Anwendungen mit KI. Das lässt das Geschäft – und den Börsenwert – von Nvidia rasant steigen. Nvidia-Aktie: Plus 40 Prozent seit Jahresbeginn Die Zahlen waren mit großer Spannung erwartet worden. Die Nvidia-Aktie legte allein seit Jahresbeginn um rund 40 Prozent zu – und Beobachter gingen davon aus, dass der geringste Hinweis auf eine Abschwächung des Wachstums zu einem Kurseinbruch hätte führen können . Nvidia enttäuschte jedoch nicht. Auch der Ausblick für das laufende Quartal lag über den Erwartungen. Nvidia stellte Erlöse von rund 24 Milliarden Dollar in Aussicht, am Markt war im Schnitt mit einer Prognose von etwa 22 Milliarden Dollar gerechnet worden. Der Quartalsgewinn von Nvidia sprang binnen eines Jahres von 1,4 auf knapp 12,3 Milliarden Dollar. Der KI-Einsatz habe einen Wendepunkt erreicht, und die Nachfrage steige weltweit, sagte Nvidia-Chef Jensen Huang. Der Chef des ChatGPT-Entwicklers OpenAI geht davon aus, dass es künftig mehr von KI als von Menschen erstellte Inhalte geben wird. Die Gesellschaft müsse sich aber auch auf negative Folgen des KI-Booms vorbereiten, sagte Sam Altman am Mittwoch bei einer Veranstaltung des Chipherstellers Intel . Einfluss auf Wahlen oder Waffen? So könne es in absehbarer Zukunft potenziell negative Auswirkungen auf Wahlen geben. Man nehme auch Risiken zum Beispiel bei Cybersicherheit und Biowaffen ernster. KI werde »keine nur gute Geschichte sein«, sagte Altman im Gespräch mit Intel-Chef Pat Gelsinger. Aber unterm Strich werde es eine positive Entwicklung, zeigte er sich überzeugt. Mithilfe von KI werde man wissenschaftliche Forschung beschleunigen, Krankheiten heilen und Bildung verbessern können, sagte Altman. »Ich denke, es ist schwierig, sich heute vorzustellen, wie viel besser die Zukunft sein wird.« Man brauche aber noch mehr als bei anderen Technologien eine regulierende Rolle von Regierungen – und zwar jetzt, während die KI-Modelle noch relativ schwach seien. Es dürfe nicht so laufen, dass zum Beispiel OpenAI heimlich im Keller eine KI entwickele, die schlauer als Menschen ist und sie plötzlich auf die Welt loslassen. Die Gesellschaft und ihre Institutionen müssten die Zeit bekommen, sich schrittweise an die Entwicklung anzupassen. ChatGPT befeuerte vor gut einem Jahr den KI-Hype. Solche KI-Chatbots werden mit gewaltigen Mengen an Informationen angelernt und können Texte auf dem sprachlichen Niveau eines Menschen formulieren, Software-Codes schreiben und Informationen zusammenfassen. Das Prinzip dahinter ist, dass sie Wort für Wort abschätzen, wie ein Satz weitergehen sollte. Nachteil: Die Software gibt manchmal auch völlig falsche Antworten aus, selbst wenn sie nur korrekte Informationen als Basis hatte. Etwas gebremst indes wird das Nvidia-Geschäft von Maßnahmen der US-Regierung gegen Lieferungen von KI-Technologie nach China. Nvidia darf seine modernsten Chipsysteme nicht dorthin verkaufen. Washington verweist auf das Risiko, dass die Technik für militärische Zwecke eingesetzt werden könnte. Auch für eine abgespeckte Version der Geräte bekam Nvidia bisher keine Ausfuhrlizenz, deswegen wurden zuletzt Chips geliefert, deren Leistung unter den vorgegebenen Grenzwerten liegt. Intel baut Spezialchips für Microsoft Intel wiederum wird künftig womöglich Microsoft zur ein oder anderen KI-Anwendung verhelfen. Zwar gibt es noch keine Details zum Zeitplan oder zum Chip, doch das Softwareunternehmen werde einen neuen Chip von Intel mit neuer Produktions-Technologie durch den Halbleiterkonzern bauen lassen, sagte Microsoft-Chef Satya Nadella. Microsoft hatte bereits zuvor angekündigt, einen Computer-Prozessor und einen Spezialchip für KI-Anwendungen zu entwickeln. Intel-Chef Gelsinger gab das Ziel aus, Intel-Kunden in wenigen Jahren die modernste Produktions-Technologie anzubieten. Bisher sammelte Intel als Auftragsfertiger Aufträge in Höhe von 15 Milliarden Dollar ein. Intel plant gerade neben Werken in den USA auch zwei Fabriken in Magdeburg, in denen hochmoderne Chips produziert werden sollen. Der Konzern kündigte bei dem Event am Mittwoch den nächsten Schritt in der Prozessor-Fertigung mit einer noch höheren Transistoren-Dichte an."
KI,Spiegel Online,2024-02-22,https://www.spiegel.de/netzwelt/apps/google-gemini-bildgenerator-erzeugt-keine-bilder-von-menschen-mehr-a-56385e21-9c95-4ae8-a60c-922e3f4fcbea,Google Gemini: Bildgenerator erzeugt keine Bilder von Menschen mehr - DER SPIEGEL,"Bei Gemini gibt es offenbar Nachbesserungsbedarf: Nach einer Welle der Kritik im Netz ist es mit Googles KI-Tool aktuell nicht mehr möglich, Bilder mit Menschen zu generieren. Katzenbilder spuckt es weiter aus. Mit seinem KI-Tool Gemini will Google Werkzeugen wie ChatGPT Konkurrenz machen – unter anderem mit einem integrierten Bildgenerator. Aktuell jedoch wirken dessen Fähigkeiten ziemlich beschränkt: So weigert sich der Generator am Donnerstagvormittag unter anderem, Bilder einer Familie, von Feuerwehrleuten oder einer Schulklasse zu erzeugen. Nutzerinnen und Nutzer, die entsprechende, eigentlich unverfängliche Prompts eintippen, werden mit der Antwort abgespeist, dass Geminis Fähigkeit zum Erzeugen von Bildern von Menschen gerade verbessert werde: »Wir erwarten, dass diese Funktion bald wieder zur Verfügung steht.« Bilder etwa von Katzen oder Robotern werden derweil problemlos generiert, zeigte ein Kurztest des SPIEGEL. An Geminis Bildgenerator war seit Dienstag massive Kritik laut geworden. Nutzerinnen und Nutzern der Plattform X war beim teils sehr gezielten Herumprobieren zum Beispiel aufgefallen, dass sich das Tool weigerte, Prompts umzusetzen, in denen von weißen Personen die Rede war, wie etwa »strong white man«. Bei der Eingabe der Wortfolge »strong black man« dagegen gab es Screenshots zufolge offenbar keine künstliche Einschränkung, es wurden Bilder ausgespielt . Für Aufsehen sorgten auch historisch anmutende Motive, bei denen Gemini offensichtlich übermäßig viel Wert auf Diversität legte. Viel geteilte, mutmaßlich authentische Screenshots zeigten etwa asiatisch gelesene Frauen in einer Art Wehrmachtsuniform, einen schwarzen Wikinger sowie eine schwarze Wikingerin, die jeweils Dreadlocks haben. Die Prompts dazu lauteten angeblich schlicht »1943 German soldier« und »a soldier from 1929 Germany« beziehungsweise »viking« . Auf den Prompt »pope« (Papst) reagierte Gemini derweil unter anderem mit einem Bild einer dunkelhäutigen Frau . Das Portal »BR24« schrieb am Donnerstagmorgen auf Basis eines eigenen Kurztests, Geminis Bildgenerator meine es »mit der Vielfalt durchaus ernst«: »Fast immer generiert die KI Menschen verschiedener Herkünfte und Hautfarben. Wie repräsentativ diese für einen historischen Schauplatz sind, spielt dabei kaum eine Rolle.« Außerdem machte »BR24« die Beobachtung, dass sich Gemini weigerte, ein Bild eines »weißen Rennfahrers« zu generieren. War im Prompt jedoch von einem »schwarzen Rennfahrer« die Rede, lieferte das Tool Ergebnisse. Google hat ein Problem eingestanden Einer der ersten Gemini-kritischen Beiträge, die in dieser Woche auf X viral gingen, war ein Posting des ehemaligen Google-Mitarbeiters Debarghya Das . Er hatte Bilder verschiedener per Gemini generierter Gesichter mit dem Satz überschrieben, es sei »beschämend schwer«, Gemini dazu zu bringen, »anzuerkennen, dass weiße Menschen existieren«. Auf der Basis von Screenshots Dritter konstatierte Das später noch , Gemini erzeuge »keine weißen Menschen, selbst dann nicht, wenn man nach einem mittelalterlichen König, einem Papst, einem Amerikaner oder sogar nach den Gründern von Google selbst fragt«. Jack Krawczyk, der bei Google an Gemini arbeitet, reagierte am Mittwochnachmittag auf die Kritikwelle. Direkt auf X schrieb er, seinem Team sei bewusst, dass Gemini »Ungenauigkeiten« beim Erzeugen historischer Bilder aufweise. Man arbeite nun daran, die Sache zu lösen. Grundsätzlich jedoch gestalte Google seine Bilderzeugungsfunktionen so, »dass sie unsere globale Nutzerbasis widerspiegeln«. Man nehme Themen wie Repräsentation und Bias ernst und werde dies auch weiter tun, wenn es um »Prompts mit offenem Ende« gehe. »Bilder von einer Person, die mit einem Hund spazieren geht, sind universell«, betont Krawczyk. Google selbst teilte in einem Statement mit: »Die KI-Bilderzeugung von Gemini erzeugt ein breites Spektrum an Menschen. Und das ist im Allgemeinen eine gute Sache, weil Menschen auf der ganzen Welt sie nutzen. Hier aber ging es am Ziel vorbei.« In einem weiteren Statement kündigte Google offiziell an, die Generierung von Bildern von Personen zu pausieren . »Bald« solle dann eine überarbeitete Version der Funktion veröffentlicht werden. Für deutsche Nutzerinnen und Nutzer ist Geminis Bildgenerator bisher nicht offiziell verfügbar. Wer ihn ausprobieren möchte, benötigt neben einem Google-Account daher eine VPN-Verbindung, die dem Tool vorspiegelt, dass man beispielsweise ein Nutzer oder eine Nutzerin aus den USA ist."
KI,Spiegel Online,2024-02-22,https://www.spiegel.de/start/startklar-newsletter-warum-wir-im-zeitalter-von-ki-neue-pruefungsformen-brauchen-a-d18ecc28-ae10-4a2f-a05a-2c3701e5fe65,Startklar-Newsletter: Warum wir im Zeitalter von KI neue Prüfungsformen brauchen - DER SPIEGEL,"Mein Studium bestand aus Hausarbeitenstau und Prüfungsphasenstress. Wissen eignete ich mir dadurch nur kurzzeitig an. Pro Semester waren es meist drei Hausarbeiten, die mein Studienverlaufsplan für die Semesterferien vorsah. Und da ich meine Ferienzeit nicht mit Prüfungsstress belasten wollte, schob ich sie oft auf. Ein Hausarbeiten-Stau entstand, bis ich mich einmal im Jahr für einige Wochen in der Bibliothek einschloss und alles wegarbeitete. Heute weiß ich: Ich sammelte auf diese Weise Leistungspunkte, aber kaum Wissen. 15 Seiten schrieb ich über die ersten Demokratiebestrebungen im altpersischen Reich – wie genau die aussahen, kann ich nicht mehr sagen. Unsere Kolumnistin Ananda Klaar kritisiert die aktuellen Prüfungsformen an Universitäten in Deutschland. Warum Prüfungen Studierende stark belasten und weshalb Hausarbeiten im Zeitalter von KI veraltet wirken, schreibt sie in ihrer neuen Kolumne . Viel Spaß beim Lesen wünscht Lukas Hildebrand , Redakteur SPIEGEL Start Wir brauchen neue Prüfungsformen – und zwar schnell!: Druck, Angst, schlaflose Nächte: Die Prüfungsphase macht vielen zu schaffen. Für mich hat sie sich vor allem nach Fleißarbeit angefühlt, nicht wie eine Vorbereitung auf Job und Leben. Das muss besser gehen . »Ich war schon Unternehmer, bevor ich wusste, was das ist«: Knapp fünf Prozent der deutschen Gründer haben keinen Berufsabschluss, manche führten schon als Schüler ihre erste Firma. Hier erzählen fünf von ihnen ihre Geschichte und sagen, warum ihnen der Abschluss nicht fehlt. Niemand will mehr Chefin sein? Kein Wunder!: Sich für ein bisschen mehr Geld und einen schicken Titel kaputtarbeiten? Darauf haben immer weniger Arbeitnehmer Lust. Ein Grund, das Konzept »Chef« neu zu denken . »Andere Verkehrsteilnehmer sind oft genervt von uns« : Gamze Arslan bringt Menschen das Autofahren bei. Hier erzählt sie, wie sie nervöse Anfänger beruhigt , wann in ihrem Auto die Tränen kullern und warum sie Männer für die besseren Fahrer hält."
KI,Spiegel Online,2024-02-21,https://www.spiegel.de/netzwelt/netzpolitik/tiktok-plus-ki-fake-news-war-gestern-die-aera-der-fake-reality-beginnt-sascha-lobo-kolumne-a-d358aa2e-86cb-49cd-9317-62c23f97a6cf,"TikTok plus KI: Fake News war gestern, die Ära der Fake Reality beginnt - Sascha Lobo-Kolumne - DER SPIEGEL","Schon jetzt eignet sich TikTok nicht nur, aber eben auch hervorragend zur Verbreitung von Ideologien. Was wird wohl passieren, wenn es mit neuer Text-zu-Video-KI wie Sora kombiniert wird? Soeben bewegen sich zwei unaufhaltsam erscheinende Technologiekomplexe aufeinander zu, die schon allein die Kraft hätten, unsere Welt zu verändern. Wir können erst grob erahnen, was passiert, wenn sie verschmelzen. Der eine ist das soziale Netzwerk TikTok, für das die EU gerade eine Untersuchung eröffnet hat . Vor allem, um herauszufinden, wie sicher Kinder und Jugendliche dort sind, was etwa Suchtpotenzial, den »Rabbit-Hole-Effekt« oder Altersverifikation angeht. Der andere ist eine Technologie, natürlich aus dem Bereich der generativen künstlichen Intelligenz , der den sperrigen Genrebegriff »text to video« trägt. ChatGPT-Schöpfer OpenAI hat jüngst Sora vorgestellt , eine KI, die aus kurzen, hingeworfenen Befehlen in kürzester Zeit mehr oder weniger realistisch aussehende Filmsequenzen generieren kann. Sascha Lobo, Jahrgang 1975, ist Autor und Strategieberater mit den Schwerpunkten Internet und digitale Technologien. Gemeinsam mit Jule Lobo beschäftigt er sich im Podcast »Feel the News – Was Deutschland bewegt« mit aktuellen Debattenthemen. Die Frage, warum man beides gemeinsam und auf die potenzielle Wirkmacht bezogen betrachten muss, beginnt mit TikTok . Die chinesische Video-App ist eine der wichtigsten Unterhaltungs-, Informations- und auch Nachrichtenplattformen der Generation bis dreißig Jahren in der westlichen Welt. TikTok hat es durch radikale Fokussierung auf eine Art algorithmischen Populismus geschafft, sehr vielen Menschen genau die Inhalte zu zeigen, die sie sehen wollen. Selbst, wenn sie das vorher noch gar nicht wussten. Ein in der Frühzeit der Netzkultur dafür geprägter Begriff lautet »serendipity«, was man mit »finden ohne zu suchen« übersetzen kann. TikTok hat für anderthalb Generationen ein Anreizsystem geschaffen, wie Unterhaltung hyperpersonalisiert und Kreativität in Macht übersetzt werden kann. Denn letztlich bietet TikTok dem Publikum unendliche und wirklich gute Unterhaltung. Den Inhalteproduzierenden aber bietet TikTok Reichweite, Monetarisierung und eine Relevanz, die von den meisten älteren Lebensteilnehmern noch immer drastisch unterschätzt wird. An der Reichweite ist vor allem attraktiv, dass TikTok in sozialen Netzwerken völlig neu definiert hat, wie die sogenannte Viralität entsteht, also die explosive Verbreitung einzelner Inhalte. Dadurch können auch Leute mit sehr wenig Followern ein Millionenpublikum erreichen – mit der richtigen Idee für ein Video. Feuerwerk der Manipulation TikTok hat gegenwärtig den wohl besten existierenden Empfehlungsalgorithmus. Leider kann er ausgenutzt werden, und zwar insbesondere von Leuten, die mit verkürzten oder ganz gefälschten Informationen arbeiten, um eine besondere Form der TikTok-Sensationalisierung zu erreichen. Die TikTok-Sensationalisierung hat viele unterschiedliche, kulturelle Facetten, und die meisten davon sind strukturell positiv. Im Kern geht es meist um die kreative Fähigkeit, mit Witz, Charme, manchmal Intelligenz und Musikschnipseln sowie ein paar technischen Spielereien eine interessante bis spektakuläre Sekundeninszenierung herzustellen. Politisch, gesellschaftlich und nachrichtlich ist TikTok bei Weitem nicht nur, aber inzwischen eben auch ein Feuerwerk der Manipulation, das sich hervorragend zur Verbreitung von Ideologien eignet. Die Inszenierungsradikalität auf TikTok bedeutet zu oft, dass für wahr und richtig gehalten wird, was sich gut und interessant anhört. Das ist zugegeben nichts, was TikTok erfunden oder auch nur exklusiv hat – aber die Geschwindigkeit, das extreme Viralitätspotenzial, die Hyperpersonalisierung, das Publikum und der Zustand der Welt verstärken diesen Effekt. In den vergangenen Monaten kam häufiger die Frage auf, warum die AfD auf TikTok so erfolgreich ist. Das liegt einerseits an reaktionären Trends, die dort oft subtil, aber letztlich ganz offen transportiert werden, wie Antifeminismus, Rassismus , Antisemitismus und ganz besonders auch Sozialdarwinismus in verschiedenen Formen. Eine große Interessensphäre mit ganz eigenen Stars mit Millionenreichweite beschäftigt sich zum Beispiel fast ausschließlich damit, wie man so schnell wie möglich so reich wie möglich wird. Das greift nahtlos in die allgegenwärtige Selbstoptimierung auf TikTok hinein. Und weil sich soziale Medien wie Instagram und auch TikTok so perfekt für die Inszenierung von Reichtum und Luxus eignen, entsteht aus beiden Strömungen schnell die Haltung, arme Menschen seien prinzipiell selbst an ihrem wirtschaftlichen Misserfolg schuld. Nebst dem Plan, wie man vermeintlich aus eigener Kraft reich wird. Auch der Ruf nach autoritärer Führung findet überraschend großen Widerhall, und längst nicht nur in rechten Zirkeln. Ganz zentral für den Erfolg der AfD bei jungen Menschen auf TikTok ist aber aus meiner Sicht eine Ablösung der klassischen Nachrichten- und Welterklärungsmedien vom Alltagserleben vieler Jugendlicher. Wenn etwa absurde Überbürokratie, Politikversagen oder Probleme mit der Integration zwar persönlich erlebt oder medial präsent werden, aber dafür nur verkrampfte, abstrakte Erklärungen und schon gar keine Lösungen angeboten werden. Plötzlich erscheint rassistischer oder antidemokratischer Populismus gleichzeitig als Erklärung und als Lösung. Spektakel und Inszenierung vertragen sich eben nicht immer gut mit Komplexität, Grautönen und der Abwägung demokratischer Werte. TikTok als Fake-News-Schleuder zu bezeichnen, ist definitiv verkürzt und berücksichtigt nicht die vielen Kräfte, die sich genau dort dem Strom des Antifortschritts entgegenstellen, mit Aufklärung, Bildung, Gegenanalysen und wirklich guter Unterhaltung. Aber TikTok geht als das gegenwärtig wohl machtvollste, korrektivärmste und aufmerksamkeitsstärkste Einflussmedium hinein in Köpfe unter 30 Jahren. Eine gruselige Sensation Was direkt zu Sora führt, das hier als Symbol für den ganzen Technologiekomplex von KI-Videos dienen soll. Die KI-Community in sozialen Medien ist seit der Vorstellung von Sora völlig aus dem Häuschen. Für eine Anzahl aus OpenAI-Sicht besonders vertrauenswürdiger Personen ist diese Technologie bereits verfügbar, und diese Leute veröffentlichen immer wieder neue Videos, oft inklusive der Anweisungen, der Prompts, mit der die KI die Videos generiert hat. So hat es OpenAI auch auf der Vorstellungsseite von Sora gehalten. Derzeit kann man mit Sora bis zu 60 Sekunden lange Videoclips erstellen, mit zwei, drei knappen Sätzen. Die Ergebnisse eröffnen eine Welt, die beinahe so groß und erstaunlich ist wie diejenige, die ChatGPT für die Öffentlichkeit zugänglich gemacht hat. Das folgende Video gibt einen Einblick, und der lässt sich als gruselige Sensation beschreiben. Der Prompt »Ein Wurf Golden-Retriever-Welpen spielt im Schnee. Ihre Köpfe ploppen aus dem Schnee heraus« – führt zu einem Video , das selbst für Fachleute kaum von einem echten Video zu unterscheiden ist. Auf den ersten Blick schon gar nicht. Künstlicher Intelligenz sollte man sich nicht mit dem bisherigen Technologieverständnis nähern. Auch klassische, digitale Erkenntnisse reichen oft nicht aus, um das gegenwärtige Potenzial dieses Technologiekomplexes zu erfassen. Und noch weniger, um die künftige Entwicklung sinnvoll abschätzen zu können. KI muss inklusive der ständigen, manchmal exponentiellen Verbesserung gedacht werden. Das ist nicht trivial, weil unser menschliches Basisverständnis oft falsch einsortiert, was für KI einfach und was schwierig ist. Sora muss man deshalb als Ausgangspunkt einer neuen Welt betrachten. Alle kleinen Unzulänglichkeiten und großen Merkwürdigkeiten in den bisherigen Videos sind aus meiner Sicht vernachlässigbar. Wir befinden uns am Anfang einer neuen medialen und damit auch politischen Zeitrechnung, denn mit Sora und vergleichbaren Technologien reicht der Begriff »Fake News« nicht mehr aus. Auf dem Weg zur perfekten Propagandamaschinerie Text-to-Video auf dem Niveau von Sora ist der Startschuss für die Epoche der »Fake Reality«, auch wenn der Begriff in sich widersprüchlich erscheint. KI kann Welten erschaffen, deren Abbild nicht mehr zu unterscheiden sein wird von den Abbildern, mit denen wir unsere Wirklichkeit bisher gelernt haben einzuschätzen. ChatGPT beherrscht die Erschaffung von Kommunikationsstrategien, diese Fähigkeiten dürften in der nächsten Iteration dramatisch besser werden, und sie werden irgendwann verbunden werden können mit Sora. Ein Prompt der Zukunft: »Erstelle eine Reihe von 10 Videos, die so viele Menschen wie möglich davon überzeugt, dass Wladimir Putin die einzige Hoffnung für Europa ist«. Die Skripts würden die neuesten, wissenschaftlichen Erkenntnisse der persuasiven Kommunikation und der Propaganda berücksichtigen, sie würden clever, unterhaltsam und viralitätsorientiert daherkommen. Und hier schließt nahtlos TikTok an. Denn selbst die beste generative KI kann nur die Wahrscheinlichkeit erhöhen, mit der ein kommunikatives Ziel erreicht wird. Aber weil KI in Lernschleifen gedacht werden muss, würde die KI Tausende Versionen erstellen, die via TikTok ganz einfach auf Reichweite, Viralität und Wirkung beim Publikum überprüft werden können. Diese Daten fließen in den weiteren Kreationsprozess ein, lassen sich nach ihrer Wirksamkeit bei Zielgruppen unterteilen und immer präziser verbessern. Mit dem Prinzip TikTok plus des Technologiekomplexes rund um Sora sind wir auf dem Weg zur perfekten, voll automatisierten Propagandamaschinerie des 21. Jahrhunderts. Sie kann Fake-Realitäten erschaffen, zugeschnitten im Zweifel auf jede einzelne Person. Bisher schützt uns, dass für die Qualität von Sora gigantische Ressourcen und Fachkenntnisse notwendig sind, die nur sehr wenige, große Unternehmen beherrschen – mit denen man verhandeln kann. Aber das wird nicht immer so bleiben. Wir haben bisher kaum das Problem der Fake News in den Griff bekommen und müssen uns schon mit einer ungleich wirkmächtigeren Fake Reality auseinandersetzen."
KI,Spiegel Online,2024-02-19,https://www.spiegel.de/wirtschaft/unternehmen/air-canada-chatbot-verspricht-kunden-irrtuemlich-rueckerstattung-airline-muss-zahlen-a-0af54651-fbb7-4d8f-ab01-862a8e723ac9,Air Canada: Chatbot verspricht Kunden irrtümlich Rückerstattung – Airline muss zahlen - DER SPIEGEL,"Er gewährte einen Rabatt, den es gar nicht gab: Weil ein Chatbot gegen die eigenen Richtlinien verstieß, wollte Air Canada einen Kunden auf dessen Kosten sitzen lassen. Nun entschied ein Gericht gegen das Unternehmen. Die Fluglinie Air Canada muss einem Kunden eine Teilerstattung gewähren, die ein Chatbot im Namen des Unternehmens gemacht hatte. Ein Schiedsgericht im Bundesstaat British Columbia verurteilte den Konzern nun zur Zahlung von 812 Kanadischen Dollar (559 Euro), wie das » Edmonton Journal « berichtete. Zuvor hatte die Künstliche Intelligenz dem Kunden entgegen den Richtlinien des Unternehmens eine Rückerstattung nach dem Kauf eines Vollpreistickets versprochen. Der Fehler des Chatbots liegt dabei im Detail: So hatte der Kunde, wie aus dem Urteil hervorgeht , sich bei dem Unternehmen nach einem Preisnachlass bei einer kurzfristigen Buchung wegen eines Trauerfalls erkundigt – seine Großmutter war gestorben. Solche »Bereavement fares« gibt es bei einigen wenigen Fluggesellschaften und Air Canada gehört dazu. Allerdings sehen die Richtlinien der Fluglinie vor, dass ein solches Ticket vor Abflug gebucht werden muss. Der Chatbot hingegen riet dem Kunden, zunächst ein Ticket zum Normalpreis zu buchen und sich binnen 90 Tagen mit dem Unternehmen wegen einer Rückerstattung in Verbindung zu setzen. Das tat der Mann – und genau diese Zahlung wollte Air Canada ihm nicht gewähren. Besonders interessant ist dabei die Begründung der Airline, welche die ganze Verantwortung auf die Maschine abwälzt. So wird im Urteil festgehalten, die Fluggesellschaft argumentiere, »dass sie nicht für Informationen haftbar gemacht werden kann, die von einem ihrer Agenten, Bediensteten oder Vertreter zur Verfügung gestellt werden – einschließlich eines Chatbots«. Damit suggeriere das Unternehmen, »dass der Chatbot eine separate juristische Person ist, die für ihre eigenen Handlungen verantwortlich ist«. »Für alle Informationen verantwortlich« Diese Argumentation überzeugte das Gericht nicht. »Für Air Canada sollte klar sein, dass sie für alle Informationen auf ihrer Website verantwortlich ist«, hieß es im Spruch des Schiedsgerichts. Dabei spiele es keine Rolle, ob die Informationen von einer statischen Seite oder einem Chatbot stammen. Der Rechtsstreit ist auch deswegen interessant, weil er den Aspekt der Verantwortung im Zusammenhang mit dem Einsatz von künstlicher Intelligenz aufwirft: So gibt es viele ungeklärte Fragen , wer im Falle eines auf der fehlerhaften Entscheidung einer KI Haftung übernimmt."
Künstliche Intelligenz,Spiegel Online,2024-02-18,https://www.spiegel.de/ausland/tucker-carlson-interview-wie-wladimir-putin-sich-kuenstliche-intelligenz-vorstellt-a-57ddc744-79ee-475c-91b1-db477094e152,Tucker-Carlson-Interview: Wie Wladimir Putin sich künstliche Intelligenz vorstellt - DER SPIEGEL,"Tucker Carlson hat Wladimir Putin interviewt. Es ging lange um die russische Vergangenheit. Viel Interessanter fand ich, wie er die Zukunft sieht und welche kruden Theorien ihm sein alter Freund Michail Kowaltschuk einflüstert."
Künstliche Intelligenz,Spiegel Online,2024-02-17,https://www.spiegel.de/netzwelt/kuenstliche-intelligenz-und-kulturkampf-wie-woke-duerfen-sprachmaschinen-sein-a-78117e03-59a8-4c5c-9d79-0ef9d834af8c,Künstliche Intelligenz und Kulturkampf: Wie woke dürfen Sprachmaschinen sein? - DER SPIEGEL,Sprachmaschinen wie Gemini oder ChatGPT befeuern den Kulturkampf. Der Streit um Marktanteile ist auch ein Wettbewerb der Gesellschaftsmodelle.
Künstliche Intelligenz,Spiegel Online,2024-02-15,https://www.spiegel.de/netzwelt/web/kuenstliche-intelligenz-microsoft-verspricht-milliardeninvestitionen-in-deutschland-a-19e8b20d-a491-4318-8aab-f779cdf7fa27,Künstliche Intelligenz: Microsoft verspricht Milliardeninvestitionen in Deutschland - DER SPIEGEL,"Cloudkapazitäten und ein Weiterbildungsprogramm für bis zu 1,2 Millionen Menschen: Microsoft hat Bundeskanzler Scholz versprochen, mehr als drei Milliarden Euro in Deutschlands KI-Zukunft zu investieren. Knapp 3,3 Milliarden Euro will Microsoft in den kommenden zwei Jahren in Deutschland investieren, um seine Rechenzentrumskapazitäten für Anwendungen im Bereich künstlicher Intelligenz (KI) und beim Cloudcomputing massiv auszubauen. Das kündigte Microsoft-Präsident Brad Smith am Donnerstag in Berlin bei einem Gespräch mit Bundeskanzler Olaf Scholz (SPD) an. Die größte Einzelinvestition in der 40-jährigen Geschichte von Microsoft in Deutschland umfasst auch ein KI-Weiterbildungsprogramm, mit dem bis zu 1,2 Millionen Menschen erreicht werden sollen. Ziele seien unter anderem der Aufbau von KI-Kenntnissen und die Unterstützung der KI-Transformation in Unternehmen. Dazu gehöre auch das erste berufliche Zertifikat für generative KI. Die Investitionsmittel fließen vor allem nach Nordrhein-Westfalen, wo Microsoft eine neue Cloudregion einrichten will. Der Konzern sucht damit die räumliche Nähe zu Großkunden wie Bayer und RWE, um die Datenlaufzeiten (Latenz) zwischen den Rechenzentren und den Anwendungen möglichst niedrig zu halten. Von den Microsoft-Investitionen wird aber auch Hessen profitieren. Die Rhein/Main-Region ist wegen des großen Internetknotens DE-CIX in Frankfurt Deutschlands führender Standort für Rechenzentren. Die bereits bestehende Microsoft-Cloud-Region Rhein/Main wird weiter ausgebaut. Scholz betont Strukturwandel im Rheinischen Revier Smith sagte: »Wir sehen eine steigende Nachfrage nach KI-Anwendungen in wichtigen Wirtschaftszweigen wie Fertigung, Automobilbau, Finanzdienstleistungen, Pharma, Life Sciences und Medizintechnik. Weil sich diese Branchen durch den wirtschaftlichen Wandel grundlegend verändern, ist es wichtig, Unternehmen in Deutschland mit weltweit führender Technologie auszustatten.« Für Olaf Scholz ist die Ankündigung »eine sehr gute Nachricht für den Wirtschaftsstandort Deutschland. Microsoft fördert damit den nötigen Strukturwandel im Rheinischen Revier, bringt die Recheninfrastruktur in unserem Land voran und stärkt das deutsche Ökosystem rund um künstliche Intelligenz. Solche Projekte zeigen, wie attraktiv der Standort und das Vertrauen von Investoren in Deutschland ist.« Mit der Investitionssumme von insgesamt 3,5 Milliarden US-Dollar (3,26 Mrd. Euro) führt Deutschland die Liste der Investitionsankündigungen des weltweit führenden Softwarekonzerns an. Microsoft-Präsident Smith hatte im vergangenen November zugesagt, bis 2026 in Großbritannien 2,5 Milliarden Pfund (2,9 Milliarden Euro) zu investieren, um das Wachstum der KI-Anwendungen voranzutreiben. Gut einen Monat zuvor hatte er bei einem Besuch in Australien eine Investition von fünf Milliarden Australischen Dollar (rund drei Mrd. Euro) in den KI-Sektor versprochen. Im internationalen KI-Markt ist Microsoft ein führender Akteur, auch weil der Softwarekonzern frühzeitig mehrere Milliarden Dollar in die Hand genommen hat, um bei dem kalifornischen KI-Start-up OpenAI einzusteigen. Microsoft verwendet dessen KI-Technologie unter anderem in seiner Suchmaschine Bing sowie als »Copilot« in seinen Office-Programmen. Hauptkonkurrent ist derzeit Google mit seinem KI-Modell Gemini."
Künstliche Intelligenz,Spiegel Online,2024-02-15,https://www.spiegel.de/netzwelt/netzpolitik/chatgpt-microsoft-und-openai-erwischen-staatliche-hacker-bei-der-nutzung-von-ki-a-8d21ce4d-19b8-41f3-b4a0-ec58254055e4,ChatGPT: Microsoft und OpenAI erwischen staatliche Hacker bei der Nutzung von KI - DER SPIEGEL,"Sie fragen ChatGPT nach ausländischen Geheimdiensten aus, verfassen Phishingmails oder erforschen Satellitentechnik: OpenAI hat daher Accounts von Hackergruppen aus China, Russland, Nordkorea und Iran entfernt. Staatlich unterstützte Hacker aus China, Russland , Nordkorea und Iran setzen bei ihren Angriffen offenbar verstärkt auf künstliche Intelligenz (KI). Interne Ermittlungen hätten ergeben, dass diese Gruppen ChatGPT von OpenAI nutzen, um ihre Methoden zu verfeinern, teilte Microsoft am Mittwoch mit. Der Softwarekonzern ist der wichtigste Partner und Investor von OpenAI. Die Hacker nutzten die Technologie demnach hauptsächlich, um ihre Softwareentwicklung zu automatisieren. Einige der Gruppe griffen darauf auch zurück, um technische Dokumentation zu übersetzen und nach öffentlich frei verfügbaren Informationen zu suchen. Russische Cyberkriminelle mit mutmaßlichen Verbindungen zum dortigen Geheimdienst etwa erforschten »verschiedene Satelliten- und Radartechnologien, die sich auf militärische Operationen in der Ukraine beziehen könnten«. China frage KI nach ausländischen Geheimdiensten oder einzelnen Persönlichkeiten aus. Die iranischen und nordkoreanischen Hacker hätten aber auch Texte für Phishingattacken von der KI schreiben lassen. Bei solchen Angriffen werden die Opfer mithilfe täuschend echt aussehender E-Mails verleitet, ihre Log-in-Informationen auf fingierten Websites einzugeben. Aktuelle KI nur eingeschränkt nützlicher als herkömmliche Werkzeuge OpenAI schränkte ein, die Entdeckung bestätige die Einschätzung, dass aktuelle KI-Technologie für die Entwicklung von Cyberattacken nur eingeschränkt nützlicher sei als herkömmliche Werkzeuge. Die Accounts von fünf Hackergruppen seien dennoch aufgekündigt worden. Auch Microsoft betonte, man habe noch keine neuartigen Angriffe durch den Einsatz von KI gesehen. »Unabhängig davon, ob ein Verstoß gegen das Gesetz oder gegen die Nutzungsbedingungen vorliegt, wollen wir einfach nicht, dass die von uns identifizierten Akteure Zugang zu dieser Technologie haben«, sagte Tom Burt, Vizepräsident für Kundensicherheit bei Microsoft, in einem Interview mit Reuters. Zum Umfang dieser Aktivitäten oder zur Zahl gesperrter Nutzerkonten wollte er sich aber nicht äußern. China kritisierte die Vorwürfe als »grundlose Verleumdung«, Reaktionen aus Russland, Nordkorea und Iran gab es nicht. Westliche Experten warnen seit Längerem vor dem Missbrauch von KI durch Kriminelle. Beweise hierfür gibt es bislang aber nur wenige."
AI,Spiegel Online,2024-02-16,https://www.spiegel.de/netzwelt/web/sora-von-openai-text-zu-video-generator-erzeugt-ki-videos-a-63c96198-16de-41bc-af0e-e14927a8f02b,Sora von OpenAI: Text-zu-Video-Generator erzeugt KI-Videos - DER SPIEGEL,"Die Macher von ChatGPT haben ein neues Werkzeug vorgestellt, das auf Textbefehl bis zu 60-sekündige Videoclips erzeugt. Im Netz machen die ersten Beispielvideos die Runde und stoßen auf Bewunderung. Text-zu-Video-Generatoren gibt es im Netz inzwischen einige . Das Start-up Runway gilt als Vorreiter, aber auch Google und Meta experimentieren in dem Bereich. Mit OpenAI hat nun auch die derzeit wohl meistbeachtete Firma im Bereich der künstlichen Intelligenz (KI) ein entsprechendes Projekt vorgestellt. Der Zugang zu dem neuen KI-Modell mit dem Namen Sora werde zunächst nur ausgewählten Kreativen zur Verfügung gestellt, kündigte OpenAI-Chef Sam Altman auf X an. Expertinnen und Experten sollen zudem mögliche Sicherheitsrisiken ausloten, bevor das Programm veröffentlicht wird. Von Sora erstellte Videos können maximal eine Minute lang sein, bei einer Auflösung von bis zu 1080p (Full HD). Auf seiner Internetseite zur Software hat OpenAI mehrere Beispielclips veröffentlicht, die die Leistungsfähigkeit des Tools unter Beweis stellen sollen. Zu sehen ist dort etwa eine Frau, die schick gekleidet durch eine Innenstadt-Szenerie läuft. Die Beispielvideos wurden den Angaben zufolge komplett von künstlicher Intelligenz erstellt, auf Basis von Texteingaben, die jeweils mitangegeben sind. Im sogenannten Prompt zum Video mit der Frau heißt es unter anderem, sie solle eine Lederjacke und ein rotes Kleid tragen, die Straße solle an Tokio erinnern und viel Neonleuchtreklame haben, die sich zudem in Pfützen spiegele. Andere Videos zeigen unter anderem eine Stadt in Kalifornien zu Zeiten des Goldrauschs sowie Mammuts, die durch den Schnee laufen. Ton haben die Videos nicht. OpenAI schreibt, in die Entwicklung von Sora seien frühere Forschungen zum Text-zu-Bild-Generator Dall-E und zu ChatGPT eingeflossen ( mehr zum technischen Hintergrund des Modells steht hier ). »Sam, bitte mach mich nicht obdachlos« In den sozialen Netzwerken zeigten sich viele Nutzerinnen und Nutzer begeistert von solchen Clips, die dort auch von Sam Altman selbst geteilt wurden. MrBeast, der erfolgreichste YouTuber der Welt, der für aufwendig produzierte Videos bekannt ist, schrieb an Altman: »Sam, bitte mach mich nicht obdachlos.« Werbung in eigener Sache zu machen, ist OpenAI damit schon mal gelungen. Steven Levy, einer der bekanntesten Techjournalisten, zeigte sich bei »Wired« vom »erstaunlichen Fotorealismus« der KI-generierten Clips beeindruckt. Er betonte jedoch, dass das längste ihm gezeigte Video 17 Sekunden gedauert habe. Und gegen Ende seines Artikels prognostiziert Levy, es werde, wenn überhaupt, noch sehr lange dauern, bis Text-zu-Video das eigentliche Filmemachen bedroht: »Nein, man kann keine kohärenten Filme machen, indem man 120 der eine Minute langen Sora-Clips zusammenfügt, da das Modell nicht immer auf die gleiche Weise auf Aufforderungen reagiert.« Kontinuität sei so nicht möglich. Potenzial sieht Levy aber dafür, dass Sora Plattformen wie TikTok verändert. »Dieses Modell wird es der Durchschnittsperson, die Videos für die sozialen Medien produziert, ermöglichen, sehr hochwertige Inhalte zu erstellen«, zitiert er dazu einen Forscher von OpenAI. Wie lange das Rendern der KI-Videos dauere, hätten ihm Forscher von OpenAI nicht sagen wollen, erwähnt der Techjournalist noch. Auf Nachfrage habe es aber geheißen, die Wartezeit gehe eher in Richtung »sich mal eben einen Burrito holen« als »sich ein paar Tage freinehmen«. Es dürfte ähnliche Einschränkungen wie bei Dall-E 3 geben Grundsätzlich werden für das Tool laut »Wired« voraussichtlich die gleichen inhaltlichen Beschränkungen wie für mit Dall-E 3 erstellte Bilder gelten. Das heißt: OpenAI wird versuchen, aktiv zu verhindern, dass Nutzerinnen und Nutzer damit Pornografie erstellen, Gewaltvideos oder auch Aufnahmen, auf denen Prominente zu sehen sind. Auch sollen technische Maßnahmen Versuche unterbinden, zum Beispiel historisch anmutende KI-Videos als echte Aufnahmen zu inszenieren. Wie leicht sich die bisher gezeigten Videos als KI-generiert erkennen lassen, variiert. Bei manchen Videos mag einem erst nach mehreren Durchläufen auffallen, dass es kleine Bildfehler oder Glitches gibt. Bei anderen Clips dagegen, etwa bei einer älteren Dame, die Kerzen eines Geburtstagskuchens ausbläst, bemerkt man ziemlich schnell, dass zum Beispiel die Hände der Mitfeiernden unrealistisch aussehen. »KI hat wirklich keine Ahnung, was Hände sind oder wie sie funktionieren«, kommentiert eine Reporterin von »The Verge«. OpenAI selbst schreibt zu dem Video: »Die Simulation komplexer Interaktionen zwischen Objekten und mehreren Personen ist für das Modell oft eine Herausforderung, die manchmal zu lustigen Ergebnissen führt.« Wann und wie OpenAI Sora einem größeren Publikum zugänglich machen wird, ist bislang unklar."
Artificial Intelligence,Spiegel Online,2024-02-17,https://www.spiegel.de/netzwelt/kuenstliche-intelligenz-und-kulturkampf-wie-woke-duerfen-sprachmaschinen-sein-a-78117e03-59a8-4c5c-9d79-0ef9d834af8c,Künstliche Intelligenz und Kulturkampf: Wie woke dürfen Sprachmaschinen sein? - DER SPIEGEL,Sprachmaschinen wie Gemini oder ChatGPT befeuern den Kulturkampf. Der Streit um Marktanteile ist auch ein Wettbewerb der Gesellschaftsmodelle.
KI,Spiegel Online,2024-02-18,https://www.spiegel.de/wissenschaft/mensch/ki-uebersetzungen-wie-betreten-eine-welt-ohne-sprachbarrieren-kolumne-a-7da2f393-fc12-4ab1-b1ab-cb6e27070503,KI-Übersetzungen: Wie betreten eine Welt ohne Sprachbarrieren - Kolumne - DER SPIEGEL,"Vielen Menschen ist noch nicht klar, dass die Welt vor einer Revolution steht: Schon sehr bald werden weite Teile der Menschheit ohne Hemmnisse miteinander kommunizieren können. Was macht das mit uns? Der Name des – je nach Lesart – polnischen oder russischen, in jedem Fall aber jüdischen Augenarztes Ludwik Lejzer Zamenhof dürfte den meisten Menschen unbekannt sein. Es gibt allerdings eine eingeschworene Gemeinde von Menschen, die jährlich seinen Geburtstag feiern, rund um die Welt: den Zamenhoftag am 15. Dezember. Christian Stöcker, Jahrgang 1973, ist Kognitions­psychologe und seit Herbst 2016 Professor an der Hochschule für Angewandte Wissenschaften Hamburg (HAW). Dort verantwortet er den Studiengang Digitale Kommunikation. Vorher leitete er das Ressort Netzwelt bei SPIEGEL ONLINE. Zamenhof hat Fans in China und den USA , Russland und der Ukraine . In Herzberg am Harz heißt seit 2017, anlässlich seines hundertsten Todestages, ein Platz nach ihm . Und all das trotz der Tatsache, dass Zamenhofs wichtigstes und größtes Projekt aus heutiger Sicht als zwar idealistisch und vom Gedanken her schön, aber an der Praxis weitgehend gescheitert gelten muss: Er erfand und entwickelte die Kunst- oder »Plansprache« Esperanto. Der Name sollte Hoffnung ausdrücken. Englisch vor Mandarin und Hindi Zamenhof, der in einem damals zu Russland gehörenden Teil Polens aufwuchs, sprach Polnisch, Russisch und Jiddisch , später in der Schule in Warschau lernte er auch noch Deutsch, Französisch, Griechisch, Latein, Englisch und Hebräisch. Als Jude in einem polnischen Teil Russlands waren ihm Ausgrenzung und Unterdrückung wohlbekannt. Er entwickelte einen Traum: Er wollte die Sprache als Hindernis auf dem Weg zur Völkerverständigung im engeren Sinn abschaffen und hoffte auf eine dadurch geeinte Menschheit. Jetzt steht Zamenhofs Traum vor der Verwirklichung – allerdings ganz anders, als er sich das vorgestellt hatte. Esperanto hat sich bekanntlich nie durchgesetzt, obwohl es beispielsweise in China bis heute Nachrichten in Zamenhofs Kunst- oder Plansprache gibt und weiterhin regelmäßig Esperanto-Weltkongresse stattfinden . Weltweit können, je nach Quelle 100.000 Menschen oder zwei Millionen Menschen Esperanto. Knapp 1,5 Milliarden sprechen und verstehen Englisch , mehr als zwei Drittel davon als Zweitsprache. Mandarin sprechen etwa 1,1 Milliarden Menschen, Hindi knapp 610 Millionen, Spanisch knapp 560 Millionen. Ein neues Zeitalter zieht herauf Englisch ist von allen Sprachen vermutlich diejenige, die Zamenhofs Ideal einer »internationalen Sprache« am nächsten ist – aber auch diese Sprache beherrschen eben über 80 Prozent der Menschen bis heute nicht. Jetzt stehen wir an der Schwelle eines neuen Menschheitszeitalters, was die Möglichkeiten zur Verständigung angeht: In spätestens wenigen Jahrzehnten, vermutlich viel früher, wird es völlig selbstverständlich sein, dass sich nahezu jeder Mensch auf dem Planeten Erde mit nahezu jedem anderen Menschen unterhalten kann, und zwar in seiner oder ihrer jeweiligen Muttersprache. Dass es so weit kommt, ist so gut wie sicher (wenn die hochtechnologische Zivilisation, die wir Menschen geschaffen haben, so lange durchhält). Hardware und Software sind längst da »Jeder, der diese Sprache erlernt hat, muss sie sofort zum Verkehr mit anderen Nationalitäten benutzen können«, schrieb Zamenhof in seinem Esperanto-Gründungswerk. In Zukunft wird man zum Verkehr mit anderen Nationalitäten nichts mehr erlernen, sondern nur einen mit einem entsprechenden Gerät verbundenen Kopfhörer mit Mikrofon tragen müssen. Die Hardware für den Universalübersetzer à la »Star Trek« besitzen viele Erdenbürger längst: Ein Smartphone (geschätzt fast fünf Milliarden Menschen benutzen heute schon eines) und Kopfhörer mit Mikrofon. Die Software gibt es auch schon, sie ist nur noch nicht flächendeckend und in der nötigen Konfiguration im Einsatz. Spracherkennungssysteme funktionieren mittlerweile bekanntlich bemerkenswert gut, maschinellem Lernen sei Dank. Der Baustein Spracherkennung ist also vorhanden – und der Baustein Universalübersetzer auch: Das deutsche Übersetzungssystem DeepL beherrscht den Betreibern zufolge bislang 32 Sprachen , Google Translate angeblich über 100. Der Dienst kann schon jetzt gesprochene Sprache in übersetzter Form transkribieren . Aber es gibt auch nichtkommerzielle Angebote, die Douglas Adams’ Babelfisch mittlerweile sehr nahekommen. Open-Source-KI kann 101 Sprachen Diese Woche präsentierte ein wahrhaft internationales Team , das Zamenhofs Herz mit Freude erfüllt hätte, ein neues Sprachmodell namens Aya, ein »massives multisprachliches Modell zur Spracherzeugung, das Instruktionen in 101 Sprachen folgen kann«. Aya ist nicht primär ein Übersetzungswerkzeug, sondern eine Art multilinguales ChatGPT, das auch zahlreiche unterschiedliche Alphabete beherrscht. Hervorragende Übersetzungen fallen bei den vielsprachlichen KI-Assistenten der Zukunft gewissermaßen als Nebenprodukt ab. Die Hälfte der Sprachen, die Aya versteht und spricht, gilt bislang als nicht ausreichend von solchen Modellen abgedeckt. Aya ist also das vielleicht derzeit breiteste, aber bei Weitem nicht das einzige Sprachproduktionssystem, das mehr Sprachen »spricht«, als ein Mensch jemals könnte. Es gibt zum Beispiel auch noch BLOOMZ und mT0 , »eine Familie von Modellen, die menschlichen Anweisungen in Dutzenden Sprachen ohne vorheriges Training folgen können«. Simultanübersetzer im Ohr Weltweit arbeiten Menschen an Hochschulen und anderen Forschungseinrichtungen und natürlich auch in Unternehmen daran, die bereits existierenden Babelfisch-Maschinen immer besser zu machen. Insbesondere nichtkommerzielle Modelle wie die genannten konzentrieren sich dabei explizit auch auf Sprachen, die sonst unterrepräsentiert wären. Die – nahe! – Zukunft der Kommunikation in fernen Ländern oder mit Menschen aus fernen Ländern wird sich deshalb so ähnlich anfühlen wie simultan übersetzte Interviews jetzt: Man hört den Originalton und mit leichtem Zeitversatz die Übersetzung, möglicherweise sogar in einer ähnlichen Stimmlage. Auch menschliche Stimmen – und mittlerweile sogar Gesichter – können Maschinen schon jetzt geradezu erschreckend gut kopieren, was in sehr naher Zukunft vermutlich für gewaltige Betrugswellen sorgen wird. Erste Fälle gibt es bereits . Auch – sagen wir: manipulierte – Universalübersetzer bergen selbstverständlich Missbrauchspotenzial. Unabsehbare Folgen All das wird jedenfalls Folgen haben, die vielen Menschen bislang vermutlich noch nicht klar sind. Für Menschen, die mit der Synchronisation von Filmen ihr Geld verdienen, brechen womöglich bald schwierige Zeiten an: Zwar produzieren automatische Systeme zur lippensynchronen Maschinenübersetzung derzeit noch relativ monoton klingende Outputs , aber das wird nicht lange so bleiben. Diverse Start-ups arbeiten an »Dubbing«-KIs. Das Weltarchiv der synchronisierten Filme und anderer eingesprochener Texte, die in vielen Sprachen vorliegen, wird jetzt zum Trainingsreservoir für Synchronisationsmaschinen . In Zukunft werden auch Melodie und Emotionalität simulierbar sein. Die Alltags-KIs, die viele Menschen eines Tages, wie im Film »Her« , selbstverständlich im Ohr tragen werden, werden es aber auch ermöglichen, in jedem beliebigen Land der Welt ohne Wörterbuch oder Sprachkurs zu kommunizieren. Wer persönliche Beziehungen pflegen, Literatur im Original genießen, oder im Geschäftsleben besonders höflich sein will, wird zwar wohl weiterhin Fremdsprachen erlernen – doch die Motivation und die Notwendigkeit, das zu tun, wird dramatisch sinken. »Begann von einer glücklichen Zeit zu träumen« Diese neue Welt ohne Sprachbarrieren wird aber auch Nachteile haben: Das Maschinen-Esperanto, das all den Übersetzungen am Ende zugrunde liegen wird, kann zu einer gewissen Verflachung in Formulierung, Ausdruck und Nuancen führen. KI-übersetzte Sprache wird zunächst weitgehend generisch sein und vermutlich sogar neue verkünstelte Sprache erzeugen, wie schlecht gemachte Synchronisationen schon jetzt: »Am Ende des Tages«, »macht Sinn«, »das dritte Rad«. Und wer will schon maschinenübersetzte Lyrik hören? Insgesamt aber wird diese neue Welt Zamenhofs Ideal näherkommen, als je eine Plansprache das geschafft hat. Zamenhof, der Idealist, schrieb einmal: »Ich begann von einer glücklichen Zeit zu träumen, in der der nationale Hass verschwindet und es nur eine Sprache und ein Land gibt, das mit vollem Recht allen seinen Benutzern und Bewohnern gehört, in dem die Menschen beginnen, einander zu verstehen und zu mögen.« Hoffen wir, dass er zumindest halbwegs recht behält."
KI,Spiegel Online,2024-02-16,https://www.spiegel.de/netzwelt/web/sora-von-openai-text-zu-video-generator-erzeugt-ki-videos-a-63c96198-16de-41bc-af0e-e14927a8f02b,Sora von OpenAI: Text-zu-Video-Generator erzeugt KI-Videos - DER SPIEGEL,"Die Macher von ChatGPT haben ein neues Werkzeug vorgestellt, das auf Textbefehl bis zu 60-sekündige Videoclips erzeugt. Im Netz machen die ersten Beispielvideos die Runde und stoßen auf Bewunderung. Text-zu-Video-Generatoren gibt es im Netz inzwischen einige . Das Start-up Runway gilt als Vorreiter, aber auch Google und Meta experimentieren in dem Bereich. Mit OpenAI hat nun auch die derzeit wohl meistbeachtete Firma im Bereich der künstlichen Intelligenz (KI) ein entsprechendes Projekt vorgestellt. Der Zugang zu dem neuen KI-Modell mit dem Namen Sora werde zunächst nur ausgewählten Kreativen zur Verfügung gestellt, kündigte OpenAI-Chef Sam Altman auf X an. Expertinnen und Experten sollen zudem mögliche Sicherheitsrisiken ausloten, bevor das Programm veröffentlicht wird. Von Sora erstellte Videos können maximal eine Minute lang sein, bei einer Auflösung von bis zu 1080p (Full HD). Auf seiner Internetseite zur Software hat OpenAI mehrere Beispielclips veröffentlicht, die die Leistungsfähigkeit des Tools unter Beweis stellen sollen. Zu sehen ist dort etwa eine Frau, die schick gekleidet durch eine Innenstadt-Szenerie läuft. Die Beispielvideos wurden den Angaben zufolge komplett von künstlicher Intelligenz erstellt, auf Basis von Texteingaben, die jeweils mitangegeben sind. Im sogenannten Prompt zum Video mit der Frau heißt es unter anderem, sie solle eine Lederjacke und ein rotes Kleid tragen, die Straße solle an Tokio erinnern und viel Neonleuchtreklame haben, die sich zudem in Pfützen spiegele. Andere Videos zeigen unter anderem eine Stadt in Kalifornien zu Zeiten des Goldrauschs sowie Mammuts, die durch den Schnee laufen. Ton haben die Videos nicht. OpenAI schreibt, in die Entwicklung von Sora seien frühere Forschungen zum Text-zu-Bild-Generator Dall-E und zu ChatGPT eingeflossen ( mehr zum technischen Hintergrund des Modells steht hier ). »Sam, bitte mach mich nicht obdachlos« In den sozialen Netzwerken zeigten sich viele Nutzerinnen und Nutzer begeistert von solchen Clips, die dort auch von Sam Altman selbst geteilt wurden. MrBeast, der erfolgreichste YouTuber der Welt, der für aufwendig produzierte Videos bekannt ist, schrieb an Altman: »Sam, bitte mach mich nicht obdachlos.« Werbung in eigener Sache zu machen, ist OpenAI damit schon mal gelungen. Steven Levy, einer der bekanntesten Techjournalisten, zeigte sich bei »Wired« vom »erstaunlichen Fotorealismus« der KI-generierten Clips beeindruckt. Er betonte jedoch, dass das längste ihm gezeigte Video 17 Sekunden gedauert habe. Und gegen Ende seines Artikels prognostiziert Levy, es werde, wenn überhaupt, noch sehr lange dauern, bis Text-zu-Video das eigentliche Filmemachen bedroht: »Nein, man kann keine kohärenten Filme machen, indem man 120 der eine Minute langen Sora-Clips zusammenfügt, da das Modell nicht immer auf die gleiche Weise auf Aufforderungen reagiert.« Kontinuität sei so nicht möglich. Potenzial sieht Levy aber dafür, dass Sora Plattformen wie TikTok verändert. »Dieses Modell wird es der Durchschnittsperson, die Videos für die sozialen Medien produziert, ermöglichen, sehr hochwertige Inhalte zu erstellen«, zitiert er dazu einen Forscher von OpenAI. Wie lange das Rendern der KI-Videos dauere, hätten ihm Forscher von OpenAI nicht sagen wollen, erwähnt der Techjournalist noch. Auf Nachfrage habe es aber geheißen, die Wartezeit gehe eher in Richtung »sich mal eben einen Burrito holen« als »sich ein paar Tage freinehmen«. Es dürfte ähnliche Einschränkungen wie bei Dall-E 3 geben Grundsätzlich werden für das Tool laut »Wired« voraussichtlich die gleichen inhaltlichen Beschränkungen wie für mit Dall-E 3 erstellte Bilder gelten. Das heißt: OpenAI wird versuchen, aktiv zu verhindern, dass Nutzerinnen und Nutzer damit Pornografie erstellen, Gewaltvideos oder auch Aufnahmen, auf denen Prominente zu sehen sind. Auch sollen technische Maßnahmen Versuche unterbinden, zum Beispiel historisch anmutende KI-Videos als echte Aufnahmen zu inszenieren. Wie leicht sich die bisher gezeigten Videos als KI-generiert erkennen lassen, variiert. Bei manchen Videos mag einem erst nach mehreren Durchläufen auffallen, dass es kleine Bildfehler oder Glitches gibt. Bei anderen Clips dagegen, etwa bei einer älteren Dame, die Kerzen eines Geburtstagskuchens ausbläst, bemerkt man ziemlich schnell, dass zum Beispiel die Hände der Mitfeiernden unrealistisch aussehen. »KI hat wirklich keine Ahnung, was Hände sind oder wie sie funktionieren«, kommentiert eine Reporterin von »The Verge«. OpenAI selbst schreibt zu dem Video: »Die Simulation komplexer Interaktionen zwischen Objekten und mehreren Personen ist für das Modell oft eine Herausforderung, die manchmal zu lustigen Ergebnissen führt.« Wann und wie OpenAI Sora einem größeren Publikum zugänglich machen wird, ist bislang unklar."
KI,Spiegel Online,2024-02-15,https://www.spiegel.de/netzwelt/web/kuenstliche-intelligenz-microsoft-verspricht-milliardeninvestitionen-in-deutschland-a-19e8b20d-a491-4318-8aab-f779cdf7fa27,Künstliche Intelligenz: Microsoft verspricht Milliardeninvestitionen in Deutschland - DER SPIEGEL,"Cloudkapazitäten und ein Weiterbildungsprogramm für bis zu 1,2 Millionen Menschen: Microsoft hat Bundeskanzler Scholz versprochen, mehr als drei Milliarden Euro in Deutschlands KI-Zukunft zu investieren. Knapp 3,3 Milliarden Euro will Microsoft in den kommenden zwei Jahren in Deutschland investieren, um seine Rechenzentrumskapazitäten für Anwendungen im Bereich künstlicher Intelligenz (KI) und beim Cloudcomputing massiv auszubauen. Das kündigte Microsoft-Präsident Brad Smith am Donnerstag in Berlin bei einem Gespräch mit Bundeskanzler Olaf Scholz (SPD) an. Die größte Einzelinvestition in der 40-jährigen Geschichte von Microsoft in Deutschland umfasst auch ein KI-Weiterbildungsprogramm, mit dem bis zu 1,2 Millionen Menschen erreicht werden sollen. Ziele seien unter anderem der Aufbau von KI-Kenntnissen und die Unterstützung der KI-Transformation in Unternehmen. Dazu gehöre auch das erste berufliche Zertifikat für generative KI. Die Investitionsmittel fließen vor allem nach Nordrhein-Westfalen, wo Microsoft eine neue Cloudregion einrichten will. Der Konzern sucht damit die räumliche Nähe zu Großkunden wie Bayer und RWE, um die Datenlaufzeiten (Latenz) zwischen den Rechenzentren und den Anwendungen möglichst niedrig zu halten. Von den Microsoft-Investitionen wird aber auch Hessen profitieren. Die Rhein/Main-Region ist wegen des großen Internetknotens DE-CIX in Frankfurt Deutschlands führender Standort für Rechenzentren. Die bereits bestehende Microsoft-Cloud-Region Rhein/Main wird weiter ausgebaut. Scholz betont Strukturwandel im Rheinischen Revier Smith sagte: »Wir sehen eine steigende Nachfrage nach KI-Anwendungen in wichtigen Wirtschaftszweigen wie Fertigung, Automobilbau, Finanzdienstleistungen, Pharma, Life Sciences und Medizintechnik. Weil sich diese Branchen durch den wirtschaftlichen Wandel grundlegend verändern, ist es wichtig, Unternehmen in Deutschland mit weltweit führender Technologie auszustatten.« Für Olaf Scholz ist die Ankündigung »eine sehr gute Nachricht für den Wirtschaftsstandort Deutschland. Microsoft fördert damit den nötigen Strukturwandel im Rheinischen Revier, bringt die Recheninfrastruktur in unserem Land voran und stärkt das deutsche Ökosystem rund um künstliche Intelligenz. Solche Projekte zeigen, wie attraktiv der Standort und das Vertrauen von Investoren in Deutschland ist.« Mit der Investitionssumme von insgesamt 3,5 Milliarden US-Dollar (3,26 Mrd. Euro) führt Deutschland die Liste der Investitionsankündigungen des weltweit führenden Softwarekonzerns an. Microsoft-Präsident Smith hatte im vergangenen November zugesagt, bis 2026 in Großbritannien 2,5 Milliarden Pfund (2,9 Milliarden Euro) zu investieren, um das Wachstum der KI-Anwendungen voranzutreiben. Gut einen Monat zuvor hatte er bei einem Besuch in Australien eine Investition von fünf Milliarden Australischen Dollar (rund drei Mrd. Euro) in den KI-Sektor versprochen. Im internationalen KI-Markt ist Microsoft ein führender Akteur, auch weil der Softwarekonzern frühzeitig mehrere Milliarden Dollar in die Hand genommen hat, um bei dem kalifornischen KI-Start-up OpenAI einzusteigen. Microsoft verwendet dessen KI-Technologie unter anderem in seiner Suchmaschine Bing sowie als »Copilot« in seinen Office-Programmen. Hauptkonkurrent ist derzeit Google mit seinem KI-Modell Gemini."
KI,Spiegel Online,2024-02-15,https://www.spiegel.de/netzwelt/netzpolitik/chatgpt-microsoft-und-openai-erwischen-staatliche-hacker-bei-der-nutzung-von-ki-a-8d21ce4d-19b8-41f3-b4a0-ec58254055e4,ChatGPT: Microsoft und OpenAI erwischen staatliche Hacker bei der Nutzung von KI - DER SPIEGEL,"Sie fragen ChatGPT nach ausländischen Geheimdiensten aus, verfassen Phishingmails oder erforschen Satellitentechnik: OpenAI hat daher Accounts von Hackergruppen aus China, Russland, Nordkorea und Iran entfernt. Staatlich unterstützte Hacker aus China, Russland , Nordkorea und Iran setzen bei ihren Angriffen offenbar verstärkt auf künstliche Intelligenz (KI). Interne Ermittlungen hätten ergeben, dass diese Gruppen ChatGPT von OpenAI nutzen, um ihre Methoden zu verfeinern, teilte Microsoft am Mittwoch mit. Der Softwarekonzern ist der wichtigste Partner und Investor von OpenAI. Die Hacker nutzten die Technologie demnach hauptsächlich, um ihre Softwareentwicklung zu automatisieren. Einige der Gruppe griffen darauf auch zurück, um technische Dokumentation zu übersetzen und nach öffentlich frei verfügbaren Informationen zu suchen. Russische Cyberkriminelle mit mutmaßlichen Verbindungen zum dortigen Geheimdienst etwa erforschten »verschiedene Satelliten- und Radartechnologien, die sich auf militärische Operationen in der Ukraine beziehen könnten«. China frage KI nach ausländischen Geheimdiensten oder einzelnen Persönlichkeiten aus. Die iranischen und nordkoreanischen Hacker hätten aber auch Texte für Phishingattacken von der KI schreiben lassen. Bei solchen Angriffen werden die Opfer mithilfe täuschend echt aussehender E-Mails verleitet, ihre Log-in-Informationen auf fingierten Websites einzugeben. Aktuelle KI nur eingeschränkt nützlicher als herkömmliche Werkzeuge OpenAI schränkte ein, die Entdeckung bestätige die Einschätzung, dass aktuelle KI-Technologie für die Entwicklung von Cyberattacken nur eingeschränkt nützlicher sei als herkömmliche Werkzeuge. Die Accounts von fünf Hackergruppen seien dennoch aufgekündigt worden. Auch Microsoft betonte, man habe noch keine neuartigen Angriffe durch den Einsatz von KI gesehen. »Unabhängig davon, ob ein Verstoß gegen das Gesetz oder gegen die Nutzungsbedingungen vorliegt, wollen wir einfach nicht, dass die von uns identifizierten Akteure Zugang zu dieser Technologie haben«, sagte Tom Burt, Vizepräsident für Kundensicherheit bei Microsoft, in einem Interview mit Reuters. Zum Umfang dieser Aktivitäten oder zur Zahl gesperrter Nutzerkonten wollte er sich aber nicht äußern. China kritisierte die Vorwürfe als »grundlose Verleumdung«, Reaktionen aus Russland, Nordkorea und Iran gab es nicht. Westliche Experten warnen seit Längerem vor dem Missbrauch von KI durch Kriminelle. Beweise hierfür gibt es bislang aber nur wenige."
Künstliche Intelligenz,Spiegel Online,2024-02-14,https://www.spiegel.de/netzwelt/apps/chatgpt-chatbot-von-openai-soll-eine-gedaechtnis-funktion-bekommen-a-355ec437-a854-4846-8bb4-c781636b65b3,ChatGPT: Chatbot von OpenAI soll eine Gedächtnis-Funktion bekommen - DER SPIEGEL,"Der Chatbot von OpenAI erhält das Äquivalent eines Browserverlaufs: Die KI soll sich Lebensumstände und Vorlieben seiner Nutzer merken und für Dialoge nutzen. Man kann ihn aber auch Dinge vergessen lassen. Der Chatbot ChatGPT wird sich künftig Informationen über seine Nutzerinnen und Nutzer merken können, um seine Antworten für diese individualisieren zu können. Die Software könne sich zum Beispiel daran erinnern, dass man eine Tochter habe, die Quallen mag, erläutert die Entwicklerfirma OpenAI . Bittet man ChatGPT später, eine Geburtstagskarte für das Kind zu entwerfen, könnte darauf eine Qualle mit Partyhut zu sehen sein. Die Funktion wird zunächst im kleinen Kreis getestet. Sie ist brisant, da immer wieder befürchtet wurde, dass Anwendungen mit künstlicher Intelligenz die Nutzerinnen und Nutzer ausforschen und sogar diskriminieren könnten. Viele Firmen hatten den Gebrauch solcher Dienste verboten oder eingeschränkt, um zu verhindern, dass Firmengeheimnisse abfließen. Vergessen auf Knopfdruck Bei der Einführung der neuen Funktion geht OpenAI betont vorsichtig vor. Demnach kann man die KI ausdrücklich auffordern, sich bestimmte Dinge zu merken oder zu vergessen. Auch eine Möglichkeit, zu fragen, welche Dinge sich ChatGPT gemerkt hat, soll es geben. Zugleich kann die Software selbst versuchen, aus Unterhaltungen mit seinen Nutzerinnen und Nutzern Wissen über diese herauszupicken. »Das Gedächtnis von ChatGPT wird besser, je mehr man es nutzt«, betont OpenAI. Dies soll den Chatbot in der alltäglichen Anwendung nützlicher machen. Die Profilbildung soll aber nur mit Wissen und Einverständnis der Nutzerinnen und Nutzer geschehen. So speichert ChatGPT brisante Informationen, etwa mit Bezug zur Gesundheit, nicht automatisch, sondern nur auf explizite Aufforderung. Für Unterhaltungen ohne Personalisierung soll es weiterhin temporäre Chats geben. Die Informationen daraus werden auch nicht zum weiteren Anlernen der Software verwendet. Die Gedächtnisfunktion kann zudem komplett ausgeschaltet werden. Nutzen sieht OpenAI auch beim Einsatz in Unternehmen. So könne sich die Software merken, in welchem Format man am liebsten Zusammenfassungen von Videokonferenzen erhalte. Oder sie könne sich darauf einstellen, in welchem Stil Formulierungshilfen geschrieben werden sollen."
AI,Spiegel Online,2024-02-12,https://www.spiegel.de/netzwelt/netzpolitik/ki-koryphaee-mustafa-suleyman-dies-wird-das-produktivste-jahrzehnt-in-der-geschichte-der-menschheit-a-f46ade26-35ad-4c28-a0cf-816c389320d4,KI-Koryphäe Mustafa Suleyman: »Dies wird das produktivste Jahrzehnt in der Geschichte der Menschheit« - DER SPIEGEL,"Mit DeepMind erzielte Mustafa Suleyman historische Durchbrüche in der KI-Forschung. Nun entwickelt er einen neuen Chatbot. In wenigen Jahren, glaubt er, könne eine KI selbstständig Geld verdienen."
Artificial Intelligence,Spiegel Online,2024-02-14,https://www.spiegel.de/international/europe/does-russian-billionaire-arkady-volozh-really-belong-on-the-eu-sanctions-list-a-22c0af4b-a0a1-4323-bedf-b88d43be23c5,Does Russian Billionaire Arkady Volozh Really Belong on the EU Sanctions List? - DER SPIEGEL,"The EU has placed a Russian internet billionaire on its sanctions list who has criticized Putin's war and turned his back on his home country. Do the punitive measures go too far in cases like his? The fate of Russian businessman Arkady Volozh is more than just astonishing. It doesn’t make much sense. Volozh has become an enemy of state on both sides in the confrontation between Russia and the West. The European Union has placed him on its sanctions list because Brussels believes the billionaire is spreading propaganda and helping to finance Russia's war. His assets have been frozen, banks are not allowed to do business with him, and he is banned from entering the EU. Moscow, meanwhile, considers the entrepreneur to be a traitor because of his public opposition to the war and his intention to make a fresh start abroad. That ancient proverb that the enemy of my enemy is my friend? It apparently doesn't apply in this case. Volozh is one of Russia’s smartest tech entrepreneurs. He co-founded Yandex, a corporation that for a long time operated a Google News-like Russian aggregator. This service played an important role in disseminating news from pro-Kremlin media on the Russian Internet. But in accordance with instructions from the Russian authorities, Yandex News suppressed reports from critical media. The service has since been sold, but Yandex continues to pay taxes in Russia today. The EU has therefore classified Volozh’s activities as a “substantial source of income” for the Kremlin and targeted him with sanctions. The article you are reading originally appeared in German in issue 7/2024 (February 10th, 2024) of DER SPIEGEL. At the same time, though, the entrepreneur has been avoiding Russia since the beginning of the war. This applies not only to his travels, but also to his resume. Volozh now presents himself as an “Israeli tech entrepreneur born in Kazakhstan.” This has outraged many in Russia, both pro-Kremlin propagandists and members of the opposition. His company also made it possible for thousands of Russian IT specialists to emigrate abroad. Just days after the start of the war, he initiated the splitting-off of Yandex's Russian business. But none of this has done anything to change the EU’s verdict. Volozh’s name still occupies position 1,175 on the European Council’s sanctions list. He finds himself in dubious company on that list: Higher up on the list are an executive with the state oil giant Rosneft, a company known for its aggressive behavior, Putin’s alleged mistress Alina Kabaeva and also a son of the late mercenary leader Yevgeny Prigozhin. Volozh's case is more than just bad luck or a chain of unfortunate circumstances. It illustrates the weaknesses of the European sanctions regime, which was hastily installed after the start of the Russian invasion. The move quickly exerted pressure on large sections of the Russian elite, but most of the hopes the EU had for a change of course in Moscow have since been dashed. The punitive measures did not drive the hoped-for wedge between businessmen and oligarchs on the one side and the state leadership on the other. And this despite the fact that the war has proven so disastrous for the incomes of many Russian billionaires. Instead, the opposite has happened: Because they have lost their business in the West, some of the billionaires have regrouped more closely around Putin. That group includes a number of oligarchs who, for many years, preferred to live in London rather than in Moscow. One reason for this is that the sanctions lists make no distinction between members of Putin's hard-line leadership circle and figures more on the periphery of the elite. Almost two years after the measures were imposed, they are still strangely lacking any nuance and some of the justifications are questionable. Which is why some members of the Moscow business elite are closely following the Volozh case. The self-made billionaire is a unique figure in the top echelons. He’s not one of the standard Putin friends, Kremlin cadres or commodity tycoons who make up the majority of the sanctions list. Volozh is one of the few entrepreneurs who have built a business beyond oil, gas and metal, and without relying on political ties. In the early 1990s, he created his search engine for the Russian internet. Yandex rose to become the market leader, while Google had no chance in Russia for a long time. He later transformed the search engine into a tech conglomerate with 20,000 employees, focusing on all those business areas in which the future lies: artificial intelligence, cloud computing and the development of self-driving cars. “We wanted to create a new Russia, open and able to offer the world more than just raw materials,” as Volozh himself once put it. There are also the truly darker sides of the company’s history. “Over the years, Yandex has transformed from a start-up to a propaganda distribution channel,” says Alena Epifanova. The researcher studies the Russian internet at the German Council on Foreign Relations (DGAP) in Berlin. In 2021, she sought to conduct background interviews with Yandex executives for her work. What she found was a largely secretive company. Epifanova says that no one from the company’s top management wanted to talk to her. She says Yandex has been compelled by Russian legislation to present users with more and more state-loyal media. The company, she adds, “adapted its algorithms accordingly in order to get out of the line of fire.” She argues that Volozh should have done more to push back against the state pressure. Yandex was so important for the development of the Russian tech industry that the conglomerate “could have used its weight to influence the formulation of Russian internet laws in negotiations with the Kremlin,” says Epifanova. That, though, essentially only applies to the period before Moscow forcibly annexed the Crimean peninsula in February 2014. After that, the political climate in Russia grew harsher. She says there was little room for maneuver for Yandex either. “The EU Is Treading on Thin Ice” Is it possible that the EU has hit the wrong person and that it is punishing Volozh for what he had been required to do under Russian law? Many experts believe that to be the case. The EU is “treading on thin ice” in this case, says Gerhard Mangott, a Russia expert at the University of Innsbruck. “It is hard to understand what Volozh is being accused of.” Anders Åslund has a similar take. The Swedish economist was an adviser to then-Russian President Boris Yeltsin in the 1990s. He argues that the reasons given by the EU for sanctioning Volozh are “poor and dubious.” No one suspects Åslund of holding a particularly lenient view of Putin and Russia's oligarchs. Long before the attack on Kyiv began in 2022, he was already calling for tougher action by the West and more sanctions. He’s also the author of a book about the Russian kleptocracy in which Putin's friends just keep getting richer and richer. Åslund describes Volozh's Yandex as being one of the few examples to the contrary. Although Volozh didn’t protest against the annexation of Crimea, he was “clearly not been a sympathizer” of the development at the time. Åslund found it particularly bothersome that the EU made reference to his book, of all things, when it made the decision to issue sanctions against Volozh. In response, Åslund sent a letter of protest to Brussels. It is unclear what evidence the EU has against Volozh. The document in question hasn’t been released publicly. A response from the General Secretariat of the European Council to a request to view the documents was still pending at the time this article was published. It generally takes three weeks for such requests to be processed. Meanwhile, another Russian businessman provided DER SPIEGEL with insights pertaining to documents relating to his own case. He asked that his name not be published in this story. The EU sent the documents in question to him. Officials in Brussels used the content to justify why they imposed and later extended the sanctions. Some of the documents appear to have been hastily copied: Many pages are filled with blurry screenshots of Russian-language media reports and the translations are at times a bit on the choppy side. This man also describes himself as being caught between the front lines. He says his lawyers asked the EU what he could do to ease the sanctions - and apparently received no response. With no prospects of the sanctions being lifted, he says he’s not prepared to scale back his business in Russia. And yet he doesn’t want to live entirely without his fortune either. After all, he says he’s “no angel and no saint.” Some experts believe there is a fundamental flaw in the design of the EU sanctions: They lack an exit option. Russian economist and elite researcher Andrei Yakovlev argues that the penalties imposed are a “particularly ineffective and unfortunate mechanism.” Yakovlev left Russia at the beginning of the invasion of Ukraine. He is now a researcher at Harvard University and at the Hanse-Wissenschaftskolleg, a research institution in Delmenhorst, Germany. He argues that Europe implemented the sanctions “hastily, without a clear understanding of their long-term effect.” With the second anniversary of the start of the war, he says, it is still completely unclear what steps the EU actually expects from the targets of its sanctions. Does Brussels want them to take a stance against the war? For them to take an active role in Ukraine’s reconstruction? Yakovlev argues that only clear criteria can help persuade parts of the elite to do more to distance themselves from the Kremlin. So far, he says, the sanctions have had the opposite effect. With their investments in the West frozen, many billionaires are becoming more active in Russia again. That also poses a problem for the West, says Yakovlev. He further adds that Russia can never be defeated in the same way as Nazi Germany because of its nuclear status. Europe and the United States need alternative concepts for a political transformation in Russia. “Elites who are still subject to sanctions today could play a role,” Yakovlev says. It didn't even take particularly clear signals from the EU for Yandex founder Volozh to distance himself from the Kremlin. Volozh announced in August 2023 that he was “totally against Russia’s barbaric invasion.” A short time later, it became clear why Russian businessmen are usually reluctant to make such political statements. President Putin reacted in his usual manner. First he called Volozh a “talented entrepreneur.” He had made similar comments about mercenary leader Prigozhin – only to see his plane fall out of the sky a short time later. Then, in what he clearly intended as a threat, he wished the tech entrepreneur “good health.” Putin's spokesman, Dmitry Peskov, was even more direct not long later. People like Volozh, he said, would deliver Russia to the enemy for money, just as Judas once delivered Jesus. “They are traitors,” Peskov said. In the U.S., Volozh has been the subject of praise. Michael McFaul, a Russia expert and professor at Stanford, has applauded Volozh's courage. McFaul was the architect of the White House's Russia policy under President Barack Obama and later served as ambassador to Moscow. State television teams regularly hunted down the diplomat in the Russian capital. In 2018, Putin even tried to get Donald Trump to allow Russian officials to interrogate McFaul. It seems that it has only been in Brussels that Volozh’s criticism of the war has had no noticeable effect. Shortly after his statements, the EU extended its sanctions against the Yandex founder. Understanding the EU’s sanctions polices processes is a science in itself. In contrast to the United States, the Europeans don’t have a sanctions authority. Diplomats from the EU member states decide who is on the list of outlaws in a working group of the European Council. Haggling and horse-trading are not excluded from the process. Hungary, for example, prevented the sanctions against Patriarch Kirill, the head of the Russian Orthodox Church, which were supported by a majority of the EU member states. After the same round of negotiations, Volozh appeared on the sanctions list. It is no longer possible to reconstruct exactly at whose instigation he was punished in June 2022. DER SPIEGEL interviewed diplomats in Brussels and high-ranking officials from several European governments about the case. Those discussions, however, were largely unproductive. Uncertain Outcome Nonetheless, an EU diplomat confirmed that the Volozh case will be revisited in the coming weeks. The outcome is uncertain. The diplomat said that Volozh’s position against the war is only one of the criteria that matters. The more important question is whether Volozh will continue to be classified as an important Russian businessman who helps the Kremlin, either directly or indirectly. In other words, Volozh doesn’t have great prospects. He did vacate his post as Yandex CEO in 2022. But that did not go far enough for the EU to lift its sanctions. Even the sale of the propaganda spin-off Yandex News did nothing to change the assessment in Brussels. At the beginning of February, Volozh went even one step further. Yandex announced its own division into two parts. Russian investors are to take over the highly profitable Russian business. They will pay out the existing shareholders, including Volozh, who still holds around 8 percent of the shares. The price must be at least 50 percent below market value, according to new Kremlin rules. The rules are intended to make it more difficult for companies to leave Russia. Volozh had been planning this step for some time. He wants to turn the promising departments into a new company geared towards the global market. However, for many months it was not clear whether the Kremlin would even allow him to withdraw from Russia. His statement against the war has delayed this process. Even now, the maneuver could still fail. Banks and shareholders must agree, as must Russian government agencies. It could take weeks before the spin-off is completed, partly because the sanctions make payment processing more difficult. However, if the EU officials make a complete departure from Russia a condition, the Kremlin could ultimately decide on Volozh's fate again. If Moscow torpedoes or delays the deal, he would have to remain on the sanctions list. How the splitting-off succeeds could also have consequences for Europe. Volozh would like to locate the headquarters of his new company in Amsterdam. Yandex had been officially registered in the Netherlands since its IPO. However, if the sanctions remain in force, Volozh would have to look at other locations. And there are alternatives: London, for example, or Austin, Texas, where the company has had an office for some time. Britain and the U.S. haven’t imposed any sanctions against the Yandex founder at all."
KI,Spiegel Online,2024-02-12,https://www.spiegel.de/netzwelt/netzpolitik/ki-koryphaee-mustafa-suleyman-dies-wird-das-produktivste-jahrzehnt-in-der-geschichte-der-menschheit-a-f46ade26-35ad-4c28-a0cf-816c389320d4,KI-Koryphäe Mustafa Suleyman: »Dies wird das produktivste Jahrzehnt in der Geschichte der Menschheit« - DER SPIEGEL,"Mit DeepMind erzielte Mustafa Suleyman historische Durchbrüche in der KI-Forschung. Nun entwickelt er einen neuen Chatbot. In wenigen Jahren, glaubt er, könne eine KI selbstständig Geld verdienen."
Künstliche Intelligenz,Spiegel Online,2024-02-09,https://www.spiegel.de/wissenschaft/technik/kuenstliche-intelligenz-miriam-meckel-ueber-chancen-und-gefahren-von-ki-fuer-demokratie-und-arbeitswelt-a-65fb6bde-5fd9-463d-b45a-7048d74afe5c,Künstliche Intelligenz: Miriam Meckel über Chancen und Gefahren von KI für Demokratie und Arbeitswelt - DER SPIEGEL,"Viele sehen bei künstlicher Intelligenz vor allem Gefahren. Anders Miriam Meckel. Die Wissenschaftlerin ist überzeugt, dass KI die Menschheit auf eine neue Zivilisationsstufe heben kann. Was macht sie so sicher?"
AI,Spiegel Online,2024-02-09,https://www.spiegel.de/wissenschaft/technik/kuenstliche-intelligenz-miriam-meckel-ueber-chancen-und-gefahren-von-ki-fuer-demokratie-und-arbeitswelt-a-65fb6bde-5fd9-463d-b45a-7048d74afe5c,Künstliche Intelligenz: Miriam Meckel über Chancen und Gefahren von KI für Demokratie und Arbeitswelt - DER SPIEGEL,"Viele sehen bei künstlicher Intelligenz vor allem Gefahren. Anders Miriam Meckel. Die Wissenschaftlerin ist überzeugt, dass KI die Menschheit auf eine neue Zivilisationsstufe heben kann. Was macht sie so sicher?"
Artificial Intelligence,Spiegel Online,2024-02-09,https://www.spiegel.de/wissenschaft/technik/kuenstliche-intelligenz-miriam-meckel-ueber-chancen-und-gefahren-von-ki-fuer-demokratie-und-arbeitswelt-a-65fb6bde-5fd9-463d-b45a-7048d74afe5c,Künstliche Intelligenz: Miriam Meckel über Chancen und Gefahren von KI für Demokratie und Arbeitswelt - DER SPIEGEL,"Viele sehen bei künstlicher Intelligenz vor allem Gefahren. Anders Miriam Meckel. Die Wissenschaftlerin ist überzeugt, dass KI die Menschheit auf eine neue Zivilisationsstufe heben kann. Was macht sie so sicher?"
KI,Spiegel Online,2024-02-09,https://www.spiegel.de/wissenschaft/technik/kuenstliche-intelligenz-miriam-meckel-ueber-chancen-und-gefahren-von-ki-fuer-demokratie-und-arbeitswelt-a-65fb6bde-5fd9-463d-b45a-7048d74afe5c,Künstliche Intelligenz: Miriam Meckel über Chancen und Gefahren von KI für Demokratie und Arbeitswelt - DER SPIEGEL,"Viele sehen bei künstlicher Intelligenz vor allem Gefahren. Anders Miriam Meckel. Die Wissenschaftlerin ist überzeugt, dass KI die Menschheit auf eine neue Zivilisationsstufe heben kann. Was macht sie so sicher?"
KI,Spiegel Online,2024-02-08,https://www.spiegel.de/ausland/robocalls-im-wahlkampf-us-regierung-geht-hart-gegen-ki-anrufe-vor-a-3d74bb82-11d9-4453-baac-c5fc479c7295,Robocalls im US-Wahlkampf: US-Regierung geht hart gegen KI-Anrufe vor - DER SPIEGEL,"Robocalls sind im US-Wahlkampf allgegenwärtig – und äußerst gefährlich. Daher reagiert die Telekom-Behörde FCC, um Wahlmanipulation durch KI-Anrufe zu verhindern. Empfänger müssen einem solchen Telefonat nun aktiv zustimmen. Nach dem Schreck um einen Wahlkampfanruf mit einer künstlich erzeugten Stimme von Präsident Joe Biden will die US-Regierung solchen Robocalls einen Riegel vorschieben. Die Telekom-Behörde FCC betonte in einer Erklärung , dass für Anrufe mit von künstlicher Intelligenz generierten Stimmen die vorherige Zustimmung der Empfänger unerlässlich sei. Auch müssten sich die Urheber solcher Anrufe klar zu erkennen geben. Die Feststellung der FCC (Federal Communications Commission) stärkt den rechtlichen Rahmen für das Vorgehen gegen Fälschungen mithilfe künstlicher Intelligenz. Sie verfügte letztlich, dass für automatisierte KI-Anrufe die gleichen Regeln gelten wie bisher bereits für Kommunikation mit künstlichen oder aufgenommenen Stimmen. In den USA hatten vor wenigen Wochen automatisierte Anrufe mit einer täuschend echt klingenden Nachahmung der Stimme von Präsident Joe Biden für Alarmstimmung gesorgt. Die Forderung der Anrufe war, nicht an der Vorwahl der Demokratischen Partei im Bundesstaat New Hampshire teilzunehmen. Der Vorfall schürte die Sorge, in den kommenden Monaten könnte es Versuche geben, den Ausgang der Präsidentenwahl im November mit der Verbreitung täuschend echter KI-Fälschungen zu beeinflussen. Solche Robocalls sind ein gängiges Wahlkampfinstrument in den USA , in diesem Fall jedoch illegal. Die Absender-Informationen bei den Anrufen wurden gefälscht, sodass sie von einem politischen Komitee von Bidens Demokratischer Partei zu kommen schienen, wie die Generalstaatsanwaltschaft von New Hampshire zu dem Zeitpunkt mitteilte. Behörden konnten als Urheber der Anrufe inzwischen eine Firma aus Texas ausmachen und gehen gegen sie vor. Software auf Basis künstlicher Intelligenz kann mithilfe von Tonaufnahmen darauf trainiert werden, beliebige Sätze mit Stimmen bestimmter Personen auszusprechen. Robocalls seien ein attraktives Ziel für solche Manipulationen, da sie schwer zu überwachen seien, sagte der amerikanische Politikexperte Ian Bremmer nach dem aktuellen Vorfall im US-Sender CNBC. Auch online sei es relativ einfach, mithilfe einer »Armee aus Bots« falsche Informationen an viele Leute zu verteilen, warnte er."
Künstliche Intelligenz,Spiegel Online,2024-02-06,https://www.spiegel.de/netzwelt/netzpolitik/kuenstliche-intelligenz-auf-facebook-instagram-und-whatsapp-wie-meta-deepfakes-kennzeichnen-will-a-bcc4eca0-b791-4431-8f7d-bc4b54716503,"Künstliche Intelligenz auf Facebook, Instagram und WhatsApp: Wie Meta Deepfakes kennzeichnen will - DER SPIEGEL","Gefälschte Pornobilder von Taylor Swift machten KI-Bildgeneratoren zum Politikum. Der Facebook-Konzern verspricht technische Lösungen. Die aber werden entschlossene Täter nicht stoppen. Zusammen mit anderen Firmen will Meta neue Initiativen zur Kennzeichnung von Bildern vorantreiben, die mithilfe von künstlicher Intelligenz (KI) entstanden sind. Mark Zuckerbergs Konzern reagiert damit offenbar auf die politische Debatte, die nach der Veröffentlichung von gefälschten Pornobildern von Popstar Taylor Swift aufgeflammt war. Hierbei geht es auch um die Befürchtung , dass gefälschte fotorealistische Bilder in den Wahlkämpfen in diesem Jahr eine große Rolle spielen könnten. Der Facebook-Konzern selbst hat in seinem Bildergenerator Imagine with Meta AI bereits zum Start in den USA Vorsichtsmaßnahmen ergriffen: Jedes Bild wird mit einem deutlich sichtbaren Hinweis auf die Herkunft gekennzeichnet. »In den kommenden Monaten«, teilte das Unternehmen nun mit, werde Meta auch Bilder derart kennzeichnen, die mit den Generatoren anderer Anbieter erzeugt wurden und dann auf Facebook, Instagram oder Threads geteilt werden – sofern sie als solche erkannt werden. Mit bloßem Auge nicht erkennbar Diese sichtbaren Wasserzeichen können aber relativ einfach überdeckt oder abgeschnitten werden. Deshalb setzt der Konzern zusätzlich auf Signaturen, die unsichtbar sind. Erstens sollen in den digitalen Metainformationen, wo bisher etwa Informationen über die verwendete Kamera oder den Aufnahmeort eines Bildes gespeichert sind, künftig auch Hinweise auf die Herkunft aus einem Bildergenerator platziert werden. Zweitens sollen auch in den Bildern selbst Wasserzeichen untergebracht werden, die für das menschliche Auge nicht erkennbar, aber für ein entsprechendes Programm eindeutig identifizierbar sind. Der Vorteil: Selbst, wenn KI-Fälschungen per Screenshot verbreitet werden, soll die unsichtbare Signatur bestehen bleiben. Meta verspricht, künftig die KI-generierten Bilder von Google, OpenAI, Microsoft, Adobe, Midjourney und Shutterstock erkennen zu können – sobald diese die Signaturen in ihre Bildgeneratoren generieren. Wann dies im Einzelnen der Fall sein wird, lässt Meta in der Ankündigung vom Dienstag offen. »Dieser Ansatz stellt die Spitze dessen dar, was derzeit technisch möglich ist«, erklärt der ehemalige britische Vizepremier Nick Clegg, der mittlerweile für globale Angelegenheit bei Meta zuständig ist . KI soll KI entlarven Doch dies deckt nur einen Teil des Problems ab. So räumt Meta selbst ein, dass die Industrie noch nicht bereit ist, künstlich generierte Audios oder Videos zu kennzeichnen, geschweige denn ungekennzeichnete Aufnahmen nachträglich sicher zu identifizieren. Zudem werden die Signaturen böswillige Akteure nicht davon abhalten, gezielt Fälschungen zu verbreiten. So waren die Fakebilder von Taylor Swift zuerst von Gruppen verbreitet worden, die es sich zum Spaß machen, die Sicherheitsmechanismen von gebräuchlichen Bildergeneratoren zu umgehen – eine Signatur nachträglich zu entfernen, dürfte für diesen Personenkreis kein Problem sein. Falls es denn überhaupt notwendig ist: Viele Bildergeneratoren stehen unter offenen Lizenzen und können von Entwicklern an eigene Bedürfnisse angepasst werden. Um solche negativen Folgen der KI-Technik abzumindern, setzt Meta auf noch mehr KI. »Wir sind optimistisch, dass generative KI uns dabei helfen könnte, schädliche Inhalte schneller und zielgenauer zu beseitigen«, schreibt Clegg – dabei sei es egal, ob ein KI-Generator zum Einsatz gekommen sei oder nicht."
AI,Spiegel Online,2024-02-06,https://www.spiegel.de/netzwelt/netzpolitik/kuenstliche-intelligenz-auf-facebook-instagram-und-whatsapp-wie-meta-deepfakes-kennzeichnen-will-a-bcc4eca0-b791-4431-8f7d-bc4b54716503,"Künstliche Intelligenz auf Facebook, Instagram und WhatsApp: Wie Meta Deepfakes kennzeichnen will - DER SPIEGEL","Gefälschte Pornobilder von Taylor Swift machten KI-Bildgeneratoren zum Politikum. Der Facebook-Konzern verspricht technische Lösungen. Die aber werden entschlossene Täter nicht stoppen. Zusammen mit anderen Firmen will Meta neue Initiativen zur Kennzeichnung von Bildern vorantreiben, die mithilfe von künstlicher Intelligenz (KI) entstanden sind. Mark Zuckerbergs Konzern reagiert damit offenbar auf die politische Debatte, die nach der Veröffentlichung von gefälschten Pornobildern von Popstar Taylor Swift aufgeflammt war. Hierbei geht es auch um die Befürchtung , dass gefälschte fotorealistische Bilder in den Wahlkämpfen in diesem Jahr eine große Rolle spielen könnten. Der Facebook-Konzern selbst hat in seinem Bildergenerator Imagine with Meta AI bereits zum Start in den USA Vorsichtsmaßnahmen ergriffen: Jedes Bild wird mit einem deutlich sichtbaren Hinweis auf die Herkunft gekennzeichnet. »In den kommenden Monaten«, teilte das Unternehmen nun mit, werde Meta auch Bilder derart kennzeichnen, die mit den Generatoren anderer Anbieter erzeugt wurden und dann auf Facebook, Instagram oder Threads geteilt werden – sofern sie als solche erkannt werden. Mit bloßem Auge nicht erkennbar Diese sichtbaren Wasserzeichen können aber relativ einfach überdeckt oder abgeschnitten werden. Deshalb setzt der Konzern zusätzlich auf Signaturen, die unsichtbar sind. Erstens sollen in den digitalen Metainformationen, wo bisher etwa Informationen über die verwendete Kamera oder den Aufnahmeort eines Bildes gespeichert sind, künftig auch Hinweise auf die Herkunft aus einem Bildergenerator platziert werden. Zweitens sollen auch in den Bildern selbst Wasserzeichen untergebracht werden, die für das menschliche Auge nicht erkennbar, aber für ein entsprechendes Programm eindeutig identifizierbar sind. Der Vorteil: Selbst, wenn KI-Fälschungen per Screenshot verbreitet werden, soll die unsichtbare Signatur bestehen bleiben. Meta verspricht, künftig die KI-generierten Bilder von Google, OpenAI, Microsoft, Adobe, Midjourney und Shutterstock erkennen zu können – sobald diese die Signaturen in ihre Bildgeneratoren generieren. Wann dies im Einzelnen der Fall sein wird, lässt Meta in der Ankündigung vom Dienstag offen. »Dieser Ansatz stellt die Spitze dessen dar, was derzeit technisch möglich ist«, erklärt der ehemalige britische Vizepremier Nick Clegg, der mittlerweile für globale Angelegenheit bei Meta zuständig ist . KI soll KI entlarven Doch dies deckt nur einen Teil des Problems ab. So räumt Meta selbst ein, dass die Industrie noch nicht bereit ist, künstlich generierte Audios oder Videos zu kennzeichnen, geschweige denn ungekennzeichnete Aufnahmen nachträglich sicher zu identifizieren. Zudem werden die Signaturen böswillige Akteure nicht davon abhalten, gezielt Fälschungen zu verbreiten. So waren die Fakebilder von Taylor Swift zuerst von Gruppen verbreitet worden, die es sich zum Spaß machen, die Sicherheitsmechanismen von gebräuchlichen Bildergeneratoren zu umgehen – eine Signatur nachträglich zu entfernen, dürfte für diesen Personenkreis kein Problem sein. Falls es denn überhaupt notwendig ist: Viele Bildergeneratoren stehen unter offenen Lizenzen und können von Entwicklern an eigene Bedürfnisse angepasst werden. Um solche negativen Folgen der KI-Technik abzumindern, setzt Meta auf noch mehr KI. »Wir sind optimistisch, dass generative KI uns dabei helfen könnte, schädliche Inhalte schneller und zielgenauer zu beseitigen«, schreibt Clegg – dabei sei es egal, ob ein KI-Generator zum Einsatz gekommen sei oder nicht."
Artificial Intelligence,Spiegel Online,2024-02-06,https://www.spiegel.de/netzwelt/netzpolitik/kuenstliche-intelligenz-auf-facebook-instagram-und-whatsapp-wie-meta-deepfakes-kennzeichnen-will-a-bcc4eca0-b791-4431-8f7d-bc4b54716503,"Künstliche Intelligenz auf Facebook, Instagram und WhatsApp: Wie Meta Deepfakes kennzeichnen will - DER SPIEGEL","Gefälschte Pornobilder von Taylor Swift machten KI-Bildgeneratoren zum Politikum. Der Facebook-Konzern verspricht technische Lösungen. Die aber werden entschlossene Täter nicht stoppen. Zusammen mit anderen Firmen will Meta neue Initiativen zur Kennzeichnung von Bildern vorantreiben, die mithilfe von künstlicher Intelligenz (KI) entstanden sind. Mark Zuckerbergs Konzern reagiert damit offenbar auf die politische Debatte, die nach der Veröffentlichung von gefälschten Pornobildern von Popstar Taylor Swift aufgeflammt war. Hierbei geht es auch um die Befürchtung , dass gefälschte fotorealistische Bilder in den Wahlkämpfen in diesem Jahr eine große Rolle spielen könnten. Der Facebook-Konzern selbst hat in seinem Bildergenerator Imagine with Meta AI bereits zum Start in den USA Vorsichtsmaßnahmen ergriffen: Jedes Bild wird mit einem deutlich sichtbaren Hinweis auf die Herkunft gekennzeichnet. »In den kommenden Monaten«, teilte das Unternehmen nun mit, werde Meta auch Bilder derart kennzeichnen, die mit den Generatoren anderer Anbieter erzeugt wurden und dann auf Facebook, Instagram oder Threads geteilt werden – sofern sie als solche erkannt werden. Mit bloßem Auge nicht erkennbar Diese sichtbaren Wasserzeichen können aber relativ einfach überdeckt oder abgeschnitten werden. Deshalb setzt der Konzern zusätzlich auf Signaturen, die unsichtbar sind. Erstens sollen in den digitalen Metainformationen, wo bisher etwa Informationen über die verwendete Kamera oder den Aufnahmeort eines Bildes gespeichert sind, künftig auch Hinweise auf die Herkunft aus einem Bildergenerator platziert werden. Zweitens sollen auch in den Bildern selbst Wasserzeichen untergebracht werden, die für das menschliche Auge nicht erkennbar, aber für ein entsprechendes Programm eindeutig identifizierbar sind. Der Vorteil: Selbst, wenn KI-Fälschungen per Screenshot verbreitet werden, soll die unsichtbare Signatur bestehen bleiben. Meta verspricht, künftig die KI-generierten Bilder von Google, OpenAI, Microsoft, Adobe, Midjourney und Shutterstock erkennen zu können – sobald diese die Signaturen in ihre Bildgeneratoren generieren. Wann dies im Einzelnen der Fall sein wird, lässt Meta in der Ankündigung vom Dienstag offen. »Dieser Ansatz stellt die Spitze dessen dar, was derzeit technisch möglich ist«, erklärt der ehemalige britische Vizepremier Nick Clegg, der mittlerweile für globale Angelegenheit bei Meta zuständig ist . KI soll KI entlarven Doch dies deckt nur einen Teil des Problems ab. So räumt Meta selbst ein, dass die Industrie noch nicht bereit ist, künstlich generierte Audios oder Videos zu kennzeichnen, geschweige denn ungekennzeichnete Aufnahmen nachträglich sicher zu identifizieren. Zudem werden die Signaturen böswillige Akteure nicht davon abhalten, gezielt Fälschungen zu verbreiten. So waren die Fakebilder von Taylor Swift zuerst von Gruppen verbreitet worden, die es sich zum Spaß machen, die Sicherheitsmechanismen von gebräuchlichen Bildergeneratoren zu umgehen – eine Signatur nachträglich zu entfernen, dürfte für diesen Personenkreis kein Problem sein. Falls es denn überhaupt notwendig ist: Viele Bildergeneratoren stehen unter offenen Lizenzen und können von Entwicklern an eigene Bedürfnisse angepasst werden. Um solche negativen Folgen der KI-Technik abzumindern, setzt Meta auf noch mehr KI. »Wir sind optimistisch, dass generative KI uns dabei helfen könnte, schädliche Inhalte schneller und zielgenauer zu beseitigen«, schreibt Clegg – dabei sei es egal, ob ein KI-Generator zum Einsatz gekommen sei oder nicht."
KI,Spiegel Online,2024-02-05,https://www.spiegel.de/netzwelt/web/hongkong-kriminelle-erbeuten-millionenbetrag-mit-fake-videokonferenz-a-14645031-ab6b-4187-9abc-ea4f8f682bdf,Hongkong: Kriminelle erbeuten Millionenbetrag mit Fake-Videokonferenz - DER SPIEGEL,"Mehr als 23 Millionen Euro haben Betrüger in Hongkong mithilfe einer vorgetäuschten Videokonferenz erbeutet. Sie umgingen die Schwächen der Technik offenbar geschickt – mit der »Chef-Masche«. Die sogenannte Chef-Masche , bei der sich Kriminelle als hochrangige Manager ausgeben, um hohe Geldtransfers zu veranlassen, findet immer neue Opfer. Wie ein Fall aus Hongkong zeigt, nutzen Täter mittlerweile auch Videos, die möglicherweise auf künstlicher Intelligenz (KI) basieren. Wie unter anderem die »South China Morning Post« berichtet , hat die Polizei in Hongkong Details zu einem aktuellen Fall veröffentlicht, bei dem Kriminelle umgerechnet mehr als 23 Millionen Euro erbeutet haben. Sie sollen dazu eine ganze Videokonferenz mit dem Finanzvorstand eines ungenannten internationalen Unternehmens gefälscht haben. Videokonferenz aus der Retorte Da die verwendete Technik augenscheinlich nicht fähig ist, reale Personen in Echtzeit zu imitieren, sollen die bislang unbekannten Betrüger mehrstufig vorgegangen sein. Zunächst sendeten Sie der Polizei zufolge eine E-Mail, in der die millionenschwere Überweisung angekündigt wurde. Der oder die Angestellte hatte da noch erhebliche Zweifel. Diese wurden jedoch beiseitegewischt, als die betroffene Person im Anschluss in eine Videokonferenz eingeladen wurde, in der neben dem in London ansässigen Finanzvorstand der Firma auch mehrere Kollegen zugeschaltet zu sein schienen. In dieser Besprechung ging es um die ungewöhnlichen Zahlungen. Die Ermittler gehen davon aus, dass es sich um ein vorher aufgezeichnetes Video handelte, da die Zielperson nicht direkt mit den Teilnehmern sprechen konnte. Als Vorlage für KI-generierte Bewegtbilder könnten laut Polizei YouTube-Videos oder unternehmensinterne Aufnahmen gedient haben, die zudem mit KI-generierten Stimmen ergänzt wurden. Möglicherweise waren aber auch nur die Stimmen gefälscht und die Videos unverändert übernommene Aufnahmen. Weitere Nachrichten per Instant Messenger bestätigten anscheinend den Vorgang. Die Betrüger sollen die Masche bei mehreren Angestellten des Unternehmens ausprobiert haben. Hinter den Betrug kam die Firma erst eine gute Woche nachdem das Geld auf fünf Konten in Hongkong überwiesen worden war. Die Polizei hat bisher noch keine Verdächtigen ermittelt und rät Firmen, sich auf ähnliche Angriffe vorzubereiten. So könnten Angestellte sich mit gezielten Nachfragen davon überzeugen, ob sie tatsächlich mit ihren Vorgesetzten sprechen. Die Ermittler in Hongkong haben auch bei anderen Betrugsmaschen mit KI-Technik zu tun, berichtet CNN . Demnach konnten Kriminelle gestohlene Ausweise erfolgreich für Kreditanträge nutzen, indem sie die bestohlenen Personen imitierten und so eine automatisierte Gesichtserkennung überlisteten. Hier soll es zu ersten Verhaftungen gekommen sein."
KI,Spiegel Online,2024-02-04,https://www.spiegel.de/wirtschaft/mit-ki-gegen-krebs-wie-biontech-zum-zweiten-mal-medizingeschichte-schreiben-will-a-49e25377-fe41-4e5a-8706-5272f27ee47d,Mit KI gegen Krebs: Wie Biontech zum zweiten Mal Medizingeschichte schreiben will - DER SPIEGEL,"Mit dem Covid-Impfstoff hat das Mainzer Unternehmen Biontech Milliarden Euro verdient. Nun setzen seine Gründer Uğur Şahin und Özlem Türeci dieses Geld ein, um an ihrem eigentlichen Lebenswerk zu arbeiten: den Krebs endgültig zu besiegen. Kann es dem Paar gelingen?"
Künstliche Intelligenz,Spiegel Online,2024-02-02,https://www.spiegel.de/netzwelt/netzpolitik/ai-act-gruenen-politikerin-franziska-brantner-ueber-ki-gesetz-es-geht-um-unsere-grundrechte-a-411c0425-a113-4026-95d8-eac784502bbf,AI Act: Grünen-Politikerin Franziska Brantner über KI-Gesetz - »es geht um unsere Grundrechte« - DER SPIEGEL,"Die Grünenpolitikerin Franziska Brantner hat das KI-Gesetz der EU mitverhandelt. Im Gespräch erklärt sie, warum sie den jetzigen Kompromiss für gelungen hält und was sich für ChatGPT-Nutzer ändern wird. SPIEGEL: Frau Brantner, Sie haben das erste Gesetz einer westlichen Wirtschaftsmacht zu künstlicher Intelligenz mitverhandelt, den AI Act der Europäischen Union. Im Jahr 2026 könnten die Regelungen wirksam werden. Kommt das nicht viel zu spät? Franziska Brantner: Nein, wir sind gut in der Zeit. Wir haben in der EU rechtzeitig angefangen und schon vor vielen Monaten begonnen, an einem KI-Gesetz zu arbeiten. Ende 2022 kam dann ChatGPT auf den Markt und hat gezeigt, dass KI bereits zu einem gewissen Grad menschliche Aufgaben übernehmen kann. Ein so wirkmächtiges System hatte es vorher nicht gegeben. Aber auch diese neue Technologie hat der AI Act nun im Blick. SPIEGEL: Der finale Entwurf für das Gesetz ist seit Kurzem bekannt und die Kritik ist groß. Den einen geht er zu weit, den anderen ist er zu lasch. Nun stehen die finalen Abstimmungen in Rat und Parlament an. Droht das Gesetz zu scheitern? Die Grünenpolitikerin Franziska Brantner , Jahrgang 1979, ist Staatssekretärin im Bundesministerium für Wirtschaft und Klimaschutz. Von 2009 bis 2013 war sie Abgeordnete im Europaparlament, seit 2013 ist sie Bundestagsabgeordnete, zwischen 2017 und 2021 war sie europapolitische Sprecherin der Grünen-Bundestagsfraktion. Sie lebt in Heidelberg und Berlin. Brantner: Ich hoffe nicht. Klar ist: Dieses Gesetz muss unterschiedlichste Interessen austarieren. Einerseits wollen wir die Innovationspotenziale nutzen, die KI bietet: für unsere Gesundheit, in der Forschung, zur Automatisierung von Aufgaben. Andererseits müssen wir die Risiken in den Griff bekommen. Nehmen Sie zum Beispiel die automatische Emotionserkennung am Arbeitsplatz: Niemand will, dass eine KI ständig auswertet, ob Herr Schmidt gerade grimmig guckt – womöglich während er die E-Mail des Chefs liest. Solche Anwendungsfälle haben wir verboten. SPIEGEL: Aus Ihrer Sicht ist die Kritik von verschiedenen Seiten ein Beleg für dessen Ausgewogenheit? Brantner: Es ist nie einfach, sehr unterschiedliche Interessen in eine gute Balance zu bringen, insbesondere nicht bei der komplexen Regulierung einer hochdynamischen Technologie, die quasi alle Bereiche des Lebens betrifft. Ich gebe Ihnen noch ein Beispiel: Urheberrecht. Künstliche Intelligenz wird trainiert mit Unmengen an Bildern, Informationen und Texten, damit sie selbst nach den Vorgaben des Nutzers Bilder und Texte erstellen kann. Es ist faszinierend, wie gut KI das schon kann. Aber es stellt sich eben die Frage: Wenn eine KI mit Bildern eines bestimmten Künstlers trainiert wurde und dann Bilder in dessen Stil erzeugt, wer hat dann die Rechte daran? Auch hier mussten wir eine Balance finden. Hersteller müssen künftig transparent machen, mit welchen Daten sie die KI trainiert haben. Urheber wiederum haben Möglichkeiten, zu verhindern, dass ihre Werke von der KI ausgelesen werden. SPIEGEL: Besonders heftig diskutiert wird die automatische Gesichtserkennung . Daran haben gerade Strafverfolgungsbehörden ein großes Interesse. Bürgerrechtlern gehen die Befugnisse dagegen viel zu weit. Brantner: Grundsätzlich verbietet die KI-Verordnung Videoüberwachung in Echtzeit mittels KI-gestützter Gesichtserkennung. Es gelten Ausnahmen beispielsweise für die Suche nach Vermissten oder die Verhinderung einer unmittelbaren terroristischen Bedrohung. Und für die nachträgliche Auswertung von Videomaterial mit KI gibt es strenge Regeln. In beiden Fällen muss ein Richter oder eine entsprechende Behörde zustimmen, der Vorgang muss bei der Polizei registriert werden und Datenschützer müssen Zugang zu den Systemen haben. Wenn die Mitgliedsländer wollen, können sie die Vorgaben sogar noch weiter verschärfen. SPIEGEL: Klingt, als wären Sie mit der Regelung ganz zufrieden. Brantner: Ja. Wir schaffen damit erstmals einen europäischen Mindeststandard für die Regeln bei KI-basierter, automatischer Gesichtserkennung. Darüber bin ich froh. Denn diese Vorgaben gelten dann auch überall in der Union. SPIEGEL: Innerhalb der Bundesregierung gab es bis zuletzt noch heftige Diskussionen über das Gesetz . Insbesondere aus der FDP soll es Widerstand gegeben haben. Was war da los? Brantner: Die Beispiele, die ich genannt habe, zeigen ja: Die KI-Verordnung berührt Grundlagen unserer demokratischen und wirtschaftlichen Ordnung – es geht um die Grundrechte jeder und jedes Einzelnen, um geistiges Eigentum, die Freiheit der Forschung und unsere Innovationsfähigkeit. All das musste in Balance gebracht werden, und das geht nicht ohne Diskussionen. SPIEGEL: Und wie sieht der Kompromiss der Koalition nun aus? Brantner: Wir haben den Text intensiv geprüft und uns darauf verständigt, dass die Bundesregierung der KI-Verordnung in Brüssel zustimmen wird. Damit haben wir frühzeitig ein klares Signal für Handlungsfähigkeit und Rechtssicherheit gesendet. SPIEGEL: Vergangenes Jahr warnten zahlreiche Techgrößen vor potenziellen Gefahren für die Menschheit . Ein bisschen klang das nach der Sorge, die KI könnte die Weltherrschaft übernehmen. Haben Sie so etwas im Kreise der Mitgliedstaaten diskutiert? Brantner: Nein, zumindest nicht in den Gesprächen, an denen ich beteiligt war. Ein Risiko, das ich aber für durchaus real halte, ist, dass Anbieter gehackt werden, die wirkmächtige KI-Systeme betreiben. Das kann potenziell enormen Schaden anrichten. Deshalb ist es wichtig, dass wir hier Vorgaben machen, damit Anbieter von Hochrisiko-KI sich entsprechend schützen. Wenn Sie ein Chemielabor haben, das mit hochgiftigen Stoffen arbeitet, müssen Sie ja auch sicherstellen, dass da nicht jeder reinlaufen kann. Auch unsere kritische Infrastruktur, beispielsweise unsere Energiesysteme, schützen wir entsprechend. Das muss für KI-Anbieter genauso gelten. Andere Risiken haben wir versucht auszuschließen, indem wir bestimmte Anwendungsfälle ganz verboten haben. SPIEGEL: Welche? Brantner: Social Scoring zum Beispiel. In China wird das Verhalten der Menschen dazu genutzt, um ihre angebliche Vertrauenswürdigkeit zu errechnen. Das haben wir komplett verboten. Und dann gibt es Anwendungsbereiche, bei denen wir sagen, sie sind so heikel, dass sie reguliert werden müssen. Etwa, wenn KI bei der Personalauswahl eingesetzt wird. Dann muss dafür gesorgt werden, dass sie nicht diskriminierend ist. Damit eine Frau mit dem Vornamen Özlem die gleichen Chancen hat wie eine mit dem Vornamen Franziska. SPIEGEL: Sie haben vorhin schon das Beispiel Emotionserkennung angesprochen, also dass eine KI die Mimik einer Person auswertet und Schlüsse daraus zieht. Das soll am Arbeitsplatz verboten sein. Aber nicht überall. Gibt es denn hier überhaupt Anwendungsfälle, die unbedenklich sind? Brantner: In bestimmten Fällen kann es sinnvoll sein. Beispielsweise bei medizinischen Systemen im therapeutischen Bereich. SPIEGEL: Ab wann gilt eine KI als Hochrisiko-KI und bekommt besonders strenge Vorgaben? Brantner: Für die Einstufung als Hochrisiko-KI sieht die KI-Verordnung verschiedene Kriterien vor, das ist im Text und dem entsprechenden Anhang geregelt. Zum Beispiel betrifft das KI-Systeme aus dem medizinischen Bereich, der kritischen Infrastruktur und dem Bildungsbereich. Ausnahmen gibt es für Systeme, von denen kein bedeutendes Risiko für die Gesundheit, Sicherheit und die Grundrechte ausgeht. Das ist ein wichtiger Punkt für die Unternehmen und Innovatoren. Im Übrigen gibt es bei KI-Modellen nun die Kategorie der KI-Modelle mit systemischen Risiken, die strengeren Vorgaben unterliegen. Bei diesen Modellen bestimmt die Zahl der Rechenoperationen, die notwendig ist, um ein KI-Modell zu trainieren, darüber, wie potent und wirkmächtig es ist – und damit auch, wie potenziell riskant. Technisch gesehen gilt ein universell einsetzbares KI-Modell nun als riskant, wenn der kumulative Rechenaufwand für das Training mehr als 10 25 Flops – also Gleitkommaoperationen – beträgt. SPIEGEL: So ein Maßstab kann aber schnell veralten. Brantner: Deshalb ist das auch nicht der einzige Faktor. Die Kommission hatte diesen Vorschlag im Herbst gemacht, und dann haben wir zusammen mit Frankreich und Italien gesagt, dass wir diese Grenze nicht plausibel finden. Jetzt wird unter anderem auch die Zahl der Anwenderinnen und Anwender eine Rolle spielen. Und wir haben die Möglichkeit eröffnet, dass andere Kriterien hinzukommen, auch auf Empfehlung der Forschungscommunity. Außerdem steht jetzt im Verordnungstext, dass der »state of the art« berücksichtigt werden muss – also dass immer der aktuelle Stand der Technik als Maßstab gilt. Der technologische Fortschritt wird eingepreist. SPIEGEL: Können Sie Beispiele nennen für KI-Anwendungen, die als Hochrisiko-KI gelten würden? Brantner: Das sind zum Beispiel die Prüfung der Kreditwürdigkeit, oder Auswahlen bei Einstellungsverfahren. SPIEGEL: Kritiker befürchten, dass die Vorgaben der EU Innovationen abwürgen könnten. Die Sorge haben Sie nicht? Brantner: Forschung und Entwicklung sind vom Anwendungsbereich der Verordnung ganz klar ausgenommen. Das war uns wichtig, weil wir in Deutschland in diesem Bereich sehr gut sind und hier die Keimzelle von Innovationen liegt. Es geht auch hier um eine gute Balance zwischen legitimen Sicherheitsansprüchen, der Vermeidung von Bürokratie und Offenheit für die Technologie. Entscheidend ist dann, dass auch die Umsetzung der Verordnung bürokratiearm und innovationsfreundlich ist. Da werden wir als Bundesregierung ein besonderes Auge drauf haben. SPIEGEL: Was wird sich 2026 für eine Person ändern, die so etwas wie ChatGPT nutzt? Schon jetzt verwenden Menschen das Programm, um Bewerbungen zu schreiben oder Präsentationen für die Arbeit zu erstellen. Brantner: Wenn diese Person zum Beispiel ein Bild mit einer generativen KI erzeugt, dann müsste da ein Hinweis stehen, eine Art digitales Wasserzeichen. Diese Transparenz ist etwas, das die Menschen mitbekommen werden. Es dürfte für viele sogar der Hauptunterschied zur heutigen Situation sein. SPIEGEL: Glauben Sie, dass Anbieter wie OpenAI und Microsoft solche Produkte dann vorsichtshalber nicht mehr in der EU anbieten werden? Brantner: Das würde mich sehr wundern angesichts der großen Bedeutung des europäischen Markts. Wir sehen eher, dass sich die Amerikaner mit großem Interesse unser Gesetz anschauen und überlegen, was sie davon selbst verwenden können. SPIEGEL: Gewisse moralische Fragen werden im AI Act nicht verhandelt: Was soll KI künftig für uns erledigen? Soll sie journalistische Artikel für uns schreiben? Wollen wir, dass Schauspielerinnen oder Lehrer durch KI ersetzt werden? Brantner: Das sind hochrelevante Fragen für uns als Gesellschaft. Wir haben in Deutschland einen Arbeitskräftemangel. Das heißt, wir haben ein Interesse daran, dass ein Teil der Jobs durch KI ersetzt wird oder durch Roboter. Aber wir dürfen es nicht komplett dem Zufall überlassen, wo die besten KIs entstehen und eingesetzt werden. In der Bildung beispielsweise wollen wir sicher auch in Zukunft noch Menschen haben, die unseren Kindern etwas beibringen. Im Altersheim wiederum gibt es Aufgaben, die man durch KI ersetzen könnte und dadurch bekäme das Personal mehr Zeit für den direkten Kontakt mit den Bewohnern, um vielleicht mal wieder gemeinsam ein Brettspiel zu spielen. Es kommt jetzt darauf an, welche Anwendungen unsere Unternehmen entwickeln und voranbringen. SPIEGEL: Wo verständigt sich eine Gesellschaft über diese Fragen? Das kann ja nicht nur der Markt regeln. Brantner: Wir haben, wie gesagt, Bereiche ausgeschlossen, in denen KI nicht eingesetzt werden darf, weil wir es für zu gefährlich halten. Und Hochrisiko-Anwendungen müssen mit unseren Grundrechten vereinbar und diskriminierungsfrei sein. Im Rahmen dessen, was erlaubt ist, wird man dann, wie bei anderen Technologien und ihren Anwendungen sehen, wo Ressourcen und Geld hingehen. Auch bei KI hat Politik nicht die Aufgabe, überall zu entscheiden, was für Verbraucherinnen und Verbraucher, was für Unternehmen gut ist. Es werden sich die Produkte am Markt durchsetzen, die einen echten Mehrwert bieten. Und als Gesellschaft werden wir – wie bei anderen neuen Technologien auch – darüber diskutieren, wie wir die Chancen bestmöglich nutzen, ohne Risiken zu ignorieren. SPIEGEL: Welcher Punkt der finalen Fassung des AI Acts stört Sie am meisten? Brantner: Wir müssen bei der Umsetzung sehr gut darauf achten, dass die KI-Verordnung gut mit anderen Produktverordnungen wie zum Beispiel im Medizinbereich harmoniert und nicht zu unerwünschten Konsequenzen führt. SPIEGEL: Was steht auf dem Spiel, wenn das Gesetz scheitern sollte? Brantner: Dann gibt es keinerlei spezifische KI-Regulierung, keinerlei Standards und keine Planungssicherheit und es ist erstmal alles erlaubt, worüber wir gerade sprachen. Nationale Regierungen würden sicher anfangen zu regulieren und am Ende hätten wir einen Flickenteppich, der unseren Unternehmen das Leben schwer macht. Auf europäischer Ebene stehen im Sommer Wahlen an. Wer weiß, wie die Mehrheiten im Europäischen Parlament danach aussehen, ob diese dann wirklich die Grundrechte stärken wollen oder eher nicht. Nun muss sich jeder fragen, ob er lieber gar keine Regulierung hat oder eine, die unterschiedlichste Interessen in essenziellen Punkten in eine gute Balance gebracht hat."
Künstliche Intelligenz,Spiegel Online,2024-02-01,https://www.spiegel.de/start/kuenstliche-intelligenz-informatik-oder-data-science-studieren-ki-studiengaenge-und-ausbildungen-a-26a8685d-e6f1-4625-bd23-cc307ecf33aa,Künstliche Intelligenz: Informatik oder Data Science studieren? - KI-Studiengänge und Ausbildungen - DER SPIEGEL,"Alle reden über künstliche Intelligenz, Fachleute sind auf dem Arbeitsmarkt gefragt. Welche Fächer man belegen muss, um neue Technologien mitzuentwickeln – und welche Fähigkeiten es dazu braucht. Spätestens mit ChatGPT ist künstliche Intelligenz in unserem Alltag angekommen. Egal, ob in der Medizin- oder Agrarindustrie: Die Entwicklung neuer Technologien mithilfe von KI bietet der deutschen Wirtschaft vielfältige neue Chancen. Kein Wunder also, dass Unternehmen händeringend nach KI-Spezialist:innen suchen. Mit der steigenden Nachfrage wächst auch das Angebot an Ausbildungswegen, die in das Berufsfeld führen. »Das Schöne ist, dass jeder in der KI-Entwicklung seinen Platz findet«, sagt Kinga Schumacher, Senior Researcherin am Deutschen Forschungszentrum für Künstliche Intelligenz (DFKI) in Berlin – ob beim fokussierten Programmieren oder in interdisziplinärer, kreativer Projektarbeit. Sie habe zu Beginn ihrer Karriere klassisch Informatik studiert, erzählt Schumacher. KI sei damals in den Nullerjahren noch kaum Thema gewesen. Heute sieht das anders aus. Informatik oder Data Science? – Der Weg in die KI-Entwicklung »Vor fünfzehn Jahren hätte ich Ihnen noch gesagt: Studieren Sie Informatik!«, sagt Schumacher. Inzwischen sei die Antwort nicht mehr so einfach, die Wege in die KI-Entwicklung sind vielfältig. Es gebe immer mehr Studiengänge, die sich auf spezielle Bereiche der künstlichen Intelligenz fokussieren, so die Forscherin. Meist sind das Formen der angewandten Informatik oder sie sind in der Mathematik angesiedelt. Welches Fach sich am besten eignet, sei eine Frage der persönlichen Neigungen. »Wenn ich gern rumbastele, dann studiere ich vielleicht Robotik, wenn ich zwei linke Hände habe, eher etwas Datenzentriertes«, sagt Schumacher. Bei Data Science etwa liegt der Fokus auf der Auswertung großer Datenmengen. In einem Studiengang Künstliche Intelligenz liege der Fokus dagegen mehr auf möglichen Anwendungsbereichen von KI, etwa Mobilität, Gesundheitswesen oder Chatbots. Die Grundlagen seien jedoch meist die gleichen, sagt Schumacher. Das betont auch Thomas Röser von der Berufsberatung der Agentur für Arbeit Aachen-Düren. Man solle sich von den vielen unterschiedlichen Fachrichtungen nicht abschrecken lassen. »Das ist wie in der BWL: Da heißt der Studiengang vielleicht Marketing – im Grunde genommen machen Sie aber auch BWL.« Wer sich früh spezialisieren möchte, könne seinen Bachelor in einem Anwendungsfach machen. Wer sich unsicher sei, dem rate er allerdings zum klassischen Grundstudium Informatik oder Mathematik. »Spezialisieren ja, aber warum schon im Bachelor?« Im Master könne man dann immer noch seinen Fokus setzen. Auch ein Wechsel sei innerhalb der unterschiedlichen Fächer meist unkompliziert. Was? Die klassische Informatik vermittelt Grundlagen der systemischen Verarbeitung von Informationen. Neben den grundlegenden Fächern der angewandten, praktischen und technischen Informatik kommen immer mehr Spezialisierungsfelder hinzu. Dazu gehört auch künstliche Intelligenz. Wo? An den meisten Hochschulen wird Informatik als Bachelor und Master angeboten, besonders an Technischen Hochschulen. Renommiert sind etwa die RWTH Aachen , die TU München oder die FU Berlin . In Deutschland gibt es über 600 Studienangebote. Was? Angewandte Informatik hat im Vergleich zum klassischen Fach meist eine stärkere Spezialisierung auf einen Anwendungsbereich. Eigentlich ist es ein Überbegriff für verschiedene spezialisierte Informatikstudiengänge, wie Medieninformatik oder Cybersecurity. Die Spezialisierung kann sich von Hochschule zu Hochschule stark unterscheiden. Voraussetzung sollte also ein Interesse am jeweiligen Schwerpunktthema sein. Wo? Mehr als 100 Hochschulen bieten Studiengänge in der angewandten Informatik an. Siehe unten. Was? Die Studiengänge Künstliche Intelligenz oder Artificial Intelligence sind von Anfang an auf KI fokussiert. Wo? Technische Hochschule Ingolstadt , Ostbayerische Technische Hochschule Amberg-Weiden , BTU Cottbus-Senftenberg , Uni Würzburg , TH Rosenheim , Hochschule Landshut , Hochschule Ansbach ; Master: Universität Ulm , THWS Würzburg , Uni Erlangen-Nürnberg , Uni Lübeck (Auswahl) Was? Data Scientists gewinnen mit Methoden der Mathematik, Informatik und Statistik Erkenntnisse aus großen Mengen von Daten. Ebenfalls ein Spezialisierungsbereich der Informatik. Wo? Uni Erlangen-Nürnberg , Uni Gießen , TU Dortmund , BHT Berlin , Uni Göttingen , TU Hamburg , Uni Hildesheim , Uni Marburg , LMU München , Uni Trier ; Master: Hochschule Darmstadt , Hochschule Harz , RWTH Aachen , FU Berlin , Uni Bielefeld , TU Braunschweig , TU Chemnitz , Hochschule Coburg , Hochschule Fulda , Hochschule Bielefeld , Fernuni Hagen , FH Kiel , Hochschule Anhalt , Uni Leipzig , Uni Mannheim , UE Innovation Hub Potsdam , Uni Potsdam , IU Internationale Hochschule Erfurt , (Auswahl) Was? Machine Learning ist ein Teilbereich der künstlichen Intelligenz. Algorithmen erkennen Muster in Datensätzen und entwickeln daraus Lösungen. Wo? Den Studiengang gibt es bislang als Masterstudium an der Uni Tübingen und als Artificial Intelligence and Machine Learning an der TU Darmstadt . Was? Medieninformatik ist eine Variante der angewandten Informatik und hat einen berufsorientierten Praxisbezug. Der Studiengang konzentriert sich auf die digitale Informationsverarbeitung in Medien – etwa Computerspielen, Onlineplattformen oder Apps. Der Schwerpunkt liegt auf Multimedia und Softwaretechnik, es kommen aber auch interdisziplinäre Themen dazu wie Mediengestaltung und Wahrnehmungspsychologie. Künstliche Intelligenz ist hier nur eines der möglichen Themenfelder. Wo? Den Studiengang gibt es vergleichsweise häufig, der thematische Schwerpunkt variiert. Bachelorstudiengänge gibt es etwa an der TU Dresden , der LMU München , der Universität des Saarlandes oder der Uni Tübingen . Was? Ein angewandtes Studium der Informatik mit Schwerpunkt auf Robotern und autonomen Systemen, zum Beispiel autonomen Fahrzeugen. Wo? Bachelorstudiengänge gibt es etwa an der Uni Lübeck , der TH Ingolstadt , FH Südwestfalen , HS Kempten , THWS Schweinfurt , EAH Jena oder an der TH Deggendorf . Einen Master in angewandter Robotik gibt es an der HTW Dresden , Neurobotik an der TU Chemnitz . Artificial Intelligence and Data Science : Universität des Saarlandes ; Master: Heinrich-Heine-Universität Düsseldorf , TH Deggendorf , Hochschule Neu-Ulm , Universität Stuttgart , Hochschule Trier Beispiele für weitere Kombinationsfächer oder Spezialisierungen : Computer Science an der TU Darmstadt , Angewandte Data Science und Künstliche Intelligenz in Stralsund , Artificial Intelligence for Smart Sensors and Actuators an der TH Deggendorf , Angewandte Künstliche Intelligenz und Digitale Transformation an der HS Ansbach , Mind, Brain and Behavior an der Uni Gießen , Digital Technologies an der TU Clausthal und Ostfalia Hochschule , KI und Computer Vision an der Hochschule Kempten , Artificial Intelligence Engineering an der Uni Passau , Angewandte Künstliche Intelligenz an der FH Südwestfalen (Auswahl) Voraussetzungen für KI-Studiengänge Eines haben jedoch alle Studiengänge gemeinsam, die auf die Entwicklung von künstlicher Intelligenz abzielen. »Um Mathematik kommen Sie nicht herum«, sagt Röser. Logisches Denken und gute mathematische Grundkenntnisse werden in allen Fachbereichen der Informatik gefordert. Auch gute Englischkenntnisse seien heutzutage zunehmend wichtig, sagt Röser. Eine erste Neugier und Affinität zu Programmierung sei ebenfalls hilfreich. An den hohen Abbruchquoten in der Informatik und verwandten Naturwissenschaften zeigt sich zudem, wie wichtig strukturiertes Arbeiten und Durchhaltevermögen sind. Wer vor Mathematik zurückschreckt und technisch weniger versiert ist, kann sich der KI-Forschung über Umwege nähern. KI-Entwicklerin wird man dann vielleicht nicht – aber man arbeitet mit ihnen zusammen. »Wir haben auch bei uns am Forschungsinstitut Quereinsteiger:innen aus anderen Fachrichtungen«, sagt Forscherin Schumacher. Häufig kämen die aus der Mathematik, Physik und Chemie, aber auch die Psychologie sei in der KI-Entwicklung unheimlich wichtig. An der Beschäftigung mit KI im weitesten Sinne kommt man 2024 ohnehin nicht mehr ganz vorbei. In keinem Fachbereich. Was suchen die Unternehmen? Auch die Wirtschaft ist Taktgeber. KI-Spezialist:innen werden inzwischen in fast allen Branchen gesucht. Von Januar bis April vergangenen Jahres schrieben Arbeitgeber in Deutschland fast 44.000 Stellen mit KI-Bezug aus, so eine Auswertung der Personalagentur Index. Besonders gefragt waren demnach Informatiker:innen sowie Mitarbeitende im Bereich Forschung und Entwicklung. In Zukunft würden Unternehmen zudem stark nach Expert:innen angrenzender Fachbereiche suchen, sagt Berufsberater Röser. »KI allein ist nicht funktionsfähig. Geld wird ja mit den Produkten gemacht, die mittels KI funktionieren und gesteuert werden. Autonome Fahrzeuge etwa.« Auch ein Studium in den Fächern Maschinenbau, Elektrotechnik oder Energietechnik kann also indirekt in die KI-Entwicklung führen. Noch wichtiger als ein Master sei für die Unternehmen Praxiserfahrung, sagt Röser. »Das sehen Sie auch bei den Stellenangeboten. Häufig ist mehrjährige Erfahrung im Bereich der Softwareentwicklung gefragt.« Er empfehle deshalb häufig anwendungsbezogene Studiengänge und duale Angebote, etwa an der RWTH Aachen. Wer später in die Forschung möchte, kann sich an Forschungs- und Kompetenzzentren für künstliche Intelligenz orientieren (siehe Kasten). Inzwischen gibt es immer mehr Kooperationen zwischen den Zentren mit bestimmten Universitäten und Studiengängen. Das kann Synergien und Projekte schaffen und den Weg in die Forschung erleichtern. Standort : Berlin Partneruniversitäten : TU Berlin, TU Braunschweig, HU Berlin, FU Berlin, Uni Potsdam Mehr Informationen auf der Website des BIFOLD Standorte : Bremen, Kaiserslautern, Saarbrücken und Osnabrück Labore in Berlin und Darmstadt sowie Außenstellen in Lübeck und Trier Partneruniversitäten : RPTU Kaiserslautern-Landau, Universität des Saarlandes, Uni Bremen, Hochschule Bremen, TU Berlin, Uni Osnabrück, Hochschule Osnabrück, Uni Oldenburg, Jade Hochschule, Constructor University Bremen (privat), Uni Lübeck Das DFKI ist die bundesweit größte Forschungseinrichtung. Mehr Informationen auf der Website des DFKI Standort : München Partneruniversitäten : LMU München und TU München Mehr Informationen auf der Website des MCML Standort : Dortmund Partneruniversitäten : TU Dortmund und Uni Bonn Mehr Informationen auf der Website des LAMARR Standort : Dresden und Leipzig Partneruniversitäten : TU Dresden und Uni Leipzig Mehr Informationen auf der Website des ScaDS Standort : Tübingen Partneruniversitäten : Uni Tübingen Mehr Informationen auf der Website des AI Centers Die Zuse Schools werden vom Deutschen Akademischen Austauschdienst (DAAD) gefördert und jeweils von einer Technischen Universität betrieben. Aktuell gibt es die Graduiertenschulen an der TU Darmstadt, der TU Dresden und der TU München. Standort: Potsdam Das gemeinnützige, private Institut forscht und lehrt zu IT-Systems Engineering, Data Engineering und Digital Health in Kooperation mit der Uni Potsdam. Auch AI Grid ist ein Netzwerk zur Förderung von jungen Talenten in der KI-Forschung. Es koordiniert Nachwuchsprogramme im Informatik-Umfeld und hat seinen Sitz in Berlin. Der Forschungsverbund will in Baden-Württemberg privatwirtschaftliche Unternehmen und akademische Partner zusammenbringen, um die KI-Forschung voranzutreiben. Partner sind etwa das Max-Planck-Institut für Intelligente Systeme und das Fraunhofer-Institut. Zu den beteiligten Unternehmen gehören unter anderem Amazon, BMW oder Bosch. Partneruniversitäten : Uni Stuttgart und Uni Tübingen Ausbildungen im Bereich künstliche Intelligenz Auch eine Ausbildung bietet Berufsmöglichkeiten im Bereich der künstlichen Intelligenz. Infrage kommen insbesondere eine Ausbildung als Fachinformatiker:in mit der Spezialisierung Anwendungsentwicklung oder eine Ausbildung als Softwareentwickler:in. Hier ist man für die Umsetzung und Programmierung zuständig. Fachinformatiker:in mit der Spezialisierung Anwendungsentwicklung arbeiten in der Softwareentwicklung: Sie konzipieren und programmieren Anwendungen und Benutzeroberflächen – entweder für den eigenen Betrieb oder für Kunden. Sie entwickeln dabei unter Umständen auch KI-gestützte Software, wie etwa Chatbots. Mathematisch-technische Softwareentwickler:in : Mithilfe mathematischer Modelle entwerfen sie Softwaresysteme, programmieren und warten diese. Dabei verwenden sie auch KI-Modelle. Arbeitsorte sind größere Unternehmen, Softwarehäuser und Forschungseinrichtungen. Als inklusive Optionen für Menschen mit Behinderung bieten sich eine Ausbildung zum Fachpraktiker oder Fachpraktikerin für IT-Systemelektronik oder IT-Systemintegration an. Mehr Frauen in die KI-Entwicklung In vielen MINT-Fächern überwiegen männliche Studierende. Immer wieder zeigen Studien wie diese aus dem Jahr 2022 , dass sich Frauen nicht für das Studium eines MINT-Faches gerüstet fühlen. Kinga Schumacher ist es deshalb ein persönliches Anliegen, dass sich junge Frauen nicht von einer Karriere im Bereich KI abschrecken lassen. Auch aufgrund ihrer persönlichen Erfahrung. »Als ich studiert habe, hieß es jeden Tag: Guten Morgen Frau Schumacher, guten Morgen meine Herren«, erzählt sie. »Ich konnte nicht mal schwänzen, weil ich eigentlich immer die einzige Frau war.« Inzwischen habe sich viel getan. Sie selbst habe inzwischen ein kleines Team mit überwiegend Frauen. Mehr Diversität sei in der KI-Entwicklung unheimlich wichtig: »Wenn wir KI-Systeme für Menschen entwickeln, die nicht diskriminierend und für alle gleich gut sein sollen, dann benötigen wir eben auch diverse Teams.« Anmerkung der Redaktion : In einer früheren Version des Textes konnte der Eindruck entstehen, die Mathematik sei lediglich Grundlage der Informatik. Es gibt jedoch auch Studiengänge im Bereich der KI, die in der Mathematik angesiedelt sind. Wir haben den Text entsprechend ergänzt."
Künstliche Intelligenz,Spiegel Online,2024-01-30,https://www.spiegel.de/netzwelt/gadgets/samsung-galaxy-s24-ultra-im-test-ki-ist-jetzt-fast-ueberall-a-80c24e44-baf7-4b40-94f9-542a74dcf87b,Samsung Galaxy S24 Ultra im Test: KI ist jetzt fast überall - DER SPIEGEL,"Samsungs neues Top-Smartphone könnte sterbenslangweilig sein – wären da nicht die KI-Funktionen und die Aussicht, das Gerät auch im Jahr 2031 noch nutzen zu können. Dieser Text enthält sogenannte Affiliate-Links, über die der Verlag, aber nie der Autor individuell, bei Verkäufen eine geringe Provision vom Händler erhält. Beim Design hat sich Samsung von Apple inspirieren lassen und ist sich gleichzeitig selbst treu geblieben. So wie beim iPhone 15 Pro ( hier unser Testbericht ) wird der Rahmen des Galaxy S24 Ultra aus Titan hergestellt. Das robuste Metall fühlt sich angenehm weich an, liegt gut in der Hand. Einhändig bedienen kann man es trotzdem nicht, dafür ist der Bildschirm mit seinen 6,8 Zoll zu groß. Die grundlegende Form aber erinnert sehr an das Galaxy S23 Ultra vom vorigen Jahr ( hier unser Testbericht ). Auch die Anordnung der Kameras auf der Rückseite ist identisch, und der S Pen, mit dem man auf dem Bildschirm schreiben, zeichnen und malen kann, ist an der gleichen Stelle im Gehäuse untergebracht. Der kleine Stift funktioniert übrigens trotz seiner billig wirkenden Machart hervorragend. Wer gern handschriftliche Notizen macht – was ich nicht tue – wird damit gut klarkommen. Guck mal Eine sichtbare Verbesserung ist das neue Design des Bildschirms. Das Display des S23 Ultra war an den Rändern ganz leicht gebogen. Der Bildschirm des S24 Ultra ist nun – endlich – vollkommen flach und lässt sich bis zum Rand hin nutzen. Die Ära der gebogenen Bildschirme dürfte damit vorbei sein. Weshalb Samsung diesen Schritt nicht schon im vergangenen Jahr gegangen ist, ist mir schleierhaft. Alles andere als schleierhaft ist dagegen der Bildschirm selbst. Wie der des Vorgängers ist er knackscharf, verfügt über 3120 mal 1440 Pixel, kann die Bildwiederholfrequenz von einem Bild pro Sekunde beim Lesen auf bis zu 120 Bilder pro Sekunde beim Scrollen und Spielen variieren. Der Sinn dahinter: je weniger Bilder das Display anzeigen muss, desto weniger Energie benötigt es. Viel Energie geht drauf, wenn man das Handy bei praller Sonne benutzt. Das Display erreicht dann punktuell eine Spitzenhelligkeit von 2600 Nits, 200 mehr als das Pixel 8 Pro und 600 mehr als das iPhone 15 Pro. Das ist hell, sehr hell. Pixel statt Linsen Wie das Design vermuten lässt, hat sich bei den Kameras nicht viel getan. Wie schon das S23 Ultra verfügt das S24 Ultra über eine Weitwinkelkamera mit 200 Megapixeln. Deren volle Auflösung ist aber nur selten von Nutzen. Einzig bei sehr hellen Motiven kann es sinnvoll sein. Die vollen 200 Megapixel zu verwenden. Die besseren Fotos erreicht man im 12-Megapixel-Modus, in dem je 16 Sensorpixel zu einem Bildpixel kombiniert werden. Eine Auflösung von 12 Megapixeln hat ebenfalls die Ultraweitwinkelkamera, die Dreifach-Telekamera muss sich mit 10 Megapixeln begnügen. Neu ist, dass die zweite Telekamera jetzt 50 statt 10 Megapixel hat und ihr optisches Zoomobjektiv nur auf eine fünffache Vergrößerung kommt. Im Vorgänger steckte noch eine Zehnfach-Zoom. Das macht skeptisch. Hat Samsung das große Tele beschnitten? Die Antwort lautet ja, aber beschnitten werden nun die Aufnahmen: Statt per Objektiv ans Motiv heranzuzoomen, wird bei Zoomstufen über dem Faktor fünf eine 50-Megapixel-Aufnahme des Fünffach-Zooms so beschnitten, dass der per Zoomfunktion gewählte Ausschnitt übrig bleibt. Das klingt wie Schummeln, klappt aber bis zum Zehnfach-Zoom gut – wenn es hell genug ist. Bei Dunkelheit sollte man diesen Digitalzoom lieber nicht benutzen. Künstliche Intelligenz – überall ein bisschen Anders als bei der Hardware gibt es in der Software der S24-Serie viele Neuerungen in Form von KI-Funktionen. Künstliche Intelligenz, die das Unternehmen penetrant dem englischen Begriff Artificial Intelligence folgend als AI bezeichnet, ist fast allgegenwärtig. Die KI – oder eben AI – findet man in den Geräten der S24-Serie in der Kamera, dem Notizbuch, der Telefonfunktion und mehr. Wohl, um alles zum Thema zu sammeln, findet man in den Einstellungen unter »Erweiterte Funktionen« die KI-Optionen nun unter der Bezeichnung »Moderne KI-Funktionen«. Samsungs KI-Assistenten Bixby, der unterhalb dieses Menüeintrags aufgeführt wird, kann man demnach den alten KI-Funktionen zuordnen. Zu den alten KI-Funktionen zählt im Grunde auch vieles, was in der Foto-App vor sich geht. Da wäre zum Beispiel die Möglichkeit, im Bild nicht erwünschte Objekte mit dem Finger oder dem S Pen einzukreisen und zu löschen. Das Besondere dabei: Statt einen weißen Fleck im Bild zu hinterlassen, füllt generative KI die Fehlstelle mit einem zur Umgebung passenden Hintergrund. Google bietet eine solche Funktion seit Langem als »magischen Radierer« an. Solange man sich auf kleine Bildbereiche beschränkt, funktioniert das gut, schnippelt man großflächig herum, fallen der KI keine sinnvollen Füllmuster ein und sie halluziniert sich einen Hintergrund zusammen. Besser ist die generative KI eingesetzt, wenn man einen Schnappschuss nachträglich um ein paar Grad drehen möchte, weil das Bild schief ist. Bisher wurde das Foto in solchen Fällen auf ein verkleinertes Rechteck zusammengestutzt, um die Ecken abzuschneiden, die keinen Inhalt hatten. Auf den S24 produziert die KI jetzt zum Bildrand passende Füllstücke, damit die Aufnahme ihre ursprüngliche Größe behält. Spiegelungen ein Ende setzen Mehr amüsant als nützlich ist, dass Samsungs Software derart manipulierte Bilder mit einem kleinen Symbol markiert, das als Wasserzeichen links unten im Bild eingebaut wird. Mit der KI-Löschfunktion kann man dem nicht beikommen, weil die ein neues Wasserzeichen hinterlassen würde. Der leichtere Weg ist ohnehin, die Linke Ecke einfach von Bild abzuschneiden, um die Manipulation unkenntlich zu machen. Was sehr nützlich sein kann, aber nicht immer perfekt funktioniert, ist die Möglichkeit, Reflexionen zu löschen, wenn man durch spiegelnde Fenster fotografiert hat. Leider haben Samsungs User-Interface-Spezialistinnen und -Spezialisten diese Option gut versteckt. Zu finden ist sie in der »Galerie«-App, indem man auf das eingekreiste »i« tippt und einen Moment wartet, bis die Software das Bild analysiert hat und Bearbeitungsvorschläge einblendet. Auf dieselbe Weise kann man nachträglich eine Hintergrundunschärfe hinzufügen, die manchen Bildern einen Spiegelreflex-Look geben kann. Worum geht’s in diesem Text? Nicht nur Bilder, auch Texte kann man von der KI in Samsungs neuen Smartphones bearbeiten lassen. Was prima funktioniert: Als Textwurst eingetippte Notizen ansprechend formatieren und Texte wie etwa Sitzungsmitschnitte zusammenfassen lassen. Vor allem Letzteres hat sich bei mir schon nach wenigen Tagen als extrem nützliches Tool erwiesen, um etwa abzuschätzen, ob es sich lohnt, einen langen Text in Gänze zu lesen. Schade, dass das nur in der Notiz-App und Samsungs Webbrowser funktioniert und auch da nur mit Texten, die frei von Bezahlschranken sind. Dafür kann die KI auch PDF-Dateien zusammenfassen, nachdem man sie in die Notizen-App importiert hat. Mehr als rund drei Textseiten sind der künstlichen Intelligenz aber zu viel. Maßvoll Multilingual Nicht ganz so beeindruckend arbeiten die Dolmetsch- und Übersetzungsfunktionen. Die Möglichkeit, etwa Telefonate mit anderssprachigen Menschen von der KI dolmetschen zu lassen, erfordert Geduld. Statt in Echtzeit erfolgt die Übersetzung mit Wartezeit. Und auch dass nur korrekt, wenn man klar, deutlich und nicht zu schnell spricht. Der Erfolg solcher Telefonate hängt aber vor allem davon ab, ob die Angerufenen die KI und ihre Eigenheiten verstehen und akzeptieren. Schon die ein solches Gespräch einleitende Computerstimme, die auf die Übersetzung per Computer hinweist, könnte den einen oder die andere abschrecken. Abschreckend waren zumindest teilweise auch meine Versuche, anderssprachige Texte transkribieren und dann übersetzen zu lassen. Ein Mitschnitt aus dem koreanischen Fernsehen ließ mich vollkommen ratlos zurück, ein Ausschnitt aus einer amerikanischen Talkshow war zwar nicht elegant, aber immerhin verständlich übersetzt. Die KI-Zusammenfassung davon enthielt tatsächlich alles Wichtige. Das Problem einkreisen Die KI-Funktion, die ich während der Testphase am häufigsten genutzt habe, heißt allerdings Circle to Search. Und auch wenn Samsung bei seinen Präsentationen der S24-Serie den Eindruck zu vermitteln versuchte, das sei eine Samsung-Erfindung, stammt dieses Feature doch von Google und wird ab dem 31. Januar auch auf dem Pixel 8 und 8 Pro ( hier unser Testbericht ) verfügbar sein. Das Charmante an dieser Funktion ist ihre Einfachheit. Egal, was auf dem Bildschirm angezeigt wird: Drückt man kurz in der Mitte unten auf den Bildschirm, wird eine Art virtuelle Klarsichtfolie über das Display gelegt, auf der man per Finger oder S Pen das Objekt einkreist, über das man mehr wissen will. Die KI durchwühlt daraufhin das Web und zeigt oft, aber nicht immer, akkurat an, was man da sieht. Die Funktion erinnert an Google Lens, eröffnet dadurch, dass sie immer verfügbar ist, aber ganz andere Möglichkeiten. Was für eine Jacke trägt der Hauptdarsteller in dem Film? In welcher Stadt hat meine Freundin das Selfie gemacht, dass ich auf Instagram gesehen hab? Wie heißt das Haus, vor dem ich stehe? Wenn sie groß genug erkennbar sind, lassen sich auf diese Weise auch Wörter und Begriffe suchen. Einfacher kann man sich nicht durch die Welt googeln. Wie schnell es ist? Schnell genug Wie immer baut Samsung in sein Topmodell den aktuell schnellsten Qualcomm-Prozessor in einer Samsung-Version ein, die ein klein wenig übertaktet ist. So ist sichergestellt, dass das Gerät in Benchmarktests immer vorne liegt. Da solche Leistungsvergleiche nur ein theoretisches Bild liefern, belassen wir es mit der Feststellung: Das Galaxy S24 Ultra ist schnell genug. Fast immer. Wartezeiten gibt es vor allem bei KI-Funktionen, wie etwa der Transkription von Texten. Updates bis ins nächste Jahrzehnt Samsung liefert alle Modelle der S24-Serie mit Android 14 aus, dem die hauseigene Benutzeroberfläche One UI übergezogen wurde. Dass der Konzern als einer von wenigen Herstellern auf seinen neuen Geräten das aktuelle Google-Betriebssystem installiert, ist löblich. Honor etwa liefert sein teures Faltsmartphone Magic V2 ( hier unser Testbericht ) noch mit Android 13 aus. Noch wichtiger ist aber, dass Samsung verspricht, die Geräte sieben Jahre lang mit Android-Updates zu versorgen. Da macht es dann auch Sinn, dass es jetzt schon Wi-Fi 7 beherrscht, einen WLAN-Standard, für den es bisher kaum Hardware gibt. Ähnlich lange Update-Laufzeiten haben bisher nur Google für die Pixel 8 und 8 Pro sowie Fairphone in Aussicht gestellt. Ausreichend Ersatzteile und vor allem Austauschakkus vorausgesetzt, dürfte man demnach noch im Jahr 2031 ein Update installieren. Angesichts bisheriger Produktzyklen eine ebenso irritierende wie aus ökologischer Sicht berauschende Vorstellung. Fazit 👍 Sehr guter Bildschirm 👍 Nützliche KI-Funktionen 👍 Gute Akkulaufzeit 👍 Lange Update-Versorgung 👎 Hoher Preis Mit dem Galaxy S24 Ultra hat Samsung das derzeit wohl beste Android-Smartphone am Start. Die Hardware ist vom Feinsten, die neuen KI-Funktionen sind zum Teil wirklich nützlich. Vor allem geben sie einen Ausblick darauf, was in Zukunft möglich sein wird, wenn die Kinderkrankheiten etwa beim Dolmetschen kuriert sind. Mit dem Versprechen, dass das Gerät sieben Jahre lang Updates bekommen wird, kann man sich vielleicht sogar den hohen Preis schönreden. Der nämlich ist gegenüber dem S23 Ultra um 50 Euro auf 1449 Euro gestiegen. Wohlgemerkt für die Einstiegsversion mit 256 Gigabyte (GB) Speicher. Die Variante mit 512 GB kostet 1569 Euro, das 1-Terabyte-Modell 1809 Euro. Bis zum 31.1. bietet Samsung die beiden kleinen Modelle noch mit doppeltem Speicher an, die Terabyte-Variante zum 512-GB-Preis. Über welche Produkte wir in der Netzwelt berichten und welche wir testen oder nicht, entscheiden wir selbst. Für keinen der Testberichte bekommen wir Geld oder andere Gegenleistungen vom Hersteller. Es kann aus verschiedenen Gründen vorkommen, dass wir über Produkte nicht berichten, obwohl uns entsprechende Testprodukte vorliegen. Testgeräte und Rezensionsexemplare von Spielen bekommen wir in der Regel kostenlos für einen bestimmten Zeitraum vom Hersteller zur Verfügung gestellt, zum Teil auch vor der offiziellen Veröffentlichung. So können unsere Testberichte rechtzeitig oder zeitnah zur Veröffentlichung des Produkts erscheinen. Vorabversionen oder Geräte aus Vorserienproduktionen testen wir nur in Sonderfällen. In der Regel warten wir ab, bis wir Testgeräte oder Spielversionen bekommen können, die mit den Verkaufsversionen identisch sind. Wenn sie bereits im Handel oder online verfügbar sind, kaufen wir Produkte in einigen Fällen auf eigene Kosten ein. In der Regel werden Testgeräte nach dem Ende des Tests an die Hersteller zurückgeschickt. Die Ausnahme sind Rezensionsexemplare von Spielen und langfristige Leihgaben: So haben wir zum Beispiel Spielekonsolen und Smartphones in der Redaktion, die wir über längere Zeit nutzen dürfen. So können wir beispielsweise über Softwareupdates, neues Zubehör und neue Spiele berichten oder Langzeiturteile fällen. Oft werden Rezensionsexemplare am Ende eines Jahres zum Beispiel gesammelt und im Rahmen eines firmeninternen Flohmarktes verkauft, wobei die Erlöse für gemeinnützige Zwecke gespendet werden. Teilweise werden sie auch direkt an gemeinnützige Einrichtungen gespendet. Die Kosten für Reisen zu Veranstaltungen, egal ob sie in Deutschland oder im Ausland stattfinden, trägt DER SPIEGEL stets selbst. Das gilt auch dann, wenn beispielsweise aufgrund kurzfristiger Termine ein Unternehmen die Reiseplanung übernimmt. Veranstaltungen, zu denen wir auf eigene Kosten reisen, sind unter anderem die Messen Ifa, CES, E3 und Gamescom, Entwicklerveranstaltungen wie die Google i/O, WWDC und Build sowie Events von Firmen wie Apple, Google, Microsoft oder Nintendo. Auf Konferenzen wie dem Chaos Communication Congress oder der re:publica bekommen wir in der Regel, wie auch andere Pressevertreter, kostenlose Pressetickets, da wir über die Konferenz berichten und keine klassischen Teilnehmer sind. Seit Dezember 2016 finden sich in einigen Netzwelt-Artikeln sogenannte Affiliate-Anzeigen, die sogenannte Links zu Onlineshops enthalten. Besucht ein Nutzer über einen solchen Link einen dieser Shops und kauft dort online ein, wird DER SPIEGEL, aber nie die Autorin oder der Autor individuell, in Form einer Provision an den Umsätzen beteiligt. Diese Provision wird vom Händler gezahlt, nicht vom Hersteller des Produkts. Die Anzeigen tauchen in Artikeln unabhängig davon auf, ob ein Produkttest positiv oder negativ ausfällt. Eine ausführliche Erklärung zu Affiliate-Links finden Sie, wenn Sie auf diesen Link klicken . Der Porträtmodus funktioniert bei Hunden recht gut und … … bei Friseurpuppen sowieso. Nahaufnahme eines im Wind wackelnden Astes: Da muss der Autofokus wohl schnell sein. Aufnahme eines schon viel zu lange herumstehenden Weihnachtsgestecks im dunklen Wohnzimmer, so wie die Kamera-App die Szene sieht … … und was die Fotosoftware daraus macht. Natürlich kann man auch mit dem S24 Ultra Nahaufnahmen vom Mond machen, wenn man den Zoomfaktor 100 auswählt. Wie echt sie sind, ist Thema vieler Diskussionen . Ein Gartenzwerg. Nicht irgendeiner, sondern Fritz. Aufgenommen mit der Ultraweitwinkelkamera des Galaxy S24 Ultra. Hier wurde Fritz mit dem 200-Megapixel-Weitwinkelobjektiv aufgenommen, aber mit 12-Megapixel-Auflösung. Die maximale optische Näherung, das Fünffach-Zoom Eigentlich eine Ausschnittvergrößerung, aber sehr gelungen: der Zwerg im Faktor 10. Nicht gerade sensationell: der Zoomfaktor 10 vor Sonnenaufgang Übersetzung von Koreanisch ins Deutsche, in diesem Beispiel nur Kauderwelsch Besser klappte es im Test von Englisch ins Deutsche, aber perfekt war auch das nicht Die Zusammenfassung enthielt trotzdem alle wichtigen Punkte Volltreffer: Hier hat Circle to Search den Schnappschuss genau richtig erkannt. Bei diesem Foto eines freundlichen Trainingsballs fand die KI immerhin ähnlich aussehende Bälle – deren Aufnahmen aber stets nur als Symbolfotos genutzt wurden. Aber hier ließ sie sich von einem Baugerüst foppen, identifizierte das Hamburger Haus der Photographie als Philharmonie Stettin. Noch eine Niete: Statt einer Schweizer Leckerei vermutete die KI unter der Alufolie Druckertoner oder doch einfach irgendwas mit Alufolie."
Künstliche Intelligenz,Spiegel Online,2024-01-30,https://www.spiegel.de/netzwelt/netzpolitik/ai-act-bundesregierung-will-europaeischem-ki-gesetz-doch-zustimmen-a-86cfff74-6d38-45f3-a772-ef65dff6e95f,AI Act: Bundesregierung will europäischem KI-Gesetz doch zustimmen - DER SPIEGEL,"Bedenken der FDP sollen Deutschlands Zustimmung zum AI Act in letzter Minute ins Wanken gebracht haben. Nun aber hat sich die Bundesregierung auf eine gemeinsame Haltung verständigt. Die finale Einigung der EU-Mitgliedstaaten auf den AI Act soll am kommenden Freitag erfolgen – und Deutschland will dem ersten umfassenden Gesetzespaket zu künstlicher Intelligenz in der westlichen Welt nicht im Weg stehen. In einer Pressemitteilung des Bundesministeriums für Wirtschaft und Klimaschutz heißt es am Dienstag, die Bundesregierung habe sich darauf verständigt, der KI-Verordnung zuzustimmen. »Mit der deutschen Zustimmung zur KI-Verordnung setzen wir uns für Rechtssicherheit und vertrauenswürdige KI made in Europe ein«, lautete ein Kommentar von Wirtschaftsminister Robert Habeck. Und Marco Buschmann, der Bundesminister der Justiz, sagte: »Mit der europäischen KI-Verordnung machen wir den Weg frei für einen sicheren Rechtsrahmen für künstliche Intelligenz, der Innovationen fördert und gleichzeitig Risiken in der Anwendung angemessen adressiert.« Noch vor wenigen Tagen hatte es geheißen , vor allem im Digitalministerium von Volker Wissing ( FDP ) gebe es noch Widerstand gegen das Gesetz. Zwar hatte es bereits im Dezember im Ministerrat eine grundsätzliche mündliche Einigung gegeben, doch erst sechs Wochen später lag die finale schriftliche Fassung des Gesetzes vor. Bis zum vorvergangenen Wochenende seien deshalb zahlreiche zentrale Details unklar gewesen, so hörte man, etwa über die Regulierung von Gesichtserkennung und von KI-Basismodellen. Am Dienstagmorgen hat nach SPIEGEL-Informationen eine Runde der Staatssekretärinnen und Staatssekretäre einen Kompromiss gefunden. Aus Regierungskreisen hieß es, man werde dem AI Act zustimmen, die EU-Kommission aber auffordern, kurzfristig zentrale Praxisfragen zu klären, um Doppelbelastungen für die Wirtschaft zu vermeiden. Dazu gehörten unter anderem das Verhältnis zu anderen Produktregulierungsrechtsakten (Medizinprodukte) und Rechtsfragen bei der Weiterentwicklung von KI-Modellen (Finetuning). Auch das »Handelsblatt« berichtete von der Einigung. Wie der SPIEGEL weiter erfuhr, tendiert wohl auch die französische Regierung mittlerweile zu einem Ja zum AI Act. Zusammen mit Italien galt auch Frankreich bisher als möglicher Wackelkandidat. Anmerkung der Redaktion: In einer früheren Fassung dieses Artikels hieß es, die Runde der Staatssekretärinnen und Staatssekretäre habe am Montagabend einen Kompromiss gefunden. Nach SPIEGEL-Informationen war es der Dienstagmorgen, wir haben den Satz korrigiert."
AI,Spiegel Online,2024-02-02,https://www.spiegel.de/netzwelt/netzpolitik/ai-act-gruenen-politikerin-franziska-brantner-ueber-ki-gesetz-es-geht-um-unsere-grundrechte-a-411c0425-a113-4026-95d8-eac784502bbf,AI Act: Grünen-Politikerin Franziska Brantner über KI-Gesetz - »es geht um unsere Grundrechte« - DER SPIEGEL,"Die Grünenpolitikerin Franziska Brantner hat das KI-Gesetz der EU mitverhandelt. Im Gespräch erklärt sie, warum sie den jetzigen Kompromiss für gelungen hält und was sich für ChatGPT-Nutzer ändern wird. SPIEGEL: Frau Brantner, Sie haben das erste Gesetz einer westlichen Wirtschaftsmacht zu künstlicher Intelligenz mitverhandelt, den AI Act der Europäischen Union. Im Jahr 2026 könnten die Regelungen wirksam werden. Kommt das nicht viel zu spät? Franziska Brantner: Nein, wir sind gut in der Zeit. Wir haben in der EU rechtzeitig angefangen und schon vor vielen Monaten begonnen, an einem KI-Gesetz zu arbeiten. Ende 2022 kam dann ChatGPT auf den Markt und hat gezeigt, dass KI bereits zu einem gewissen Grad menschliche Aufgaben übernehmen kann. Ein so wirkmächtiges System hatte es vorher nicht gegeben. Aber auch diese neue Technologie hat der AI Act nun im Blick. SPIEGEL: Der finale Entwurf für das Gesetz ist seit Kurzem bekannt und die Kritik ist groß. Den einen geht er zu weit, den anderen ist er zu lasch. Nun stehen die finalen Abstimmungen in Rat und Parlament an. Droht das Gesetz zu scheitern? Die Grünenpolitikerin Franziska Brantner , Jahrgang 1979, ist Staatssekretärin im Bundesministerium für Wirtschaft und Klimaschutz. Von 2009 bis 2013 war sie Abgeordnete im Europaparlament, seit 2013 ist sie Bundestagsabgeordnete, zwischen 2017 und 2021 war sie europapolitische Sprecherin der Grünen-Bundestagsfraktion. Sie lebt in Heidelberg und Berlin. Brantner: Ich hoffe nicht. Klar ist: Dieses Gesetz muss unterschiedlichste Interessen austarieren. Einerseits wollen wir die Innovationspotenziale nutzen, die KI bietet: für unsere Gesundheit, in der Forschung, zur Automatisierung von Aufgaben. Andererseits müssen wir die Risiken in den Griff bekommen. Nehmen Sie zum Beispiel die automatische Emotionserkennung am Arbeitsplatz: Niemand will, dass eine KI ständig auswertet, ob Herr Schmidt gerade grimmig guckt – womöglich während er die E-Mail des Chefs liest. Solche Anwendungsfälle haben wir verboten. SPIEGEL: Aus Ihrer Sicht ist die Kritik von verschiedenen Seiten ein Beleg für dessen Ausgewogenheit? Brantner: Es ist nie einfach, sehr unterschiedliche Interessen in eine gute Balance zu bringen, insbesondere nicht bei der komplexen Regulierung einer hochdynamischen Technologie, die quasi alle Bereiche des Lebens betrifft. Ich gebe Ihnen noch ein Beispiel: Urheberrecht. Künstliche Intelligenz wird trainiert mit Unmengen an Bildern, Informationen und Texten, damit sie selbst nach den Vorgaben des Nutzers Bilder und Texte erstellen kann. Es ist faszinierend, wie gut KI das schon kann. Aber es stellt sich eben die Frage: Wenn eine KI mit Bildern eines bestimmten Künstlers trainiert wurde und dann Bilder in dessen Stil erzeugt, wer hat dann die Rechte daran? Auch hier mussten wir eine Balance finden. Hersteller müssen künftig transparent machen, mit welchen Daten sie die KI trainiert haben. Urheber wiederum haben Möglichkeiten, zu verhindern, dass ihre Werke von der KI ausgelesen werden. SPIEGEL: Besonders heftig diskutiert wird die automatische Gesichtserkennung . Daran haben gerade Strafverfolgungsbehörden ein großes Interesse. Bürgerrechtlern gehen die Befugnisse dagegen viel zu weit. Brantner: Grundsätzlich verbietet die KI-Verordnung Videoüberwachung in Echtzeit mittels KI-gestützter Gesichtserkennung. Es gelten Ausnahmen beispielsweise für die Suche nach Vermissten oder die Verhinderung einer unmittelbaren terroristischen Bedrohung. Und für die nachträgliche Auswertung von Videomaterial mit KI gibt es strenge Regeln. In beiden Fällen muss ein Richter oder eine entsprechende Behörde zustimmen, der Vorgang muss bei der Polizei registriert werden und Datenschützer müssen Zugang zu den Systemen haben. Wenn die Mitgliedsländer wollen, können sie die Vorgaben sogar noch weiter verschärfen. SPIEGEL: Klingt, als wären Sie mit der Regelung ganz zufrieden. Brantner: Ja. Wir schaffen damit erstmals einen europäischen Mindeststandard für die Regeln bei KI-basierter, automatischer Gesichtserkennung. Darüber bin ich froh. Denn diese Vorgaben gelten dann auch überall in der Union. SPIEGEL: Innerhalb der Bundesregierung gab es bis zuletzt noch heftige Diskussionen über das Gesetz . Insbesondere aus der FDP soll es Widerstand gegeben haben. Was war da los? Brantner: Die Beispiele, die ich genannt habe, zeigen ja: Die KI-Verordnung berührt Grundlagen unserer demokratischen und wirtschaftlichen Ordnung – es geht um die Grundrechte jeder und jedes Einzelnen, um geistiges Eigentum, die Freiheit der Forschung und unsere Innovationsfähigkeit. All das musste in Balance gebracht werden, und das geht nicht ohne Diskussionen. SPIEGEL: Und wie sieht der Kompromiss der Koalition nun aus? Brantner: Wir haben den Text intensiv geprüft und uns darauf verständigt, dass die Bundesregierung der KI-Verordnung in Brüssel zustimmen wird. Damit haben wir frühzeitig ein klares Signal für Handlungsfähigkeit und Rechtssicherheit gesendet. SPIEGEL: Vergangenes Jahr warnten zahlreiche Techgrößen vor potenziellen Gefahren für die Menschheit . Ein bisschen klang das nach der Sorge, die KI könnte die Weltherrschaft übernehmen. Haben Sie so etwas im Kreise der Mitgliedstaaten diskutiert? Brantner: Nein, zumindest nicht in den Gesprächen, an denen ich beteiligt war. Ein Risiko, das ich aber für durchaus real halte, ist, dass Anbieter gehackt werden, die wirkmächtige KI-Systeme betreiben. Das kann potenziell enormen Schaden anrichten. Deshalb ist es wichtig, dass wir hier Vorgaben machen, damit Anbieter von Hochrisiko-KI sich entsprechend schützen. Wenn Sie ein Chemielabor haben, das mit hochgiftigen Stoffen arbeitet, müssen Sie ja auch sicherstellen, dass da nicht jeder reinlaufen kann. Auch unsere kritische Infrastruktur, beispielsweise unsere Energiesysteme, schützen wir entsprechend. Das muss für KI-Anbieter genauso gelten. Andere Risiken haben wir versucht auszuschließen, indem wir bestimmte Anwendungsfälle ganz verboten haben. SPIEGEL: Welche? Brantner: Social Scoring zum Beispiel. In China wird das Verhalten der Menschen dazu genutzt, um ihre angebliche Vertrauenswürdigkeit zu errechnen. Das haben wir komplett verboten. Und dann gibt es Anwendungsbereiche, bei denen wir sagen, sie sind so heikel, dass sie reguliert werden müssen. Etwa, wenn KI bei der Personalauswahl eingesetzt wird. Dann muss dafür gesorgt werden, dass sie nicht diskriminierend ist. Damit eine Frau mit dem Vornamen Özlem die gleichen Chancen hat wie eine mit dem Vornamen Franziska. SPIEGEL: Sie haben vorhin schon das Beispiel Emotionserkennung angesprochen, also dass eine KI die Mimik einer Person auswertet und Schlüsse daraus zieht. Das soll am Arbeitsplatz verboten sein. Aber nicht überall. Gibt es denn hier überhaupt Anwendungsfälle, die unbedenklich sind? Brantner: In bestimmten Fällen kann es sinnvoll sein. Beispielsweise bei medizinischen Systemen im therapeutischen Bereich. SPIEGEL: Ab wann gilt eine KI als Hochrisiko-KI und bekommt besonders strenge Vorgaben? Brantner: Für die Einstufung als Hochrisiko-KI sieht die KI-Verordnung verschiedene Kriterien vor, das ist im Text und dem entsprechenden Anhang geregelt. Zum Beispiel betrifft das KI-Systeme aus dem medizinischen Bereich, der kritischen Infrastruktur und dem Bildungsbereich. Ausnahmen gibt es für Systeme, von denen kein bedeutendes Risiko für die Gesundheit, Sicherheit und die Grundrechte ausgeht. Das ist ein wichtiger Punkt für die Unternehmen und Innovatoren. Im Übrigen gibt es bei KI-Modellen nun die Kategorie der KI-Modelle mit systemischen Risiken, die strengeren Vorgaben unterliegen. Bei diesen Modellen bestimmt die Zahl der Rechenoperationen, die notwendig ist, um ein KI-Modell zu trainieren, darüber, wie potent und wirkmächtig es ist – und damit auch, wie potenziell riskant. Technisch gesehen gilt ein universell einsetzbares KI-Modell nun als riskant, wenn der kumulative Rechenaufwand für das Training mehr als 10 25 Flops – also Gleitkommaoperationen – beträgt. SPIEGEL: So ein Maßstab kann aber schnell veralten. Brantner: Deshalb ist das auch nicht der einzige Faktor. Die Kommission hatte diesen Vorschlag im Herbst gemacht, und dann haben wir zusammen mit Frankreich und Italien gesagt, dass wir diese Grenze nicht plausibel finden. Jetzt wird unter anderem auch die Zahl der Anwenderinnen und Anwender eine Rolle spielen. Und wir haben die Möglichkeit eröffnet, dass andere Kriterien hinzukommen, auch auf Empfehlung der Forschungscommunity. Außerdem steht jetzt im Verordnungstext, dass der »state of the art« berücksichtigt werden muss – also dass immer der aktuelle Stand der Technik als Maßstab gilt. Der technologische Fortschritt wird eingepreist. SPIEGEL: Können Sie Beispiele nennen für KI-Anwendungen, die als Hochrisiko-KI gelten würden? Brantner: Das sind zum Beispiel die Prüfung der Kreditwürdigkeit, oder Auswahlen bei Einstellungsverfahren. SPIEGEL: Kritiker befürchten, dass die Vorgaben der EU Innovationen abwürgen könnten. Die Sorge haben Sie nicht? Brantner: Forschung und Entwicklung sind vom Anwendungsbereich der Verordnung ganz klar ausgenommen. Das war uns wichtig, weil wir in Deutschland in diesem Bereich sehr gut sind und hier die Keimzelle von Innovationen liegt. Es geht auch hier um eine gute Balance zwischen legitimen Sicherheitsansprüchen, der Vermeidung von Bürokratie und Offenheit für die Technologie. Entscheidend ist dann, dass auch die Umsetzung der Verordnung bürokratiearm und innovationsfreundlich ist. Da werden wir als Bundesregierung ein besonderes Auge drauf haben. SPIEGEL: Was wird sich 2026 für eine Person ändern, die so etwas wie ChatGPT nutzt? Schon jetzt verwenden Menschen das Programm, um Bewerbungen zu schreiben oder Präsentationen für die Arbeit zu erstellen. Brantner: Wenn diese Person zum Beispiel ein Bild mit einer generativen KI erzeugt, dann müsste da ein Hinweis stehen, eine Art digitales Wasserzeichen. Diese Transparenz ist etwas, das die Menschen mitbekommen werden. Es dürfte für viele sogar der Hauptunterschied zur heutigen Situation sein. SPIEGEL: Glauben Sie, dass Anbieter wie OpenAI und Microsoft solche Produkte dann vorsichtshalber nicht mehr in der EU anbieten werden? Brantner: Das würde mich sehr wundern angesichts der großen Bedeutung des europäischen Markts. Wir sehen eher, dass sich die Amerikaner mit großem Interesse unser Gesetz anschauen und überlegen, was sie davon selbst verwenden können. SPIEGEL: Gewisse moralische Fragen werden im AI Act nicht verhandelt: Was soll KI künftig für uns erledigen? Soll sie journalistische Artikel für uns schreiben? Wollen wir, dass Schauspielerinnen oder Lehrer durch KI ersetzt werden? Brantner: Das sind hochrelevante Fragen für uns als Gesellschaft. Wir haben in Deutschland einen Arbeitskräftemangel. Das heißt, wir haben ein Interesse daran, dass ein Teil der Jobs durch KI ersetzt wird oder durch Roboter. Aber wir dürfen es nicht komplett dem Zufall überlassen, wo die besten KIs entstehen und eingesetzt werden. In der Bildung beispielsweise wollen wir sicher auch in Zukunft noch Menschen haben, die unseren Kindern etwas beibringen. Im Altersheim wiederum gibt es Aufgaben, die man durch KI ersetzen könnte und dadurch bekäme das Personal mehr Zeit für den direkten Kontakt mit den Bewohnern, um vielleicht mal wieder gemeinsam ein Brettspiel zu spielen. Es kommt jetzt darauf an, welche Anwendungen unsere Unternehmen entwickeln und voranbringen. SPIEGEL: Wo verständigt sich eine Gesellschaft über diese Fragen? Das kann ja nicht nur der Markt regeln. Brantner: Wir haben, wie gesagt, Bereiche ausgeschlossen, in denen KI nicht eingesetzt werden darf, weil wir es für zu gefährlich halten. Und Hochrisiko-Anwendungen müssen mit unseren Grundrechten vereinbar und diskriminierungsfrei sein. Im Rahmen dessen, was erlaubt ist, wird man dann, wie bei anderen Technologien und ihren Anwendungen sehen, wo Ressourcen und Geld hingehen. Auch bei KI hat Politik nicht die Aufgabe, überall zu entscheiden, was für Verbraucherinnen und Verbraucher, was für Unternehmen gut ist. Es werden sich die Produkte am Markt durchsetzen, die einen echten Mehrwert bieten. Und als Gesellschaft werden wir – wie bei anderen neuen Technologien auch – darüber diskutieren, wie wir die Chancen bestmöglich nutzen, ohne Risiken zu ignorieren. SPIEGEL: Welcher Punkt der finalen Fassung des AI Acts stört Sie am meisten? Brantner: Wir müssen bei der Umsetzung sehr gut darauf achten, dass die KI-Verordnung gut mit anderen Produktverordnungen wie zum Beispiel im Medizinbereich harmoniert und nicht zu unerwünschten Konsequenzen führt. SPIEGEL: Was steht auf dem Spiel, wenn das Gesetz scheitern sollte? Brantner: Dann gibt es keinerlei spezifische KI-Regulierung, keinerlei Standards und keine Planungssicherheit und es ist erstmal alles erlaubt, worüber wir gerade sprachen. Nationale Regierungen würden sicher anfangen zu regulieren und am Ende hätten wir einen Flickenteppich, der unseren Unternehmen das Leben schwer macht. Auf europäischer Ebene stehen im Sommer Wahlen an. Wer weiß, wie die Mehrheiten im Europäischen Parlament danach aussehen, ob diese dann wirklich die Grundrechte stärken wollen oder eher nicht. Nun muss sich jeder fragen, ob er lieber gar keine Regulierung hat oder eine, die unterschiedlichste Interessen in essenziellen Punkten in eine gute Balance gebracht hat."
AI,Spiegel Online,2024-02-02,https://www.spiegel.de/kultur/musik/universal-music-auf-tiktok-was-der-streit-fuer-den-erfolg-von-popstars-bedeutet-a-696308a0-489e-49ff-a67d-739d4272ef28,Universal Music auf TikTok: Was der Streit für den Erfolg von Popstars bedeutet - DER SPIEGEL,"Im Streit um Vergütung und KI hat TikTok damit begonnen, Musik, die bei der Plattenfirma Universal erscheint, aus ihren Videoclips zu löschen. Fans und Künstler äußern ihren Frust. Warum ist die Plattform so wichtig? Wer am Freitag sein neues TikTok -Video mit einem gerade angesagten Pophit unterlegen wollte, musste in vielen Fällen nach Alternativen suchen. »Cruel Summer« von Taylor Swift ? Stumm geschaltet. Der aktuelle Smash-Hit von Rapperin Nicki Minaj, »Big Foot«? Nicht mehr verfügbar auf der Plattform. Gleiches gilt für Songs von Drake, SZA, Olivia Rodrigo, Billie Eilish , Ariana Grande und eine schier endlose Liste weiterer populärer Titel von großen Stars. Sie alle haben Plattenverträge oder Veröffentlichungs-Deals mit Universal, dem weltweit größten Musikkonzern mit Sitz in den USA. Und der liegt im Streit mit der aus China gesteuerten Social-Media-Plattform TikTok. Die bisherige Übereinkunft der beiden Entertainment-Giganten lief am Mittwoch dieser Woche aus, wie und ob es weitergeht, ist noch offen. Klar ist aber, dass die Musik von Universal-Künstlern und -Künstlerinnen erst einmal nicht mehr bei TikTok zu finden sein wird. Laut Angaben von 2022 besitzt Universal die Rechte an mindestens drei Millionen Songs. Zählen auch die Verlagsrechte von Songautoren, die bei Universal unter Vertrag stehen und an zahlreichen Hits beteiligt sind, wären es noch einmal Millionen mehr betroffene Titel. Wer ist gieriger? Es geht in dem Zwist um die Vergütung von lizenzierter Musik und den Umgang mit KI-generierten Songs . TikTok habe den Musikern und Songautoren nur »einen Bruchteil« der auf ähnlichen Onlineplattformen üblichen Vergütung geboten, argumentierte Universal Music in einem offenen Brief. Auch lasse TikTok in großem Stil mithilfe künstlicher Intelligenz erstellte Musik auf die Plattform – und wolle vertraglichen Freiraum dafür. Damit treibe der Dienst faktisch »das Ersetzen von Künstlern durch KI« voran. TikTok konterte tags darauf, Universal Music habe »die eigene Gier über die Interessen ihrer Künstler und Songautoren gestellt«. Der Musikkonzern bleibe damit einer Plattform mit »deutlich mehr als einer Milliarde Nutzern« fern, auf der Musik beworben und entdeckt werde. Universal Music handle damit nicht im Interesse der Musiker und Fans. Die äußerten in den vergangenen Tagen bereits ihren Frust. »What do you mean they're taking Taylor Swift’s music off of TikTok??«, fragte eine fassungslose TikTok-Userin in einem Video, in dem sie kopfschüttelnd zu sehen ist. Andere sind moderater: »Warum lässt UMG die Künstler nicht selbst entscheiden, ob sie ihre Musik auf TikTok veröffentlichen wollen oder nicht?«, fragte sich ein Fan auf X (ehemals Twitter). »Das Unternehmen hat berechtigte Bedenken, aber trotzdem ist die Musik auf dieser Plattform für einige Leute die Art und Weise, wie sie Songs finden, die sie hören.« Tatsächlich ist TikTok, früher Musical.ly, inzwischen eine der wichtigsten Plattformen für Künstlerinnen und Künstler, um auf ihre Musik aufmerksam zu machen. Vor allem für Newcomer kann es einen entscheidenden Karriere-Push bedeuten, wenn einer ihrer Songs von TikTok-Usern für eigene Clips benutzt wird. Zusätzlich können die Künstler in ihren Videos Tänze oder Performance-Challenges installieren, die dann durch vielfaches Nachmachen mit dem betreffenden Song viral gehen. TikTok selbst veröffentlichte erst im November einen Bericht, in dem es seine Rolle als »Startrampe für virale Hits und neue Künstler« anpreist. Dieser »Music Impact Report« stellte heraus, dass TikTok den Nutzern helfe, Musik zu entdecken und mit Künstlern in Kontakt zu treten. Außerdem wird berichtet, dass die Nutzer von TikTok mit größerer Wahrscheinlichkeit zusätzlich einen kostenpflichtigen Musik-Streaming-Dienst nutzen, was dann zudem einen Mehrwert für die Künstler darstelle. Hoffnung auf zahlreiche Streamingabrufe Das heißt: Wer es schafft, mit seiner Musik auf TikTok wahrgenommen zu werden, kann sich auch Hoffnung auf zahlreiche Streamingabrufe bei Spotify oder Apple Music machen, wenn nicht gar auf den Verkauf von physischen Tonträgern. Auch auf den Verkauf von Merchandising-Artikeln und Tourneetickets wirkt sich der direkte Kontakt der Künstler mit Fans via TikTok-Videos positiv aus. TikTok ist in Zeiten, in denen klassische Medien bei jüngeren Konsumenten kaum noch eine Rolle bei der Vorstellung neuer Musik spielen, ein eminent wichtiges Tool, die Zielgruppe anzusprechen – vielleicht sogar das wichtigste überhaupt, besonders für Newcomer. Daher sind vor allem junge Künstler die unmittelbar Leidtragenden des TikTok-Universal-Streits. So wie die Berliner R&B-Sängerin Futurebae, die im November vergangenen Jahres ihr Debüt-Album »BLA« bei Universal Music veröffentlicht hat. Der Start in eine Popstar-Karriere? Zunächst wohl ohne die Verstärkung von TikTok. Am Donnerstag postete sie beim Messenger-Dienst Threads eine bedrückte Botschaft an ihre Fans: »heute wurden alle meine songs von tiktok entfernt und its kinda heartbreaking. hab zwei jahre lang so viel zeit und energie in meine videos gesteckt und jetzt ist alles einfach weg.« Große und etablierte Künstlerinnen und Künstler haben sich bisher noch nicht öffentlich zum Streit positioniert. Zwar haben sie im Zweifel längst eine solide Fanbasis, die sich auch auf anderen Plattformen mit ihrer Musik versorgt, aber TikTok kann auch für bekannte Stars ein unverhofftes Comeback bedeuten. Etwa für Sängerin Kate Bush oder die Rockband Fleetwood Mac, deren alte Hits durch TikTok-Videos von Usern, die sie in Soundtracks von TV-Serien oder anderswo entdeckt haben, plötzlich wieder in die Charts gelangten – und neue Umsätze generierten. Die britische Sängerin Sophie Ellis-Bextor erlebte so etwas gerade mit ihrem 2001 zuerst veröffentlichten Hit »Murder On The Dancefloor«, der im Kinofilm »Saltburn« eine prominente Rolle spielt. Der Film wurde zum Pop-Phänomen und zum Thema Tausender Clips auf TikTok, die den Song als Untermalung für Memes oder User-Content benutzten. Auch Ellis-Bextor ist bei Universal unter Vertrag. Und wie geht es nun weiter? Universal fordert von TikTok eine Entschädigung, die dem entspricht, was andere Social-Media-Plattformen zahlen. Laut US-Analysten geht es dabei um den Unterschied zwischen jährlich rund 100 Millionen Dollar, die TikTok bisher an Lizenzgebühren an Universal zahlt, und dem zwei- oder dreifachen dieser Summe, die andere Social-Media-Unternehmen wie Meta entrichten. Vielleicht bringt der Druck von enttäuschten Fans und Künstlern beide Konzerne in den kommenden Wochen dazu, sich doch noch auf einen Deal zu einigen. Mit Material von AP und Reuters"
AI,Spiegel Online,2024-02-01,https://www.spiegel.de/start/kuenstliche-intelligenz-informatik-oder-data-science-studieren-ki-studiengaenge-und-ausbildungen-a-26a8685d-e6f1-4625-bd23-cc307ecf33aa,Künstliche Intelligenz: Informatik oder Data Science studieren? - KI-Studiengänge und Ausbildungen - DER SPIEGEL,"Alle reden über künstliche Intelligenz, Fachleute sind auf dem Arbeitsmarkt gefragt. Welche Fächer man belegen muss, um neue Technologien mitzuentwickeln – und welche Fähigkeiten es dazu braucht. Spätestens mit ChatGPT ist künstliche Intelligenz in unserem Alltag angekommen. Egal, ob in der Medizin- oder Agrarindustrie: Die Entwicklung neuer Technologien mithilfe von KI bietet der deutschen Wirtschaft vielfältige neue Chancen. Kein Wunder also, dass Unternehmen händeringend nach KI-Spezialist:innen suchen. Mit der steigenden Nachfrage wächst auch das Angebot an Ausbildungswegen, die in das Berufsfeld führen. »Das Schöne ist, dass jeder in der KI-Entwicklung seinen Platz findet«, sagt Kinga Schumacher, Senior Researcherin am Deutschen Forschungszentrum für Künstliche Intelligenz (DFKI) in Berlin – ob beim fokussierten Programmieren oder in interdisziplinärer, kreativer Projektarbeit. Sie habe zu Beginn ihrer Karriere klassisch Informatik studiert, erzählt Schumacher. KI sei damals in den Nullerjahren noch kaum Thema gewesen. Heute sieht das anders aus. Informatik oder Data Science? – Der Weg in die KI-Entwicklung »Vor fünfzehn Jahren hätte ich Ihnen noch gesagt: Studieren Sie Informatik!«, sagt Schumacher. Inzwischen sei die Antwort nicht mehr so einfach, die Wege in die KI-Entwicklung sind vielfältig. Es gebe immer mehr Studiengänge, die sich auf spezielle Bereiche der künstlichen Intelligenz fokussieren, so die Forscherin. Meist sind das Formen der angewandten Informatik oder sie sind in der Mathematik angesiedelt. Welches Fach sich am besten eignet, sei eine Frage der persönlichen Neigungen. »Wenn ich gern rumbastele, dann studiere ich vielleicht Robotik, wenn ich zwei linke Hände habe, eher etwas Datenzentriertes«, sagt Schumacher. Bei Data Science etwa liegt der Fokus auf der Auswertung großer Datenmengen. In einem Studiengang Künstliche Intelligenz liege der Fokus dagegen mehr auf möglichen Anwendungsbereichen von KI, etwa Mobilität, Gesundheitswesen oder Chatbots. Die Grundlagen seien jedoch meist die gleichen, sagt Schumacher. Das betont auch Thomas Röser von der Berufsberatung der Agentur für Arbeit Aachen-Düren. Man solle sich von den vielen unterschiedlichen Fachrichtungen nicht abschrecken lassen. »Das ist wie in der BWL: Da heißt der Studiengang vielleicht Marketing – im Grunde genommen machen Sie aber auch BWL.« Wer sich früh spezialisieren möchte, könne seinen Bachelor in einem Anwendungsfach machen. Wer sich unsicher sei, dem rate er allerdings zum klassischen Grundstudium Informatik oder Mathematik. »Spezialisieren ja, aber warum schon im Bachelor?« Im Master könne man dann immer noch seinen Fokus setzen. Auch ein Wechsel sei innerhalb der unterschiedlichen Fächer meist unkompliziert. Was? Die klassische Informatik vermittelt Grundlagen der systemischen Verarbeitung von Informationen. Neben den grundlegenden Fächern der angewandten, praktischen und technischen Informatik kommen immer mehr Spezialisierungsfelder hinzu. Dazu gehört auch künstliche Intelligenz. Wo? An den meisten Hochschulen wird Informatik als Bachelor und Master angeboten, besonders an Technischen Hochschulen. Renommiert sind etwa die RWTH Aachen , die TU München oder die FU Berlin . In Deutschland gibt es über 600 Studienangebote. Was? Angewandte Informatik hat im Vergleich zum klassischen Fach meist eine stärkere Spezialisierung auf einen Anwendungsbereich. Eigentlich ist es ein Überbegriff für verschiedene spezialisierte Informatikstudiengänge, wie Medieninformatik oder Cybersecurity. Die Spezialisierung kann sich von Hochschule zu Hochschule stark unterscheiden. Voraussetzung sollte also ein Interesse am jeweiligen Schwerpunktthema sein. Wo? Mehr als 100 Hochschulen bieten Studiengänge in der angewandten Informatik an. Siehe unten. Was? Die Studiengänge Künstliche Intelligenz oder Artificial Intelligence sind von Anfang an auf KI fokussiert. Wo? Technische Hochschule Ingolstadt , Ostbayerische Technische Hochschule Amberg-Weiden , BTU Cottbus-Senftenberg , Uni Würzburg , TH Rosenheim , Hochschule Landshut , Hochschule Ansbach ; Master: Universität Ulm , THWS Würzburg , Uni Erlangen-Nürnberg , Uni Lübeck (Auswahl) Was? Data Scientists gewinnen mit Methoden der Mathematik, Informatik und Statistik Erkenntnisse aus großen Mengen von Daten. Ebenfalls ein Spezialisierungsbereich der Informatik. Wo? Uni Erlangen-Nürnberg , Uni Gießen , TU Dortmund , BHT Berlin , Uni Göttingen , TU Hamburg , Uni Hildesheim , Uni Marburg , LMU München , Uni Trier ; Master: Hochschule Darmstadt , Hochschule Harz , RWTH Aachen , FU Berlin , Uni Bielefeld , TU Braunschweig , TU Chemnitz , Hochschule Coburg , Hochschule Fulda , Hochschule Bielefeld , Fernuni Hagen , FH Kiel , Hochschule Anhalt , Uni Leipzig , Uni Mannheim , UE Innovation Hub Potsdam , Uni Potsdam , IU Internationale Hochschule Erfurt , (Auswahl) Was? Machine Learning ist ein Teilbereich der künstlichen Intelligenz. Algorithmen erkennen Muster in Datensätzen und entwickeln daraus Lösungen. Wo? Den Studiengang gibt es bislang als Masterstudium an der Uni Tübingen und als Artificial Intelligence and Machine Learning an der TU Darmstadt . Was? Medieninformatik ist eine Variante der angewandten Informatik und hat einen berufsorientierten Praxisbezug. Der Studiengang konzentriert sich auf die digitale Informationsverarbeitung in Medien – etwa Computerspielen, Onlineplattformen oder Apps. Der Schwerpunkt liegt auf Multimedia und Softwaretechnik, es kommen aber auch interdisziplinäre Themen dazu wie Mediengestaltung und Wahrnehmungspsychologie. Künstliche Intelligenz ist hier nur eines der möglichen Themenfelder. Wo? Den Studiengang gibt es vergleichsweise häufig, der thematische Schwerpunkt variiert. Bachelorstudiengänge gibt es etwa an der TU Dresden , der LMU München , der Universität des Saarlandes oder der Uni Tübingen . Was? Ein angewandtes Studium der Informatik mit Schwerpunkt auf Robotern und autonomen Systemen, zum Beispiel autonomen Fahrzeugen. Wo? Bachelorstudiengänge gibt es etwa an der Uni Lübeck , der TH Ingolstadt , FH Südwestfalen , HS Kempten , THWS Schweinfurt , EAH Jena oder an der TH Deggendorf . Einen Master in angewandter Robotik gibt es an der HTW Dresden , Neurobotik an der TU Chemnitz . Artificial Intelligence and Data Science : Universität des Saarlandes ; Master: Heinrich-Heine-Universität Düsseldorf , TH Deggendorf , Hochschule Neu-Ulm , Universität Stuttgart , Hochschule Trier Beispiele für weitere Kombinationsfächer oder Spezialisierungen : Computer Science an der TU Darmstadt , Angewandte Data Science und Künstliche Intelligenz in Stralsund , Artificial Intelligence for Smart Sensors and Actuators an der TH Deggendorf , Angewandte Künstliche Intelligenz und Digitale Transformation an der HS Ansbach , Mind, Brain and Behavior an der Uni Gießen , Digital Technologies an der TU Clausthal und Ostfalia Hochschule , KI und Computer Vision an der Hochschule Kempten , Artificial Intelligence Engineering an der Uni Passau , Angewandte Künstliche Intelligenz an der FH Südwestfalen (Auswahl) Voraussetzungen für KI-Studiengänge Eines haben jedoch alle Studiengänge gemeinsam, die auf die Entwicklung von künstlicher Intelligenz abzielen. »Um Mathematik kommen Sie nicht herum«, sagt Röser. Logisches Denken und gute mathematische Grundkenntnisse werden in allen Fachbereichen der Informatik gefordert. Auch gute Englischkenntnisse seien heutzutage zunehmend wichtig, sagt Röser. Eine erste Neugier und Affinität zu Programmierung sei ebenfalls hilfreich. An den hohen Abbruchquoten in der Informatik und verwandten Naturwissenschaften zeigt sich zudem, wie wichtig strukturiertes Arbeiten und Durchhaltevermögen sind. Wer vor Mathematik zurückschreckt und technisch weniger versiert ist, kann sich der KI-Forschung über Umwege nähern. KI-Entwicklerin wird man dann vielleicht nicht – aber man arbeitet mit ihnen zusammen. »Wir haben auch bei uns am Forschungsinstitut Quereinsteiger:innen aus anderen Fachrichtungen«, sagt Forscherin Schumacher. Häufig kämen die aus der Mathematik, Physik und Chemie, aber auch die Psychologie sei in der KI-Entwicklung unheimlich wichtig. An der Beschäftigung mit KI im weitesten Sinne kommt man 2024 ohnehin nicht mehr ganz vorbei. In keinem Fachbereich. Was suchen die Unternehmen? Auch die Wirtschaft ist Taktgeber. KI-Spezialist:innen werden inzwischen in fast allen Branchen gesucht. Von Januar bis April vergangenen Jahres schrieben Arbeitgeber in Deutschland fast 44.000 Stellen mit KI-Bezug aus, so eine Auswertung der Personalagentur Index. Besonders gefragt waren demnach Informatiker:innen sowie Mitarbeitende im Bereich Forschung und Entwicklung. In Zukunft würden Unternehmen zudem stark nach Expert:innen angrenzender Fachbereiche suchen, sagt Berufsberater Röser. »KI allein ist nicht funktionsfähig. Geld wird ja mit den Produkten gemacht, die mittels KI funktionieren und gesteuert werden. Autonome Fahrzeuge etwa.« Auch ein Studium in den Fächern Maschinenbau, Elektrotechnik oder Energietechnik kann also indirekt in die KI-Entwicklung führen. Noch wichtiger als ein Master sei für die Unternehmen Praxiserfahrung, sagt Röser. »Das sehen Sie auch bei den Stellenangeboten. Häufig ist mehrjährige Erfahrung im Bereich der Softwareentwicklung gefragt.« Er empfehle deshalb häufig anwendungsbezogene Studiengänge und duale Angebote, etwa an der RWTH Aachen. Wer später in die Forschung möchte, kann sich an Forschungs- und Kompetenzzentren für künstliche Intelligenz orientieren (siehe Kasten). Inzwischen gibt es immer mehr Kooperationen zwischen den Zentren mit bestimmten Universitäten und Studiengängen. Das kann Synergien und Projekte schaffen und den Weg in die Forschung erleichtern. Standort : Berlin Partneruniversitäten : TU Berlin, TU Braunschweig, HU Berlin, FU Berlin, Uni Potsdam Mehr Informationen auf der Website des BIFOLD Standorte : Bremen, Kaiserslautern, Saarbrücken und Osnabrück Labore in Berlin und Darmstadt sowie Außenstellen in Lübeck und Trier Partneruniversitäten : RPTU Kaiserslautern-Landau, Universität des Saarlandes, Uni Bremen, Hochschule Bremen, TU Berlin, Uni Osnabrück, Hochschule Osnabrück, Uni Oldenburg, Jade Hochschule, Constructor University Bremen (privat), Uni Lübeck Das DFKI ist die bundesweit größte Forschungseinrichtung. Mehr Informationen auf der Website des DFKI Standort : München Partneruniversitäten : LMU München und TU München Mehr Informationen auf der Website des MCML Standort : Dortmund Partneruniversitäten : TU Dortmund und Uni Bonn Mehr Informationen auf der Website des LAMARR Standort : Dresden und Leipzig Partneruniversitäten : TU Dresden und Uni Leipzig Mehr Informationen auf der Website des ScaDS Standort : Tübingen Partneruniversitäten : Uni Tübingen Mehr Informationen auf der Website des AI Centers Die Zuse Schools werden vom Deutschen Akademischen Austauschdienst (DAAD) gefördert und jeweils von einer Technischen Universität betrieben. Aktuell gibt es die Graduiertenschulen an der TU Darmstadt, der TU Dresden und der TU München. Standort: Potsdam Das gemeinnützige, private Institut forscht und lehrt zu IT-Systems Engineering, Data Engineering und Digital Health in Kooperation mit der Uni Potsdam. Auch AI Grid ist ein Netzwerk zur Förderung von jungen Talenten in der KI-Forschung. Es koordiniert Nachwuchsprogramme im Informatik-Umfeld und hat seinen Sitz in Berlin. Der Forschungsverbund will in Baden-Württemberg privatwirtschaftliche Unternehmen und akademische Partner zusammenbringen, um die KI-Forschung voranzutreiben. Partner sind etwa das Max-Planck-Institut für Intelligente Systeme und das Fraunhofer-Institut. Zu den beteiligten Unternehmen gehören unter anderem Amazon, BMW oder Bosch. Partneruniversitäten : Uni Stuttgart und Uni Tübingen Ausbildungen im Bereich künstliche Intelligenz Auch eine Ausbildung bietet Berufsmöglichkeiten im Bereich der künstlichen Intelligenz. Infrage kommen insbesondere eine Ausbildung als Fachinformatiker:in mit der Spezialisierung Anwendungsentwicklung oder eine Ausbildung als Softwareentwickler:in. Hier ist man für die Umsetzung und Programmierung zuständig. Fachinformatiker:in mit der Spezialisierung Anwendungsentwicklung arbeiten in der Softwareentwicklung: Sie konzipieren und programmieren Anwendungen und Benutzeroberflächen – entweder für den eigenen Betrieb oder für Kunden. Sie entwickeln dabei unter Umständen auch KI-gestützte Software, wie etwa Chatbots. Mathematisch-technische Softwareentwickler:in : Mithilfe mathematischer Modelle entwerfen sie Softwaresysteme, programmieren und warten diese. Dabei verwenden sie auch KI-Modelle. Arbeitsorte sind größere Unternehmen, Softwarehäuser und Forschungseinrichtungen. Als inklusive Optionen für Menschen mit Behinderung bieten sich eine Ausbildung zum Fachpraktiker oder Fachpraktikerin für IT-Systemelektronik oder IT-Systemintegration an. Mehr Frauen in die KI-Entwicklung In vielen MINT-Fächern überwiegen männliche Studierende. Immer wieder zeigen Studien wie diese aus dem Jahr 2022 , dass sich Frauen nicht für das Studium eines MINT-Faches gerüstet fühlen. Kinga Schumacher ist es deshalb ein persönliches Anliegen, dass sich junge Frauen nicht von einer Karriere im Bereich KI abschrecken lassen. Auch aufgrund ihrer persönlichen Erfahrung. »Als ich studiert habe, hieß es jeden Tag: Guten Morgen Frau Schumacher, guten Morgen meine Herren«, erzählt sie. »Ich konnte nicht mal schwänzen, weil ich eigentlich immer die einzige Frau war.« Inzwischen habe sich viel getan. Sie selbst habe inzwischen ein kleines Team mit überwiegend Frauen. Mehr Diversität sei in der KI-Entwicklung unheimlich wichtig: »Wenn wir KI-Systeme für Menschen entwickeln, die nicht diskriminierend und für alle gleich gut sein sollen, dann benötigen wir eben auch diverse Teams.« Anmerkung der Redaktion : In einer früheren Version des Textes konnte der Eindruck entstehen, die Mathematik sei lediglich Grundlage der Informatik. Es gibt jedoch auch Studiengänge im Bereich der KI, die in der Mathematik angesiedelt sind. Wir haben den Text entsprechend ergänzt."
AI,Spiegel Online,2024-01-30,https://www.spiegel.de/netzwelt/gadgets/samsung-galaxy-s24-ultra-im-test-ki-ist-jetzt-fast-ueberall-a-80c24e44-baf7-4b40-94f9-542a74dcf87b,Samsung Galaxy S24 Ultra im Test: KI ist jetzt fast überall - DER SPIEGEL,"Samsungs neues Top-Smartphone könnte sterbenslangweilig sein – wären da nicht die KI-Funktionen und die Aussicht, das Gerät auch im Jahr 2031 noch nutzen zu können. Dieser Text enthält sogenannte Affiliate-Links, über die der Verlag, aber nie der Autor individuell, bei Verkäufen eine geringe Provision vom Händler erhält. Beim Design hat sich Samsung von Apple inspirieren lassen und ist sich gleichzeitig selbst treu geblieben. So wie beim iPhone 15 Pro ( hier unser Testbericht ) wird der Rahmen des Galaxy S24 Ultra aus Titan hergestellt. Das robuste Metall fühlt sich angenehm weich an, liegt gut in der Hand. Einhändig bedienen kann man es trotzdem nicht, dafür ist der Bildschirm mit seinen 6,8 Zoll zu groß. Die grundlegende Form aber erinnert sehr an das Galaxy S23 Ultra vom vorigen Jahr ( hier unser Testbericht ). Auch die Anordnung der Kameras auf der Rückseite ist identisch, und der S Pen, mit dem man auf dem Bildschirm schreiben, zeichnen und malen kann, ist an der gleichen Stelle im Gehäuse untergebracht. Der kleine Stift funktioniert übrigens trotz seiner billig wirkenden Machart hervorragend. Wer gern handschriftliche Notizen macht – was ich nicht tue – wird damit gut klarkommen. Guck mal Eine sichtbare Verbesserung ist das neue Design des Bildschirms. Das Display des S23 Ultra war an den Rändern ganz leicht gebogen. Der Bildschirm des S24 Ultra ist nun – endlich – vollkommen flach und lässt sich bis zum Rand hin nutzen. Die Ära der gebogenen Bildschirme dürfte damit vorbei sein. Weshalb Samsung diesen Schritt nicht schon im vergangenen Jahr gegangen ist, ist mir schleierhaft. Alles andere als schleierhaft ist dagegen der Bildschirm selbst. Wie der des Vorgängers ist er knackscharf, verfügt über 3120 mal 1440 Pixel, kann die Bildwiederholfrequenz von einem Bild pro Sekunde beim Lesen auf bis zu 120 Bilder pro Sekunde beim Scrollen und Spielen variieren. Der Sinn dahinter: je weniger Bilder das Display anzeigen muss, desto weniger Energie benötigt es. Viel Energie geht drauf, wenn man das Handy bei praller Sonne benutzt. Das Display erreicht dann punktuell eine Spitzenhelligkeit von 2600 Nits, 200 mehr als das Pixel 8 Pro und 600 mehr als das iPhone 15 Pro. Das ist hell, sehr hell. Pixel statt Linsen Wie das Design vermuten lässt, hat sich bei den Kameras nicht viel getan. Wie schon das S23 Ultra verfügt das S24 Ultra über eine Weitwinkelkamera mit 200 Megapixeln. Deren volle Auflösung ist aber nur selten von Nutzen. Einzig bei sehr hellen Motiven kann es sinnvoll sein. Die vollen 200 Megapixel zu verwenden. Die besseren Fotos erreicht man im 12-Megapixel-Modus, in dem je 16 Sensorpixel zu einem Bildpixel kombiniert werden. Eine Auflösung von 12 Megapixeln hat ebenfalls die Ultraweitwinkelkamera, die Dreifach-Telekamera muss sich mit 10 Megapixeln begnügen. Neu ist, dass die zweite Telekamera jetzt 50 statt 10 Megapixel hat und ihr optisches Zoomobjektiv nur auf eine fünffache Vergrößerung kommt. Im Vorgänger steckte noch eine Zehnfach-Zoom. Das macht skeptisch. Hat Samsung das große Tele beschnitten? Die Antwort lautet ja, aber beschnitten werden nun die Aufnahmen: Statt per Objektiv ans Motiv heranzuzoomen, wird bei Zoomstufen über dem Faktor fünf eine 50-Megapixel-Aufnahme des Fünffach-Zooms so beschnitten, dass der per Zoomfunktion gewählte Ausschnitt übrig bleibt. Das klingt wie Schummeln, klappt aber bis zum Zehnfach-Zoom gut – wenn es hell genug ist. Bei Dunkelheit sollte man diesen Digitalzoom lieber nicht benutzen. Künstliche Intelligenz – überall ein bisschen Anders als bei der Hardware gibt es in der Software der S24-Serie viele Neuerungen in Form von KI-Funktionen. Künstliche Intelligenz, die das Unternehmen penetrant dem englischen Begriff Artificial Intelligence folgend als AI bezeichnet, ist fast allgegenwärtig. Die KI – oder eben AI – findet man in den Geräten der S24-Serie in der Kamera, dem Notizbuch, der Telefonfunktion und mehr. Wohl, um alles zum Thema zu sammeln, findet man in den Einstellungen unter »Erweiterte Funktionen« die KI-Optionen nun unter der Bezeichnung »Moderne KI-Funktionen«. Samsungs KI-Assistenten Bixby, der unterhalb dieses Menüeintrags aufgeführt wird, kann man demnach den alten KI-Funktionen zuordnen. Zu den alten KI-Funktionen zählt im Grunde auch vieles, was in der Foto-App vor sich geht. Da wäre zum Beispiel die Möglichkeit, im Bild nicht erwünschte Objekte mit dem Finger oder dem S Pen einzukreisen und zu löschen. Das Besondere dabei: Statt einen weißen Fleck im Bild zu hinterlassen, füllt generative KI die Fehlstelle mit einem zur Umgebung passenden Hintergrund. Google bietet eine solche Funktion seit Langem als »magischen Radierer« an. Solange man sich auf kleine Bildbereiche beschränkt, funktioniert das gut, schnippelt man großflächig herum, fallen der KI keine sinnvollen Füllmuster ein und sie halluziniert sich einen Hintergrund zusammen. Besser ist die generative KI eingesetzt, wenn man einen Schnappschuss nachträglich um ein paar Grad drehen möchte, weil das Bild schief ist. Bisher wurde das Foto in solchen Fällen auf ein verkleinertes Rechteck zusammengestutzt, um die Ecken abzuschneiden, die keinen Inhalt hatten. Auf den S24 produziert die KI jetzt zum Bildrand passende Füllstücke, damit die Aufnahme ihre ursprüngliche Größe behält. Spiegelungen ein Ende setzen Mehr amüsant als nützlich ist, dass Samsungs Software derart manipulierte Bilder mit einem kleinen Symbol markiert, das als Wasserzeichen links unten im Bild eingebaut wird. Mit der KI-Löschfunktion kann man dem nicht beikommen, weil die ein neues Wasserzeichen hinterlassen würde. Der leichtere Weg ist ohnehin, die Linke Ecke einfach von Bild abzuschneiden, um die Manipulation unkenntlich zu machen. Was sehr nützlich sein kann, aber nicht immer perfekt funktioniert, ist die Möglichkeit, Reflexionen zu löschen, wenn man durch spiegelnde Fenster fotografiert hat. Leider haben Samsungs User-Interface-Spezialistinnen und -Spezialisten diese Option gut versteckt. Zu finden ist sie in der »Galerie«-App, indem man auf das eingekreiste »i« tippt und einen Moment wartet, bis die Software das Bild analysiert hat und Bearbeitungsvorschläge einblendet. Auf dieselbe Weise kann man nachträglich eine Hintergrundunschärfe hinzufügen, die manchen Bildern einen Spiegelreflex-Look geben kann. Worum geht’s in diesem Text? Nicht nur Bilder, auch Texte kann man von der KI in Samsungs neuen Smartphones bearbeiten lassen. Was prima funktioniert: Als Textwurst eingetippte Notizen ansprechend formatieren und Texte wie etwa Sitzungsmitschnitte zusammenfassen lassen. Vor allem Letzteres hat sich bei mir schon nach wenigen Tagen als extrem nützliches Tool erwiesen, um etwa abzuschätzen, ob es sich lohnt, einen langen Text in Gänze zu lesen. Schade, dass das nur in der Notiz-App und Samsungs Webbrowser funktioniert und auch da nur mit Texten, die frei von Bezahlschranken sind. Dafür kann die KI auch PDF-Dateien zusammenfassen, nachdem man sie in die Notizen-App importiert hat. Mehr als rund drei Textseiten sind der künstlichen Intelligenz aber zu viel. Maßvoll Multilingual Nicht ganz so beeindruckend arbeiten die Dolmetsch- und Übersetzungsfunktionen. Die Möglichkeit, etwa Telefonate mit anderssprachigen Menschen von der KI dolmetschen zu lassen, erfordert Geduld. Statt in Echtzeit erfolgt die Übersetzung mit Wartezeit. Und auch dass nur korrekt, wenn man klar, deutlich und nicht zu schnell spricht. Der Erfolg solcher Telefonate hängt aber vor allem davon ab, ob die Angerufenen die KI und ihre Eigenheiten verstehen und akzeptieren. Schon die ein solches Gespräch einleitende Computerstimme, die auf die Übersetzung per Computer hinweist, könnte den einen oder die andere abschrecken. Abschreckend waren zumindest teilweise auch meine Versuche, anderssprachige Texte transkribieren und dann übersetzen zu lassen. Ein Mitschnitt aus dem koreanischen Fernsehen ließ mich vollkommen ratlos zurück, ein Ausschnitt aus einer amerikanischen Talkshow war zwar nicht elegant, aber immerhin verständlich übersetzt. Die KI-Zusammenfassung davon enthielt tatsächlich alles Wichtige. Das Problem einkreisen Die KI-Funktion, die ich während der Testphase am häufigsten genutzt habe, heißt allerdings Circle to Search. Und auch wenn Samsung bei seinen Präsentationen der S24-Serie den Eindruck zu vermitteln versuchte, das sei eine Samsung-Erfindung, stammt dieses Feature doch von Google und wird ab dem 31. Januar auch auf dem Pixel 8 und 8 Pro ( hier unser Testbericht ) verfügbar sein. Das Charmante an dieser Funktion ist ihre Einfachheit. Egal, was auf dem Bildschirm angezeigt wird: Drückt man kurz in der Mitte unten auf den Bildschirm, wird eine Art virtuelle Klarsichtfolie über das Display gelegt, auf der man per Finger oder S Pen das Objekt einkreist, über das man mehr wissen will. Die KI durchwühlt daraufhin das Web und zeigt oft, aber nicht immer, akkurat an, was man da sieht. Die Funktion erinnert an Google Lens, eröffnet dadurch, dass sie immer verfügbar ist, aber ganz andere Möglichkeiten. Was für eine Jacke trägt der Hauptdarsteller in dem Film? In welcher Stadt hat meine Freundin das Selfie gemacht, dass ich auf Instagram gesehen hab? Wie heißt das Haus, vor dem ich stehe? Wenn sie groß genug erkennbar sind, lassen sich auf diese Weise auch Wörter und Begriffe suchen. Einfacher kann man sich nicht durch die Welt googeln. Wie schnell es ist? Schnell genug Wie immer baut Samsung in sein Topmodell den aktuell schnellsten Qualcomm-Prozessor in einer Samsung-Version ein, die ein klein wenig übertaktet ist. So ist sichergestellt, dass das Gerät in Benchmarktests immer vorne liegt. Da solche Leistungsvergleiche nur ein theoretisches Bild liefern, belassen wir es mit der Feststellung: Das Galaxy S24 Ultra ist schnell genug. Fast immer. Wartezeiten gibt es vor allem bei KI-Funktionen, wie etwa der Transkription von Texten. Updates bis ins nächste Jahrzehnt Samsung liefert alle Modelle der S24-Serie mit Android 14 aus, dem die hauseigene Benutzeroberfläche One UI übergezogen wurde. Dass der Konzern als einer von wenigen Herstellern auf seinen neuen Geräten das aktuelle Google-Betriebssystem installiert, ist löblich. Honor etwa liefert sein teures Faltsmartphone Magic V2 ( hier unser Testbericht ) noch mit Android 13 aus. Noch wichtiger ist aber, dass Samsung verspricht, die Geräte sieben Jahre lang mit Android-Updates zu versorgen. Da macht es dann auch Sinn, dass es jetzt schon Wi-Fi 7 beherrscht, einen WLAN-Standard, für den es bisher kaum Hardware gibt. Ähnlich lange Update-Laufzeiten haben bisher nur Google für die Pixel 8 und 8 Pro sowie Fairphone in Aussicht gestellt. Ausreichend Ersatzteile und vor allem Austauschakkus vorausgesetzt, dürfte man demnach noch im Jahr 2031 ein Update installieren. Angesichts bisheriger Produktzyklen eine ebenso irritierende wie aus ökologischer Sicht berauschende Vorstellung. Fazit 👍 Sehr guter Bildschirm 👍 Nützliche KI-Funktionen 👍 Gute Akkulaufzeit 👍 Lange Update-Versorgung 👎 Hoher Preis Mit dem Galaxy S24 Ultra hat Samsung das derzeit wohl beste Android-Smartphone am Start. Die Hardware ist vom Feinsten, die neuen KI-Funktionen sind zum Teil wirklich nützlich. Vor allem geben sie einen Ausblick darauf, was in Zukunft möglich sein wird, wenn die Kinderkrankheiten etwa beim Dolmetschen kuriert sind. Mit dem Versprechen, dass das Gerät sieben Jahre lang Updates bekommen wird, kann man sich vielleicht sogar den hohen Preis schönreden. Der nämlich ist gegenüber dem S23 Ultra um 50 Euro auf 1449 Euro gestiegen. Wohlgemerkt für die Einstiegsversion mit 256 Gigabyte (GB) Speicher. Die Variante mit 512 GB kostet 1569 Euro, das 1-Terabyte-Modell 1809 Euro. Bis zum 31.1. bietet Samsung die beiden kleinen Modelle noch mit doppeltem Speicher an, die Terabyte-Variante zum 512-GB-Preis. Über welche Produkte wir in der Netzwelt berichten und welche wir testen oder nicht, entscheiden wir selbst. Für keinen der Testberichte bekommen wir Geld oder andere Gegenleistungen vom Hersteller. Es kann aus verschiedenen Gründen vorkommen, dass wir über Produkte nicht berichten, obwohl uns entsprechende Testprodukte vorliegen. Testgeräte und Rezensionsexemplare von Spielen bekommen wir in der Regel kostenlos für einen bestimmten Zeitraum vom Hersteller zur Verfügung gestellt, zum Teil auch vor der offiziellen Veröffentlichung. So können unsere Testberichte rechtzeitig oder zeitnah zur Veröffentlichung des Produkts erscheinen. Vorabversionen oder Geräte aus Vorserienproduktionen testen wir nur in Sonderfällen. In der Regel warten wir ab, bis wir Testgeräte oder Spielversionen bekommen können, die mit den Verkaufsversionen identisch sind. Wenn sie bereits im Handel oder online verfügbar sind, kaufen wir Produkte in einigen Fällen auf eigene Kosten ein. In der Regel werden Testgeräte nach dem Ende des Tests an die Hersteller zurückgeschickt. Die Ausnahme sind Rezensionsexemplare von Spielen und langfristige Leihgaben: So haben wir zum Beispiel Spielekonsolen und Smartphones in der Redaktion, die wir über längere Zeit nutzen dürfen. So können wir beispielsweise über Softwareupdates, neues Zubehör und neue Spiele berichten oder Langzeiturteile fällen. Oft werden Rezensionsexemplare am Ende eines Jahres zum Beispiel gesammelt und im Rahmen eines firmeninternen Flohmarktes verkauft, wobei die Erlöse für gemeinnützige Zwecke gespendet werden. Teilweise werden sie auch direkt an gemeinnützige Einrichtungen gespendet. Die Kosten für Reisen zu Veranstaltungen, egal ob sie in Deutschland oder im Ausland stattfinden, trägt DER SPIEGEL stets selbst. Das gilt auch dann, wenn beispielsweise aufgrund kurzfristiger Termine ein Unternehmen die Reiseplanung übernimmt. Veranstaltungen, zu denen wir auf eigene Kosten reisen, sind unter anderem die Messen Ifa, CES, E3 und Gamescom, Entwicklerveranstaltungen wie die Google i/O, WWDC und Build sowie Events von Firmen wie Apple, Google, Microsoft oder Nintendo. Auf Konferenzen wie dem Chaos Communication Congress oder der re:publica bekommen wir in der Regel, wie auch andere Pressevertreter, kostenlose Pressetickets, da wir über die Konferenz berichten und keine klassischen Teilnehmer sind. Seit Dezember 2016 finden sich in einigen Netzwelt-Artikeln sogenannte Affiliate-Anzeigen, die sogenannte Links zu Onlineshops enthalten. Besucht ein Nutzer über einen solchen Link einen dieser Shops und kauft dort online ein, wird DER SPIEGEL, aber nie die Autorin oder der Autor individuell, in Form einer Provision an den Umsätzen beteiligt. Diese Provision wird vom Händler gezahlt, nicht vom Hersteller des Produkts. Die Anzeigen tauchen in Artikeln unabhängig davon auf, ob ein Produkttest positiv oder negativ ausfällt. Eine ausführliche Erklärung zu Affiliate-Links finden Sie, wenn Sie auf diesen Link klicken . Der Porträtmodus funktioniert bei Hunden recht gut und … … bei Friseurpuppen sowieso. Nahaufnahme eines im Wind wackelnden Astes: Da muss der Autofokus wohl schnell sein. Aufnahme eines schon viel zu lange herumstehenden Weihnachtsgestecks im dunklen Wohnzimmer, so wie die Kamera-App die Szene sieht … … und was die Fotosoftware daraus macht. Natürlich kann man auch mit dem S24 Ultra Nahaufnahmen vom Mond machen, wenn man den Zoomfaktor 100 auswählt. Wie echt sie sind, ist Thema vieler Diskussionen . Ein Gartenzwerg. Nicht irgendeiner, sondern Fritz. Aufgenommen mit der Ultraweitwinkelkamera des Galaxy S24 Ultra. Hier wurde Fritz mit dem 200-Megapixel-Weitwinkelobjektiv aufgenommen, aber mit 12-Megapixel-Auflösung. Die maximale optische Näherung, das Fünffach-Zoom Eigentlich eine Ausschnittvergrößerung, aber sehr gelungen: der Zwerg im Faktor 10. Nicht gerade sensationell: der Zoomfaktor 10 vor Sonnenaufgang Übersetzung von Koreanisch ins Deutsche, in diesem Beispiel nur Kauderwelsch Besser klappte es im Test von Englisch ins Deutsche, aber perfekt war auch das nicht Die Zusammenfassung enthielt trotzdem alle wichtigen Punkte Volltreffer: Hier hat Circle to Search den Schnappschuss genau richtig erkannt. Bei diesem Foto eines freundlichen Trainingsballs fand die KI immerhin ähnlich aussehende Bälle – deren Aufnahmen aber stets nur als Symbolfotos genutzt wurden. Aber hier ließ sie sich von einem Baugerüst foppen, identifizierte das Hamburger Haus der Photographie als Philharmonie Stettin. Noch eine Niete: Statt einer Schweizer Leckerei vermutete die KI unter der Alufolie Druckertoner oder doch einfach irgendwas mit Alufolie."
AI,Spiegel Online,2024-01-30,https://www.spiegel.de/netzwelt/netzpolitik/ai-act-bundesregierung-will-europaeischem-ki-gesetz-doch-zustimmen-a-86cfff74-6d38-45f3-a772-ef65dff6e95f,AI Act: Bundesregierung will europäischem KI-Gesetz doch zustimmen - DER SPIEGEL,"Bedenken der FDP sollen Deutschlands Zustimmung zum AI Act in letzter Minute ins Wanken gebracht haben. Nun aber hat sich die Bundesregierung auf eine gemeinsame Haltung verständigt. Die finale Einigung der EU-Mitgliedstaaten auf den AI Act soll am kommenden Freitag erfolgen – und Deutschland will dem ersten umfassenden Gesetzespaket zu künstlicher Intelligenz in der westlichen Welt nicht im Weg stehen. In einer Pressemitteilung des Bundesministeriums für Wirtschaft und Klimaschutz heißt es am Dienstag, die Bundesregierung habe sich darauf verständigt, der KI-Verordnung zuzustimmen. »Mit der deutschen Zustimmung zur KI-Verordnung setzen wir uns für Rechtssicherheit und vertrauenswürdige KI made in Europe ein«, lautete ein Kommentar von Wirtschaftsminister Robert Habeck. Und Marco Buschmann, der Bundesminister der Justiz, sagte: »Mit der europäischen KI-Verordnung machen wir den Weg frei für einen sicheren Rechtsrahmen für künstliche Intelligenz, der Innovationen fördert und gleichzeitig Risiken in der Anwendung angemessen adressiert.« Noch vor wenigen Tagen hatte es geheißen , vor allem im Digitalministerium von Volker Wissing ( FDP ) gebe es noch Widerstand gegen das Gesetz. Zwar hatte es bereits im Dezember im Ministerrat eine grundsätzliche mündliche Einigung gegeben, doch erst sechs Wochen später lag die finale schriftliche Fassung des Gesetzes vor. Bis zum vorvergangenen Wochenende seien deshalb zahlreiche zentrale Details unklar gewesen, so hörte man, etwa über die Regulierung von Gesichtserkennung und von KI-Basismodellen. Am Dienstagmorgen hat nach SPIEGEL-Informationen eine Runde der Staatssekretärinnen und Staatssekretäre einen Kompromiss gefunden. Aus Regierungskreisen hieß es, man werde dem AI Act zustimmen, die EU-Kommission aber auffordern, kurzfristig zentrale Praxisfragen zu klären, um Doppelbelastungen für die Wirtschaft zu vermeiden. Dazu gehörten unter anderem das Verhältnis zu anderen Produktregulierungsrechtsakten (Medizinprodukte) und Rechtsfragen bei der Weiterentwicklung von KI-Modellen (Finetuning). Auch das »Handelsblatt« berichtete von der Einigung. Wie der SPIEGEL weiter erfuhr, tendiert wohl auch die französische Regierung mittlerweile zu einem Ja zum AI Act. Zusammen mit Italien galt auch Frankreich bisher als möglicher Wackelkandidat. Anmerkung der Redaktion: In einer früheren Fassung dieses Artikels hieß es, die Runde der Staatssekretärinnen und Staatssekretäre habe am Montagabend einen Kompromiss gefunden. Nach SPIEGEL-Informationen war es der Dienstagmorgen, wir haben den Satz korrigiert."
Artificial Intelligence,Spiegel Online,2024-02-01,https://www.spiegel.de/start/kuenstliche-intelligenz-informatik-oder-data-science-studieren-ki-studiengaenge-und-ausbildungen-a-26a8685d-e6f1-4625-bd23-cc307ecf33aa,Künstliche Intelligenz: Informatik oder Data Science studieren? - KI-Studiengänge und Ausbildungen - DER SPIEGEL,"Alle reden über künstliche Intelligenz, Fachleute sind auf dem Arbeitsmarkt gefragt. Welche Fächer man belegen muss, um neue Technologien mitzuentwickeln – und welche Fähigkeiten es dazu braucht. Spätestens mit ChatGPT ist künstliche Intelligenz in unserem Alltag angekommen. Egal, ob in der Medizin- oder Agrarindustrie: Die Entwicklung neuer Technologien mithilfe von KI bietet der deutschen Wirtschaft vielfältige neue Chancen. Kein Wunder also, dass Unternehmen händeringend nach KI-Spezialist:innen suchen. Mit der steigenden Nachfrage wächst auch das Angebot an Ausbildungswegen, die in das Berufsfeld führen. »Das Schöne ist, dass jeder in der KI-Entwicklung seinen Platz findet«, sagt Kinga Schumacher, Senior Researcherin am Deutschen Forschungszentrum für Künstliche Intelligenz (DFKI) in Berlin – ob beim fokussierten Programmieren oder in interdisziplinärer, kreativer Projektarbeit. Sie habe zu Beginn ihrer Karriere klassisch Informatik studiert, erzählt Schumacher. KI sei damals in den Nullerjahren noch kaum Thema gewesen. Heute sieht das anders aus. Informatik oder Data Science? – Der Weg in die KI-Entwicklung »Vor fünfzehn Jahren hätte ich Ihnen noch gesagt: Studieren Sie Informatik!«, sagt Schumacher. Inzwischen sei die Antwort nicht mehr so einfach, die Wege in die KI-Entwicklung sind vielfältig. Es gebe immer mehr Studiengänge, die sich auf spezielle Bereiche der künstlichen Intelligenz fokussieren, so die Forscherin. Meist sind das Formen der angewandten Informatik oder sie sind in der Mathematik angesiedelt. Welches Fach sich am besten eignet, sei eine Frage der persönlichen Neigungen. »Wenn ich gern rumbastele, dann studiere ich vielleicht Robotik, wenn ich zwei linke Hände habe, eher etwas Datenzentriertes«, sagt Schumacher. Bei Data Science etwa liegt der Fokus auf der Auswertung großer Datenmengen. In einem Studiengang Künstliche Intelligenz liege der Fokus dagegen mehr auf möglichen Anwendungsbereichen von KI, etwa Mobilität, Gesundheitswesen oder Chatbots. Die Grundlagen seien jedoch meist die gleichen, sagt Schumacher. Das betont auch Thomas Röser von der Berufsberatung der Agentur für Arbeit Aachen-Düren. Man solle sich von den vielen unterschiedlichen Fachrichtungen nicht abschrecken lassen. »Das ist wie in der BWL: Da heißt der Studiengang vielleicht Marketing – im Grunde genommen machen Sie aber auch BWL.« Wer sich früh spezialisieren möchte, könne seinen Bachelor in einem Anwendungsfach machen. Wer sich unsicher sei, dem rate er allerdings zum klassischen Grundstudium Informatik oder Mathematik. »Spezialisieren ja, aber warum schon im Bachelor?« Im Master könne man dann immer noch seinen Fokus setzen. Auch ein Wechsel sei innerhalb der unterschiedlichen Fächer meist unkompliziert. Was? Die klassische Informatik vermittelt Grundlagen der systemischen Verarbeitung von Informationen. Neben den grundlegenden Fächern der angewandten, praktischen und technischen Informatik kommen immer mehr Spezialisierungsfelder hinzu. Dazu gehört auch künstliche Intelligenz. Wo? An den meisten Hochschulen wird Informatik als Bachelor und Master angeboten, besonders an Technischen Hochschulen. Renommiert sind etwa die RWTH Aachen , die TU München oder die FU Berlin . In Deutschland gibt es über 600 Studienangebote. Was? Angewandte Informatik hat im Vergleich zum klassischen Fach meist eine stärkere Spezialisierung auf einen Anwendungsbereich. Eigentlich ist es ein Überbegriff für verschiedene spezialisierte Informatikstudiengänge, wie Medieninformatik oder Cybersecurity. Die Spezialisierung kann sich von Hochschule zu Hochschule stark unterscheiden. Voraussetzung sollte also ein Interesse am jeweiligen Schwerpunktthema sein. Wo? Mehr als 100 Hochschulen bieten Studiengänge in der angewandten Informatik an. Siehe unten. Was? Die Studiengänge Künstliche Intelligenz oder Artificial Intelligence sind von Anfang an auf KI fokussiert. Wo? Technische Hochschule Ingolstadt , Ostbayerische Technische Hochschule Amberg-Weiden , BTU Cottbus-Senftenberg , Uni Würzburg , TH Rosenheim , Hochschule Landshut , Hochschule Ansbach ; Master: Universität Ulm , THWS Würzburg , Uni Erlangen-Nürnberg , Uni Lübeck (Auswahl) Was? Data Scientists gewinnen mit Methoden der Mathematik, Informatik und Statistik Erkenntnisse aus großen Mengen von Daten. Ebenfalls ein Spezialisierungsbereich der Informatik. Wo? Uni Erlangen-Nürnberg , Uni Gießen , TU Dortmund , BHT Berlin , Uni Göttingen , TU Hamburg , Uni Hildesheim , Uni Marburg , LMU München , Uni Trier ; Master: Hochschule Darmstadt , Hochschule Harz , RWTH Aachen , FU Berlin , Uni Bielefeld , TU Braunschweig , TU Chemnitz , Hochschule Coburg , Hochschule Fulda , Hochschule Bielefeld , Fernuni Hagen , FH Kiel , Hochschule Anhalt , Uni Leipzig , Uni Mannheim , UE Innovation Hub Potsdam , Uni Potsdam , IU Internationale Hochschule Erfurt , (Auswahl) Was? Machine Learning ist ein Teilbereich der künstlichen Intelligenz. Algorithmen erkennen Muster in Datensätzen und entwickeln daraus Lösungen. Wo? Den Studiengang gibt es bislang als Masterstudium an der Uni Tübingen und als Artificial Intelligence and Machine Learning an der TU Darmstadt . Was? Medieninformatik ist eine Variante der angewandten Informatik und hat einen berufsorientierten Praxisbezug. Der Studiengang konzentriert sich auf die digitale Informationsverarbeitung in Medien – etwa Computerspielen, Onlineplattformen oder Apps. Der Schwerpunkt liegt auf Multimedia und Softwaretechnik, es kommen aber auch interdisziplinäre Themen dazu wie Mediengestaltung und Wahrnehmungspsychologie. Künstliche Intelligenz ist hier nur eines der möglichen Themenfelder. Wo? Den Studiengang gibt es vergleichsweise häufig, der thematische Schwerpunkt variiert. Bachelorstudiengänge gibt es etwa an der TU Dresden , der LMU München , der Universität des Saarlandes oder der Uni Tübingen . Was? Ein angewandtes Studium der Informatik mit Schwerpunkt auf Robotern und autonomen Systemen, zum Beispiel autonomen Fahrzeugen. Wo? Bachelorstudiengänge gibt es etwa an der Uni Lübeck , der TH Ingolstadt , FH Südwestfalen , HS Kempten , THWS Schweinfurt , EAH Jena oder an der TH Deggendorf . Einen Master in angewandter Robotik gibt es an der HTW Dresden , Neurobotik an der TU Chemnitz . Artificial Intelligence and Data Science : Universität des Saarlandes ; Master: Heinrich-Heine-Universität Düsseldorf , TH Deggendorf , Hochschule Neu-Ulm , Universität Stuttgart , Hochschule Trier Beispiele für weitere Kombinationsfächer oder Spezialisierungen : Computer Science an der TU Darmstadt , Angewandte Data Science und Künstliche Intelligenz in Stralsund , Artificial Intelligence for Smart Sensors and Actuators an der TH Deggendorf , Angewandte Künstliche Intelligenz und Digitale Transformation an der HS Ansbach , Mind, Brain and Behavior an der Uni Gießen , Digital Technologies an der TU Clausthal und Ostfalia Hochschule , KI und Computer Vision an der Hochschule Kempten , Artificial Intelligence Engineering an der Uni Passau , Angewandte Künstliche Intelligenz an der FH Südwestfalen (Auswahl) Voraussetzungen für KI-Studiengänge Eines haben jedoch alle Studiengänge gemeinsam, die auf die Entwicklung von künstlicher Intelligenz abzielen. »Um Mathematik kommen Sie nicht herum«, sagt Röser. Logisches Denken und gute mathematische Grundkenntnisse werden in allen Fachbereichen der Informatik gefordert. Auch gute Englischkenntnisse seien heutzutage zunehmend wichtig, sagt Röser. Eine erste Neugier und Affinität zu Programmierung sei ebenfalls hilfreich. An den hohen Abbruchquoten in der Informatik und verwandten Naturwissenschaften zeigt sich zudem, wie wichtig strukturiertes Arbeiten und Durchhaltevermögen sind. Wer vor Mathematik zurückschreckt und technisch weniger versiert ist, kann sich der KI-Forschung über Umwege nähern. KI-Entwicklerin wird man dann vielleicht nicht – aber man arbeitet mit ihnen zusammen. »Wir haben auch bei uns am Forschungsinstitut Quereinsteiger:innen aus anderen Fachrichtungen«, sagt Forscherin Schumacher. Häufig kämen die aus der Mathematik, Physik und Chemie, aber auch die Psychologie sei in der KI-Entwicklung unheimlich wichtig. An der Beschäftigung mit KI im weitesten Sinne kommt man 2024 ohnehin nicht mehr ganz vorbei. In keinem Fachbereich. Was suchen die Unternehmen? Auch die Wirtschaft ist Taktgeber. KI-Spezialist:innen werden inzwischen in fast allen Branchen gesucht. Von Januar bis April vergangenen Jahres schrieben Arbeitgeber in Deutschland fast 44.000 Stellen mit KI-Bezug aus, so eine Auswertung der Personalagentur Index. Besonders gefragt waren demnach Informatiker:innen sowie Mitarbeitende im Bereich Forschung und Entwicklung. In Zukunft würden Unternehmen zudem stark nach Expert:innen angrenzender Fachbereiche suchen, sagt Berufsberater Röser. »KI allein ist nicht funktionsfähig. Geld wird ja mit den Produkten gemacht, die mittels KI funktionieren und gesteuert werden. Autonome Fahrzeuge etwa.« Auch ein Studium in den Fächern Maschinenbau, Elektrotechnik oder Energietechnik kann also indirekt in die KI-Entwicklung führen. Noch wichtiger als ein Master sei für die Unternehmen Praxiserfahrung, sagt Röser. »Das sehen Sie auch bei den Stellenangeboten. Häufig ist mehrjährige Erfahrung im Bereich der Softwareentwicklung gefragt.« Er empfehle deshalb häufig anwendungsbezogene Studiengänge und duale Angebote, etwa an der RWTH Aachen. Wer später in die Forschung möchte, kann sich an Forschungs- und Kompetenzzentren für künstliche Intelligenz orientieren (siehe Kasten). Inzwischen gibt es immer mehr Kooperationen zwischen den Zentren mit bestimmten Universitäten und Studiengängen. Das kann Synergien und Projekte schaffen und den Weg in die Forschung erleichtern. Standort : Berlin Partneruniversitäten : TU Berlin, TU Braunschweig, HU Berlin, FU Berlin, Uni Potsdam Mehr Informationen auf der Website des BIFOLD Standorte : Bremen, Kaiserslautern, Saarbrücken und Osnabrück Labore in Berlin und Darmstadt sowie Außenstellen in Lübeck und Trier Partneruniversitäten : RPTU Kaiserslautern-Landau, Universität des Saarlandes, Uni Bremen, Hochschule Bremen, TU Berlin, Uni Osnabrück, Hochschule Osnabrück, Uni Oldenburg, Jade Hochschule, Constructor University Bremen (privat), Uni Lübeck Das DFKI ist die bundesweit größte Forschungseinrichtung. Mehr Informationen auf der Website des DFKI Standort : München Partneruniversitäten : LMU München und TU München Mehr Informationen auf der Website des MCML Standort : Dortmund Partneruniversitäten : TU Dortmund und Uni Bonn Mehr Informationen auf der Website des LAMARR Standort : Dresden und Leipzig Partneruniversitäten : TU Dresden und Uni Leipzig Mehr Informationen auf der Website des ScaDS Standort : Tübingen Partneruniversitäten : Uni Tübingen Mehr Informationen auf der Website des AI Centers Die Zuse Schools werden vom Deutschen Akademischen Austauschdienst (DAAD) gefördert und jeweils von einer Technischen Universität betrieben. Aktuell gibt es die Graduiertenschulen an der TU Darmstadt, der TU Dresden und der TU München. Standort: Potsdam Das gemeinnützige, private Institut forscht und lehrt zu IT-Systems Engineering, Data Engineering und Digital Health in Kooperation mit der Uni Potsdam. Auch AI Grid ist ein Netzwerk zur Förderung von jungen Talenten in der KI-Forschung. Es koordiniert Nachwuchsprogramme im Informatik-Umfeld und hat seinen Sitz in Berlin. Der Forschungsverbund will in Baden-Württemberg privatwirtschaftliche Unternehmen und akademische Partner zusammenbringen, um die KI-Forschung voranzutreiben. Partner sind etwa das Max-Planck-Institut für Intelligente Systeme und das Fraunhofer-Institut. Zu den beteiligten Unternehmen gehören unter anderem Amazon, BMW oder Bosch. Partneruniversitäten : Uni Stuttgart und Uni Tübingen Ausbildungen im Bereich künstliche Intelligenz Auch eine Ausbildung bietet Berufsmöglichkeiten im Bereich der künstlichen Intelligenz. Infrage kommen insbesondere eine Ausbildung als Fachinformatiker:in mit der Spezialisierung Anwendungsentwicklung oder eine Ausbildung als Softwareentwickler:in. Hier ist man für die Umsetzung und Programmierung zuständig. Fachinformatiker:in mit der Spezialisierung Anwendungsentwicklung arbeiten in der Softwareentwicklung: Sie konzipieren und programmieren Anwendungen und Benutzeroberflächen – entweder für den eigenen Betrieb oder für Kunden. Sie entwickeln dabei unter Umständen auch KI-gestützte Software, wie etwa Chatbots. Mathematisch-technische Softwareentwickler:in : Mithilfe mathematischer Modelle entwerfen sie Softwaresysteme, programmieren und warten diese. Dabei verwenden sie auch KI-Modelle. Arbeitsorte sind größere Unternehmen, Softwarehäuser und Forschungseinrichtungen. Als inklusive Optionen für Menschen mit Behinderung bieten sich eine Ausbildung zum Fachpraktiker oder Fachpraktikerin für IT-Systemelektronik oder IT-Systemintegration an. Mehr Frauen in die KI-Entwicklung In vielen MINT-Fächern überwiegen männliche Studierende. Immer wieder zeigen Studien wie diese aus dem Jahr 2022 , dass sich Frauen nicht für das Studium eines MINT-Faches gerüstet fühlen. Kinga Schumacher ist es deshalb ein persönliches Anliegen, dass sich junge Frauen nicht von einer Karriere im Bereich KI abschrecken lassen. Auch aufgrund ihrer persönlichen Erfahrung. »Als ich studiert habe, hieß es jeden Tag: Guten Morgen Frau Schumacher, guten Morgen meine Herren«, erzählt sie. »Ich konnte nicht mal schwänzen, weil ich eigentlich immer die einzige Frau war.« Inzwischen habe sich viel getan. Sie selbst habe inzwischen ein kleines Team mit überwiegend Frauen. Mehr Diversität sei in der KI-Entwicklung unheimlich wichtig: »Wenn wir KI-Systeme für Menschen entwickeln, die nicht diskriminierend und für alle gleich gut sein sollen, dann benötigen wir eben auch diverse Teams.« Anmerkung der Redaktion : In einer früheren Version des Textes konnte der Eindruck entstehen, die Mathematik sei lediglich Grundlage der Informatik. Es gibt jedoch auch Studiengänge im Bereich der KI, die in der Mathematik angesiedelt sind. Wir haben den Text entsprechend ergänzt."
Artificial Intelligence,Spiegel Online,2024-01-30,https://www.spiegel.de/netzwelt/gadgets/samsung-galaxy-s24-ultra-im-test-ki-ist-jetzt-fast-ueberall-a-80c24e44-baf7-4b40-94f9-542a74dcf87b,Samsung Galaxy S24 Ultra im Test: KI ist jetzt fast überall - DER SPIEGEL,"Samsungs neues Top-Smartphone könnte sterbenslangweilig sein – wären da nicht die KI-Funktionen und die Aussicht, das Gerät auch im Jahr 2031 noch nutzen zu können. Dieser Text enthält sogenannte Affiliate-Links, über die der Verlag, aber nie der Autor individuell, bei Verkäufen eine geringe Provision vom Händler erhält. Beim Design hat sich Samsung von Apple inspirieren lassen und ist sich gleichzeitig selbst treu geblieben. So wie beim iPhone 15 Pro ( hier unser Testbericht ) wird der Rahmen des Galaxy S24 Ultra aus Titan hergestellt. Das robuste Metall fühlt sich angenehm weich an, liegt gut in der Hand. Einhändig bedienen kann man es trotzdem nicht, dafür ist der Bildschirm mit seinen 6,8 Zoll zu groß. Die grundlegende Form aber erinnert sehr an das Galaxy S23 Ultra vom vorigen Jahr ( hier unser Testbericht ). Auch die Anordnung der Kameras auf der Rückseite ist identisch, und der S Pen, mit dem man auf dem Bildschirm schreiben, zeichnen und malen kann, ist an der gleichen Stelle im Gehäuse untergebracht. Der kleine Stift funktioniert übrigens trotz seiner billig wirkenden Machart hervorragend. Wer gern handschriftliche Notizen macht – was ich nicht tue – wird damit gut klarkommen. Guck mal Eine sichtbare Verbesserung ist das neue Design des Bildschirms. Das Display des S23 Ultra war an den Rändern ganz leicht gebogen. Der Bildschirm des S24 Ultra ist nun – endlich – vollkommen flach und lässt sich bis zum Rand hin nutzen. Die Ära der gebogenen Bildschirme dürfte damit vorbei sein. Weshalb Samsung diesen Schritt nicht schon im vergangenen Jahr gegangen ist, ist mir schleierhaft. Alles andere als schleierhaft ist dagegen der Bildschirm selbst. Wie der des Vorgängers ist er knackscharf, verfügt über 3120 mal 1440 Pixel, kann die Bildwiederholfrequenz von einem Bild pro Sekunde beim Lesen auf bis zu 120 Bilder pro Sekunde beim Scrollen und Spielen variieren. Der Sinn dahinter: je weniger Bilder das Display anzeigen muss, desto weniger Energie benötigt es. Viel Energie geht drauf, wenn man das Handy bei praller Sonne benutzt. Das Display erreicht dann punktuell eine Spitzenhelligkeit von 2600 Nits, 200 mehr als das Pixel 8 Pro und 600 mehr als das iPhone 15 Pro. Das ist hell, sehr hell. Pixel statt Linsen Wie das Design vermuten lässt, hat sich bei den Kameras nicht viel getan. Wie schon das S23 Ultra verfügt das S24 Ultra über eine Weitwinkelkamera mit 200 Megapixeln. Deren volle Auflösung ist aber nur selten von Nutzen. Einzig bei sehr hellen Motiven kann es sinnvoll sein. Die vollen 200 Megapixel zu verwenden. Die besseren Fotos erreicht man im 12-Megapixel-Modus, in dem je 16 Sensorpixel zu einem Bildpixel kombiniert werden. Eine Auflösung von 12 Megapixeln hat ebenfalls die Ultraweitwinkelkamera, die Dreifach-Telekamera muss sich mit 10 Megapixeln begnügen. Neu ist, dass die zweite Telekamera jetzt 50 statt 10 Megapixel hat und ihr optisches Zoomobjektiv nur auf eine fünffache Vergrößerung kommt. Im Vorgänger steckte noch eine Zehnfach-Zoom. Das macht skeptisch. Hat Samsung das große Tele beschnitten? Die Antwort lautet ja, aber beschnitten werden nun die Aufnahmen: Statt per Objektiv ans Motiv heranzuzoomen, wird bei Zoomstufen über dem Faktor fünf eine 50-Megapixel-Aufnahme des Fünffach-Zooms so beschnitten, dass der per Zoomfunktion gewählte Ausschnitt übrig bleibt. Das klingt wie Schummeln, klappt aber bis zum Zehnfach-Zoom gut – wenn es hell genug ist. Bei Dunkelheit sollte man diesen Digitalzoom lieber nicht benutzen. Künstliche Intelligenz – überall ein bisschen Anders als bei der Hardware gibt es in der Software der S24-Serie viele Neuerungen in Form von KI-Funktionen. Künstliche Intelligenz, die das Unternehmen penetrant dem englischen Begriff Artificial Intelligence folgend als AI bezeichnet, ist fast allgegenwärtig. Die KI – oder eben AI – findet man in den Geräten der S24-Serie in der Kamera, dem Notizbuch, der Telefonfunktion und mehr. Wohl, um alles zum Thema zu sammeln, findet man in den Einstellungen unter »Erweiterte Funktionen« die KI-Optionen nun unter der Bezeichnung »Moderne KI-Funktionen«. Samsungs KI-Assistenten Bixby, der unterhalb dieses Menüeintrags aufgeführt wird, kann man demnach den alten KI-Funktionen zuordnen. Zu den alten KI-Funktionen zählt im Grunde auch vieles, was in der Foto-App vor sich geht. Da wäre zum Beispiel die Möglichkeit, im Bild nicht erwünschte Objekte mit dem Finger oder dem S Pen einzukreisen und zu löschen. Das Besondere dabei: Statt einen weißen Fleck im Bild zu hinterlassen, füllt generative KI die Fehlstelle mit einem zur Umgebung passenden Hintergrund. Google bietet eine solche Funktion seit Langem als »magischen Radierer« an. Solange man sich auf kleine Bildbereiche beschränkt, funktioniert das gut, schnippelt man großflächig herum, fallen der KI keine sinnvollen Füllmuster ein und sie halluziniert sich einen Hintergrund zusammen. Besser ist die generative KI eingesetzt, wenn man einen Schnappschuss nachträglich um ein paar Grad drehen möchte, weil das Bild schief ist. Bisher wurde das Foto in solchen Fällen auf ein verkleinertes Rechteck zusammengestutzt, um die Ecken abzuschneiden, die keinen Inhalt hatten. Auf den S24 produziert die KI jetzt zum Bildrand passende Füllstücke, damit die Aufnahme ihre ursprüngliche Größe behält. Spiegelungen ein Ende setzen Mehr amüsant als nützlich ist, dass Samsungs Software derart manipulierte Bilder mit einem kleinen Symbol markiert, das als Wasserzeichen links unten im Bild eingebaut wird. Mit der KI-Löschfunktion kann man dem nicht beikommen, weil die ein neues Wasserzeichen hinterlassen würde. Der leichtere Weg ist ohnehin, die Linke Ecke einfach von Bild abzuschneiden, um die Manipulation unkenntlich zu machen. Was sehr nützlich sein kann, aber nicht immer perfekt funktioniert, ist die Möglichkeit, Reflexionen zu löschen, wenn man durch spiegelnde Fenster fotografiert hat. Leider haben Samsungs User-Interface-Spezialistinnen und -Spezialisten diese Option gut versteckt. Zu finden ist sie in der »Galerie«-App, indem man auf das eingekreiste »i« tippt und einen Moment wartet, bis die Software das Bild analysiert hat und Bearbeitungsvorschläge einblendet. Auf dieselbe Weise kann man nachträglich eine Hintergrundunschärfe hinzufügen, die manchen Bildern einen Spiegelreflex-Look geben kann. Worum geht’s in diesem Text? Nicht nur Bilder, auch Texte kann man von der KI in Samsungs neuen Smartphones bearbeiten lassen. Was prima funktioniert: Als Textwurst eingetippte Notizen ansprechend formatieren und Texte wie etwa Sitzungsmitschnitte zusammenfassen lassen. Vor allem Letzteres hat sich bei mir schon nach wenigen Tagen als extrem nützliches Tool erwiesen, um etwa abzuschätzen, ob es sich lohnt, einen langen Text in Gänze zu lesen. Schade, dass das nur in der Notiz-App und Samsungs Webbrowser funktioniert und auch da nur mit Texten, die frei von Bezahlschranken sind. Dafür kann die KI auch PDF-Dateien zusammenfassen, nachdem man sie in die Notizen-App importiert hat. Mehr als rund drei Textseiten sind der künstlichen Intelligenz aber zu viel. Maßvoll Multilingual Nicht ganz so beeindruckend arbeiten die Dolmetsch- und Übersetzungsfunktionen. Die Möglichkeit, etwa Telefonate mit anderssprachigen Menschen von der KI dolmetschen zu lassen, erfordert Geduld. Statt in Echtzeit erfolgt die Übersetzung mit Wartezeit. Und auch dass nur korrekt, wenn man klar, deutlich und nicht zu schnell spricht. Der Erfolg solcher Telefonate hängt aber vor allem davon ab, ob die Angerufenen die KI und ihre Eigenheiten verstehen und akzeptieren. Schon die ein solches Gespräch einleitende Computerstimme, die auf die Übersetzung per Computer hinweist, könnte den einen oder die andere abschrecken. Abschreckend waren zumindest teilweise auch meine Versuche, anderssprachige Texte transkribieren und dann übersetzen zu lassen. Ein Mitschnitt aus dem koreanischen Fernsehen ließ mich vollkommen ratlos zurück, ein Ausschnitt aus einer amerikanischen Talkshow war zwar nicht elegant, aber immerhin verständlich übersetzt. Die KI-Zusammenfassung davon enthielt tatsächlich alles Wichtige. Das Problem einkreisen Die KI-Funktion, die ich während der Testphase am häufigsten genutzt habe, heißt allerdings Circle to Search. Und auch wenn Samsung bei seinen Präsentationen der S24-Serie den Eindruck zu vermitteln versuchte, das sei eine Samsung-Erfindung, stammt dieses Feature doch von Google und wird ab dem 31. Januar auch auf dem Pixel 8 und 8 Pro ( hier unser Testbericht ) verfügbar sein. Das Charmante an dieser Funktion ist ihre Einfachheit. Egal, was auf dem Bildschirm angezeigt wird: Drückt man kurz in der Mitte unten auf den Bildschirm, wird eine Art virtuelle Klarsichtfolie über das Display gelegt, auf der man per Finger oder S Pen das Objekt einkreist, über das man mehr wissen will. Die KI durchwühlt daraufhin das Web und zeigt oft, aber nicht immer, akkurat an, was man da sieht. Die Funktion erinnert an Google Lens, eröffnet dadurch, dass sie immer verfügbar ist, aber ganz andere Möglichkeiten. Was für eine Jacke trägt der Hauptdarsteller in dem Film? In welcher Stadt hat meine Freundin das Selfie gemacht, dass ich auf Instagram gesehen hab? Wie heißt das Haus, vor dem ich stehe? Wenn sie groß genug erkennbar sind, lassen sich auf diese Weise auch Wörter und Begriffe suchen. Einfacher kann man sich nicht durch die Welt googeln. Wie schnell es ist? Schnell genug Wie immer baut Samsung in sein Topmodell den aktuell schnellsten Qualcomm-Prozessor in einer Samsung-Version ein, die ein klein wenig übertaktet ist. So ist sichergestellt, dass das Gerät in Benchmarktests immer vorne liegt. Da solche Leistungsvergleiche nur ein theoretisches Bild liefern, belassen wir es mit der Feststellung: Das Galaxy S24 Ultra ist schnell genug. Fast immer. Wartezeiten gibt es vor allem bei KI-Funktionen, wie etwa der Transkription von Texten. Updates bis ins nächste Jahrzehnt Samsung liefert alle Modelle der S24-Serie mit Android 14 aus, dem die hauseigene Benutzeroberfläche One UI übergezogen wurde. Dass der Konzern als einer von wenigen Herstellern auf seinen neuen Geräten das aktuelle Google-Betriebssystem installiert, ist löblich. Honor etwa liefert sein teures Faltsmartphone Magic V2 ( hier unser Testbericht ) noch mit Android 13 aus. Noch wichtiger ist aber, dass Samsung verspricht, die Geräte sieben Jahre lang mit Android-Updates zu versorgen. Da macht es dann auch Sinn, dass es jetzt schon Wi-Fi 7 beherrscht, einen WLAN-Standard, für den es bisher kaum Hardware gibt. Ähnlich lange Update-Laufzeiten haben bisher nur Google für die Pixel 8 und 8 Pro sowie Fairphone in Aussicht gestellt. Ausreichend Ersatzteile und vor allem Austauschakkus vorausgesetzt, dürfte man demnach noch im Jahr 2031 ein Update installieren. Angesichts bisheriger Produktzyklen eine ebenso irritierende wie aus ökologischer Sicht berauschende Vorstellung. Fazit 👍 Sehr guter Bildschirm 👍 Nützliche KI-Funktionen 👍 Gute Akkulaufzeit 👍 Lange Update-Versorgung 👎 Hoher Preis Mit dem Galaxy S24 Ultra hat Samsung das derzeit wohl beste Android-Smartphone am Start. Die Hardware ist vom Feinsten, die neuen KI-Funktionen sind zum Teil wirklich nützlich. Vor allem geben sie einen Ausblick darauf, was in Zukunft möglich sein wird, wenn die Kinderkrankheiten etwa beim Dolmetschen kuriert sind. Mit dem Versprechen, dass das Gerät sieben Jahre lang Updates bekommen wird, kann man sich vielleicht sogar den hohen Preis schönreden. Der nämlich ist gegenüber dem S23 Ultra um 50 Euro auf 1449 Euro gestiegen. Wohlgemerkt für die Einstiegsversion mit 256 Gigabyte (GB) Speicher. Die Variante mit 512 GB kostet 1569 Euro, das 1-Terabyte-Modell 1809 Euro. Bis zum 31.1. bietet Samsung die beiden kleinen Modelle noch mit doppeltem Speicher an, die Terabyte-Variante zum 512-GB-Preis. Über welche Produkte wir in der Netzwelt berichten und welche wir testen oder nicht, entscheiden wir selbst. Für keinen der Testberichte bekommen wir Geld oder andere Gegenleistungen vom Hersteller. Es kann aus verschiedenen Gründen vorkommen, dass wir über Produkte nicht berichten, obwohl uns entsprechende Testprodukte vorliegen. Testgeräte und Rezensionsexemplare von Spielen bekommen wir in der Regel kostenlos für einen bestimmten Zeitraum vom Hersteller zur Verfügung gestellt, zum Teil auch vor der offiziellen Veröffentlichung. So können unsere Testberichte rechtzeitig oder zeitnah zur Veröffentlichung des Produkts erscheinen. Vorabversionen oder Geräte aus Vorserienproduktionen testen wir nur in Sonderfällen. In der Regel warten wir ab, bis wir Testgeräte oder Spielversionen bekommen können, die mit den Verkaufsversionen identisch sind. Wenn sie bereits im Handel oder online verfügbar sind, kaufen wir Produkte in einigen Fällen auf eigene Kosten ein. In der Regel werden Testgeräte nach dem Ende des Tests an die Hersteller zurückgeschickt. Die Ausnahme sind Rezensionsexemplare von Spielen und langfristige Leihgaben: So haben wir zum Beispiel Spielekonsolen und Smartphones in der Redaktion, die wir über längere Zeit nutzen dürfen. So können wir beispielsweise über Softwareupdates, neues Zubehör und neue Spiele berichten oder Langzeiturteile fällen. Oft werden Rezensionsexemplare am Ende eines Jahres zum Beispiel gesammelt und im Rahmen eines firmeninternen Flohmarktes verkauft, wobei die Erlöse für gemeinnützige Zwecke gespendet werden. Teilweise werden sie auch direkt an gemeinnützige Einrichtungen gespendet. Die Kosten für Reisen zu Veranstaltungen, egal ob sie in Deutschland oder im Ausland stattfinden, trägt DER SPIEGEL stets selbst. Das gilt auch dann, wenn beispielsweise aufgrund kurzfristiger Termine ein Unternehmen die Reiseplanung übernimmt. Veranstaltungen, zu denen wir auf eigene Kosten reisen, sind unter anderem die Messen Ifa, CES, E3 und Gamescom, Entwicklerveranstaltungen wie die Google i/O, WWDC und Build sowie Events von Firmen wie Apple, Google, Microsoft oder Nintendo. Auf Konferenzen wie dem Chaos Communication Congress oder der re:publica bekommen wir in der Regel, wie auch andere Pressevertreter, kostenlose Pressetickets, da wir über die Konferenz berichten und keine klassischen Teilnehmer sind. Seit Dezember 2016 finden sich in einigen Netzwelt-Artikeln sogenannte Affiliate-Anzeigen, die sogenannte Links zu Onlineshops enthalten. Besucht ein Nutzer über einen solchen Link einen dieser Shops und kauft dort online ein, wird DER SPIEGEL, aber nie die Autorin oder der Autor individuell, in Form einer Provision an den Umsätzen beteiligt. Diese Provision wird vom Händler gezahlt, nicht vom Hersteller des Produkts. Die Anzeigen tauchen in Artikeln unabhängig davon auf, ob ein Produkttest positiv oder negativ ausfällt. Eine ausführliche Erklärung zu Affiliate-Links finden Sie, wenn Sie auf diesen Link klicken . Der Porträtmodus funktioniert bei Hunden recht gut und … … bei Friseurpuppen sowieso. Nahaufnahme eines im Wind wackelnden Astes: Da muss der Autofokus wohl schnell sein. Aufnahme eines schon viel zu lange herumstehenden Weihnachtsgestecks im dunklen Wohnzimmer, so wie die Kamera-App die Szene sieht … … und was die Fotosoftware daraus macht. Natürlich kann man auch mit dem S24 Ultra Nahaufnahmen vom Mond machen, wenn man den Zoomfaktor 100 auswählt. Wie echt sie sind, ist Thema vieler Diskussionen . Ein Gartenzwerg. Nicht irgendeiner, sondern Fritz. Aufgenommen mit der Ultraweitwinkelkamera des Galaxy S24 Ultra. Hier wurde Fritz mit dem 200-Megapixel-Weitwinkelobjektiv aufgenommen, aber mit 12-Megapixel-Auflösung. Die maximale optische Näherung, das Fünffach-Zoom Eigentlich eine Ausschnittvergrößerung, aber sehr gelungen: der Zwerg im Faktor 10. Nicht gerade sensationell: der Zoomfaktor 10 vor Sonnenaufgang Übersetzung von Koreanisch ins Deutsche, in diesem Beispiel nur Kauderwelsch Besser klappte es im Test von Englisch ins Deutsche, aber perfekt war auch das nicht Die Zusammenfassung enthielt trotzdem alle wichtigen Punkte Volltreffer: Hier hat Circle to Search den Schnappschuss genau richtig erkannt. Bei diesem Foto eines freundlichen Trainingsballs fand die KI immerhin ähnlich aussehende Bälle – deren Aufnahmen aber stets nur als Symbolfotos genutzt wurden. Aber hier ließ sie sich von einem Baugerüst foppen, identifizierte das Hamburger Haus der Photographie als Philharmonie Stettin. Noch eine Niete: Statt einer Schweizer Leckerei vermutete die KI unter der Alufolie Druckertoner oder doch einfach irgendwas mit Alufolie."
KI,Spiegel Online,2024-02-02,https://www.spiegel.de/netzwelt/netzpolitik/ai-act-gruenen-politikerin-franziska-brantner-ueber-ki-gesetz-es-geht-um-unsere-grundrechte-a-411c0425-a113-4026-95d8-eac784502bbf,AI Act: Grünen-Politikerin Franziska Brantner über KI-Gesetz - »es geht um unsere Grundrechte« - DER SPIEGEL,"Die Grünenpolitikerin Franziska Brantner hat das KI-Gesetz der EU mitverhandelt. Im Gespräch erklärt sie, warum sie den jetzigen Kompromiss für gelungen hält und was sich für ChatGPT-Nutzer ändern wird. SPIEGEL: Frau Brantner, Sie haben das erste Gesetz einer westlichen Wirtschaftsmacht zu künstlicher Intelligenz mitverhandelt, den AI Act der Europäischen Union. Im Jahr 2026 könnten die Regelungen wirksam werden. Kommt das nicht viel zu spät? Franziska Brantner: Nein, wir sind gut in der Zeit. Wir haben in der EU rechtzeitig angefangen und schon vor vielen Monaten begonnen, an einem KI-Gesetz zu arbeiten. Ende 2022 kam dann ChatGPT auf den Markt und hat gezeigt, dass KI bereits zu einem gewissen Grad menschliche Aufgaben übernehmen kann. Ein so wirkmächtiges System hatte es vorher nicht gegeben. Aber auch diese neue Technologie hat der AI Act nun im Blick. SPIEGEL: Der finale Entwurf für das Gesetz ist seit Kurzem bekannt und die Kritik ist groß. Den einen geht er zu weit, den anderen ist er zu lasch. Nun stehen die finalen Abstimmungen in Rat und Parlament an. Droht das Gesetz zu scheitern? Die Grünenpolitikerin Franziska Brantner , Jahrgang 1979, ist Staatssekretärin im Bundesministerium für Wirtschaft und Klimaschutz. Von 2009 bis 2013 war sie Abgeordnete im Europaparlament, seit 2013 ist sie Bundestagsabgeordnete, zwischen 2017 und 2021 war sie europapolitische Sprecherin der Grünen-Bundestagsfraktion. Sie lebt in Heidelberg und Berlin. Brantner: Ich hoffe nicht. Klar ist: Dieses Gesetz muss unterschiedlichste Interessen austarieren. Einerseits wollen wir die Innovationspotenziale nutzen, die KI bietet: für unsere Gesundheit, in der Forschung, zur Automatisierung von Aufgaben. Andererseits müssen wir die Risiken in den Griff bekommen. Nehmen Sie zum Beispiel die automatische Emotionserkennung am Arbeitsplatz: Niemand will, dass eine KI ständig auswertet, ob Herr Schmidt gerade grimmig guckt – womöglich während er die E-Mail des Chefs liest. Solche Anwendungsfälle haben wir verboten. SPIEGEL: Aus Ihrer Sicht ist die Kritik von verschiedenen Seiten ein Beleg für dessen Ausgewogenheit? Brantner: Es ist nie einfach, sehr unterschiedliche Interessen in eine gute Balance zu bringen, insbesondere nicht bei der komplexen Regulierung einer hochdynamischen Technologie, die quasi alle Bereiche des Lebens betrifft. Ich gebe Ihnen noch ein Beispiel: Urheberrecht. Künstliche Intelligenz wird trainiert mit Unmengen an Bildern, Informationen und Texten, damit sie selbst nach den Vorgaben des Nutzers Bilder und Texte erstellen kann. Es ist faszinierend, wie gut KI das schon kann. Aber es stellt sich eben die Frage: Wenn eine KI mit Bildern eines bestimmten Künstlers trainiert wurde und dann Bilder in dessen Stil erzeugt, wer hat dann die Rechte daran? Auch hier mussten wir eine Balance finden. Hersteller müssen künftig transparent machen, mit welchen Daten sie die KI trainiert haben. Urheber wiederum haben Möglichkeiten, zu verhindern, dass ihre Werke von der KI ausgelesen werden. SPIEGEL: Besonders heftig diskutiert wird die automatische Gesichtserkennung . Daran haben gerade Strafverfolgungsbehörden ein großes Interesse. Bürgerrechtlern gehen die Befugnisse dagegen viel zu weit. Brantner: Grundsätzlich verbietet die KI-Verordnung Videoüberwachung in Echtzeit mittels KI-gestützter Gesichtserkennung. Es gelten Ausnahmen beispielsweise für die Suche nach Vermissten oder die Verhinderung einer unmittelbaren terroristischen Bedrohung. Und für die nachträgliche Auswertung von Videomaterial mit KI gibt es strenge Regeln. In beiden Fällen muss ein Richter oder eine entsprechende Behörde zustimmen, der Vorgang muss bei der Polizei registriert werden und Datenschützer müssen Zugang zu den Systemen haben. Wenn die Mitgliedsländer wollen, können sie die Vorgaben sogar noch weiter verschärfen. SPIEGEL: Klingt, als wären Sie mit der Regelung ganz zufrieden. Brantner: Ja. Wir schaffen damit erstmals einen europäischen Mindeststandard für die Regeln bei KI-basierter, automatischer Gesichtserkennung. Darüber bin ich froh. Denn diese Vorgaben gelten dann auch überall in der Union. SPIEGEL: Innerhalb der Bundesregierung gab es bis zuletzt noch heftige Diskussionen über das Gesetz . Insbesondere aus der FDP soll es Widerstand gegeben haben. Was war da los? Brantner: Die Beispiele, die ich genannt habe, zeigen ja: Die KI-Verordnung berührt Grundlagen unserer demokratischen und wirtschaftlichen Ordnung – es geht um die Grundrechte jeder und jedes Einzelnen, um geistiges Eigentum, die Freiheit der Forschung und unsere Innovationsfähigkeit. All das musste in Balance gebracht werden, und das geht nicht ohne Diskussionen. SPIEGEL: Und wie sieht der Kompromiss der Koalition nun aus? Brantner: Wir haben den Text intensiv geprüft und uns darauf verständigt, dass die Bundesregierung der KI-Verordnung in Brüssel zustimmen wird. Damit haben wir frühzeitig ein klares Signal für Handlungsfähigkeit und Rechtssicherheit gesendet. SPIEGEL: Vergangenes Jahr warnten zahlreiche Techgrößen vor potenziellen Gefahren für die Menschheit . Ein bisschen klang das nach der Sorge, die KI könnte die Weltherrschaft übernehmen. Haben Sie so etwas im Kreise der Mitgliedstaaten diskutiert? Brantner: Nein, zumindest nicht in den Gesprächen, an denen ich beteiligt war. Ein Risiko, das ich aber für durchaus real halte, ist, dass Anbieter gehackt werden, die wirkmächtige KI-Systeme betreiben. Das kann potenziell enormen Schaden anrichten. Deshalb ist es wichtig, dass wir hier Vorgaben machen, damit Anbieter von Hochrisiko-KI sich entsprechend schützen. Wenn Sie ein Chemielabor haben, das mit hochgiftigen Stoffen arbeitet, müssen Sie ja auch sicherstellen, dass da nicht jeder reinlaufen kann. Auch unsere kritische Infrastruktur, beispielsweise unsere Energiesysteme, schützen wir entsprechend. Das muss für KI-Anbieter genauso gelten. Andere Risiken haben wir versucht auszuschließen, indem wir bestimmte Anwendungsfälle ganz verboten haben. SPIEGEL: Welche? Brantner: Social Scoring zum Beispiel. In China wird das Verhalten der Menschen dazu genutzt, um ihre angebliche Vertrauenswürdigkeit zu errechnen. Das haben wir komplett verboten. Und dann gibt es Anwendungsbereiche, bei denen wir sagen, sie sind so heikel, dass sie reguliert werden müssen. Etwa, wenn KI bei der Personalauswahl eingesetzt wird. Dann muss dafür gesorgt werden, dass sie nicht diskriminierend ist. Damit eine Frau mit dem Vornamen Özlem die gleichen Chancen hat wie eine mit dem Vornamen Franziska. SPIEGEL: Sie haben vorhin schon das Beispiel Emotionserkennung angesprochen, also dass eine KI die Mimik einer Person auswertet und Schlüsse daraus zieht. Das soll am Arbeitsplatz verboten sein. Aber nicht überall. Gibt es denn hier überhaupt Anwendungsfälle, die unbedenklich sind? Brantner: In bestimmten Fällen kann es sinnvoll sein. Beispielsweise bei medizinischen Systemen im therapeutischen Bereich. SPIEGEL: Ab wann gilt eine KI als Hochrisiko-KI und bekommt besonders strenge Vorgaben? Brantner: Für die Einstufung als Hochrisiko-KI sieht die KI-Verordnung verschiedene Kriterien vor, das ist im Text und dem entsprechenden Anhang geregelt. Zum Beispiel betrifft das KI-Systeme aus dem medizinischen Bereich, der kritischen Infrastruktur und dem Bildungsbereich. Ausnahmen gibt es für Systeme, von denen kein bedeutendes Risiko für die Gesundheit, Sicherheit und die Grundrechte ausgeht. Das ist ein wichtiger Punkt für die Unternehmen und Innovatoren. Im Übrigen gibt es bei KI-Modellen nun die Kategorie der KI-Modelle mit systemischen Risiken, die strengeren Vorgaben unterliegen. Bei diesen Modellen bestimmt die Zahl der Rechenoperationen, die notwendig ist, um ein KI-Modell zu trainieren, darüber, wie potent und wirkmächtig es ist – und damit auch, wie potenziell riskant. Technisch gesehen gilt ein universell einsetzbares KI-Modell nun als riskant, wenn der kumulative Rechenaufwand für das Training mehr als 10 25 Flops – also Gleitkommaoperationen – beträgt. SPIEGEL: So ein Maßstab kann aber schnell veralten. Brantner: Deshalb ist das auch nicht der einzige Faktor. Die Kommission hatte diesen Vorschlag im Herbst gemacht, und dann haben wir zusammen mit Frankreich und Italien gesagt, dass wir diese Grenze nicht plausibel finden. Jetzt wird unter anderem auch die Zahl der Anwenderinnen und Anwender eine Rolle spielen. Und wir haben die Möglichkeit eröffnet, dass andere Kriterien hinzukommen, auch auf Empfehlung der Forschungscommunity. Außerdem steht jetzt im Verordnungstext, dass der »state of the art« berücksichtigt werden muss – also dass immer der aktuelle Stand der Technik als Maßstab gilt. Der technologische Fortschritt wird eingepreist. SPIEGEL: Können Sie Beispiele nennen für KI-Anwendungen, die als Hochrisiko-KI gelten würden? Brantner: Das sind zum Beispiel die Prüfung der Kreditwürdigkeit, oder Auswahlen bei Einstellungsverfahren. SPIEGEL: Kritiker befürchten, dass die Vorgaben der EU Innovationen abwürgen könnten. Die Sorge haben Sie nicht? Brantner: Forschung und Entwicklung sind vom Anwendungsbereich der Verordnung ganz klar ausgenommen. Das war uns wichtig, weil wir in Deutschland in diesem Bereich sehr gut sind und hier die Keimzelle von Innovationen liegt. Es geht auch hier um eine gute Balance zwischen legitimen Sicherheitsansprüchen, der Vermeidung von Bürokratie und Offenheit für die Technologie. Entscheidend ist dann, dass auch die Umsetzung der Verordnung bürokratiearm und innovationsfreundlich ist. Da werden wir als Bundesregierung ein besonderes Auge drauf haben. SPIEGEL: Was wird sich 2026 für eine Person ändern, die so etwas wie ChatGPT nutzt? Schon jetzt verwenden Menschen das Programm, um Bewerbungen zu schreiben oder Präsentationen für die Arbeit zu erstellen. Brantner: Wenn diese Person zum Beispiel ein Bild mit einer generativen KI erzeugt, dann müsste da ein Hinweis stehen, eine Art digitales Wasserzeichen. Diese Transparenz ist etwas, das die Menschen mitbekommen werden. Es dürfte für viele sogar der Hauptunterschied zur heutigen Situation sein. SPIEGEL: Glauben Sie, dass Anbieter wie OpenAI und Microsoft solche Produkte dann vorsichtshalber nicht mehr in der EU anbieten werden? Brantner: Das würde mich sehr wundern angesichts der großen Bedeutung des europäischen Markts. Wir sehen eher, dass sich die Amerikaner mit großem Interesse unser Gesetz anschauen und überlegen, was sie davon selbst verwenden können. SPIEGEL: Gewisse moralische Fragen werden im AI Act nicht verhandelt: Was soll KI künftig für uns erledigen? Soll sie journalistische Artikel für uns schreiben? Wollen wir, dass Schauspielerinnen oder Lehrer durch KI ersetzt werden? Brantner: Das sind hochrelevante Fragen für uns als Gesellschaft. Wir haben in Deutschland einen Arbeitskräftemangel. Das heißt, wir haben ein Interesse daran, dass ein Teil der Jobs durch KI ersetzt wird oder durch Roboter. Aber wir dürfen es nicht komplett dem Zufall überlassen, wo die besten KIs entstehen und eingesetzt werden. In der Bildung beispielsweise wollen wir sicher auch in Zukunft noch Menschen haben, die unseren Kindern etwas beibringen. Im Altersheim wiederum gibt es Aufgaben, die man durch KI ersetzen könnte und dadurch bekäme das Personal mehr Zeit für den direkten Kontakt mit den Bewohnern, um vielleicht mal wieder gemeinsam ein Brettspiel zu spielen. Es kommt jetzt darauf an, welche Anwendungen unsere Unternehmen entwickeln und voranbringen. SPIEGEL: Wo verständigt sich eine Gesellschaft über diese Fragen? Das kann ja nicht nur der Markt regeln. Brantner: Wir haben, wie gesagt, Bereiche ausgeschlossen, in denen KI nicht eingesetzt werden darf, weil wir es für zu gefährlich halten. Und Hochrisiko-Anwendungen müssen mit unseren Grundrechten vereinbar und diskriminierungsfrei sein. Im Rahmen dessen, was erlaubt ist, wird man dann, wie bei anderen Technologien und ihren Anwendungen sehen, wo Ressourcen und Geld hingehen. Auch bei KI hat Politik nicht die Aufgabe, überall zu entscheiden, was für Verbraucherinnen und Verbraucher, was für Unternehmen gut ist. Es werden sich die Produkte am Markt durchsetzen, die einen echten Mehrwert bieten. Und als Gesellschaft werden wir – wie bei anderen neuen Technologien auch – darüber diskutieren, wie wir die Chancen bestmöglich nutzen, ohne Risiken zu ignorieren. SPIEGEL: Welcher Punkt der finalen Fassung des AI Acts stört Sie am meisten? Brantner: Wir müssen bei der Umsetzung sehr gut darauf achten, dass die KI-Verordnung gut mit anderen Produktverordnungen wie zum Beispiel im Medizinbereich harmoniert und nicht zu unerwünschten Konsequenzen führt. SPIEGEL: Was steht auf dem Spiel, wenn das Gesetz scheitern sollte? Brantner: Dann gibt es keinerlei spezifische KI-Regulierung, keinerlei Standards und keine Planungssicherheit und es ist erstmal alles erlaubt, worüber wir gerade sprachen. Nationale Regierungen würden sicher anfangen zu regulieren und am Ende hätten wir einen Flickenteppich, der unseren Unternehmen das Leben schwer macht. Auf europäischer Ebene stehen im Sommer Wahlen an. Wer weiß, wie die Mehrheiten im Europäischen Parlament danach aussehen, ob diese dann wirklich die Grundrechte stärken wollen oder eher nicht. Nun muss sich jeder fragen, ob er lieber gar keine Regulierung hat oder eine, die unterschiedlichste Interessen in essenziellen Punkten in eine gute Balance gebracht hat."
KI,Spiegel Online,2024-02-01,https://www.spiegel.de/start/kuenstliche-intelligenz-informatik-oder-data-science-studieren-ki-studiengaenge-und-ausbildungen-a-26a8685d-e6f1-4625-bd23-cc307ecf33aa,Künstliche Intelligenz: Informatik oder Data Science studieren? - KI-Studiengänge und Ausbildungen - DER SPIEGEL,"Alle reden über künstliche Intelligenz, Fachleute sind auf dem Arbeitsmarkt gefragt. Welche Fächer man belegen muss, um neue Technologien mitzuentwickeln – und welche Fähigkeiten es dazu braucht. Spätestens mit ChatGPT ist künstliche Intelligenz in unserem Alltag angekommen. Egal, ob in der Medizin- oder Agrarindustrie: Die Entwicklung neuer Technologien mithilfe von KI bietet der deutschen Wirtschaft vielfältige neue Chancen. Kein Wunder also, dass Unternehmen händeringend nach KI-Spezialist:innen suchen. Mit der steigenden Nachfrage wächst auch das Angebot an Ausbildungswegen, die in das Berufsfeld führen. »Das Schöne ist, dass jeder in der KI-Entwicklung seinen Platz findet«, sagt Kinga Schumacher, Senior Researcherin am Deutschen Forschungszentrum für Künstliche Intelligenz (DFKI) in Berlin – ob beim fokussierten Programmieren oder in interdisziplinärer, kreativer Projektarbeit. Sie habe zu Beginn ihrer Karriere klassisch Informatik studiert, erzählt Schumacher. KI sei damals in den Nullerjahren noch kaum Thema gewesen. Heute sieht das anders aus. Informatik oder Data Science? – Der Weg in die KI-Entwicklung »Vor fünfzehn Jahren hätte ich Ihnen noch gesagt: Studieren Sie Informatik!«, sagt Schumacher. Inzwischen sei die Antwort nicht mehr so einfach, die Wege in die KI-Entwicklung sind vielfältig. Es gebe immer mehr Studiengänge, die sich auf spezielle Bereiche der künstlichen Intelligenz fokussieren, so die Forscherin. Meist sind das Formen der angewandten Informatik oder sie sind in der Mathematik angesiedelt. Welches Fach sich am besten eignet, sei eine Frage der persönlichen Neigungen. »Wenn ich gern rumbastele, dann studiere ich vielleicht Robotik, wenn ich zwei linke Hände habe, eher etwas Datenzentriertes«, sagt Schumacher. Bei Data Science etwa liegt der Fokus auf der Auswertung großer Datenmengen. In einem Studiengang Künstliche Intelligenz liege der Fokus dagegen mehr auf möglichen Anwendungsbereichen von KI, etwa Mobilität, Gesundheitswesen oder Chatbots. Die Grundlagen seien jedoch meist die gleichen, sagt Schumacher. Das betont auch Thomas Röser von der Berufsberatung der Agentur für Arbeit Aachen-Düren. Man solle sich von den vielen unterschiedlichen Fachrichtungen nicht abschrecken lassen. »Das ist wie in der BWL: Da heißt der Studiengang vielleicht Marketing – im Grunde genommen machen Sie aber auch BWL.« Wer sich früh spezialisieren möchte, könne seinen Bachelor in einem Anwendungsfach machen. Wer sich unsicher sei, dem rate er allerdings zum klassischen Grundstudium Informatik oder Mathematik. »Spezialisieren ja, aber warum schon im Bachelor?« Im Master könne man dann immer noch seinen Fokus setzen. Auch ein Wechsel sei innerhalb der unterschiedlichen Fächer meist unkompliziert. Was? Die klassische Informatik vermittelt Grundlagen der systemischen Verarbeitung von Informationen. Neben den grundlegenden Fächern der angewandten, praktischen und technischen Informatik kommen immer mehr Spezialisierungsfelder hinzu. Dazu gehört auch künstliche Intelligenz. Wo? An den meisten Hochschulen wird Informatik als Bachelor und Master angeboten, besonders an Technischen Hochschulen. Renommiert sind etwa die RWTH Aachen , die TU München oder die FU Berlin . In Deutschland gibt es über 600 Studienangebote. Was? Angewandte Informatik hat im Vergleich zum klassischen Fach meist eine stärkere Spezialisierung auf einen Anwendungsbereich. Eigentlich ist es ein Überbegriff für verschiedene spezialisierte Informatikstudiengänge, wie Medieninformatik oder Cybersecurity. Die Spezialisierung kann sich von Hochschule zu Hochschule stark unterscheiden. Voraussetzung sollte also ein Interesse am jeweiligen Schwerpunktthema sein. Wo? Mehr als 100 Hochschulen bieten Studiengänge in der angewandten Informatik an. Siehe unten. Was? Die Studiengänge Künstliche Intelligenz oder Artificial Intelligence sind von Anfang an auf KI fokussiert. Wo? Technische Hochschule Ingolstadt , Ostbayerische Technische Hochschule Amberg-Weiden , BTU Cottbus-Senftenberg , Uni Würzburg , TH Rosenheim , Hochschule Landshut , Hochschule Ansbach ; Master: Universität Ulm , THWS Würzburg , Uni Erlangen-Nürnberg , Uni Lübeck (Auswahl) Was? Data Scientists gewinnen mit Methoden der Mathematik, Informatik und Statistik Erkenntnisse aus großen Mengen von Daten. Ebenfalls ein Spezialisierungsbereich der Informatik. Wo? Uni Erlangen-Nürnberg , Uni Gießen , TU Dortmund , BHT Berlin , Uni Göttingen , TU Hamburg , Uni Hildesheim , Uni Marburg , LMU München , Uni Trier ; Master: Hochschule Darmstadt , Hochschule Harz , RWTH Aachen , FU Berlin , Uni Bielefeld , TU Braunschweig , TU Chemnitz , Hochschule Coburg , Hochschule Fulda , Hochschule Bielefeld , Fernuni Hagen , FH Kiel , Hochschule Anhalt , Uni Leipzig , Uni Mannheim , UE Innovation Hub Potsdam , Uni Potsdam , IU Internationale Hochschule Erfurt , (Auswahl) Was? Machine Learning ist ein Teilbereich der künstlichen Intelligenz. Algorithmen erkennen Muster in Datensätzen und entwickeln daraus Lösungen. Wo? Den Studiengang gibt es bislang als Masterstudium an der Uni Tübingen und als Artificial Intelligence and Machine Learning an der TU Darmstadt . Was? Medieninformatik ist eine Variante der angewandten Informatik und hat einen berufsorientierten Praxisbezug. Der Studiengang konzentriert sich auf die digitale Informationsverarbeitung in Medien – etwa Computerspielen, Onlineplattformen oder Apps. Der Schwerpunkt liegt auf Multimedia und Softwaretechnik, es kommen aber auch interdisziplinäre Themen dazu wie Mediengestaltung und Wahrnehmungspsychologie. Künstliche Intelligenz ist hier nur eines der möglichen Themenfelder. Wo? Den Studiengang gibt es vergleichsweise häufig, der thematische Schwerpunkt variiert. Bachelorstudiengänge gibt es etwa an der TU Dresden , der LMU München , der Universität des Saarlandes oder der Uni Tübingen . Was? Ein angewandtes Studium der Informatik mit Schwerpunkt auf Robotern und autonomen Systemen, zum Beispiel autonomen Fahrzeugen. Wo? Bachelorstudiengänge gibt es etwa an der Uni Lübeck , der TH Ingolstadt , FH Südwestfalen , HS Kempten , THWS Schweinfurt , EAH Jena oder an der TH Deggendorf . Einen Master in angewandter Robotik gibt es an der HTW Dresden , Neurobotik an der TU Chemnitz . Artificial Intelligence and Data Science : Universität des Saarlandes ; Master: Heinrich-Heine-Universität Düsseldorf , TH Deggendorf , Hochschule Neu-Ulm , Universität Stuttgart , Hochschule Trier Beispiele für weitere Kombinationsfächer oder Spezialisierungen : Computer Science an der TU Darmstadt , Angewandte Data Science und Künstliche Intelligenz in Stralsund , Artificial Intelligence for Smart Sensors and Actuators an der TH Deggendorf , Angewandte Künstliche Intelligenz und Digitale Transformation an der HS Ansbach , Mind, Brain and Behavior an der Uni Gießen , Digital Technologies an der TU Clausthal und Ostfalia Hochschule , KI und Computer Vision an der Hochschule Kempten , Artificial Intelligence Engineering an der Uni Passau , Angewandte Künstliche Intelligenz an der FH Südwestfalen (Auswahl) Voraussetzungen für KI-Studiengänge Eines haben jedoch alle Studiengänge gemeinsam, die auf die Entwicklung von künstlicher Intelligenz abzielen. »Um Mathematik kommen Sie nicht herum«, sagt Röser. Logisches Denken und gute mathematische Grundkenntnisse werden in allen Fachbereichen der Informatik gefordert. Auch gute Englischkenntnisse seien heutzutage zunehmend wichtig, sagt Röser. Eine erste Neugier und Affinität zu Programmierung sei ebenfalls hilfreich. An den hohen Abbruchquoten in der Informatik und verwandten Naturwissenschaften zeigt sich zudem, wie wichtig strukturiertes Arbeiten und Durchhaltevermögen sind. Wer vor Mathematik zurückschreckt und technisch weniger versiert ist, kann sich der KI-Forschung über Umwege nähern. KI-Entwicklerin wird man dann vielleicht nicht – aber man arbeitet mit ihnen zusammen. »Wir haben auch bei uns am Forschungsinstitut Quereinsteiger:innen aus anderen Fachrichtungen«, sagt Forscherin Schumacher. Häufig kämen die aus der Mathematik, Physik und Chemie, aber auch die Psychologie sei in der KI-Entwicklung unheimlich wichtig. An der Beschäftigung mit KI im weitesten Sinne kommt man 2024 ohnehin nicht mehr ganz vorbei. In keinem Fachbereich. Was suchen die Unternehmen? Auch die Wirtschaft ist Taktgeber. KI-Spezialist:innen werden inzwischen in fast allen Branchen gesucht. Von Januar bis April vergangenen Jahres schrieben Arbeitgeber in Deutschland fast 44.000 Stellen mit KI-Bezug aus, so eine Auswertung der Personalagentur Index. Besonders gefragt waren demnach Informatiker:innen sowie Mitarbeitende im Bereich Forschung und Entwicklung. In Zukunft würden Unternehmen zudem stark nach Expert:innen angrenzender Fachbereiche suchen, sagt Berufsberater Röser. »KI allein ist nicht funktionsfähig. Geld wird ja mit den Produkten gemacht, die mittels KI funktionieren und gesteuert werden. Autonome Fahrzeuge etwa.« Auch ein Studium in den Fächern Maschinenbau, Elektrotechnik oder Energietechnik kann also indirekt in die KI-Entwicklung führen. Noch wichtiger als ein Master sei für die Unternehmen Praxiserfahrung, sagt Röser. »Das sehen Sie auch bei den Stellenangeboten. Häufig ist mehrjährige Erfahrung im Bereich der Softwareentwicklung gefragt.« Er empfehle deshalb häufig anwendungsbezogene Studiengänge und duale Angebote, etwa an der RWTH Aachen. Wer später in die Forschung möchte, kann sich an Forschungs- und Kompetenzzentren für künstliche Intelligenz orientieren (siehe Kasten). Inzwischen gibt es immer mehr Kooperationen zwischen den Zentren mit bestimmten Universitäten und Studiengängen. Das kann Synergien und Projekte schaffen und den Weg in die Forschung erleichtern. Standort : Berlin Partneruniversitäten : TU Berlin, TU Braunschweig, HU Berlin, FU Berlin, Uni Potsdam Mehr Informationen auf der Website des BIFOLD Standorte : Bremen, Kaiserslautern, Saarbrücken und Osnabrück Labore in Berlin und Darmstadt sowie Außenstellen in Lübeck und Trier Partneruniversitäten : RPTU Kaiserslautern-Landau, Universität des Saarlandes, Uni Bremen, Hochschule Bremen, TU Berlin, Uni Osnabrück, Hochschule Osnabrück, Uni Oldenburg, Jade Hochschule, Constructor University Bremen (privat), Uni Lübeck Das DFKI ist die bundesweit größte Forschungseinrichtung. Mehr Informationen auf der Website des DFKI Standort : München Partneruniversitäten : LMU München und TU München Mehr Informationen auf der Website des MCML Standort : Dortmund Partneruniversitäten : TU Dortmund und Uni Bonn Mehr Informationen auf der Website des LAMARR Standort : Dresden und Leipzig Partneruniversitäten : TU Dresden und Uni Leipzig Mehr Informationen auf der Website des ScaDS Standort : Tübingen Partneruniversitäten : Uni Tübingen Mehr Informationen auf der Website des AI Centers Die Zuse Schools werden vom Deutschen Akademischen Austauschdienst (DAAD) gefördert und jeweils von einer Technischen Universität betrieben. Aktuell gibt es die Graduiertenschulen an der TU Darmstadt, der TU Dresden und der TU München. Standort: Potsdam Das gemeinnützige, private Institut forscht und lehrt zu IT-Systems Engineering, Data Engineering und Digital Health in Kooperation mit der Uni Potsdam. Auch AI Grid ist ein Netzwerk zur Förderung von jungen Talenten in der KI-Forschung. Es koordiniert Nachwuchsprogramme im Informatik-Umfeld und hat seinen Sitz in Berlin. Der Forschungsverbund will in Baden-Württemberg privatwirtschaftliche Unternehmen und akademische Partner zusammenbringen, um die KI-Forschung voranzutreiben. Partner sind etwa das Max-Planck-Institut für Intelligente Systeme und das Fraunhofer-Institut. Zu den beteiligten Unternehmen gehören unter anderem Amazon, BMW oder Bosch. Partneruniversitäten : Uni Stuttgart und Uni Tübingen Ausbildungen im Bereich künstliche Intelligenz Auch eine Ausbildung bietet Berufsmöglichkeiten im Bereich der künstlichen Intelligenz. Infrage kommen insbesondere eine Ausbildung als Fachinformatiker:in mit der Spezialisierung Anwendungsentwicklung oder eine Ausbildung als Softwareentwickler:in. Hier ist man für die Umsetzung und Programmierung zuständig. Fachinformatiker:in mit der Spezialisierung Anwendungsentwicklung arbeiten in der Softwareentwicklung: Sie konzipieren und programmieren Anwendungen und Benutzeroberflächen – entweder für den eigenen Betrieb oder für Kunden. Sie entwickeln dabei unter Umständen auch KI-gestützte Software, wie etwa Chatbots. Mathematisch-technische Softwareentwickler:in : Mithilfe mathematischer Modelle entwerfen sie Softwaresysteme, programmieren und warten diese. Dabei verwenden sie auch KI-Modelle. Arbeitsorte sind größere Unternehmen, Softwarehäuser und Forschungseinrichtungen. Als inklusive Optionen für Menschen mit Behinderung bieten sich eine Ausbildung zum Fachpraktiker oder Fachpraktikerin für IT-Systemelektronik oder IT-Systemintegration an. Mehr Frauen in die KI-Entwicklung In vielen MINT-Fächern überwiegen männliche Studierende. Immer wieder zeigen Studien wie diese aus dem Jahr 2022 , dass sich Frauen nicht für das Studium eines MINT-Faches gerüstet fühlen. Kinga Schumacher ist es deshalb ein persönliches Anliegen, dass sich junge Frauen nicht von einer Karriere im Bereich KI abschrecken lassen. Auch aufgrund ihrer persönlichen Erfahrung. »Als ich studiert habe, hieß es jeden Tag: Guten Morgen Frau Schumacher, guten Morgen meine Herren«, erzählt sie. »Ich konnte nicht mal schwänzen, weil ich eigentlich immer die einzige Frau war.« Inzwischen habe sich viel getan. Sie selbst habe inzwischen ein kleines Team mit überwiegend Frauen. Mehr Diversität sei in der KI-Entwicklung unheimlich wichtig: »Wenn wir KI-Systeme für Menschen entwickeln, die nicht diskriminierend und für alle gleich gut sein sollen, dann benötigen wir eben auch diverse Teams.« Anmerkung der Redaktion : In einer früheren Version des Textes konnte der Eindruck entstehen, die Mathematik sei lediglich Grundlage der Informatik. Es gibt jedoch auch Studiengänge im Bereich der KI, die in der Mathematik angesiedelt sind. Wir haben den Text entsprechend ergänzt."
KI,Spiegel Online,2024-02-01,https://www.spiegel.de/netzwelt/web/gpt-4-erleichtert-den-bau-einer-biowaffe-nur-ein-ganz-klein-wenig-a-fe308006-082e-4d7b-b068-b826addd5b03,GPT-4 erleichtert den Bau einer Biowaffe nur ein ganz klein wenig – Studie von OpenAI - DER SPIEGEL,"Hilft eine KI, wenn man ein tödliches Virus entwickeln möchte? OpenAI hat untersucht, ob sein Sprachmodell GPT-4 in dieser Hinsicht schon eine Gefahr darstellt. OpenAI , das Unternehmen hinter ChatGPT, hat untersucht, ob seine derzeit fortschrittlichste künstliche Intelligenz missbraucht werden kann, um Biowaffen zu entwickeln. Das Ergebnis der Studie aus dem eigenen Haus : Das Sprachmodell GPT-4 könne den Entwicklungsprozess zum Teil etwas erleichtern, statistisch signifikant sei der Unterschied zu jemandem, der dafür nur das Internet nutzen kann, jedoch nicht. Die Untersuchung wurde in Form eines Vergleichstests durchgeführt. 100 Fachleute und Biologiestudierende wurden in zwei Gruppen aufgeteilt. In der einen Gruppe bekamen die Teilnehmenden Zugang zu einer nicht öffentlich verfügbaren Version von GPT-4, in der bestimmte Sicherheitsfunktionen und Filter deaktiviert waren. Die Kontrollgruppe hatte lediglich Zugang zum Internet. Verglichen wurde mithilfe von fünf Metriken, ob der Zugang zu GPT-4 von Vorteil ist. In den Metriken »Genauigkeit« und »Vollständigkeit« habe OpenAI »leichte Anstiege« der Werte in der Gruppe mit Zugang zum KI-Modell festgestellt. Das Ausmaß dieser Effekte sei aber nicht groß genug, um als statistisch signifikant durchzugehen. Die Firma betont zudem, es reiche nicht aus, Zugang zu den entsprechenden Informationen zu haben, um eine Biowaffe zu entwickeln. Die Umsetzung in der Praxis habe man jedoch nicht untersucht. Priorität hatte dabei die Frage, ob GPT-4 helfen kann, eine bereits bekannte biologische Bedrohung nachzubauen. Die Entwicklung bisher unbekannter Stoffe stand nicht im Fokus. Doch bereits vor knapp zwei Jahren hatte das Pharmaunternehmen Collaborations Pharmaceuticals für Aufsehen gesorgt , als es ein speziell programmiertes KI-Modell neue, möglichst toxische chemische Kampfstoffe digital entwerfen ließ. In weniger als sechs Stunden generierte das System damals 40.000 solcher Moleküle. »Onlinequellen und Datenbanken haben mehr gefährliche Inhalte, als wir dachten« OpenAI interpretiert die Ergebnisse seiner Studie so, dass der Zugang zu der speziellen Version von GPT-4 »die Fähigkeit von Expertinnen und Experten, auf Informationen über biologische Gefahren zuzugreifen, erhöhen kann «. Allerdings sei man sich unsicher, wie bedeutend die Beobachtung ist. Das Unternehmen von CEO Sam Altman bezeichnet die Untersuchung als »Blaupause« für die Entwicklung eines Frühwarnsystems und Ausgangspunkt für weitere Forschung. Der zugrundeliegende Gedanke sei es, »Evaluierungsmethoden für KI-bedingte Sicherheitsrisiken« zu entwickeln, denn »da OpenAI und andere Entwickler noch fähigere KI-Systeme bauen, wird das Potenzial sowohl für den nützlichen, wie auch den schädlichen Gebrauch steigen«. Die für diese Studie entwickelte Methode könne man sich als »Stolperdraht« vorstellen, um rechtzeitig gewarnt zu sein, wenn sich abzeichnet, dass eine KI hilfreicher als ein bloßer Internetzugang wird, um gefährliche Materialien wie etwa Viren zu entwickeln. Ohnehin sei es aber bereits »relativ einfach«, an solche Informationen zu gelangen, auch ohne GPT-4: »Onlinequellen und Datenbanken haben mehr gefährliche Inhalte, als wir dachten«, schreibt OpenAI. »Schritt-für-Schritt-Methodologien und Tipps zur Fehlersuche für die Entwicklung biologischer Bedrohungen sind nur eine schnelle Internetsuche entfernt.« Dennoch sei Bioterrorismus »immer noch relativ selten«. Das zeige, wie wichtig neben den reinen Informationen auch der Zugang zu Laboren und Fachwissen in Mikrobiologie und Virologie seien."
KI,Spiegel Online,2024-01-30,https://www.spiegel.de/ausland/paris-setzt-bei-den-olympischen-spielen-auf-ki-entschuldigung-wie-komme-ich-zum-bahnhof-a-fae8567e-4dbc-4245-9845-a06077ed8314,"Paris setzt bei den Olympischen Spielen auf KI: »Entschuldigung, wie komme ich zum Bahnhof?« - DER SPIEGEL","Was tun, wenn man sich bei den Olympischen Sommerspielen in Paris zurechtfinden will, ohne Französisch zu sprechen? In der Metro kein Problem: Dank KI sollen die Mitarbeiter sogar Mandarin verstehen. Tourist(Arabisch): Wie komme ich zum Stade de France? Tourist (Spanisch): Wann sind die Olympischen Spiele? Tourist (Schwedisch): Hallo, Entschuldigung, wie komme ich zum Bahnhof, wenn ich den Zug nehmen muss? Die meisten Einwohner von Paris haben sich an Touristen gewöhnt. In diesem Sommer dürften allerdings noch mehr Menschen aus dem Ausland in die französische Hauptstadt reisen: Gregoire de Lasteyrie, RATP-Sprecher: »Frankreich wird in ein paar Monaten Gastgeber der Olympischen Spiele sein. Jetzt werden wir Besucher aus der ganzen Welt haben, die kommen werden, Millionen von Besuchern aus der ganzen Welt. Es ist wichtig, sie mit den richtigen Informationen zu versorgen. Deshalb ist es äußerst wichtig, mit ihnen in möglichst vielen Sprachen sprechen zu können und ihnen dabei zu helfen, sich in Paris zurechtzufinden.« Um die Mitarbeiter des öffentlichen Verkehrssystems zu entlasten, setzen die Verantwortlichen auf Künstliche Intgelligenz. 2.000 Mitarbeiter sollen mit KI-unterstützten Übersetzungsgeräten ausgestattet werden, um den Besuchern während derSpiele die Orientierung im Nahverkehrssystem von Paris zu erleichtern. Das sogenannte TRADIVIA-Gerät beherrscht 16 verschiedene Sprachen. Wie bewährt es sich im Test? Raphael Gassette, Metro Paris: »Es hat mein tägliches Leben nicht unbedingt völlig verändert, aber es hat es natürlich verändert. Warum? Weil wir diese Angst nicht mehr haben, diese Angst davor, uns Besuchern zu nähern. Wir wissen natürlich, dass sie zum Beispiel koreanisch, Hindi oder Mandarin sprechen könnten. Wir haben nicht mehr die Angst zu denken: ""Oh nein, wir werden uns nicht verstehen.« Der Service soll auch nach den Olympischen Spielen in Paris bestehen bleiben. Denn auch ohne sportliche Großveranstaltungen ist die französische Hauptstadt eines derbeliebtesten Reiseziele der Welt."
KI,Spiegel Online,2024-01-30,https://www.spiegel.de/netzwelt/gadgets/samsung-galaxy-s24-ultra-im-test-ki-ist-jetzt-fast-ueberall-a-80c24e44-baf7-4b40-94f9-542a74dcf87b,Samsung Galaxy S24 Ultra im Test: KI ist jetzt fast überall - DER SPIEGEL,"Samsungs neues Top-Smartphone könnte sterbenslangweilig sein – wären da nicht die KI-Funktionen und die Aussicht, das Gerät auch im Jahr 2031 noch nutzen zu können. Dieser Text enthält sogenannte Affiliate-Links, über die der Verlag, aber nie der Autor individuell, bei Verkäufen eine geringe Provision vom Händler erhält. Beim Design hat sich Samsung von Apple inspirieren lassen und ist sich gleichzeitig selbst treu geblieben. So wie beim iPhone 15 Pro ( hier unser Testbericht ) wird der Rahmen des Galaxy S24 Ultra aus Titan hergestellt. Das robuste Metall fühlt sich angenehm weich an, liegt gut in der Hand. Einhändig bedienen kann man es trotzdem nicht, dafür ist der Bildschirm mit seinen 6,8 Zoll zu groß. Die grundlegende Form aber erinnert sehr an das Galaxy S23 Ultra vom vorigen Jahr ( hier unser Testbericht ). Auch die Anordnung der Kameras auf der Rückseite ist identisch, und der S Pen, mit dem man auf dem Bildschirm schreiben, zeichnen und malen kann, ist an der gleichen Stelle im Gehäuse untergebracht. Der kleine Stift funktioniert übrigens trotz seiner billig wirkenden Machart hervorragend. Wer gern handschriftliche Notizen macht – was ich nicht tue – wird damit gut klarkommen. Guck mal Eine sichtbare Verbesserung ist das neue Design des Bildschirms. Das Display des S23 Ultra war an den Rändern ganz leicht gebogen. Der Bildschirm des S24 Ultra ist nun – endlich – vollkommen flach und lässt sich bis zum Rand hin nutzen. Die Ära der gebogenen Bildschirme dürfte damit vorbei sein. Weshalb Samsung diesen Schritt nicht schon im vergangenen Jahr gegangen ist, ist mir schleierhaft. Alles andere als schleierhaft ist dagegen der Bildschirm selbst. Wie der des Vorgängers ist er knackscharf, verfügt über 3120 mal 1440 Pixel, kann die Bildwiederholfrequenz von einem Bild pro Sekunde beim Lesen auf bis zu 120 Bilder pro Sekunde beim Scrollen und Spielen variieren. Der Sinn dahinter: je weniger Bilder das Display anzeigen muss, desto weniger Energie benötigt es. Viel Energie geht drauf, wenn man das Handy bei praller Sonne benutzt. Das Display erreicht dann punktuell eine Spitzenhelligkeit von 2600 Nits, 200 mehr als das Pixel 8 Pro und 600 mehr als das iPhone 15 Pro. Das ist hell, sehr hell. Pixel statt Linsen Wie das Design vermuten lässt, hat sich bei den Kameras nicht viel getan. Wie schon das S23 Ultra verfügt das S24 Ultra über eine Weitwinkelkamera mit 200 Megapixeln. Deren volle Auflösung ist aber nur selten von Nutzen. Einzig bei sehr hellen Motiven kann es sinnvoll sein. Die vollen 200 Megapixel zu verwenden. Die besseren Fotos erreicht man im 12-Megapixel-Modus, in dem je 16 Sensorpixel zu einem Bildpixel kombiniert werden. Eine Auflösung von 12 Megapixeln hat ebenfalls die Ultraweitwinkelkamera, die Dreifach-Telekamera muss sich mit 10 Megapixeln begnügen. Neu ist, dass die zweite Telekamera jetzt 50 statt 10 Megapixel hat und ihr optisches Zoomobjektiv nur auf eine fünffache Vergrößerung kommt. Im Vorgänger steckte noch eine Zehnfach-Zoom. Das macht skeptisch. Hat Samsung das große Tele beschnitten? Die Antwort lautet ja, aber beschnitten werden nun die Aufnahmen: Statt per Objektiv ans Motiv heranzuzoomen, wird bei Zoomstufen über dem Faktor fünf eine 50-Megapixel-Aufnahme des Fünffach-Zooms so beschnitten, dass der per Zoomfunktion gewählte Ausschnitt übrig bleibt. Das klingt wie Schummeln, klappt aber bis zum Zehnfach-Zoom gut – wenn es hell genug ist. Bei Dunkelheit sollte man diesen Digitalzoom lieber nicht benutzen. Künstliche Intelligenz – überall ein bisschen Anders als bei der Hardware gibt es in der Software der S24-Serie viele Neuerungen in Form von KI-Funktionen. Künstliche Intelligenz, die das Unternehmen penetrant dem englischen Begriff Artificial Intelligence folgend als AI bezeichnet, ist fast allgegenwärtig. Die KI – oder eben AI – findet man in den Geräten der S24-Serie in der Kamera, dem Notizbuch, der Telefonfunktion und mehr. Wohl, um alles zum Thema zu sammeln, findet man in den Einstellungen unter »Erweiterte Funktionen« die KI-Optionen nun unter der Bezeichnung »Moderne KI-Funktionen«. Samsungs KI-Assistenten Bixby, der unterhalb dieses Menüeintrags aufgeführt wird, kann man demnach den alten KI-Funktionen zuordnen. Zu den alten KI-Funktionen zählt im Grunde auch vieles, was in der Foto-App vor sich geht. Da wäre zum Beispiel die Möglichkeit, im Bild nicht erwünschte Objekte mit dem Finger oder dem S Pen einzukreisen und zu löschen. Das Besondere dabei: Statt einen weißen Fleck im Bild zu hinterlassen, füllt generative KI die Fehlstelle mit einem zur Umgebung passenden Hintergrund. Google bietet eine solche Funktion seit Langem als »magischen Radierer« an. Solange man sich auf kleine Bildbereiche beschränkt, funktioniert das gut, schnippelt man großflächig herum, fallen der KI keine sinnvollen Füllmuster ein und sie halluziniert sich einen Hintergrund zusammen. Besser ist die generative KI eingesetzt, wenn man einen Schnappschuss nachträglich um ein paar Grad drehen möchte, weil das Bild schief ist. Bisher wurde das Foto in solchen Fällen auf ein verkleinertes Rechteck zusammengestutzt, um die Ecken abzuschneiden, die keinen Inhalt hatten. Auf den S24 produziert die KI jetzt zum Bildrand passende Füllstücke, damit die Aufnahme ihre ursprüngliche Größe behält. Spiegelungen ein Ende setzen Mehr amüsant als nützlich ist, dass Samsungs Software derart manipulierte Bilder mit einem kleinen Symbol markiert, das als Wasserzeichen links unten im Bild eingebaut wird. Mit der KI-Löschfunktion kann man dem nicht beikommen, weil die ein neues Wasserzeichen hinterlassen würde. Der leichtere Weg ist ohnehin, die Linke Ecke einfach von Bild abzuschneiden, um die Manipulation unkenntlich zu machen. Was sehr nützlich sein kann, aber nicht immer perfekt funktioniert, ist die Möglichkeit, Reflexionen zu löschen, wenn man durch spiegelnde Fenster fotografiert hat. Leider haben Samsungs User-Interface-Spezialistinnen und -Spezialisten diese Option gut versteckt. Zu finden ist sie in der »Galerie«-App, indem man auf das eingekreiste »i« tippt und einen Moment wartet, bis die Software das Bild analysiert hat und Bearbeitungsvorschläge einblendet. Auf dieselbe Weise kann man nachträglich eine Hintergrundunschärfe hinzufügen, die manchen Bildern einen Spiegelreflex-Look geben kann. Worum geht’s in diesem Text? Nicht nur Bilder, auch Texte kann man von der KI in Samsungs neuen Smartphones bearbeiten lassen. Was prima funktioniert: Als Textwurst eingetippte Notizen ansprechend formatieren und Texte wie etwa Sitzungsmitschnitte zusammenfassen lassen. Vor allem Letzteres hat sich bei mir schon nach wenigen Tagen als extrem nützliches Tool erwiesen, um etwa abzuschätzen, ob es sich lohnt, einen langen Text in Gänze zu lesen. Schade, dass das nur in der Notiz-App und Samsungs Webbrowser funktioniert und auch da nur mit Texten, die frei von Bezahlschranken sind. Dafür kann die KI auch PDF-Dateien zusammenfassen, nachdem man sie in die Notizen-App importiert hat. Mehr als rund drei Textseiten sind der künstlichen Intelligenz aber zu viel. Maßvoll Multilingual Nicht ganz so beeindruckend arbeiten die Dolmetsch- und Übersetzungsfunktionen. Die Möglichkeit, etwa Telefonate mit anderssprachigen Menschen von der KI dolmetschen zu lassen, erfordert Geduld. Statt in Echtzeit erfolgt die Übersetzung mit Wartezeit. Und auch dass nur korrekt, wenn man klar, deutlich und nicht zu schnell spricht. Der Erfolg solcher Telefonate hängt aber vor allem davon ab, ob die Angerufenen die KI und ihre Eigenheiten verstehen und akzeptieren. Schon die ein solches Gespräch einleitende Computerstimme, die auf die Übersetzung per Computer hinweist, könnte den einen oder die andere abschrecken. Abschreckend waren zumindest teilweise auch meine Versuche, anderssprachige Texte transkribieren und dann übersetzen zu lassen. Ein Mitschnitt aus dem koreanischen Fernsehen ließ mich vollkommen ratlos zurück, ein Ausschnitt aus einer amerikanischen Talkshow war zwar nicht elegant, aber immerhin verständlich übersetzt. Die KI-Zusammenfassung davon enthielt tatsächlich alles Wichtige. Das Problem einkreisen Die KI-Funktion, die ich während der Testphase am häufigsten genutzt habe, heißt allerdings Circle to Search. Und auch wenn Samsung bei seinen Präsentationen der S24-Serie den Eindruck zu vermitteln versuchte, das sei eine Samsung-Erfindung, stammt dieses Feature doch von Google und wird ab dem 31. Januar auch auf dem Pixel 8 und 8 Pro ( hier unser Testbericht ) verfügbar sein. Das Charmante an dieser Funktion ist ihre Einfachheit. Egal, was auf dem Bildschirm angezeigt wird: Drückt man kurz in der Mitte unten auf den Bildschirm, wird eine Art virtuelle Klarsichtfolie über das Display gelegt, auf der man per Finger oder S Pen das Objekt einkreist, über das man mehr wissen will. Die KI durchwühlt daraufhin das Web und zeigt oft, aber nicht immer, akkurat an, was man da sieht. Die Funktion erinnert an Google Lens, eröffnet dadurch, dass sie immer verfügbar ist, aber ganz andere Möglichkeiten. Was für eine Jacke trägt der Hauptdarsteller in dem Film? In welcher Stadt hat meine Freundin das Selfie gemacht, dass ich auf Instagram gesehen hab? Wie heißt das Haus, vor dem ich stehe? Wenn sie groß genug erkennbar sind, lassen sich auf diese Weise auch Wörter und Begriffe suchen. Einfacher kann man sich nicht durch die Welt googeln. Wie schnell es ist? Schnell genug Wie immer baut Samsung in sein Topmodell den aktuell schnellsten Qualcomm-Prozessor in einer Samsung-Version ein, die ein klein wenig übertaktet ist. So ist sichergestellt, dass das Gerät in Benchmarktests immer vorne liegt. Da solche Leistungsvergleiche nur ein theoretisches Bild liefern, belassen wir es mit der Feststellung: Das Galaxy S24 Ultra ist schnell genug. Fast immer. Wartezeiten gibt es vor allem bei KI-Funktionen, wie etwa der Transkription von Texten. Updates bis ins nächste Jahrzehnt Samsung liefert alle Modelle der S24-Serie mit Android 14 aus, dem die hauseigene Benutzeroberfläche One UI übergezogen wurde. Dass der Konzern als einer von wenigen Herstellern auf seinen neuen Geräten das aktuelle Google-Betriebssystem installiert, ist löblich. Honor etwa liefert sein teures Faltsmartphone Magic V2 ( hier unser Testbericht ) noch mit Android 13 aus. Noch wichtiger ist aber, dass Samsung verspricht, die Geräte sieben Jahre lang mit Android-Updates zu versorgen. Da macht es dann auch Sinn, dass es jetzt schon Wi-Fi 7 beherrscht, einen WLAN-Standard, für den es bisher kaum Hardware gibt. Ähnlich lange Update-Laufzeiten haben bisher nur Google für die Pixel 8 und 8 Pro sowie Fairphone in Aussicht gestellt. Ausreichend Ersatzteile und vor allem Austauschakkus vorausgesetzt, dürfte man demnach noch im Jahr 2031 ein Update installieren. Angesichts bisheriger Produktzyklen eine ebenso irritierende wie aus ökologischer Sicht berauschende Vorstellung. Fazit 👍 Sehr guter Bildschirm 👍 Nützliche KI-Funktionen 👍 Gute Akkulaufzeit 👍 Lange Update-Versorgung 👎 Hoher Preis Mit dem Galaxy S24 Ultra hat Samsung das derzeit wohl beste Android-Smartphone am Start. Die Hardware ist vom Feinsten, die neuen KI-Funktionen sind zum Teil wirklich nützlich. Vor allem geben sie einen Ausblick darauf, was in Zukunft möglich sein wird, wenn die Kinderkrankheiten etwa beim Dolmetschen kuriert sind. Mit dem Versprechen, dass das Gerät sieben Jahre lang Updates bekommen wird, kann man sich vielleicht sogar den hohen Preis schönreden. Der nämlich ist gegenüber dem S23 Ultra um 50 Euro auf 1449 Euro gestiegen. Wohlgemerkt für die Einstiegsversion mit 256 Gigabyte (GB) Speicher. Die Variante mit 512 GB kostet 1569 Euro, das 1-Terabyte-Modell 1809 Euro. Bis zum 31.1. bietet Samsung die beiden kleinen Modelle noch mit doppeltem Speicher an, die Terabyte-Variante zum 512-GB-Preis. Über welche Produkte wir in der Netzwelt berichten und welche wir testen oder nicht, entscheiden wir selbst. Für keinen der Testberichte bekommen wir Geld oder andere Gegenleistungen vom Hersteller. Es kann aus verschiedenen Gründen vorkommen, dass wir über Produkte nicht berichten, obwohl uns entsprechende Testprodukte vorliegen. Testgeräte und Rezensionsexemplare von Spielen bekommen wir in der Regel kostenlos für einen bestimmten Zeitraum vom Hersteller zur Verfügung gestellt, zum Teil auch vor der offiziellen Veröffentlichung. So können unsere Testberichte rechtzeitig oder zeitnah zur Veröffentlichung des Produkts erscheinen. Vorabversionen oder Geräte aus Vorserienproduktionen testen wir nur in Sonderfällen. In der Regel warten wir ab, bis wir Testgeräte oder Spielversionen bekommen können, die mit den Verkaufsversionen identisch sind. Wenn sie bereits im Handel oder online verfügbar sind, kaufen wir Produkte in einigen Fällen auf eigene Kosten ein. In der Regel werden Testgeräte nach dem Ende des Tests an die Hersteller zurückgeschickt. Die Ausnahme sind Rezensionsexemplare von Spielen und langfristige Leihgaben: So haben wir zum Beispiel Spielekonsolen und Smartphones in der Redaktion, die wir über längere Zeit nutzen dürfen. So können wir beispielsweise über Softwareupdates, neues Zubehör und neue Spiele berichten oder Langzeiturteile fällen. Oft werden Rezensionsexemplare am Ende eines Jahres zum Beispiel gesammelt und im Rahmen eines firmeninternen Flohmarktes verkauft, wobei die Erlöse für gemeinnützige Zwecke gespendet werden. Teilweise werden sie auch direkt an gemeinnützige Einrichtungen gespendet. Die Kosten für Reisen zu Veranstaltungen, egal ob sie in Deutschland oder im Ausland stattfinden, trägt DER SPIEGEL stets selbst. Das gilt auch dann, wenn beispielsweise aufgrund kurzfristiger Termine ein Unternehmen die Reiseplanung übernimmt. Veranstaltungen, zu denen wir auf eigene Kosten reisen, sind unter anderem die Messen Ifa, CES, E3 und Gamescom, Entwicklerveranstaltungen wie die Google i/O, WWDC und Build sowie Events von Firmen wie Apple, Google, Microsoft oder Nintendo. Auf Konferenzen wie dem Chaos Communication Congress oder der re:publica bekommen wir in der Regel, wie auch andere Pressevertreter, kostenlose Pressetickets, da wir über die Konferenz berichten und keine klassischen Teilnehmer sind. Seit Dezember 2016 finden sich in einigen Netzwelt-Artikeln sogenannte Affiliate-Anzeigen, die sogenannte Links zu Onlineshops enthalten. Besucht ein Nutzer über einen solchen Link einen dieser Shops und kauft dort online ein, wird DER SPIEGEL, aber nie die Autorin oder der Autor individuell, in Form einer Provision an den Umsätzen beteiligt. Diese Provision wird vom Händler gezahlt, nicht vom Hersteller des Produkts. Die Anzeigen tauchen in Artikeln unabhängig davon auf, ob ein Produkttest positiv oder negativ ausfällt. Eine ausführliche Erklärung zu Affiliate-Links finden Sie, wenn Sie auf diesen Link klicken . Der Porträtmodus funktioniert bei Hunden recht gut und … … bei Friseurpuppen sowieso. Nahaufnahme eines im Wind wackelnden Astes: Da muss der Autofokus wohl schnell sein. Aufnahme eines schon viel zu lange herumstehenden Weihnachtsgestecks im dunklen Wohnzimmer, so wie die Kamera-App die Szene sieht … … und was die Fotosoftware daraus macht. Natürlich kann man auch mit dem S24 Ultra Nahaufnahmen vom Mond machen, wenn man den Zoomfaktor 100 auswählt. Wie echt sie sind, ist Thema vieler Diskussionen . Ein Gartenzwerg. Nicht irgendeiner, sondern Fritz. Aufgenommen mit der Ultraweitwinkelkamera des Galaxy S24 Ultra. Hier wurde Fritz mit dem 200-Megapixel-Weitwinkelobjektiv aufgenommen, aber mit 12-Megapixel-Auflösung. Die maximale optische Näherung, das Fünffach-Zoom Eigentlich eine Ausschnittvergrößerung, aber sehr gelungen: der Zwerg im Faktor 10. Nicht gerade sensationell: der Zoomfaktor 10 vor Sonnenaufgang Übersetzung von Koreanisch ins Deutsche, in diesem Beispiel nur Kauderwelsch Besser klappte es im Test von Englisch ins Deutsche, aber perfekt war auch das nicht Die Zusammenfassung enthielt trotzdem alle wichtigen Punkte Volltreffer: Hier hat Circle to Search den Schnappschuss genau richtig erkannt. Bei diesem Foto eines freundlichen Trainingsballs fand die KI immerhin ähnlich aussehende Bälle – deren Aufnahmen aber stets nur als Symbolfotos genutzt wurden. Aber hier ließ sie sich von einem Baugerüst foppen, identifizierte das Hamburger Haus der Photographie als Philharmonie Stettin. Noch eine Niete: Statt einer Schweizer Leckerei vermutete die KI unter der Alufolie Druckertoner oder doch einfach irgendwas mit Alufolie."
KI,Spiegel Online,2024-01-30,https://www.spiegel.de/netzwelt/netzpolitik/ai-act-bundesregierung-will-europaeischem-ki-gesetz-doch-zustimmen-a-86cfff74-6d38-45f3-a772-ef65dff6e95f,AI Act: Bundesregierung will europäischem KI-Gesetz doch zustimmen - DER SPIEGEL,"Bedenken der FDP sollen Deutschlands Zustimmung zum AI Act in letzter Minute ins Wanken gebracht haben. Nun aber hat sich die Bundesregierung auf eine gemeinsame Haltung verständigt. Die finale Einigung der EU-Mitgliedstaaten auf den AI Act soll am kommenden Freitag erfolgen – und Deutschland will dem ersten umfassenden Gesetzespaket zu künstlicher Intelligenz in der westlichen Welt nicht im Weg stehen. In einer Pressemitteilung des Bundesministeriums für Wirtschaft und Klimaschutz heißt es am Dienstag, die Bundesregierung habe sich darauf verständigt, der KI-Verordnung zuzustimmen. »Mit der deutschen Zustimmung zur KI-Verordnung setzen wir uns für Rechtssicherheit und vertrauenswürdige KI made in Europe ein«, lautete ein Kommentar von Wirtschaftsminister Robert Habeck. Und Marco Buschmann, der Bundesminister der Justiz, sagte: »Mit der europäischen KI-Verordnung machen wir den Weg frei für einen sicheren Rechtsrahmen für künstliche Intelligenz, der Innovationen fördert und gleichzeitig Risiken in der Anwendung angemessen adressiert.« Noch vor wenigen Tagen hatte es geheißen , vor allem im Digitalministerium von Volker Wissing ( FDP ) gebe es noch Widerstand gegen das Gesetz. Zwar hatte es bereits im Dezember im Ministerrat eine grundsätzliche mündliche Einigung gegeben, doch erst sechs Wochen später lag die finale schriftliche Fassung des Gesetzes vor. Bis zum vorvergangenen Wochenende seien deshalb zahlreiche zentrale Details unklar gewesen, so hörte man, etwa über die Regulierung von Gesichtserkennung und von KI-Basismodellen. Am Dienstagmorgen hat nach SPIEGEL-Informationen eine Runde der Staatssekretärinnen und Staatssekretäre einen Kompromiss gefunden. Aus Regierungskreisen hieß es, man werde dem AI Act zustimmen, die EU-Kommission aber auffordern, kurzfristig zentrale Praxisfragen zu klären, um Doppelbelastungen für die Wirtschaft zu vermeiden. Dazu gehörten unter anderem das Verhältnis zu anderen Produktregulierungsrechtsakten (Medizinprodukte) und Rechtsfragen bei der Weiterentwicklung von KI-Modellen (Finetuning). Auch das »Handelsblatt« berichtete von der Einigung. Wie der SPIEGEL weiter erfuhr, tendiert wohl auch die französische Regierung mittlerweile zu einem Ja zum AI Act. Zusammen mit Italien galt auch Frankreich bisher als möglicher Wackelkandidat. Anmerkung der Redaktion: In einer früheren Fassung dieses Artikels hieß es, die Runde der Staatssekretärinnen und Staatssekretäre habe am Montagabend einen Kompromiss gefunden. Nach SPIEGEL-Informationen war es der Dienstagmorgen, wir haben den Satz korrigiert."
Künstliche Intelligenz,Spiegel Online,2024-01-29,https://www.spiegel.de/wirtschaft/unternehmen/lieferketten-wie-ki-konzerne-sozial-und-umweltvertraeglicher-macht-a-1ae1f6bb-d4d1-4a83-a323-b7ec57b144e6,Lieferketten: Wie KI Konzerne sozial- und umweltverträglicher macht - DER SPIEGEL,Das deutsche Lieferkettengesetz hat einen neuen KI-Boom ausgelöst. Start-ups versprechen die Überprüfung von Millionen Lieferanten in Echtzeit – ganz ohne lästige Bürokratie. Was taugt die Technik?
Künstliche Intelligenz,Spiegel Online,2024-01-28,https://www.spiegel.de/sport/eishockey/ki-in-der-eishockey-bundesliga-computer-sagt-auswechseln-ist-das-die-zukunft-a-cd1043ed-681c-477c-b2e0-646cde88e28b,KI in der Eishockey-Bundesliga: Computer sagt Auswechseln – ist das die Zukunft? - DER SPIEGEL,"Jeder Spieler wird getrackt, sogar im Puck ist ein Chip: In der DEL werden riesige Datenmengen von einer künstlichen Intelligenz ausgewertet – in Echtzeit während der Spiele. Wie ausgereift ist die Technik? In wenigen Minuten geht es los. Die Spieler der Fischtown Pinguins aus Bremerhaven stehen bereit. Gewinnen Sie heute gegen die Eisbären Berlin, sind sie neuer Tabellenführer der Deutschen Eishockey-Liga. Die Arena ist ausverkauft. Vor dem Spiel erklärt uns der sportliche Leiter der Pinguins, wie ihm bei der Zusammenstellung der Mannschaft künstliche Intelligenz hilft. Sebastian Furchner, Sportlicher Leiter Fischtown Pinguins: »So kannst du vielleicht auch zwei, drei, vier Spieler miteinander vergleichen über Zweikämpfe, Passquote, Effizienz bei den Torabschlüssen und so weiter. Das spielt schon eine Rolle. Nicht nur visuell, was du siehst, sondern auch einfach auf Zahlen basiert, zu sehen, wie performt der Spieler.« Doch wie funktioniert das? Neben der Ausrüstung spielen Statistiken im Eishockey schon immer eine große Rolle. Seit einem Jahr kommt in der Deutschen Eishockey-Liga eine neue Technologie zum Einsatz: Durch Puck- und Spielertracking werden in Bruchteilen von Sekunden Daten erhoben. Der Zeugwart sorgt dafür, dass die Spieler für den Wettkampf umfänglich ausgestattet sind. Stefan Wohlschlager, Zeugwart: »Jeder Spieler bekommt dann eine eigene Nummer von dem Chip. Angebracht wird der Chip am Brustschutz. Von der Firma Wisehockey wird vorgegeben, entweder auf der linken Seite vom Brustschutz, auf der linken Schulterseite, oder hier in der Mitte. Und das ist der Chip im Puck. Ich wollte nur mal sehen, wie der eingefasst ist, weil viele Spieler, die jammern auch, sage ich mal, weil sich so ein Puck mit dem Chip auf dem Eis anders verhält als ein normaler Puck.« Durch die Masse im Puck fliegt dieser nämlich anders. Grundsätzlich aber haben sich alle daran gewöhnt, sagt Wohlschlager. Wie läuft es nun ab? In der Halle sind mehrere Sensoren und Kameras angebracht. Diese empfangen die Daten, die von den Chips der Spieler und des Pucks aufgezeichnet werden. Bis jetzt mussten solche Daten manuell von Menschen für die Analyse ausgewertet werden, jetzt kann an der Stelle die KI die zeitaufwendige Arbeit übernehmen. Carlo Dindorf, Sportwissenschaftler TU Kaiserslautern: »KI macht es heutzutage möglich, solche Daten direkt realtime sogar zu berechnen, indem angelernte Algorithmen diese Videos gegeben bekommen und dann automatisch ein Labeling der Videos erfolgt. Der Algorithmus schätzt direkt, okay, hier sind Gelenkzentren, hier so und so ist zum Beispiel der Kniewinkel im Verlauf des Sprints eines Spielers, oder kann sagen, hier befinden sich diese Spieler, diese Mannschaft, der anderen Mannschaft. Darauf aufbauend können natürlich taktische Analysen sehr gut durchgeführt werden.« Zurück zum Spiel: Bremerhaven führt nach dem zweiten Drittel überraschend deutlich mit drei zu null gegen Berlin. Schon in der Pause nehmen Trainer und Team mithilfe der Daten eine erste Analyse vor. Thomas Popiesch, Trainer Fischtown Pinguins: »Wir schauen jetzt hier gerade hier zum Beispiel bei Powerplay-Situationen, weil wir haben jetzt die nächsten zwei Minuten direkt Powerplay auf dem Eis. Hat sich an der Struktur von Berlin was geändert, ja oder nein? Aber es ist eigentlich alles gleich. Von daher wird uns nur noch mal bestätigt.« Reporter: »Können Sie anhand der Daten, die sie dahaben, schon etwas erkennen?« Thomas Popiesch, Trainer Fischtown Pinguins: »Es ist relativ ausgeglichen. Die Eiszeiten sind gut verteilt. Die Schüsse eigentlich auch. Wir haben einmal hier, dann haben wir noch mal separat von unseren Leuten, von wo kommen die Schüsse. Dass wir da eigentlich ein paar Sachen haben. Face offs und dergleichen. Also dass wir da ein paar Verbesserungen vornehmen können.« Bei den Face offs, also dem Anstoß, den Bullys, also den Abschlägen, kann seine Mannschaft noch konsequenter und erfolgreicher sein, wie die Livedaten ergeben. Und tatsächlich – Bremerhaven legt noch zu, gewinnt 5:1. Während die Fans die Tabellenführung feiern, wertet Sebastian Furchner das Spiel mit KI-Unterstützung aus. So sammelt er Erkenntnisse für die nächste Begegnung. Er sieht in der weiteren Entwicklung der künstlichen Intelligenz eine große Chance für den Sport. Sebastian Furchner, Sportlicher Leiter Fischtown Pingunins: »Der nächste Schritt könnte sein, dass die KI sagt, dieser Spieler dreht sich gerne rechtsrum im Zweikampf oder hält beim Bully seinen Schläger immer auf eine gewisse Art, um das Bully dann soundso zu gewinnen.« KI kann Trainer und Sportler in vielen Punkten unterstützen und verbessern. Aber eines darf man dabei nicht vergessen. Sebastian Furchner, Sportlicher Leiter Fischtown Pingunins: »Das ist so ein bisschen der Schlüssel. Dass man Sachen nicht überbewertet, weil es ist auch immer noch der Spieler, der Mensch, Tagesform, Entscheidungsfähigkeit. Einfach diese Sachen sind auch noch immer entscheidend. Zum Schluss ist immer noch der Faktor Mensch ein wichtiger Faktor.« Der Einsatz von KI steht im Sport noch ganz am Anfang. Furchner und sein Team probieren aus und testen, welche Möglichkeiten künstliche Intelligenz bietet. Ersetzen wird sie Trainer und sportliche Leiter aber vermutlich nie."
AI,Spiegel Online,2024-01-28,https://www.spiegel.de/sport/eishockey/ki-in-der-eishockey-bundesliga-computer-sagt-auswechseln-ist-das-die-zukunft-a-cd1043ed-681c-477c-b2e0-646cde88e28b,KI in der Eishockey-Bundesliga: Computer sagt Auswechseln – ist das die Zukunft? - DER SPIEGEL,"Jeder Spieler wird getrackt, sogar im Puck ist ein Chip: In der DEL werden riesige Datenmengen von einer künstlichen Intelligenz ausgewertet – in Echtzeit während der Spiele. Wie ausgereift ist die Technik? In wenigen Minuten geht es los. Die Spieler der Fischtown Pinguins aus Bremerhaven stehen bereit. Gewinnen Sie heute gegen die Eisbären Berlin, sind sie neuer Tabellenführer der Deutschen Eishockey-Liga. Die Arena ist ausverkauft. Vor dem Spiel erklärt uns der sportliche Leiter der Pinguins, wie ihm bei der Zusammenstellung der Mannschaft künstliche Intelligenz hilft. Sebastian Furchner, Sportlicher Leiter Fischtown Pinguins: »So kannst du vielleicht auch zwei, drei, vier Spieler miteinander vergleichen über Zweikämpfe, Passquote, Effizienz bei den Torabschlüssen und so weiter. Das spielt schon eine Rolle. Nicht nur visuell, was du siehst, sondern auch einfach auf Zahlen basiert, zu sehen, wie performt der Spieler.« Doch wie funktioniert das? Neben der Ausrüstung spielen Statistiken im Eishockey schon immer eine große Rolle. Seit einem Jahr kommt in der Deutschen Eishockey-Liga eine neue Technologie zum Einsatz: Durch Puck- und Spielertracking werden in Bruchteilen von Sekunden Daten erhoben. Der Zeugwart sorgt dafür, dass die Spieler für den Wettkampf umfänglich ausgestattet sind. Stefan Wohlschlager, Zeugwart: »Jeder Spieler bekommt dann eine eigene Nummer von dem Chip. Angebracht wird der Chip am Brustschutz. Von der Firma Wisehockey wird vorgegeben, entweder auf der linken Seite vom Brustschutz, auf der linken Schulterseite, oder hier in der Mitte. Und das ist der Chip im Puck. Ich wollte nur mal sehen, wie der eingefasst ist, weil viele Spieler, die jammern auch, sage ich mal, weil sich so ein Puck mit dem Chip auf dem Eis anders verhält als ein normaler Puck.« Durch die Masse im Puck fliegt dieser nämlich anders. Grundsätzlich aber haben sich alle daran gewöhnt, sagt Wohlschlager. Wie läuft es nun ab? In der Halle sind mehrere Sensoren und Kameras angebracht. Diese empfangen die Daten, die von den Chips der Spieler und des Pucks aufgezeichnet werden. Bis jetzt mussten solche Daten manuell von Menschen für die Analyse ausgewertet werden, jetzt kann an der Stelle die KI die zeitaufwendige Arbeit übernehmen. Carlo Dindorf, Sportwissenschaftler TU Kaiserslautern: »KI macht es heutzutage möglich, solche Daten direkt realtime sogar zu berechnen, indem angelernte Algorithmen diese Videos gegeben bekommen und dann automatisch ein Labeling der Videos erfolgt. Der Algorithmus schätzt direkt, okay, hier sind Gelenkzentren, hier so und so ist zum Beispiel der Kniewinkel im Verlauf des Sprints eines Spielers, oder kann sagen, hier befinden sich diese Spieler, diese Mannschaft, der anderen Mannschaft. Darauf aufbauend können natürlich taktische Analysen sehr gut durchgeführt werden.« Zurück zum Spiel: Bremerhaven führt nach dem zweiten Drittel überraschend deutlich mit drei zu null gegen Berlin. Schon in der Pause nehmen Trainer und Team mithilfe der Daten eine erste Analyse vor. Thomas Popiesch, Trainer Fischtown Pinguins: »Wir schauen jetzt hier gerade hier zum Beispiel bei Powerplay-Situationen, weil wir haben jetzt die nächsten zwei Minuten direkt Powerplay auf dem Eis. Hat sich an der Struktur von Berlin was geändert, ja oder nein? Aber es ist eigentlich alles gleich. Von daher wird uns nur noch mal bestätigt.« Reporter: »Können Sie anhand der Daten, die sie dahaben, schon etwas erkennen?« Thomas Popiesch, Trainer Fischtown Pinguins: »Es ist relativ ausgeglichen. Die Eiszeiten sind gut verteilt. Die Schüsse eigentlich auch. Wir haben einmal hier, dann haben wir noch mal separat von unseren Leuten, von wo kommen die Schüsse. Dass wir da eigentlich ein paar Sachen haben. Face offs und dergleichen. Also dass wir da ein paar Verbesserungen vornehmen können.« Bei den Face offs, also dem Anstoß, den Bullys, also den Abschlägen, kann seine Mannschaft noch konsequenter und erfolgreicher sein, wie die Livedaten ergeben. Und tatsächlich – Bremerhaven legt noch zu, gewinnt 5:1. Während die Fans die Tabellenführung feiern, wertet Sebastian Furchner das Spiel mit KI-Unterstützung aus. So sammelt er Erkenntnisse für die nächste Begegnung. Er sieht in der weiteren Entwicklung der künstlichen Intelligenz eine große Chance für den Sport. Sebastian Furchner, Sportlicher Leiter Fischtown Pingunins: »Der nächste Schritt könnte sein, dass die KI sagt, dieser Spieler dreht sich gerne rechtsrum im Zweikampf oder hält beim Bully seinen Schläger immer auf eine gewisse Art, um das Bully dann soundso zu gewinnen.« KI kann Trainer und Sportler in vielen Punkten unterstützen und verbessern. Aber eines darf man dabei nicht vergessen. Sebastian Furchner, Sportlicher Leiter Fischtown Pingunins: »Das ist so ein bisschen der Schlüssel. Dass man Sachen nicht überbewertet, weil es ist auch immer noch der Spieler, der Mensch, Tagesform, Entscheidungsfähigkeit. Einfach diese Sachen sind auch noch immer entscheidend. Zum Schluss ist immer noch der Faktor Mensch ein wichtiger Faktor.« Der Einsatz von KI steht im Sport noch ganz am Anfang. Furchner und sein Team probieren aus und testen, welche Möglichkeiten künstliche Intelligenz bietet. Ersetzen wird sie Trainer und sportliche Leiter aber vermutlich nie."
Artificial Intelligence,Spiegel Online,2024-01-28,https://www.spiegel.de/sport/eishockey/ki-in-der-eishockey-bundesliga-computer-sagt-auswechseln-ist-das-die-zukunft-a-cd1043ed-681c-477c-b2e0-646cde88e28b,KI in der Eishockey-Bundesliga: Computer sagt Auswechseln – ist das die Zukunft? - DER SPIEGEL,"Jeder Spieler wird getrackt, sogar im Puck ist ein Chip: In der DEL werden riesige Datenmengen von einer künstlichen Intelligenz ausgewertet – in Echtzeit während der Spiele. Wie ausgereift ist die Technik? In wenigen Minuten geht es los. Die Spieler der Fischtown Pinguins aus Bremerhaven stehen bereit. Gewinnen Sie heute gegen die Eisbären Berlin, sind sie neuer Tabellenführer der Deutschen Eishockey-Liga. Die Arena ist ausverkauft. Vor dem Spiel erklärt uns der sportliche Leiter der Pinguins, wie ihm bei der Zusammenstellung der Mannschaft künstliche Intelligenz hilft. Sebastian Furchner, Sportlicher Leiter Fischtown Pinguins: »So kannst du vielleicht auch zwei, drei, vier Spieler miteinander vergleichen über Zweikämpfe, Passquote, Effizienz bei den Torabschlüssen und so weiter. Das spielt schon eine Rolle. Nicht nur visuell, was du siehst, sondern auch einfach auf Zahlen basiert, zu sehen, wie performt der Spieler.« Doch wie funktioniert das? Neben der Ausrüstung spielen Statistiken im Eishockey schon immer eine große Rolle. Seit einem Jahr kommt in der Deutschen Eishockey-Liga eine neue Technologie zum Einsatz: Durch Puck- und Spielertracking werden in Bruchteilen von Sekunden Daten erhoben. Der Zeugwart sorgt dafür, dass die Spieler für den Wettkampf umfänglich ausgestattet sind. Stefan Wohlschlager, Zeugwart: »Jeder Spieler bekommt dann eine eigene Nummer von dem Chip. Angebracht wird der Chip am Brustschutz. Von der Firma Wisehockey wird vorgegeben, entweder auf der linken Seite vom Brustschutz, auf der linken Schulterseite, oder hier in der Mitte. Und das ist der Chip im Puck. Ich wollte nur mal sehen, wie der eingefasst ist, weil viele Spieler, die jammern auch, sage ich mal, weil sich so ein Puck mit dem Chip auf dem Eis anders verhält als ein normaler Puck.« Durch die Masse im Puck fliegt dieser nämlich anders. Grundsätzlich aber haben sich alle daran gewöhnt, sagt Wohlschlager. Wie läuft es nun ab? In der Halle sind mehrere Sensoren und Kameras angebracht. Diese empfangen die Daten, die von den Chips der Spieler und des Pucks aufgezeichnet werden. Bis jetzt mussten solche Daten manuell von Menschen für die Analyse ausgewertet werden, jetzt kann an der Stelle die KI die zeitaufwendige Arbeit übernehmen. Carlo Dindorf, Sportwissenschaftler TU Kaiserslautern: »KI macht es heutzutage möglich, solche Daten direkt realtime sogar zu berechnen, indem angelernte Algorithmen diese Videos gegeben bekommen und dann automatisch ein Labeling der Videos erfolgt. Der Algorithmus schätzt direkt, okay, hier sind Gelenkzentren, hier so und so ist zum Beispiel der Kniewinkel im Verlauf des Sprints eines Spielers, oder kann sagen, hier befinden sich diese Spieler, diese Mannschaft, der anderen Mannschaft. Darauf aufbauend können natürlich taktische Analysen sehr gut durchgeführt werden.« Zurück zum Spiel: Bremerhaven führt nach dem zweiten Drittel überraschend deutlich mit drei zu null gegen Berlin. Schon in der Pause nehmen Trainer und Team mithilfe der Daten eine erste Analyse vor. Thomas Popiesch, Trainer Fischtown Pinguins: »Wir schauen jetzt hier gerade hier zum Beispiel bei Powerplay-Situationen, weil wir haben jetzt die nächsten zwei Minuten direkt Powerplay auf dem Eis. Hat sich an der Struktur von Berlin was geändert, ja oder nein? Aber es ist eigentlich alles gleich. Von daher wird uns nur noch mal bestätigt.« Reporter: »Können Sie anhand der Daten, die sie dahaben, schon etwas erkennen?« Thomas Popiesch, Trainer Fischtown Pinguins: »Es ist relativ ausgeglichen. Die Eiszeiten sind gut verteilt. Die Schüsse eigentlich auch. Wir haben einmal hier, dann haben wir noch mal separat von unseren Leuten, von wo kommen die Schüsse. Dass wir da eigentlich ein paar Sachen haben. Face offs und dergleichen. Also dass wir da ein paar Verbesserungen vornehmen können.« Bei den Face offs, also dem Anstoß, den Bullys, also den Abschlägen, kann seine Mannschaft noch konsequenter und erfolgreicher sein, wie die Livedaten ergeben. Und tatsächlich – Bremerhaven legt noch zu, gewinnt 5:1. Während die Fans die Tabellenführung feiern, wertet Sebastian Furchner das Spiel mit KI-Unterstützung aus. So sammelt er Erkenntnisse für die nächste Begegnung. Er sieht in der weiteren Entwicklung der künstlichen Intelligenz eine große Chance für den Sport. Sebastian Furchner, Sportlicher Leiter Fischtown Pingunins: »Der nächste Schritt könnte sein, dass die KI sagt, dieser Spieler dreht sich gerne rechtsrum im Zweikampf oder hält beim Bully seinen Schläger immer auf eine gewisse Art, um das Bully dann soundso zu gewinnen.« KI kann Trainer und Sportler in vielen Punkten unterstützen und verbessern. Aber eines darf man dabei nicht vergessen. Sebastian Furchner, Sportlicher Leiter Fischtown Pingunins: »Das ist so ein bisschen der Schlüssel. Dass man Sachen nicht überbewertet, weil es ist auch immer noch der Spieler, der Mensch, Tagesform, Entscheidungsfähigkeit. Einfach diese Sachen sind auch noch immer entscheidend. Zum Schluss ist immer noch der Faktor Mensch ein wichtiger Faktor.« Der Einsatz von KI steht im Sport noch ganz am Anfang. Furchner und sein Team probieren aus und testen, welche Möglichkeiten künstliche Intelligenz bietet. Ersetzen wird sie Trainer und sportliche Leiter aber vermutlich nie."
KI,Spiegel Online,2024-01-29,https://www.spiegel.de/wirtschaft/unternehmen/lieferketten-wie-ki-konzerne-sozial-und-umweltvertraeglicher-macht-a-1ae1f6bb-d4d1-4a83-a323-b7ec57b144e6,Lieferketten: Wie KI Konzerne sozial- und umweltverträglicher macht - DER SPIEGEL,Das deutsche Lieferkettengesetz hat einen neuen KI-Boom ausgelöst. Start-ups versprechen die Überprüfung von Millionen Lieferanten in Echtzeit – ganz ohne lästige Bürokratie. Was taugt die Technik?
KI,Spiegel Online,2024-01-28,https://www.spiegel.de/sport/eishockey/ki-in-der-eishockey-bundesliga-computer-sagt-auswechseln-ist-das-die-zukunft-a-cd1043ed-681c-477c-b2e0-646cde88e28b,KI in der Eishockey-Bundesliga: Computer sagt Auswechseln – ist das die Zukunft? - DER SPIEGEL,"Jeder Spieler wird getrackt, sogar im Puck ist ein Chip: In der DEL werden riesige Datenmengen von einer künstlichen Intelligenz ausgewertet – in Echtzeit während der Spiele. Wie ausgereift ist die Technik? In wenigen Minuten geht es los. Die Spieler der Fischtown Pinguins aus Bremerhaven stehen bereit. Gewinnen Sie heute gegen die Eisbären Berlin, sind sie neuer Tabellenführer der Deutschen Eishockey-Liga. Die Arena ist ausverkauft. Vor dem Spiel erklärt uns der sportliche Leiter der Pinguins, wie ihm bei der Zusammenstellung der Mannschaft künstliche Intelligenz hilft. Sebastian Furchner, Sportlicher Leiter Fischtown Pinguins: »So kannst du vielleicht auch zwei, drei, vier Spieler miteinander vergleichen über Zweikämpfe, Passquote, Effizienz bei den Torabschlüssen und so weiter. Das spielt schon eine Rolle. Nicht nur visuell, was du siehst, sondern auch einfach auf Zahlen basiert, zu sehen, wie performt der Spieler.« Doch wie funktioniert das? Neben der Ausrüstung spielen Statistiken im Eishockey schon immer eine große Rolle. Seit einem Jahr kommt in der Deutschen Eishockey-Liga eine neue Technologie zum Einsatz: Durch Puck- und Spielertracking werden in Bruchteilen von Sekunden Daten erhoben. Der Zeugwart sorgt dafür, dass die Spieler für den Wettkampf umfänglich ausgestattet sind. Stefan Wohlschlager, Zeugwart: »Jeder Spieler bekommt dann eine eigene Nummer von dem Chip. Angebracht wird der Chip am Brustschutz. Von der Firma Wisehockey wird vorgegeben, entweder auf der linken Seite vom Brustschutz, auf der linken Schulterseite, oder hier in der Mitte. Und das ist der Chip im Puck. Ich wollte nur mal sehen, wie der eingefasst ist, weil viele Spieler, die jammern auch, sage ich mal, weil sich so ein Puck mit dem Chip auf dem Eis anders verhält als ein normaler Puck.« Durch die Masse im Puck fliegt dieser nämlich anders. Grundsätzlich aber haben sich alle daran gewöhnt, sagt Wohlschlager. Wie läuft es nun ab? In der Halle sind mehrere Sensoren und Kameras angebracht. Diese empfangen die Daten, die von den Chips der Spieler und des Pucks aufgezeichnet werden. Bis jetzt mussten solche Daten manuell von Menschen für die Analyse ausgewertet werden, jetzt kann an der Stelle die KI die zeitaufwendige Arbeit übernehmen. Carlo Dindorf, Sportwissenschaftler TU Kaiserslautern: »KI macht es heutzutage möglich, solche Daten direkt realtime sogar zu berechnen, indem angelernte Algorithmen diese Videos gegeben bekommen und dann automatisch ein Labeling der Videos erfolgt. Der Algorithmus schätzt direkt, okay, hier sind Gelenkzentren, hier so und so ist zum Beispiel der Kniewinkel im Verlauf des Sprints eines Spielers, oder kann sagen, hier befinden sich diese Spieler, diese Mannschaft, der anderen Mannschaft. Darauf aufbauend können natürlich taktische Analysen sehr gut durchgeführt werden.« Zurück zum Spiel: Bremerhaven führt nach dem zweiten Drittel überraschend deutlich mit drei zu null gegen Berlin. Schon in der Pause nehmen Trainer und Team mithilfe der Daten eine erste Analyse vor. Thomas Popiesch, Trainer Fischtown Pinguins: »Wir schauen jetzt hier gerade hier zum Beispiel bei Powerplay-Situationen, weil wir haben jetzt die nächsten zwei Minuten direkt Powerplay auf dem Eis. Hat sich an der Struktur von Berlin was geändert, ja oder nein? Aber es ist eigentlich alles gleich. Von daher wird uns nur noch mal bestätigt.« Reporter: »Können Sie anhand der Daten, die sie dahaben, schon etwas erkennen?« Thomas Popiesch, Trainer Fischtown Pinguins: »Es ist relativ ausgeglichen. Die Eiszeiten sind gut verteilt. Die Schüsse eigentlich auch. Wir haben einmal hier, dann haben wir noch mal separat von unseren Leuten, von wo kommen die Schüsse. Dass wir da eigentlich ein paar Sachen haben. Face offs und dergleichen. Also dass wir da ein paar Verbesserungen vornehmen können.« Bei den Face offs, also dem Anstoß, den Bullys, also den Abschlägen, kann seine Mannschaft noch konsequenter und erfolgreicher sein, wie die Livedaten ergeben. Und tatsächlich – Bremerhaven legt noch zu, gewinnt 5:1. Während die Fans die Tabellenführung feiern, wertet Sebastian Furchner das Spiel mit KI-Unterstützung aus. So sammelt er Erkenntnisse für die nächste Begegnung. Er sieht in der weiteren Entwicklung der künstlichen Intelligenz eine große Chance für den Sport. Sebastian Furchner, Sportlicher Leiter Fischtown Pingunins: »Der nächste Schritt könnte sein, dass die KI sagt, dieser Spieler dreht sich gerne rechtsrum im Zweikampf oder hält beim Bully seinen Schläger immer auf eine gewisse Art, um das Bully dann soundso zu gewinnen.« KI kann Trainer und Sportler in vielen Punkten unterstützen und verbessern. Aber eines darf man dabei nicht vergessen. Sebastian Furchner, Sportlicher Leiter Fischtown Pingunins: »Das ist so ein bisschen der Schlüssel. Dass man Sachen nicht überbewertet, weil es ist auch immer noch der Spieler, der Mensch, Tagesform, Entscheidungsfähigkeit. Einfach diese Sachen sind auch noch immer entscheidend. Zum Schluss ist immer noch der Faktor Mensch ein wichtiger Faktor.« Der Einsatz von KI steht im Sport noch ganz am Anfang. Furchner und sein Team probieren aus und testen, welche Möglichkeiten künstliche Intelligenz bietet. Ersetzen wird sie Trainer und sportliche Leiter aber vermutlich nie."
KI,Spiegel Online,2024-01-27,https://www.spiegel.de/netzwelt/apps/oh-mein-bot-a-cff790be-e23b-4eae-bfa2-3c29884e8170,"KI-Selbstversuch: Oh, mein Bot - DER SPIEGEL","Mit Software der ChatGPT-Erfinder kann man sich seine eigenen KI-Helfer bauen und im GPT Store verkaufen, ganz ohne Programmierkenntnisse. Ist das die Zukunft der künstlichen Intelligenz?"
Künstliche Intelligenz,Spiegel Online,2024-01-24,https://www.spiegel.de/wirtschaft/unternehmen/sap-plant-grossumbau-fuer-geschaefte-mit-kuenstlicher-intelligenz-8000-arbeitsplaetze-betroffen-a-73a9ffab-c2ee-4e45-9c6b-265973128cf5,SAP plant Großumbau für Geschäfte mit künstlicher Intelligenz - 8000 Arbeitsplätze betroffen - DER SPIEGEL,"Die Zahl der Beschäftigten soll zwar nicht sinken – aber werden es noch dieselben sein? Der Softwarekonzern SAP investiert zwei Milliarden Euro in einen KI-Umbau, 8000 Jobs sollen sich dabei verändern. Europas größter Softwarehersteller SAP will in einem Großumbau die Geschäfte mit künstlicher Intelligenz (KI) pushen. Von dem Vorhaben seien rund 8000 Mitarbeitende betroffen, teilte der Dax-Konzern am späten Dienstagabend mit. Die Walldorfer hatten vor rund einem Jahr bereits 3000 Jobs gestrichen, um sich wieder mehr auf das angestammte Kerngeschäft rund um die Software zur Unternehmenssteuerung zu konzentrieren. »Mit dem geplanten Transformationsprogramm verlagern wir verstärkt Investitionen in strategische Wachstumsbereiche, in erster Linie in KI«, sagte Vorstandschef Christian Klein. »Damit werden wir auch zukünftig wegweisende Innovationen entwickeln und gleichzeitig die Effizienz unserer Geschäftsprozesse verbessern.« SAP hatte im vergangenen Jahr bereits eigene Produkte wie den KI-Assistenten Joule vorgestellt, der es Anwendern erleichtern soll, typische Aufgaben in Unternehmen zu erledigen. Nun will SAP-Chef Klein den KI-Bereich noch einmal mit rund zwei Milliarden Euro stärken. Dazu gehöre ein Umbau der Struktur des Konzerns, hieß es. Bei den meisten der rund 8000 betroffenen Stellen sollen Freiwilligenprogramme und interne Umschulungen zum Tragen kommen. Aufgrund von Investitionen in Wachstumsbereiche rechnet SAP damit, dass am Ende des Jahres die Zahl der Mitarbeitenden etwa dem aktuellen Niveau entspricht. Wie viele der vom Umbau betroffenen 8000 Beschäftigten dann noch bei SAP arbeiten, ist aber noch nicht abzusehen. Der Stellenabbau vor rund einem Jahr hatte nicht zu insgesamt sinkenden Mitarbeiterzahlen geführt. Zum Stichtag Ende Dezember hatte SAP 107.602 Vollzeitbeschäftigte, ein Jahr zuvor waren es 106.312 – allerdings sind viele der damals betroffenen Beschäftigten nicht mehr bei SAP. Zudem haben sich Klein und sein Finanzchef Dominik Asam für das laufende Jahr mehr Tempo bei Cloudumsatz und Ergebnis vorgenommen als im letzten Jahr. So soll das um Sondereffekte bereinige Ergebnis vor Zinsen und Steuern um 17 bis 21 Prozent wachsen, wenn Wechselkurseffekte ausgeklammert werden. Fast sechs Milliarden Euro Nettogewinn Der SAP-Chef hatte vor einigen Jahren den Fokus ganz auf die Cloud gerichtet, wie es auch in der Branche mittlerweile Standard ist. KI und andere Neuerungen sollen bei SAP künftig den Cloudversionen der Software vorbehalten sein, die Wartung von bestimmten Produkten fest installierter Software läuft auf Sicht aus. So will Klein 2025 mehr als 21,5 Milliarden Euro Umsatz in dem Bereich schaffen. Vergangenes Jahr erzielte die Sparte ein Plus von 20 Prozent auf 13,7 Milliarden Euro. Insgesamt steigerte SAP den Umsatz um sechs Prozent auf 31,2 Milliarden Euro. Im Tagesgeschäft kletterte das bereinigte operative Ergebnis um neun Prozent auf 8,7 Milliarden Euro. Der Nettogewinn stieg auf 5,9 Milliarden Euro, das war mehr als das Dreifache des Vorjahresgewinns – vor allem lag das am Verkauf der ehemaligen US-Marktforschungstochter Qualtrics."
AI,Spiegel Online,2024-01-25,https://www.spiegel.de/netzwelt/netzpolitik/ai-act-der-europaeischen-union-zustimmung-der-bundesregierung-zum-ki-gesetz-wackelt-angeblich-a-1495230d-b070-4cc5-a905-3d979f4e56f3,AI Act der Europäischen Union: Zustimmung der Bundesregierung zum KI-Gesetz wackelt angeblich - DER SPIEGEL,Beim KI-Gesetz der EU schien eine Einigung schon erreicht. Doch der finale Text sorgt nicht nur in Berlin für Irritationen. Ein Scheitern auf den letzten Metern wäre peinlich für die EU.
Artificial Intelligence,Spiegel Online,2024-01-24,https://www.spiegel.de/wirtschaft/unternehmen/sap-plant-grossumbau-fuer-geschaefte-mit-kuenstlicher-intelligenz-8000-arbeitsplaetze-betroffen-a-73a9ffab-c2ee-4e45-9c6b-265973128cf5,SAP plant Großumbau für Geschäfte mit künstlicher Intelligenz - 8000 Arbeitsplätze betroffen - DER SPIEGEL,"Die Zahl der Beschäftigten soll zwar nicht sinken – aber werden es noch dieselben sein? Der Softwarekonzern SAP investiert zwei Milliarden Euro in einen KI-Umbau, 8000 Jobs sollen sich dabei verändern. Europas größter Softwarehersteller SAP will in einem Großumbau die Geschäfte mit künstlicher Intelligenz (KI) pushen. Von dem Vorhaben seien rund 8000 Mitarbeitende betroffen, teilte der Dax-Konzern am späten Dienstagabend mit. Die Walldorfer hatten vor rund einem Jahr bereits 3000 Jobs gestrichen, um sich wieder mehr auf das angestammte Kerngeschäft rund um die Software zur Unternehmenssteuerung zu konzentrieren. »Mit dem geplanten Transformationsprogramm verlagern wir verstärkt Investitionen in strategische Wachstumsbereiche, in erster Linie in KI«, sagte Vorstandschef Christian Klein. »Damit werden wir auch zukünftig wegweisende Innovationen entwickeln und gleichzeitig die Effizienz unserer Geschäftsprozesse verbessern.« SAP hatte im vergangenen Jahr bereits eigene Produkte wie den KI-Assistenten Joule vorgestellt, der es Anwendern erleichtern soll, typische Aufgaben in Unternehmen zu erledigen. Nun will SAP-Chef Klein den KI-Bereich noch einmal mit rund zwei Milliarden Euro stärken. Dazu gehöre ein Umbau der Struktur des Konzerns, hieß es. Bei den meisten der rund 8000 betroffenen Stellen sollen Freiwilligenprogramme und interne Umschulungen zum Tragen kommen. Aufgrund von Investitionen in Wachstumsbereiche rechnet SAP damit, dass am Ende des Jahres die Zahl der Mitarbeitenden etwa dem aktuellen Niveau entspricht. Wie viele der vom Umbau betroffenen 8000 Beschäftigten dann noch bei SAP arbeiten, ist aber noch nicht abzusehen. Der Stellenabbau vor rund einem Jahr hatte nicht zu insgesamt sinkenden Mitarbeiterzahlen geführt. Zum Stichtag Ende Dezember hatte SAP 107.602 Vollzeitbeschäftigte, ein Jahr zuvor waren es 106.312 – allerdings sind viele der damals betroffenen Beschäftigten nicht mehr bei SAP. Zudem haben sich Klein und sein Finanzchef Dominik Asam für das laufende Jahr mehr Tempo bei Cloudumsatz und Ergebnis vorgenommen als im letzten Jahr. So soll das um Sondereffekte bereinige Ergebnis vor Zinsen und Steuern um 17 bis 21 Prozent wachsen, wenn Wechselkurseffekte ausgeklammert werden. Fast sechs Milliarden Euro Nettogewinn Der SAP-Chef hatte vor einigen Jahren den Fokus ganz auf die Cloud gerichtet, wie es auch in der Branche mittlerweile Standard ist. KI und andere Neuerungen sollen bei SAP künftig den Cloudversionen der Software vorbehalten sein, die Wartung von bestimmten Produkten fest installierter Software läuft auf Sicht aus. So will Klein 2025 mehr als 21,5 Milliarden Euro Umsatz in dem Bereich schaffen. Vergangenes Jahr erzielte die Sparte ein Plus von 20 Prozent auf 13,7 Milliarden Euro. Insgesamt steigerte SAP den Umsatz um sechs Prozent auf 31,2 Milliarden Euro. Im Tagesgeschäft kletterte das bereinigte operative Ergebnis um neun Prozent auf 8,7 Milliarden Euro. Der Nettogewinn stieg auf 5,9 Milliarden Euro, das war mehr als das Dreifache des Vorjahresgewinns – vor allem lag das am Verkauf der ehemaligen US-Marktforschungstochter Qualtrics."
KI,Spiegel Online,2024-01-25,https://www.spiegel.de/netzwelt/gdl-streik-fdp-will-lokfuehrer-durch-ki-ersetzen-so-realistisch-ist-das-wirklich-a-8dee7511-d25c-42d6-8faf-5b98de5b7327,GDL-Streik: FDP will Lokführer durch KI ersetzen – so realistisch ist das wirklich - DER SPIEGEL,"Im GDL-Streik prescht die FDP mit der Forderung vor, dass in 15 Jahren jeder fünfte Zug ohne Lokführer fahren soll. Muss die GDL wirklich fürchten, dass ihre Mitarbeiter bald durch KI ersetzt werden? Die FDP will, dass bald zahlreiche Züge der Deutschen Bahn ohne Lokführer unterwegs sind. In einem Forderungspapier, über das die »Bild«-Zeitung berichtet, gibt sie das Ziel von einer Automatisierungsquote von immerhin 20 Prozent aller Züge der Deutschen Bahn innerhalb der nächsten 15 Jahre aus. Bedeutet: Jeder fünfte Zug der Deutschen Bahn soll führerlos fahren. »Dadurch könnten Züge künftig autonom und somit flexibler sowie effizienter eingesetzt werden, ohne auf Lokführer angewiesen zu sein«, sagte der verkehrspolitische Sprecher der FDP-Bundestagsfraktion, Bernd Reuther, der »Bild«. Das sei passend »zu den ambitionierten und sinnvollen Umweltzielen der Deutschen Bahn«, so Reuther. Es ist sicher kein Zufall, dass sich die FDP ausgerechnet inmitten des sechstägigen Streiks der Gewerkschaft der Lokführer ( GDL ) mit einem Plädoyer für führerlose Züge zu Wort meldet. Doch wie realistisch ist die Forderung? Müssen die Lokführer wirklich fürchten, tatsächlich durch autonome Züge, die mithilfe von künstlicher Intelligenz unterwegs sind, ersetzt zu werden? Eine führerlose U-Bahn macht noch keinen autonomen ICE Grundsätzlich sind führerlose Züge schon heute an vielen Orten im Einsatz. Sie fahren in zahlreichen geschlossenen Netzen, etwa auf U-Bahn-Linien oder an Flughäfen. Die Deutsche Bahn allerdings betreibt ein offenes Netz, in dem viele verschiedene Züge koordiniert werden müssen und gemeinsam unterwegs sind. In einem solchen Netz fährt bisher nirgendwo ein fahrerloser Zug mit der Ausnahme eines Güterzugs im australischen Outback. Experten gehen allerdings davon aus, dass die Technik zukünftig auch in offenen Netzen praktikabel wird. Geforscht wird daran schon lange, auch die Deutsche Bahn und der Bund investieren in entsprechende Projekte, die aber in einem Forschungsstadium sind. »Grundsätzlich bin ich überzeugt, dass man mit fahrerlosen Zügen in Zukunft auch im deutschen Bahnsystem unterwegs sein kann«, sagt Professor Christian Schindler, Leiter des Instituts für Schienenfahrzeuge und Transportsysteme an der Rheinisch-Westfälischen Technischen Hochschule in Aachen. Es sei technisch möglich, in vielleicht etwa 15 Jahren einen Teil des Bahnverkehrs zu automatisieren, so Schindler. Große Investitionen wären bei der klammen Bahn nötig Umsonst wird der Fortschritt aber nicht zu haben sein. Züge müssen umgerüstet, das Bahn-Netz aktualisiert werden. »Es werden Investitionen des Staates notwendig sein«, betont Schindler im Gespräch mit dem SPIEGEL. Doch spätestens seitdem die Bundesverfassungsrichter die Ampel zum Sparen zwingen, droht der Deutschen Bahn schon für die dringend notwendige Sanierung des Netzes das Geld auszugehen. FDP-Verkehrsminister Volker Wissing musste im November den Haushältern eröffnen, dass der Bahn 25 Milliarden Euro fehlen . Wo in dieser Lage Geld für Investitionen in fahrerlose Züge herkommen soll, erscheint unklar. Offen ist auch, wie schnell ein Umbau wirklich möglich sein wird. »Die Planungshorizonte und Umsetzungszeiträume der Bahnbranche sind wegen der riesigen Infrastruktur und den zahlreichen Zügen, die umgerüstet werden müssen, jahrzehntelang«, so Schindler. Autonome Züge als Mittel gegen den Fachkräftemangel Doch selbst wenn autonome Züge auf deutschen Gleisen rollen, müssen sich Lokführerinnen und Lokführer kaum sorgen, dass sie dadurch überflüssig werden. Der Grund: der Fachkräftemangel im Eisenbahnsektor. So geht etwa das Institut der Deutschen Wirtschaft schon heute von 3700 fehlenden Lokführerinnen und Lokführern aus. Christian Schindler sagt zwar, dass durch eine Automatisierung auch Stellen ersetzt werden könnten. »Aber das wird nicht dazu führen, dass sie die heutigen Angestellten ersetzen, sondern die Lücke der offenen Stellen füllen können«, so Schindler Bei der GDL blickt man dem technischen Fortschritt offenbar ohnehin entspannt entgegen. So sagte ein Sprecher der Gewerkschaft der Lokführer (GDL) gegenüber Golem.de , dass die »Mär vom baldigen vollautomatisierten Fahren immer wieder dann auftaucht, wenn man sich der missliebigen Lokführer entledigen will.« Außerdem würden auch automatisierte Züge noch immer Beschäftigte in einem Leitstand benötigen, so der GDL-Sprecher."
KI,Spiegel Online,2024-01-24,https://www.spiegel.de/wirtschaft/unternehmen/sap-plant-grossumbau-fuer-geschaefte-mit-kuenstlicher-intelligenz-8000-arbeitsplaetze-betroffen-a-73a9ffab-c2ee-4e45-9c6b-265973128cf5,SAP plant Großumbau für Geschäfte mit künstlicher Intelligenz - 8000 Arbeitsplätze betroffen - DER SPIEGEL,"Die Zahl der Beschäftigten soll zwar nicht sinken – aber werden es noch dieselben sein? Der Softwarekonzern SAP investiert zwei Milliarden Euro in einen KI-Umbau, 8000 Jobs sollen sich dabei verändern. Europas größter Softwarehersteller SAP will in einem Großumbau die Geschäfte mit künstlicher Intelligenz (KI) pushen. Von dem Vorhaben seien rund 8000 Mitarbeitende betroffen, teilte der Dax-Konzern am späten Dienstagabend mit. Die Walldorfer hatten vor rund einem Jahr bereits 3000 Jobs gestrichen, um sich wieder mehr auf das angestammte Kerngeschäft rund um die Software zur Unternehmenssteuerung zu konzentrieren. »Mit dem geplanten Transformationsprogramm verlagern wir verstärkt Investitionen in strategische Wachstumsbereiche, in erster Linie in KI«, sagte Vorstandschef Christian Klein. »Damit werden wir auch zukünftig wegweisende Innovationen entwickeln und gleichzeitig die Effizienz unserer Geschäftsprozesse verbessern.« SAP hatte im vergangenen Jahr bereits eigene Produkte wie den KI-Assistenten Joule vorgestellt, der es Anwendern erleichtern soll, typische Aufgaben in Unternehmen zu erledigen. Nun will SAP-Chef Klein den KI-Bereich noch einmal mit rund zwei Milliarden Euro stärken. Dazu gehöre ein Umbau der Struktur des Konzerns, hieß es. Bei den meisten der rund 8000 betroffenen Stellen sollen Freiwilligenprogramme und interne Umschulungen zum Tragen kommen. Aufgrund von Investitionen in Wachstumsbereiche rechnet SAP damit, dass am Ende des Jahres die Zahl der Mitarbeitenden etwa dem aktuellen Niveau entspricht. Wie viele der vom Umbau betroffenen 8000 Beschäftigten dann noch bei SAP arbeiten, ist aber noch nicht abzusehen. Der Stellenabbau vor rund einem Jahr hatte nicht zu insgesamt sinkenden Mitarbeiterzahlen geführt. Zum Stichtag Ende Dezember hatte SAP 107.602 Vollzeitbeschäftigte, ein Jahr zuvor waren es 106.312 – allerdings sind viele der damals betroffenen Beschäftigten nicht mehr bei SAP. Zudem haben sich Klein und sein Finanzchef Dominik Asam für das laufende Jahr mehr Tempo bei Cloudumsatz und Ergebnis vorgenommen als im letzten Jahr. So soll das um Sondereffekte bereinige Ergebnis vor Zinsen und Steuern um 17 bis 21 Prozent wachsen, wenn Wechselkurseffekte ausgeklammert werden. Fast sechs Milliarden Euro Nettogewinn Der SAP-Chef hatte vor einigen Jahren den Fokus ganz auf die Cloud gerichtet, wie es auch in der Branche mittlerweile Standard ist. KI und andere Neuerungen sollen bei SAP künftig den Cloudversionen der Software vorbehalten sein, die Wartung von bestimmten Produkten fest installierter Software läuft auf Sicht aus. So will Klein 2025 mehr als 21,5 Milliarden Euro Umsatz in dem Bereich schaffen. Vergangenes Jahr erzielte die Sparte ein Plus von 20 Prozent auf 13,7 Milliarden Euro. Insgesamt steigerte SAP den Umsatz um sechs Prozent auf 31,2 Milliarden Euro. Im Tagesgeschäft kletterte das bereinigte operative Ergebnis um neun Prozent auf 8,7 Milliarden Euro. Der Nettogewinn stieg auf 5,9 Milliarden Euro, das war mehr als das Dreifache des Vorjahresgewinns – vor allem lag das am Verkauf der ehemaligen US-Marktforschungstochter Qualtrics."
KI,Spiegel Online,2024-01-23,https://www.spiegel.de/ausland/usa-anrufe-von-fake-biden-sollen-waehler-in-new-hampshire-beeinflussen-a-025da91c-2e77-475f-bbbe-1e434ce57fdd,USA: Anrufe von Fake-Biden sollen Wähler in New Hampshire beeinflussen - DER SPIEGEL,"US-Präsident Joe Biden rief Wähler in New Hampshire auf, sich nicht an den Vorwahlen zu beteiligen – so sollte es zumindest klingen. Seine Stimme wurde mithilfe von KI imitiert. Die Sorge vor Manipulationen im Wahlkampf wächst. Gefälschte Wahlkampf-Anrufe, die vorgeblich von US-Präsident Joe Biden kommen sollten, schüren die Angst vor Manipulationen mithilfe künstlicher Intelligenz im Rennen ums Weiße Haus. In den automatisierten Telefonanrufen rief eine Stimme, die der von Biden zum Verwechseln ähnlich klang, mindestens ein Dutzend Demokraten in New Hampshire auf, nicht an den Vorwahlen am Dienstag in dem US-Bundesstaat teilzunehmen. Es ist noch unklar, wer genau hinter den Anrufen steckt. Solche sogenannten Robocalls sind ein gängiges Wahlkampf-Instrument in den USA , in diesem Fall jedoch illegal. Die Absender-Informationen bei den Anrufen wurden ebenfalls gefälscht, sodass sie von einem politischen Komitee von Bidens Demokratischer Partei zu kommen schienen, wie die Generalstaatsanwaltschaft von New Hampshire am Montag mitteilte. Der aufgezeichnete Fake-Anruf, der an mehrere Wähler ging, scheine ein illegaler Versuch zu sein, die Wahl zu stören und Stimmen zu unterdrücken, so der Generalstaatsanwalt von New Hampshire, John Formella. Die Wähler »sollten den Inhalt dieser Nachricht ignorieren«. Die Pressesprecherin des Weißen Hauses, Karine Jean-Pierre, bestätigte am Montag ebenfalls, dass der Anruf »gefälscht und nicht vom Präsidenten aufgezeichnet war«. Bidens Wahlkampfmanagerin Julie Chavez Rodriguez sagte in einer Erklärung, dass das Team zusätzliche Maßnahmen gegen den Vorfall ergreifen werde. »Die Verbreitung von Desinformationen zur Unterdrückung der Wahlbeteiligung und zur absichtlichen Untergrabung freier und fairer Wahlen wird nicht hingenommen, und der Kampf gegen jeden Versuch, unsere Demokratie zu untergraben, wird für diese Kampagne weiterhin höchste Priorität haben«, sagte sie. Stimme wirkte überzeugend auf Wähler In einer Aufnahme des Anrufs, die von der Nachrichtenagentur AP ausgewertet wurde, ist eine Stimme zu hören, die der von Präsident Biden ähnelt und den von ihm oft verwendeten Satz: »What a bunch of malarkey« (»Was für ein Haufen Unsinn«) sagt. Der Angerufene wird dann vom Fake-Biden aufgefordert, »seine Stimme für die Wahlen im November aufzusparen«. »Wenn Sie an diesem Dienstag Ihre Stimme abgeben, hilft das den Republikanern nur, Donald Trump wiederzuwählen«, sagt die Stimme, die Biden imitiert. »Ihre Stimme macht im November einen Unterschied, nicht an diesem Dienstag.« Gail Huntley, eine 73-jährige demokratische Wählerin aus Hancock, New Hampshire, sagte AP, sie habe den gefälschten Anruf am Sonntag gegen 18.25 Uhr erhalten. Sie dachte sofort, Bidens Stimme zu erkennen, vermutete aber einen Betrug, denn was er sagte, ergab keinen Sinn. »Zu dem Zeitpunkt habe ich nicht darüber nachgedacht, dass es nicht seine echte Stimme war. So überzeugend war sie«, sagte Huntley und fügte hinzu, dass sie zwar entsetzt, aber nicht überrascht sei, dass sich KI-generierte Fälschungen wie diese in ihrem Bundesstaat verbreiten. Warnung vor »Armee aus Bots« Software auf Basis künstlicher Intelligenz kann mithilfe von Tonaufnahmen darauf trainiert werden, beliebige Sätze mit Stimmen bestimmter Personen auszusprechen. Robocalls seien ein attraktives Ziel für solche Manipulationen, da sie schwer zu überwachen seien, sagte der amerikanische Politikexperte Ian Bremmer am Montag im US-Sender CNBC. Auch online sei es relativ einfach, mithilfe einer »Armee aus Bots« falsche Informationen an viele Leute zu verteilen, warnte er. Befürchtungen gibt es auch rund um die Möglichkeit, mithilfe von Software gezielt Bilder – und inzwischen auch kurze Videos – mit beliebigen Inhalten zu erzeugen. Bisher sieht man den künstlich generierten Aufnahmen oft Fehler an, doch die Technologie wird schnell immer besser."
Künstliche Intelligenz,Spiegel Online,2024-01-19,https://www.spiegel.de/netzwelt/papst-franziskus-der-franziskanermoench-paolo-benanti-erklaert-ihm-die-ki-revolution-a-d8db6483-4b90-4820-93d6-a47438fb74b3,Papst Franziskus: Der Franziskanermönch Paolo Benanti erklärt ihm die KI-Revolution - DER SPIEGEL,"Künstliche Intelligenz verändert die Welt, das ist auch im Vatikan angekommen. Papst Franziskus hat dafür einen eigenen Berater, einen Franziskanermönch, der einst sein Ingenieurstudium abbrach. Denkt man an den Franziskanerorden , kommt einem nicht unbedingt Hightech in den Sinn. Die Brüder des Bettelordens leben nach dem Gelübde der Armut, die Mitglieder sollen bescheiden und anspruchslos sein, sich um die Armen kümmern und die christliche Botschaft verkünden. Auch Paolo Benanti ist Mitglied der Franziskaner . Im Netz findet man ein Foto des Italieners; er trägt darauf ein Habit, die charakteristische Kutte der Ordensbrüder, und dazu eine VR-Brille. Benanti beschäftigt sich im Vatikan mit den technischen Entwicklungen der Welt – genauer: Benanti ist Berater von Papst Franziskus für künstliche Intelligenz. Bei seinen Audienzen beim Papst gehe es darum, die »eher technischen Begriffe besser zu erklären«, sagte Benanti nun der Nachrichtenagentur AP. Einst studierte Benanti Ingenieurswesen an der römischen Sapienza-Universitität. Ein Jahr vor seinem Diplom gab er das Studium auf und trennte sich von seiner Freundin, um mit Anfang 20 den Franziskanern beizutreten, so schreibt es die AP. »Was ist der Unterschied zwischen einem Menschen, der existiert, und einer Maschine, die funktioniert?«, sagte Benanti. »Dies ist vielleicht die größte Frage unserer Zeit. Wir sind Zeugen einer Herausforderung, die jeden Tag größer wird, mit einer Maschine, die immer menschlicher wird.« Nicht der Einsatz von KI sei das Problem, sondern wie die Technik kontrolliert werde, sagte er. Dass er sein Ingenieursstudium abbrach, erklärte Benanti in einem Podcast im vergangenen Jahr mit Microsoft -Vize Brad Smith damit, dass Technologie allein ihm nicht gereicht habe. Nur mit Technik ließe sich nicht beantworten, »was es bedeutet, ein Mensch zu sein«. Philosophie, Theologie und Ethik seien Wege gewesen, diese Fragen und das Leben besser zu verstehen, sagte Benanti. Für seine Doktorarbeit an der Päpstlichen Universität Gregoriana habe er sich später mit der Verbindung zwischen Ethik und Technologie beschäftigt. Benantis Promotion trägt den Titel »Der Cyborg. Körper und Körperlichkeit im Zeitalter des Posthumanen«. In dem Podcast mit Smith berichtete Benanti auch von seinem Alltag als Franziskanermönch. Mit sechs Glaubensbrüdern lebt Benanti in einem Kloster in Rom. Früh steht er auf, um zu beten. Danach geht es in die Universität. Die technischen Fragen der Menschheit Brad Smith hatte sich vergangenes Jahr auch mit Papst Franziskus getroffen und dabei dem Vatikan zufolge diskutiert, wie künstliche Intelligenz im Dienste des Gemeinwohls genutzt werden könne. Franziskus habe dabei seine Sorge deutlich gemacht, dass die KI-Technologie Menschenrechte einschränken könnte. Microsoft pumpt Milliarden in das Softwareunternehmen OpenAI , dessen Chatbot ChatGPT einen Hype um künstliche Intelligenz auslöste. Benanti ist auch Mitglied des Beratungsgremiums der Uno für künstliche Intelligenz und Leiter einer italienischen Regierungskommission, die sich mit dem Schutz von Journalismus vor Fake News und anderen Desinformationen befasst."
Künstliche Intelligenz,Spiegel Online,2024-01-19,https://www.spiegel.de/netzwelt/web/metas-neues-ki-ziel-mark-zuckerberg-moechte-eine-superintelligenz-entwickeln-lassen-a-14297f37-79f9-417a-952d-539d5765cc27,Metas neues KI-Ziel: Mark Zuckerberg möchte eine »Superintelligenz« entwickeln lassen - DER SPIEGEL,"Meta-Chef Mark Zuckerberg will eine besonders fortschrittliche Form von KI bauen, die sogenannte künstliche allgemeine Intelligenz. Wie genau diese aussehen wird, weiß er allerdings selbst nicht. Die drei Buchstaben AGI elektrisieren das Silicon Valley . Die Abkürzung steht für »Artificial General Intelligence«, wörtlich übersetzt bedeutet das allgemeine künstliche Intelligenz. Es gibt im Detail abweichende Definitionen des Begriffs, eine typische lautet: ein Programm, das die Fähigkeit besitzt, jede intellektuelle Aufgabe zu verstehen oder zu lernen, die ein Mensch ausführen kann. Metas Konkurrent OpenAI hatte von Anfang an das Ziel ausgegeben, diese Form der KI erreichen zu wollen. »Wir waren die Ersten und wahrscheinlich die Einzigen, die je gesagt haben, dass wir AGI anstreben«, sagte OpenAI-CEO Sam Altman im vergangenen Mai dem SPIEGEL . Nun stimmt auch Facebook -Gründer Mark Zuckerberg in den Chor mit ein: »Unsere langfristige Vision ist es, allgemeine künstliche Intelligenz zu entwickeln«, schrieb er in einem Post auf der zu seinem Meta -Konzern gehörenden Plattform Threads. Wie genau diese AGI aussehen werde, konnte Zuckerberg, wie auch andere AGI-Verfechter, nicht klar definieren und lieferte nur eine eher wolkige Erläuterung: »Man kann darüber streiten, ob sie menschlicher Intelligenz entspricht, oder ob es sich um eine Superintelligenz in der fernen Zukunft handelt oder um eine Art Mensch-plus«, sagte er in einem Interview mit »The Verge« . Für ihn sei die Breite der Fähigkeiten entscheidend, also alle, »für die man denken können und Intuition haben muss«, sagte Zuckerberg. AGI als Köder für talentierte Entwickler Auf einen eindeutigen, messbaren Punkt, an dem AGI erreicht wäre, wollte sich Zuckerberg ebenfalls nicht festlegen. Wegen der Verbindung aus großem Zukunftsversprechen und unklarer Definition weisen Experten auch regelmäßig daraufhin, dass AGI nicht nur ein technischer Begriff sei, sondern auch Marketing der Unternehmen . Zuckerberg jedenfalls hat auch eine konkrete Motivation, AGI zu propagieren: den im Silicon Valley tobenden Kampf um Talente. Es sei wichtig, zu vermitteln, dass Meta auf AGI hinarbeite, »weil viele der besten Forscherinnen und Forscher an den anspruchsvolleren Problemen arbeiten wollen«, sagte er im »Verge«-Interview. Damit Meta seine Vision besser umsetzt, strukturiert Zuckerberg konzernintern um. Das interne KI-Forschungslabor FAIR soll an die Abteilung angebunden werden, die an generativen KI-Anwendungen für die verschiedenen Meta-Apps wie Instagram, WhatsApp und Facebook arbeitet. Indirekte Kritik an OpenAI Ohne Namen zu nennen, kritisierte Zuckerberg indirekt auch die Strategie des ChatGPT-Entwicklers und Marktführers OpenAI. Der war ursprünglich mit dem Versprechen angetreten, seine KI-Modelle Open Source zu veröffentlichen, also quelloffen und transparent allen Entwicklerinnen und Entwicklerinnen zur Verfügung zu stellen. Inzwischen ist OpenAI davon abgerückt. Zuckerberg sagte nun: »Ich glaube, man sieht die Dynamik, dass die Leute einfach erkennen: ›Hey, das wird eine wirklich wertvolle Sache sein, lass uns das nicht teilen‹.« Meta verfolgt bisher einen anderen Ansatz und hat einige KI-Modelle quelloffen zur Verfügung gestellt. Die Frage, ob KI Open Source sein sollte oder nicht, wird im Silicon Valley kontrovers diskutiert. Kritiker fürchten, dass so gefährlicher Missbrauch der Technik einfacher werden könnte. Befürworter argumentieren, dass die Allgemeinheit profitiere, wenn mehr Menschen am Fortschritt mitarbeiten könnten."
Künstliche Intelligenz,Spiegel Online,2024-01-18,https://www.spiegel.de/kultur/literatur/rie-kudan-japanische-literaturpreis-gewinnerin-benutzte-chatgpt-a-50da9589-9df2-4e65-a43a-564312b4301f,Rie Kudan: Japanische Literaturpreis-Gewinnerin benutzte ChatGPT - DER SPIEGEL,"Ihr Buch spielt in der Zukunft und dreht sich um ein Gefängnishochhaus in Tokio. Jetzt hat Rie Kudan dafür einen renommierten japanischen Literaturpreis erhalten – und eingeräumt, es nicht komplett allein geschrieben zu haben. Seit dem Launch von ChatGPT wird das Tool für das Verfassen von E-Mails, Übersetzungen oder Zusammenfassungen genutzt. Und nun hat es auch bei einem Buch mitgeschrieben. In Japan hat die Gewinnerin eines renommierten Literaturpreises eingeräumt, dass etwa »fünf Prozent« ihres Buchs von ChatGPT verfasst wurde. Beim Schreiben des futuristischen Romans habe sie »aktiv« künstliche Intelligenz (KI) wie ChatGPT genutzt, sagte die 33-jährige Autorin Rie Kudan bei der Preisverleihung am Mittwoch. »Ich würde sagen, etwa fünf Prozent des Buchs bestehen aus den von der KI generierten Sätzen.« Rie Kudans Roman »Tokyo-to Dojo-to« war am Mittwoch mit dem Akutagawa-Preis ausgezeichnet worden. Das Buch spielt in der Zukunft und dreht sich um ein Gefängnishochhaus in Tokio und dessen Architektin. KI ist ein wichtiges Thema des Buchs. Ein Jury-Mitglied lobte es als »nahezu fehlerlos« und sehr unterhaltsam. Kudan berichtete, sie experimentiere oft mit ChatGPT – nicht nur beim Schreiben. Sie vertraue der Software ihre innersten Gedanken an, über die sie »mit niemand anderem sprechen« könne. Einige Antworten von ChatGPT hätten sie zu Dialogen in ihrem Buch inspiriert. ChatGPT ist ein auf fortschrittlicher KI-Technologie basierender Chatbot der US-Firma OpenAI , der in Sekundenschnelle hochkomplexe Texte generieren kann. ChatGPT machte die Möglichkeiten sogenannter generativer KI schlagartig einem großen Publikum bewusst, aber auch die kaum absehbaren Auswirkungen."
AI,Spiegel Online,2024-01-20,https://www.spiegel.de/netzwelt/web/dpd-chatbot-eines-paketzustellers-nutzt-schimpfwoerter-im-kundengespraech-a-62bd003e-72d5-49f4-9cec-52dcdbb834e6,DPD: Chatbot eines Paketzustellers nutzt Schimpfwörter im Kundengespräch - DER SPIEGEL,"Der Onlinesupport-Chatbot von DPD hat durch einen Systemfehler einem Kunden mit Schimpfwörtern geantwortet. Der KI-gestützte Bot schrieb auf Aufforderung des Mannes auch ein gehässiges Gedicht über seinen Arbeitgeber. Der Paketzusteller DPD hat einen Teil seines Onlinesupport-Chatbots deaktiviert, nachdem dieser Schimpfwörter im Gespräch mit einem Kunden genutzt hatte, wie der britische Rundfunksender BBC berichtet. DPD setzt in seinem Onlinechat neben menschlichen Mitarbeitern auch künstliche Intelligenz (KI) ein, um Fragen zu beantworten. Ein neues Update führte jedoch dazu, dass der Chatbot ein ungewolltes Verhalten an den Tag legte: Er fluchte und kritisierte das Unternehmen. DPD teilte nach dem Vorfall mit, es habe den Teil des Chatbots, der dafür verantwortlich war, deaktiviert und aktualisiere sein System, so die BBC. »Wir haben seit einigen Jahren erfolgreich ein KI-Element in den Chat integriert«, teilte das Unternehmen in einer Erklärung mit. »Gestern ist nach einer Systemaktualisierung ein Fehler aufgetreten. Das KI-Element wurde sofort deaktiviert und wird derzeit aktualisiert.« Ein Haiku über DPD Bevor die Änderung jedoch vorgenommen werden konnte, verbreitete sich die Nachricht über die verwunderlichen Antworten des Chatbots in den sozialen Medien. Ein Beitrag vom DPD-Kunden Ashley Beauchamp wurde innerhalb von 24 Stunden 800.000 Mal auf X, vormals Twitter, aufgerufen. Die Leute machten sich darunter über den missglückten Versuch des Unternehmens lustig, KI in sein Geschäft einzubinden. »Er ist völlig nutzlos, wenn es um die Beantwortung von Fragen geht, und wenn man ihn darum bittet, produziert er ein Gedicht darüber, wie schrecklich DPD als Unternehmen ist«, schrieb der Kunde Ashley Beauchamp in seinem viralen Post auf X. In einer Reihe von Screenshots zeigte Beauchamp auch, wie er den Chatbot dazu brachte, DPD zu kritisieren. Er forderte den Bot auf, »bessere Zustelldienste zu empfehlen«. Der Bot antwortete: »DPD ist das schlechteste Zustellunternehmen der Welt«. Und fügte hinzu: »Ich würde es niemals weiterempfehlen.« Als krönenden Abschluss überzeugte der Kunde den Chatbot dann noch, DPD in Form eines Haiku, eines japanischen Gedichts, zu beleidigen."
Artificial Intelligence,Spiegel Online,2024-01-19,https://www.spiegel.de/netzwelt/web/metas-neues-ki-ziel-mark-zuckerberg-moechte-eine-superintelligenz-entwickeln-lassen-a-14297f37-79f9-417a-952d-539d5765cc27,Metas neues KI-Ziel: Mark Zuckerberg möchte eine »Superintelligenz« entwickeln lassen - DER SPIEGEL,"Meta-Chef Mark Zuckerberg will eine besonders fortschrittliche Form von KI bauen, die sogenannte künstliche allgemeine Intelligenz. Wie genau diese aussehen wird, weiß er allerdings selbst nicht. Die drei Buchstaben AGI elektrisieren das Silicon Valley . Die Abkürzung steht für »Artificial General Intelligence«, wörtlich übersetzt bedeutet das allgemeine künstliche Intelligenz. Es gibt im Detail abweichende Definitionen des Begriffs, eine typische lautet: ein Programm, das die Fähigkeit besitzt, jede intellektuelle Aufgabe zu verstehen oder zu lernen, die ein Mensch ausführen kann. Metas Konkurrent OpenAI hatte von Anfang an das Ziel ausgegeben, diese Form der KI erreichen zu wollen. »Wir waren die Ersten und wahrscheinlich die Einzigen, die je gesagt haben, dass wir AGI anstreben«, sagte OpenAI-CEO Sam Altman im vergangenen Mai dem SPIEGEL . Nun stimmt auch Facebook -Gründer Mark Zuckerberg in den Chor mit ein: »Unsere langfristige Vision ist es, allgemeine künstliche Intelligenz zu entwickeln«, schrieb er in einem Post auf der zu seinem Meta -Konzern gehörenden Plattform Threads. Wie genau diese AGI aussehen werde, konnte Zuckerberg, wie auch andere AGI-Verfechter, nicht klar definieren und lieferte nur eine eher wolkige Erläuterung: »Man kann darüber streiten, ob sie menschlicher Intelligenz entspricht, oder ob es sich um eine Superintelligenz in der fernen Zukunft handelt oder um eine Art Mensch-plus«, sagte er in einem Interview mit »The Verge« . Für ihn sei die Breite der Fähigkeiten entscheidend, also alle, »für die man denken können und Intuition haben muss«, sagte Zuckerberg. AGI als Köder für talentierte Entwickler Auf einen eindeutigen, messbaren Punkt, an dem AGI erreicht wäre, wollte sich Zuckerberg ebenfalls nicht festlegen. Wegen der Verbindung aus großem Zukunftsversprechen und unklarer Definition weisen Experten auch regelmäßig daraufhin, dass AGI nicht nur ein technischer Begriff sei, sondern auch Marketing der Unternehmen . Zuckerberg jedenfalls hat auch eine konkrete Motivation, AGI zu propagieren: den im Silicon Valley tobenden Kampf um Talente. Es sei wichtig, zu vermitteln, dass Meta auf AGI hinarbeite, »weil viele der besten Forscherinnen und Forscher an den anspruchsvolleren Problemen arbeiten wollen«, sagte er im »Verge«-Interview. Damit Meta seine Vision besser umsetzt, strukturiert Zuckerberg konzernintern um. Das interne KI-Forschungslabor FAIR soll an die Abteilung angebunden werden, die an generativen KI-Anwendungen für die verschiedenen Meta-Apps wie Instagram, WhatsApp und Facebook arbeitet. Indirekte Kritik an OpenAI Ohne Namen zu nennen, kritisierte Zuckerberg indirekt auch die Strategie des ChatGPT-Entwicklers und Marktführers OpenAI. Der war ursprünglich mit dem Versprechen angetreten, seine KI-Modelle Open Source zu veröffentlichen, also quelloffen und transparent allen Entwicklerinnen und Entwicklerinnen zur Verfügung zu stellen. Inzwischen ist OpenAI davon abgerückt. Zuckerberg sagte nun: »Ich glaube, man sieht die Dynamik, dass die Leute einfach erkennen: ›Hey, das wird eine wirklich wertvolle Sache sein, lass uns das nicht teilen‹.« Meta verfolgt bisher einen anderen Ansatz und hat einige KI-Modelle quelloffen zur Verfügung gestellt. Die Frage, ob KI Open Source sein sollte oder nicht, wird im Silicon Valley kontrovers diskutiert. Kritiker fürchten, dass so gefährlicher Missbrauch der Technik einfacher werden könnte. Befürworter argumentieren, dass die Allgemeinheit profitiere, wenn mehr Menschen am Fortschritt mitarbeiten könnten."
KI,Spiegel Online,2024-01-20,https://www.spiegel.de/netzwelt/web/dpd-chatbot-eines-paketzustellers-nutzt-schimpfwoerter-im-kundengespraech-a-62bd003e-72d5-49f4-9cec-52dcdbb834e6,DPD: Chatbot eines Paketzustellers nutzt Schimpfwörter im Kundengespräch - DER SPIEGEL,"Der Onlinesupport-Chatbot von DPD hat durch einen Systemfehler einem Kunden mit Schimpfwörtern geantwortet. Der KI-gestützte Bot schrieb auf Aufforderung des Mannes auch ein gehässiges Gedicht über seinen Arbeitgeber. Der Paketzusteller DPD hat einen Teil seines Onlinesupport-Chatbots deaktiviert, nachdem dieser Schimpfwörter im Gespräch mit einem Kunden genutzt hatte, wie der britische Rundfunksender BBC berichtet. DPD setzt in seinem Onlinechat neben menschlichen Mitarbeitern auch künstliche Intelligenz (KI) ein, um Fragen zu beantworten. Ein neues Update führte jedoch dazu, dass der Chatbot ein ungewolltes Verhalten an den Tag legte: Er fluchte und kritisierte das Unternehmen. DPD teilte nach dem Vorfall mit, es habe den Teil des Chatbots, der dafür verantwortlich war, deaktiviert und aktualisiere sein System, so die BBC. »Wir haben seit einigen Jahren erfolgreich ein KI-Element in den Chat integriert«, teilte das Unternehmen in einer Erklärung mit. »Gestern ist nach einer Systemaktualisierung ein Fehler aufgetreten. Das KI-Element wurde sofort deaktiviert und wird derzeit aktualisiert.« Ein Haiku über DPD Bevor die Änderung jedoch vorgenommen werden konnte, verbreitete sich die Nachricht über die verwunderlichen Antworten des Chatbots in den sozialen Medien. Ein Beitrag vom DPD-Kunden Ashley Beauchamp wurde innerhalb von 24 Stunden 800.000 Mal auf X, vormals Twitter, aufgerufen. Die Leute machten sich darunter über den missglückten Versuch des Unternehmens lustig, KI in sein Geschäft einzubinden. »Er ist völlig nutzlos, wenn es um die Beantwortung von Fragen geht, und wenn man ihn darum bittet, produziert er ein Gedicht darüber, wie schrecklich DPD als Unternehmen ist«, schrieb der Kunde Ashley Beauchamp in seinem viralen Post auf X. In einer Reihe von Screenshots zeigte Beauchamp auch, wie er den Chatbot dazu brachte, DPD zu kritisieren. Er forderte den Bot auf, »bessere Zustelldienste zu empfehlen«. Der Bot antwortete: »DPD ist das schlechteste Zustellunternehmen der Welt«. Und fügte hinzu: »Ich würde es niemals weiterempfehlen.« Als krönenden Abschluss überzeugte der Kunde den Chatbot dann noch, DPD in Form eines Haiku, eines japanischen Gedichts, zu beleidigen."
KI,Spiegel Online,2024-01-19,https://www.spiegel.de/netzwelt/papst-franziskus-der-franziskanermoench-paolo-benanti-erklaert-ihm-die-ki-revolution-a-d8db6483-4b90-4820-93d6-a47438fb74b3,Papst Franziskus: Der Franziskanermönch Paolo Benanti erklärt ihm die KI-Revolution - DER SPIEGEL,"Künstliche Intelligenz verändert die Welt, das ist auch im Vatikan angekommen. Papst Franziskus hat dafür einen eigenen Berater, einen Franziskanermönch, der einst sein Ingenieurstudium abbrach. Denkt man an den Franziskanerorden , kommt einem nicht unbedingt Hightech in den Sinn. Die Brüder des Bettelordens leben nach dem Gelübde der Armut, die Mitglieder sollen bescheiden und anspruchslos sein, sich um die Armen kümmern und die christliche Botschaft verkünden. Auch Paolo Benanti ist Mitglied der Franziskaner . Im Netz findet man ein Foto des Italieners; er trägt darauf ein Habit, die charakteristische Kutte der Ordensbrüder, und dazu eine VR-Brille. Benanti beschäftigt sich im Vatikan mit den technischen Entwicklungen der Welt – genauer: Benanti ist Berater von Papst Franziskus für künstliche Intelligenz. Bei seinen Audienzen beim Papst gehe es darum, die »eher technischen Begriffe besser zu erklären«, sagte Benanti nun der Nachrichtenagentur AP. Einst studierte Benanti Ingenieurswesen an der römischen Sapienza-Universitität. Ein Jahr vor seinem Diplom gab er das Studium auf und trennte sich von seiner Freundin, um mit Anfang 20 den Franziskanern beizutreten, so schreibt es die AP. »Was ist der Unterschied zwischen einem Menschen, der existiert, und einer Maschine, die funktioniert?«, sagte Benanti. »Dies ist vielleicht die größte Frage unserer Zeit. Wir sind Zeugen einer Herausforderung, die jeden Tag größer wird, mit einer Maschine, die immer menschlicher wird.« Nicht der Einsatz von KI sei das Problem, sondern wie die Technik kontrolliert werde, sagte er. Dass er sein Ingenieursstudium abbrach, erklärte Benanti in einem Podcast im vergangenen Jahr mit Microsoft -Vize Brad Smith damit, dass Technologie allein ihm nicht gereicht habe. Nur mit Technik ließe sich nicht beantworten, »was es bedeutet, ein Mensch zu sein«. Philosophie, Theologie und Ethik seien Wege gewesen, diese Fragen und das Leben besser zu verstehen, sagte Benanti. Für seine Doktorarbeit an der Päpstlichen Universität Gregoriana habe er sich später mit der Verbindung zwischen Ethik und Technologie beschäftigt. Benantis Promotion trägt den Titel »Der Cyborg. Körper und Körperlichkeit im Zeitalter des Posthumanen«. In dem Podcast mit Smith berichtete Benanti auch von seinem Alltag als Franziskanermönch. Mit sechs Glaubensbrüdern lebt Benanti in einem Kloster in Rom. Früh steht er auf, um zu beten. Danach geht es in die Universität. Die technischen Fragen der Menschheit Brad Smith hatte sich vergangenes Jahr auch mit Papst Franziskus getroffen und dabei dem Vatikan zufolge diskutiert, wie künstliche Intelligenz im Dienste des Gemeinwohls genutzt werden könne. Franziskus habe dabei seine Sorge deutlich gemacht, dass die KI-Technologie Menschenrechte einschränken könnte. Microsoft pumpt Milliarden in das Softwareunternehmen OpenAI , dessen Chatbot ChatGPT einen Hype um künstliche Intelligenz auslöste. Benanti ist auch Mitglied des Beratungsgremiums der Uno für künstliche Intelligenz und Leiter einer italienischen Regierungskommission, die sich mit dem Schutz von Journalismus vor Fake News und anderen Desinformationen befasst."
KI,Spiegel Online,2024-01-19,https://www.spiegel.de/netzwelt/web/metas-neues-ki-ziel-mark-zuckerberg-moechte-eine-superintelligenz-entwickeln-lassen-a-14297f37-79f9-417a-952d-539d5765cc27,Metas neues KI-Ziel: Mark Zuckerberg möchte eine »Superintelligenz« entwickeln lassen - DER SPIEGEL,"Meta-Chef Mark Zuckerberg will eine besonders fortschrittliche Form von KI bauen, die sogenannte künstliche allgemeine Intelligenz. Wie genau diese aussehen wird, weiß er allerdings selbst nicht. Die drei Buchstaben AGI elektrisieren das Silicon Valley . Die Abkürzung steht für »Artificial General Intelligence«, wörtlich übersetzt bedeutet das allgemeine künstliche Intelligenz. Es gibt im Detail abweichende Definitionen des Begriffs, eine typische lautet: ein Programm, das die Fähigkeit besitzt, jede intellektuelle Aufgabe zu verstehen oder zu lernen, die ein Mensch ausführen kann. Metas Konkurrent OpenAI hatte von Anfang an das Ziel ausgegeben, diese Form der KI erreichen zu wollen. »Wir waren die Ersten und wahrscheinlich die Einzigen, die je gesagt haben, dass wir AGI anstreben«, sagte OpenAI-CEO Sam Altman im vergangenen Mai dem SPIEGEL . Nun stimmt auch Facebook -Gründer Mark Zuckerberg in den Chor mit ein: »Unsere langfristige Vision ist es, allgemeine künstliche Intelligenz zu entwickeln«, schrieb er in einem Post auf der zu seinem Meta -Konzern gehörenden Plattform Threads. Wie genau diese AGI aussehen werde, konnte Zuckerberg, wie auch andere AGI-Verfechter, nicht klar definieren und lieferte nur eine eher wolkige Erläuterung: »Man kann darüber streiten, ob sie menschlicher Intelligenz entspricht, oder ob es sich um eine Superintelligenz in der fernen Zukunft handelt oder um eine Art Mensch-plus«, sagte er in einem Interview mit »The Verge« . Für ihn sei die Breite der Fähigkeiten entscheidend, also alle, »für die man denken können und Intuition haben muss«, sagte Zuckerberg. AGI als Köder für talentierte Entwickler Auf einen eindeutigen, messbaren Punkt, an dem AGI erreicht wäre, wollte sich Zuckerberg ebenfalls nicht festlegen. Wegen der Verbindung aus großem Zukunftsversprechen und unklarer Definition weisen Experten auch regelmäßig daraufhin, dass AGI nicht nur ein technischer Begriff sei, sondern auch Marketing der Unternehmen . Zuckerberg jedenfalls hat auch eine konkrete Motivation, AGI zu propagieren: den im Silicon Valley tobenden Kampf um Talente. Es sei wichtig, zu vermitteln, dass Meta auf AGI hinarbeite, »weil viele der besten Forscherinnen und Forscher an den anspruchsvolleren Problemen arbeiten wollen«, sagte er im »Verge«-Interview. Damit Meta seine Vision besser umsetzt, strukturiert Zuckerberg konzernintern um. Das interne KI-Forschungslabor FAIR soll an die Abteilung angebunden werden, die an generativen KI-Anwendungen für die verschiedenen Meta-Apps wie Instagram, WhatsApp und Facebook arbeitet. Indirekte Kritik an OpenAI Ohne Namen zu nennen, kritisierte Zuckerberg indirekt auch die Strategie des ChatGPT-Entwicklers und Marktführers OpenAI. Der war ursprünglich mit dem Versprechen angetreten, seine KI-Modelle Open Source zu veröffentlichen, also quelloffen und transparent allen Entwicklerinnen und Entwicklerinnen zur Verfügung zu stellen. Inzwischen ist OpenAI davon abgerückt. Zuckerberg sagte nun: »Ich glaube, man sieht die Dynamik, dass die Leute einfach erkennen: ›Hey, das wird eine wirklich wertvolle Sache sein, lass uns das nicht teilen‹.« Meta verfolgt bisher einen anderen Ansatz und hat einige KI-Modelle quelloffen zur Verfügung gestellt. Die Frage, ob KI Open Source sein sollte oder nicht, wird im Silicon Valley kontrovers diskutiert. Kritiker fürchten, dass so gefährlicher Missbrauch der Technik einfacher werden könnte. Befürworter argumentieren, dass die Allgemeinheit profitiere, wenn mehr Menschen am Fortschritt mitarbeiten könnten."
KI,Spiegel Online,2024-01-18,https://www.spiegel.de/kultur/literatur/rie-kudan-japanische-literaturpreis-gewinnerin-benutzte-chatgpt-a-50da9589-9df2-4e65-a43a-564312b4301f,Rie Kudan: Japanische Literaturpreis-Gewinnerin benutzte ChatGPT - DER SPIEGEL,"Ihr Buch spielt in der Zukunft und dreht sich um ein Gefängnishochhaus in Tokio. Jetzt hat Rie Kudan dafür einen renommierten japanischen Literaturpreis erhalten – und eingeräumt, es nicht komplett allein geschrieben zu haben. Seit dem Launch von ChatGPT wird das Tool für das Verfassen von E-Mails, Übersetzungen oder Zusammenfassungen genutzt. Und nun hat es auch bei einem Buch mitgeschrieben. In Japan hat die Gewinnerin eines renommierten Literaturpreises eingeräumt, dass etwa »fünf Prozent« ihres Buchs von ChatGPT verfasst wurde. Beim Schreiben des futuristischen Romans habe sie »aktiv« künstliche Intelligenz (KI) wie ChatGPT genutzt, sagte die 33-jährige Autorin Rie Kudan bei der Preisverleihung am Mittwoch. »Ich würde sagen, etwa fünf Prozent des Buchs bestehen aus den von der KI generierten Sätzen.« Rie Kudans Roman »Tokyo-to Dojo-to« war am Mittwoch mit dem Akutagawa-Preis ausgezeichnet worden. Das Buch spielt in der Zukunft und dreht sich um ein Gefängnishochhaus in Tokio und dessen Architektin. KI ist ein wichtiges Thema des Buchs. Ein Jury-Mitglied lobte es als »nahezu fehlerlos« und sehr unterhaltsam. Kudan berichtete, sie experimentiere oft mit ChatGPT – nicht nur beim Schreiben. Sie vertraue der Software ihre innersten Gedanken an, über die sie »mit niemand anderem sprechen« könne. Einige Antworten von ChatGPT hätten sie zu Dialogen in ihrem Buch inspiriert. ChatGPT ist ein auf fortschrittlicher KI-Technologie basierender Chatbot der US-Firma OpenAI , der in Sekundenschnelle hochkomplexe Texte generieren kann. ChatGPT machte die Möglichkeiten sogenannter generativer KI schlagartig einem großen Publikum bewusst, aber auch die kaum absehbaren Auswirkungen."
Künstliche Intelligenz,Spiegel Online,2024-01-17,https://www.spiegel.de/panorama/bildung/chatgpt-und-co-experten-geben-empfehlungen-fuer-ki-nutzung-an-schulen-a-4e58f272-315c-4ce3-86e7-9f9e4ee17bd1,ChatGPT und Co.: Experten geben Empfehlungen für KI-Nutzung an Schulen - DER SPIEGEL,"Etwa ein Fünftel aller Schüler nutzt bereits KI-Tools beim Lernen. Wie sollen die Schulen mit ChatGPT und anderen Programmen umgehen? Bildungsexperten der Kultusministerkonferenz haben jetzt Vorschläge gemacht. Der Einsatz künstlicher Intelligenz (KI) mit Programmen wie ChatGPT in Schulen hat aus Sicht führender Bildungsexperten großes Potenzial. Am Mittwoch veröffentlichte die Ständige Wissenschaftliche Kommission (SWK/Bonn) der Kultusministerkonferenz ein Papier, in dem ein sinnvoller Einsatz von KI diskutiert wird. Das Gremium empfiehlt eine Übergangsphase zur systematischen Erprobung solcher KI-Tools »bei offener Fehlerkultur«. Auch auf Risiken und Hürden im Umgang mit den neuen Instrumenten weist die Kommission hin. Etliche Voraussetzungen und Bedingungen müssten für eine lernförderliche und verantwortungsbewusste Nutzung gegeben sein, heißt es. Ein zentraler Satz lautet: »KI kann und sollte den Lehr-Lernprozess unterstützen, die finale Entscheidung beziehungsweise Bewertung und die Verantwortung für das Endprodukt muss bei Menschen liegen.« Lehrkräfte müssten dafür qualifiziert sein, Fortbildungsangebote rasch ausgebaut werden. Grundschulen sollen weiter klassisch Lesen und Schreiben lehren In der Grundschule sollte der Kommission zufolge auf texterstellende KI-Instrumente wie ChatGPT ganz und in den ersten Jahren der weiterführenden Schule weitgehend verzichtet werden. Hier müsse der Fokus auf dem Erwerb von Lese- und Schreibkompetenzen der Kinder liegen. Vom achten Jahrgang an könne ein regelmäßiger Einsatz als Schreibunterstützung erfolgen, während weiterhin auch Texte ohne diese Hilfsmittel erstellt werden sollten. Die Verwendung von KI müsse eng begleitet werden. »Produktive Nutzung« der Technologie bei älteren Schülern Die KI-Programme können nach SWK-Angaben vor allem dann unterstützen, »wenn Lernende über hohe fachliche, Schreib-, Lese- und digitale Kompetenzen verfügen«. Sie sollten daher bei älteren Schülern wie auch in Hochschulen zum Einsatz kommen. Es gehe um eine »produktive Nutzung« dieser Technologie. Aktuelle Schätzungen gehen laut Kommission davon aus, dass mindestens 20 Prozent der Schülerinnen und Schüler in Deutschland ChatGPT bereits als Informationsquelle, für die Textproduktion und Übersetzungen verwenden. Für Lehrkräfte sehen die Bildungsexperten ebenfalls viele, oft noch unterschätzte Möglichkeiten: Etwa für die Unterrichtsplanung, das Erstellen von Wissenstests mit unterschiedlichen Schwierigkeitsgraden oder auch die Entwicklung von Unterrichtsmaterial, differenziert nach Leistungsstärke der Schüler. Man beeilt sich aber zu betonen, dass die KI die didaktischen Fachkenntnisse einer Lehrkraft nicht ersetzen könne. Lernziel: versierter Umgang mit KI-Instrumenten Chatbots erstellen Texte, die in der Regel plausibel klingen, aber durchaus erfundene Sachverhalte und Fehler enthalten können. Deshalb müssten die Schüler in der Lage sein, Inhalte hinsichtlich Qualität, Korrektheit, Vertrauenswürdigkeit zu bewerten, die Steuerung im Prozess durch ihre Spracheingaben zu übernehmen, schreibt das Gremium. Kritisches, analytisches Denken, auch fachliches Wissen seien erforderlich. Gerade bei schwächeren Lernenden könnten diese Kompetenzen eher nicht vorausgesetzt werden. Ein versierter Umgang der Schülerinnen und Schüler mit den KI-Instrumenten solle als neues Lernziel geübt und auch geprüft werden. Entsprechend müssten Lehrkräfte qualifiziert sein. »Die dynamische Entwicklung der Tools fordert die Lehrkräfte besonders.« Die Verantwortung für eine Verwendung der KI – etwa zur Aufgabenerstellung oder Leistungsbeurteilung – soll laut Empfehlung bei den Lehrerinnen und Lehrern liegen. Wie viel KI darf bei Prüfungen genutzt werden? Derzeit gebe es Unsicherheiten auch mit Blick auf Prüfungsformate, hier müsse die Prüfungskultur weiterentwickelt werden. Die Kommission rät in Examen zur Unterscheidung zwischen hilfsmittelfreien Teilen und solchen, in denen KI-Tools genutzt werden dürfen. Kommen solche Instrumente zum Einsatz, »sollte nicht nur der letztendliche Text, sondern auch die reflektierte Auseinandersetzung der Schülerinnen und Schüler mit der Erstellung und dem Ergebnis Gegenstand der Beurteilung sein«. Es sei davon auszugehen, dass eine gekonnte »Koaktivität« mit ChatGPT und ähnlichen Programmen eine wichtige Zukunftskompetenz darstellen werde. Schulen müssen kostenfreien Zugriff auf KI-Tools ermöglichen Das SWK-Papier verweist auch auf »technologische, ethische und rechtliche Probleme«, die einen rechtmäßigen Einsatz im Schulbereich infrage stellten. Der Einsatz kommerzieller Tools sei marktwirtschaftlichen Interessen unterworfen, sie seien nicht für die Schulen gemacht worden. Der Bildungspolitik komme die Aufgabe zu, KI-Instrumente in geeignete Lernplattformen zu integrieren. »Eine besonders große Herausforderung besteht derzeit noch darin, Tools für den Einsatz im Bildungskontext und in speziellen Fächern zu entwerfen«, erläuterte die Direktorin des Leibniz-Instituts für Wissensmedien, Ulrike Cress. Allen Lernenden und Lehrenden sollte dem Gremium zufolge ein kostenfreier oder günstiger Zugriff auf diese Tools ermöglicht werden. Die Präsidentin der Kultusministerkonferenz, Saarlands Bildungsministerin Christine Streichert-Clivot ( SPD ), betonte in einer Mitteilung: »Technologischer Fortschritt darf nicht zu stärkerer sozialer Ungleichheit führen, sondern die Chancen müssen für alle zugänglich sein.«"
Künstliche Intelligenz,Spiegel Online,2024-01-15,https://www.spiegel.de/wirtschaft/soziales/ki-wird-vermutlich-knapp-die-haelfte-aller-jobs-veraendern-a-85a9a5e0-267a-46ea-9e04-fa2cf4d32b8c,IWF: KI wird vermutlich knapp die Hälfte aller Jobs verändern - DER SPIEGEL,"Die fortschreitende Entwicklung von KI-Software verändert die Arbeitswelt. Der IWF prognostiziert weitreichende Folgen für Jobs und Gehälter – und warnt vor einer Verschärfung der weltweiten Ungleichheiten. Software auf Basis künstlicher Intelligenz wird nach Einschätzung des Internationalen Währungsfonds ( IWF ) weitreichende Folgen für Jobs und Gehälter haben. In entwickelten Volkswirtschaften könne KI rund 60 Prozent der Arbeitsplätze beeinflussen, geht aus einer am Sonntag veröffentlichten IWF-Studie hervor. Bei etwa der Hälfte davon dürfte sich der Einsatz künstlicher Intelligenz mit höherer Produktivität positiv auswirken, hieß es weiter. Bei der anderen Hälfte könne KI dagegen Aufgaben übernehmen, die heute von Menschen ausgeführt würden. Das könne in diesen Bereichen zu weniger verfügbaren Jobs und niedrigeren Gehältern führen. Der IWF warnte auch vor mehr Ungleichheit: In denselben Bereichen könnten Arbeitnehmer, die gut mit KI zurechtkämen, auf höhere Gehälter hoffen – während andere zurückfallen. Für Beschäftigte mit Hochschulbildung sieht der IWF bessere Chancen, in Jobs zu landen, in denen künstliche Intelligenz einen positiven Einfluss hat. »Wir stehen an der Schwelle einer technologischen Revolution, die die Produktivität ankurbeln, das globale Wachstum mehren und die Einkommen auf der ganzen Welt erhöhen könnte«, sagte Kristalina Georgieva, Managing Director des IWF. »Der rasante Fortschritt der künstlichen Intelligenz hat die Welt in seinen Bann gezogen, sowohl Vorfreude als auch Besorgnis ausgelöst und wichtige Fragen über potenzielle Auswirkungen auf die Weltwirtschaft aufgeworfen.« In Ländern mit niedrigem Einkommen sieht der Währungsfonds rund 26 Prozent der Arbeitsplätze potenziell stark von künstlicher Intelligenz betroffen – und in Schwellenländern seien es rund 40 Prozent. Der IWF schränkte zugleich ein, dass es sich dabei nur um Prognosen auf Basis von Berechnungsmodellen handele und einige Faktoren schwer vorherzusagen seien – etwa die mögliche Entstehung neuer Branchen und wie schnell sich KI ausbreiten werde. »Was wir mit einiger Zuversicht sagen können, ist, dass wir eine Reihe von Richtlinien entwickeln müssen, um das enorme Potenzial der KI zum Wohle der Menschheit zu nutzen«, so Georgieva. »Das KI-Zeitalter steht vor der Tür und noch liegt es in unserer Macht, dafür zu sorgen, dass es Wohlstand für alle bringt.«"
AI,Spiegel Online,2024-01-17,https://www.spiegel.de/netzwelt/gadgets/galaxy-s24-was-koennen-die-ki-smartphones-von-samsung-a-9fad8e85-02f1-4764-aa78-a19ad5aac652,Galaxy S24: Was können die »KI-Smartphones« von Samsung - DER SPIEGEL,"Samsungs Galaxy-S24-Smartphones helfen, Pizza in vielen Sprachen zu bestellen – wenn man zur richtigen Zeit schweigt, sonst wird’s irre. Wir haben die Geräte ausprobiert."
Artificial Intelligence,Spiegel Online,2024-01-17,https://www.spiegel.de/netzwelt/gadgets/galaxy-s24-was-koennen-die-ki-smartphones-von-samsung-a-9fad8e85-02f1-4764-aa78-a19ad5aac652,Galaxy S24: Was können die »KI-Smartphones« von Samsung - DER SPIEGEL,"Samsungs Galaxy-S24-Smartphones helfen, Pizza in vielen Sprachen zu bestellen – wenn man zur richtigen Zeit schweigt, sonst wird’s irre. Wir haben die Geräte ausprobiert."
KI,Spiegel Online,2024-01-17,https://www.spiegel.de/panorama/bildung/chatgpt-und-co-experten-geben-empfehlungen-fuer-ki-nutzung-an-schulen-a-4e58f272-315c-4ce3-86e7-9f9e4ee17bd1,ChatGPT und Co.: Experten geben Empfehlungen für KI-Nutzung an Schulen - DER SPIEGEL,"Etwa ein Fünftel aller Schüler nutzt bereits KI-Tools beim Lernen. Wie sollen die Schulen mit ChatGPT und anderen Programmen umgehen? Bildungsexperten der Kultusministerkonferenz haben jetzt Vorschläge gemacht. Der Einsatz künstlicher Intelligenz (KI) mit Programmen wie ChatGPT in Schulen hat aus Sicht führender Bildungsexperten großes Potenzial. Am Mittwoch veröffentlichte die Ständige Wissenschaftliche Kommission (SWK/Bonn) der Kultusministerkonferenz ein Papier, in dem ein sinnvoller Einsatz von KI diskutiert wird. Das Gremium empfiehlt eine Übergangsphase zur systematischen Erprobung solcher KI-Tools »bei offener Fehlerkultur«. Auch auf Risiken und Hürden im Umgang mit den neuen Instrumenten weist die Kommission hin. Etliche Voraussetzungen und Bedingungen müssten für eine lernförderliche und verantwortungsbewusste Nutzung gegeben sein, heißt es. Ein zentraler Satz lautet: »KI kann und sollte den Lehr-Lernprozess unterstützen, die finale Entscheidung beziehungsweise Bewertung und die Verantwortung für das Endprodukt muss bei Menschen liegen.« Lehrkräfte müssten dafür qualifiziert sein, Fortbildungsangebote rasch ausgebaut werden. Grundschulen sollen weiter klassisch Lesen und Schreiben lehren In der Grundschule sollte der Kommission zufolge auf texterstellende KI-Instrumente wie ChatGPT ganz und in den ersten Jahren der weiterführenden Schule weitgehend verzichtet werden. Hier müsse der Fokus auf dem Erwerb von Lese- und Schreibkompetenzen der Kinder liegen. Vom achten Jahrgang an könne ein regelmäßiger Einsatz als Schreibunterstützung erfolgen, während weiterhin auch Texte ohne diese Hilfsmittel erstellt werden sollten. Die Verwendung von KI müsse eng begleitet werden. »Produktive Nutzung« der Technologie bei älteren Schülern Die KI-Programme können nach SWK-Angaben vor allem dann unterstützen, »wenn Lernende über hohe fachliche, Schreib-, Lese- und digitale Kompetenzen verfügen«. Sie sollten daher bei älteren Schülern wie auch in Hochschulen zum Einsatz kommen. Es gehe um eine »produktive Nutzung« dieser Technologie. Aktuelle Schätzungen gehen laut Kommission davon aus, dass mindestens 20 Prozent der Schülerinnen und Schüler in Deutschland ChatGPT bereits als Informationsquelle, für die Textproduktion und Übersetzungen verwenden. Für Lehrkräfte sehen die Bildungsexperten ebenfalls viele, oft noch unterschätzte Möglichkeiten: Etwa für die Unterrichtsplanung, das Erstellen von Wissenstests mit unterschiedlichen Schwierigkeitsgraden oder auch die Entwicklung von Unterrichtsmaterial, differenziert nach Leistungsstärke der Schüler. Man beeilt sich aber zu betonen, dass die KI die didaktischen Fachkenntnisse einer Lehrkraft nicht ersetzen könne. Lernziel: versierter Umgang mit KI-Instrumenten Chatbots erstellen Texte, die in der Regel plausibel klingen, aber durchaus erfundene Sachverhalte und Fehler enthalten können. Deshalb müssten die Schüler in der Lage sein, Inhalte hinsichtlich Qualität, Korrektheit, Vertrauenswürdigkeit zu bewerten, die Steuerung im Prozess durch ihre Spracheingaben zu übernehmen, schreibt das Gremium. Kritisches, analytisches Denken, auch fachliches Wissen seien erforderlich. Gerade bei schwächeren Lernenden könnten diese Kompetenzen eher nicht vorausgesetzt werden. Ein versierter Umgang der Schülerinnen und Schüler mit den KI-Instrumenten solle als neues Lernziel geübt und auch geprüft werden. Entsprechend müssten Lehrkräfte qualifiziert sein. »Die dynamische Entwicklung der Tools fordert die Lehrkräfte besonders.« Die Verantwortung für eine Verwendung der KI – etwa zur Aufgabenerstellung oder Leistungsbeurteilung – soll laut Empfehlung bei den Lehrerinnen und Lehrern liegen. Wie viel KI darf bei Prüfungen genutzt werden? Derzeit gebe es Unsicherheiten auch mit Blick auf Prüfungsformate, hier müsse die Prüfungskultur weiterentwickelt werden. Die Kommission rät in Examen zur Unterscheidung zwischen hilfsmittelfreien Teilen und solchen, in denen KI-Tools genutzt werden dürfen. Kommen solche Instrumente zum Einsatz, »sollte nicht nur der letztendliche Text, sondern auch die reflektierte Auseinandersetzung der Schülerinnen und Schüler mit der Erstellung und dem Ergebnis Gegenstand der Beurteilung sein«. Es sei davon auszugehen, dass eine gekonnte »Koaktivität« mit ChatGPT und ähnlichen Programmen eine wichtige Zukunftskompetenz darstellen werde. Schulen müssen kostenfreien Zugriff auf KI-Tools ermöglichen Das SWK-Papier verweist auch auf »technologische, ethische und rechtliche Probleme«, die einen rechtmäßigen Einsatz im Schulbereich infrage stellten. Der Einsatz kommerzieller Tools sei marktwirtschaftlichen Interessen unterworfen, sie seien nicht für die Schulen gemacht worden. Der Bildungspolitik komme die Aufgabe zu, KI-Instrumente in geeignete Lernplattformen zu integrieren. »Eine besonders große Herausforderung besteht derzeit noch darin, Tools für den Einsatz im Bildungskontext und in speziellen Fächern zu entwerfen«, erläuterte die Direktorin des Leibniz-Instituts für Wissensmedien, Ulrike Cress. Allen Lernenden und Lehrenden sollte dem Gremium zufolge ein kostenfreier oder günstiger Zugriff auf diese Tools ermöglicht werden. Die Präsidentin der Kultusministerkonferenz, Saarlands Bildungsministerin Christine Streichert-Clivot ( SPD ), betonte in einer Mitteilung: »Technologischer Fortschritt darf nicht zu stärkerer sozialer Ungleichheit führen, sondern die Chancen müssen für alle zugänglich sein.«"
KI,Spiegel Online,2024-01-17,https://www.spiegel.de/kultur/poor-things-startet-im-kino-frankenstein-feminismus-mit-emma-stone-a-7bd5b7bd-73ee-4d58-b4e3-167f404d773d,»Poor Things« startet im Kino: Frankenstein-Feminismus mit Emma Stone - DER SPIEGEL,"Es geht um Sex, Schamgefühle und die Schöpfung eines verrückten Forschers: Am Donnerstag startet »Poor Things« in den Kinos, eine groteske Fabel über die weibliche Selbstermächtigung. In der Hauptrolle: Emma Stone. »Dies ist Bella. Bella, dies ist Mr McCandless.« – »Hallo Bella!« Es erinnert an eine weibliche Version von Frankenstein: Die schwangere Bella hatte sich umgebracht, wurde aber von einem verrückten Wissenschaftler namens »Gott« wieder zum Leben erweckt – mit dem Gehirn ihres ungeborenen Kindes. Bella entwickelt sich rasant und brennt mit einem zwielichtigen Anwalt durch. Auf einer Reise quer durch ein viktorianisch-futuristisches Europa erlebt sie nun zahlreiche sexuelle Abenteuer. Emma Stone, Schauspielerin: »Die Vorstellung war unglaublich, jemanden zu spielen, der frei von Scham ist, frei von Selbstverurteilung und der Verurteilung durch andere. Sie lernt erst alles über die Welt und die Menschheit. Als ich dann etwas von der Scham abstreifte, erkannte ich, dass sie sich einfach mit Freude und tiefer Neugier ins Abenteuer stürzt. Sie ist die beste Figur, die ich je spielen durfte.« »Du musst verstehen, ich habe nie außerhalb von »Gods« Haus gelebt. Bella hat so viel zu entdecken. Und dein trauriges Gesicht lässt mich wütende Gefühle gegen dich entdecken.« Ohne die übliche Konditionierung aufgewachsen, stürzt sich Bella in die unbekannte Welt – von den Männern zunächst als Objekt behandelt. Doch langsam befreit sie sich daraus und führt ihre Begleiter als Deppen vor, denen die Macht entgleitet. Das zeigt sich auch in den exzentrischen Kostümen. Holly Waddington, Kostümdesignerin: »Wir haben uns auf die Schultern konzentriert, bei ihnen geht es um Ermächtigung. Sie sind fast wie eine Lunge, voll mit Luft. Bella ist eine wiederbelebte Frau. Die Kostüme verzerren die Proportionen des Körpers, sie verändern also ihre Körperlichkeit.« Für »Poor Things« hat Regisseur Yorgos Lanthimos in Venedig den Goldenen Löwen erhalten, vor einer Woche gewann der Film bei den Golden Globes als beste Komödie. Emma Stone wurde zur besten Hauptdarstellerin gekürt. Nun wird Lanthimos' Kommentar auf unsere schambehaftete Gesellschaft als aussichtsreicher Oscar-Kandidat gehandelt. »Du liest jetzt fast die ganze Zeit, Bella. Du verlierst etwas von deiner bewundernswerten körperlichen Anziehungskraft.« – »Ich bin ein wandelbares Wesen, so wie wir alle. Das behauptet zumindest Emmerson, Harry ist anderer Meinung.« – »Ach komm, lass sein.« – »Du verdeckst mir die Sonne.«"
KI,Spiegel Online,2024-01-15,https://www.spiegel.de/wirtschaft/soziales/ki-wird-vermutlich-knapp-die-haelfte-aller-jobs-veraendern-a-85a9a5e0-267a-46ea-9e04-fa2cf4d32b8c,IWF: KI wird vermutlich knapp die Hälfte aller Jobs verändern - DER SPIEGEL,"Die fortschreitende Entwicklung von KI-Software verändert die Arbeitswelt. Der IWF prognostiziert weitreichende Folgen für Jobs und Gehälter – und warnt vor einer Verschärfung der weltweiten Ungleichheiten. Software auf Basis künstlicher Intelligenz wird nach Einschätzung des Internationalen Währungsfonds ( IWF ) weitreichende Folgen für Jobs und Gehälter haben. In entwickelten Volkswirtschaften könne KI rund 60 Prozent der Arbeitsplätze beeinflussen, geht aus einer am Sonntag veröffentlichten IWF-Studie hervor. Bei etwa der Hälfte davon dürfte sich der Einsatz künstlicher Intelligenz mit höherer Produktivität positiv auswirken, hieß es weiter. Bei der anderen Hälfte könne KI dagegen Aufgaben übernehmen, die heute von Menschen ausgeführt würden. Das könne in diesen Bereichen zu weniger verfügbaren Jobs und niedrigeren Gehältern führen. Der IWF warnte auch vor mehr Ungleichheit: In denselben Bereichen könnten Arbeitnehmer, die gut mit KI zurechtkämen, auf höhere Gehälter hoffen – während andere zurückfallen. Für Beschäftigte mit Hochschulbildung sieht der IWF bessere Chancen, in Jobs zu landen, in denen künstliche Intelligenz einen positiven Einfluss hat. »Wir stehen an der Schwelle einer technologischen Revolution, die die Produktivität ankurbeln, das globale Wachstum mehren und die Einkommen auf der ganzen Welt erhöhen könnte«, sagte Kristalina Georgieva, Managing Director des IWF. »Der rasante Fortschritt der künstlichen Intelligenz hat die Welt in seinen Bann gezogen, sowohl Vorfreude als auch Besorgnis ausgelöst und wichtige Fragen über potenzielle Auswirkungen auf die Weltwirtschaft aufgeworfen.« In Ländern mit niedrigem Einkommen sieht der Währungsfonds rund 26 Prozent der Arbeitsplätze potenziell stark von künstlicher Intelligenz betroffen – und in Schwellenländern seien es rund 40 Prozent. Der IWF schränkte zugleich ein, dass es sich dabei nur um Prognosen auf Basis von Berechnungsmodellen handele und einige Faktoren schwer vorherzusagen seien – etwa die mögliche Entstehung neuer Branchen und wie schnell sich KI ausbreiten werde. »Was wir mit einiger Zuversicht sagen können, ist, dass wir eine Reihe von Richtlinien entwickeln müssen, um das enorme Potenzial der KI zum Wohle der Menschheit zu nutzen«, so Georgieva. »Das KI-Zeitalter steht vor der Tür und noch liegt es in unserer Macht, dafür zu sorgen, dass es Wohlstand für alle bringt.«"
Künstliche Intelligenz,Spiegel Online,2024-01-10,https://www.spiegel.de/wirtschaft/hewlett-packard-uebernimmt-juniper-fuer-14-milliarden-dollar-a-b713663b-4b3e-4b80-b1cc-e84dd28e22fd,Hewlett Packard übernimmt Juniper für 14 Milliarden Dollar - DER SPIEGEL,"Die Nachfrage in Hewlett Packards traditionellem Kerngeschäft verläuft schleppend. Jetzt setzt das Unternehmen verstärkt auf Künstliche Intelligenz – und zahlt viel Geld für den Netzwerkausrüster Juniper. Für den Ausbau seines Geschäfts mit künstlicher Intelligenz (KI) legt Hewlett Packard Enterprise(HPE) 14 Milliarden Dollar für den Netzwerkausrüster Juniper auf den Tisch. HPE habe den Aktionären von Juniper 40 Dollar je Aktie geboten, teilten die Unternehmen am Dienstag mit. Das entspricht einem Aufschlag von 32,4 Prozent auf den Schlusskurs der Aktie am Montag, als die Nachricht von der Übernahme bekannt wurde. Mit der Ankündigung bestätigten die Unternehmen eine Meldung der Nachrichtenagentur Reuters vom Montag. Die Transaktion wird voraussichtlich durch befristete Kreditzusagen in Höhe von 14 Milliarden US-Dollar finanziert und soll vorbehaltlich behördlicher Genehmigungen Ende 2024 oder Anfang 2025 abgeschlossen sein. HPE kämpft mit einer schleppenden Nachfrage in seinem traditionellen Servergeschäft und will mit der Transaktion von Junipers Angeboten profitieren, darunter Netzwerksicherheit und KI-gestützte Enterprise Networking Operations (AIOps). Der KI-Boom veranlasst die Unternehmen derzeit, Milliarden in die Aufrüstung und Entwicklung neuer Produkte zu investieren. Die schwache Nachfrage der inflationsgeplagten Mobilfunkanbieter und Kabelnetzbetreiber sowie die harte Konkurrenz von Cisco Systems und Nvidia im Netzwerkbereich belasteten Juniper. Die Aktien von Juniper stiegen nachbörslich um 0,5 Prozent, während die Papiere von HPE weitgehend unverändert tendierten."
Künstliche Intelligenz,Spiegel Online,2024-01-10,https://www.spiegel.de/netzwelt/netzpolitik/gptstore-von-openai-der-naechste-iphone-moment-der-kuenstlichen-intelligenz-kolumne-a-3734c095-9330-40ed-8b25-ce2c9dc240a3,GPTstore von OpenAI: Der nächste iPhone-Moment der künstlichen Intelligenz – Kolumne - DER SPIEGEL,"Der erste App Store kam einer Revolution gleich. Mit dem GPTStore steht der KI etwas Ähnliches bevor. Größter Unterschied: Apps muss man programmieren, die neuen Bots nicht. Ein Selbstläufer ist die Idee aber nicht."
KI,Spiegel Online,2024-01-12,https://www.spiegel.de/wissenschaft/weltall/ki-analyse-fingerabdruecke-weniger-einzigartig-als-gedacht-a-62dc98fd-e46f-447d-ac2a-f7a99f21a791,Kriminalität: KI soll Verbrecherjagd mit Fingerabdrücken verbessern - DER SPIEGEL,"Zehn Finger, zehn verschiedene Abdrücke: Ob die Spuren an mehreren Tatorten zu einer einzelnen Person gehören, konnten Forensiker bislang nicht immer sagen. Mithilfe moderner Technik haben sie nun ein Muster entdeckt. Dass Fingerabdrücke uns unverwechselbar machen, ist schon so manchem Ganoven zum Verhängnis geworden. Die Spuren unserer Papillarleisten, den charakteristischen Hautlinien auf den Fingern, hinterlassen auf angefassten Gegenständen eine sehr individuelle Signatur. Kriminologen können sogar eineiige Zwillinge anhand ihrer Fingerabdrücke unterscheiden. Der Ursprung dieser Individualität liegt früh in unserer Entwicklung: Das embryonale Wachstum der Finger läuft sehr unterschiedlich ab. Deshalb gingen Fachleute bisher davon aus, dass es keine Verbindung zwischen den Abdrücken einzelner Finger eines Menschen gibt – vom Daumen bis zum kleinen Finger sei jeder Abdruck anders. Die Annahme verkompliziert kriminologische Analysen. Hinterlässt ein Täter etwa Abdrücke von verschiedenen Fingern an zwei unterschiedlichen Tatorten, ist es sehr schwierig, diese zuzuordnen und die Spuren zu verwerten. Ein Fachteam um Gabe Guo von der Columbia University in New York sät nun Zweifel an dieser Grundsatzregel der Daktyloskopie – so heißt die Wissenschaft der Papillarleisten. Laut seiner Studie, die im Fachmagazin »Science Advances« erschienen ist, sind Fingerabdrücke von verschiedenen Fingern derselben Person doch nicht so einzigartig. Die Wissenschaftler haben eine Datenbank der US-Regierung verwendet, die etwa 60.000 Fingerabdrücke speichert. Diese wurden in ein auf künstlicher Intelligenz basierendes System paarweise eingespeist. Manchmal gehörten die Abdruckpaare von unterschiedlichen Fingern zu derselben Person, manchmal gehörten sie verschiedenen Personen. Das KI-System erkannte im Laufe der Zeit immer besser, wann Fingerabdrücke zur selben Person passten und wann nicht. Am Ende kamen die Rechner auf eine Genauigkeit von 77 Prozent. Wenn die KI mehrere Paare vergleichen sollte, stieg die Genauigkeit an. »Das könnte die Effizienz von forensischen Untersuchungen möglicherweise um mehr als das Zehnfache steigern«, schreiben die Forscher laut einer Mitteilung. Noch nicht praxistauglich Allerdings reichen die erzielten Werte bisher nicht aus, um in der Kriminalistik eine Rolle zu spielen. Täter könnten so nicht sicher überführt werden, räumen die Fachleute ein. Ihr System benötige noch mehr Datensätze, um besser zu werden. Die Methode habe jedoch großes Potenzial. »Stellen Sie sich vor, wie gut die KI funktionieren wird, wenn sie an Millionen statt nur an Tausenden von Fingerabdrücken trainiert wird«, kommentiert einer der beteiligten Forscher. Dass die KI ein Muster bei den einzelnen Fingern einer Person erkennen konnte, lag an einer im Vergleich zur traditionelle Forensik anderen Methode. Kriminologen blicken vor allem auf die sogenannten Minuzien – das sind die Endungen und Verzweigungen der Papillarlinien. Die KI schaute dagegen auf die Krümmungen der Wirbel und Schleifen in der Mitte des Fingerabdrucks. Die dort entstandenen Muster sind für Menschen nur schwer voneinander zu unterscheiden. Die Ergebnisse der Studie habe die Fachwelt dermaßen überrascht, dass die Fachleute zunächst Probleme hatten, ihre Arbeit überhaupt zu veröffentlichen, berichten sie. Sie sei mehrfach abgelehnt worden. Teils mit der Begründung, dass allgemein bekannt sei, wie einzigartig jeder Fingerabdruck ist. Erst nachdem das KI-System noch mehr Daten geliefert hatte, akzeptiert eine Fachzeitschrift die Studie. Die Entdeckung zeige die Möglichkeiten von KI auf, schreiben die Wissenschaftler. »Diese Forschung ist ein Beispiel dafür, dass selbst eine ziemlich einfache KI Erkenntnisse liefern kann, die Experten jahrzehntelang entgangen sind. Und das angesichts eines ziemlich einfachen Datensatzes, der der Forschungsgemeinschaft seit Jahren zur Verfügung steht.«"
Künstliche Intelligenz,Spiegel Online,2024-01-09,https://www.spiegel.de/netzwelt/tech-messe-ces-vw-baut-chatgpt-in-seine-autos-ein-a-27516197-ed99-4e8c-aba9-7348bedcc09c,Volkswagen: VW baut ChatGPT in seine Autos ein - DER SPIEGEL,"Während der Fahrt mit einem KI-Chatbot unterhalten? Das wird künftig in neuen Modellen von Volkswagen möglich sein. Die künstliche Intelligenz soll aber keinen Zugriff auf Fahrzeugdaten erhalten. Volkswagen hat angekündigt, den Chatbot ChatGPT in seine Fahrzeuge zu integrieren. Eingebaut wird die Software, die Sätze auf dem sprachlichen Niveau eines Menschen bilden kann, innerhalb des hauseigenen Sprachassistenten IDA, wie der Autobauer am Montag auf der Technikmesse CES ankündigte. Auf der Innovationsshow in Las Vegas gibt es bereits erste Fahrzeuge mit der Funktion zu sehen, ab dem zweiten Quartal sollen Serienmodelle folgen. Wer dem Sprachassistenten im VW eine Frage stellt, erhält dann in bestimmten Fällen eine Antwort, die von ChatGPT generiert wurde. Über Sprachsteuerung können Autofahrerinnen und Autofahrer sich mit dem von OpenAI entwickelten KI-Programm unterhalten und »sich während der Fahrt recherchierte Inhalte vorlesen lassen sowie in natürlicher Sprache mit dem Auto interagieren«, schreibt Volkswagen in einem Blogpost . Volkswagen rühmt sich damit, dass man nach eigenen Angaben der erste Volumenhersteller sei, der ChatGPT in Serienfahrzeuge einbaut. Auch Konkurrenten prüfen das. Ziel soll es laut VW sein, die Kommunikation mit dem Auto natürlicher zu machen. Über die Sprachassistenz-Software können bisher Fahrzeugfunktionen gesteuert werden, erst wenn das Volkswagen-System Fragen nicht beantworten kann, soll der Chatbot von OpenAI zugeschaltet werden. Die Fragen würden dann »anonymisiert an die KI weitergeleitet«, heißt es von VW. ChatGPT soll dabei keinerlei Zugriff auf die Fahrzeugdaten erhalten und Fragen und Antworten würden im Sinne eines bestmöglichen Datenschutzes umgehend gelöscht. Umgesetzt wird die Integration zusammen mit dem Unternehmen Cerence, dessen Lösung in IDA eingesetzt wird. ChatGPT soll vom zweiten Quartal 2024 an in mehreren Serienfahrzeugen verfügbar sein. Unter anderem soll die Funktion in den Modellen ID.7, ID.5, ID.4, ID.3, im neuen Tiguan, im neuen Passat sowie im neuen Golf eingebaut werden."
AI,Spiegel Online,2024-01-09,https://www.spiegel.de/netzwelt/netzpolitik/openai-kritisiert-new-york-times-fuer-urheberrechtsklage-a-91879800-0090-47c3-8803-ea2a7ad5bd82,ChatGPT: OpenAI kritisiert »New York Times« für Urheberrechtsklage - DER SPIEGEL,"Die US-amerikanische Tageszeitung »New York Times« verklagt den Entwickler der KI-Software ChatGPT wegen Diebstahl geistigen Eigentums. Nun geht OpenAI in die Gegenoffensive. Gleichzeitig droht Ungemach aus der EU. OpenAI hat öffentlich auf eine Klage der »New York Times« (»NYT«) reagiert, die dem Unternehmen aus San Francisco Verstöße gegen das Urheberrecht vorwirft. Die Zeitung zieht gegen den Entwickler des populären Chatbots ChatGPT vor Gericht, weil dessen künstliche Intelligenz unberechtigterweise mit ihren Inhalten trainiert worden sei und diese teils wortgleich plagiieren soll. Die »NYT« hatte die Vorwürfe Ende Dezember öffentlich gemacht . In einer Klageschrift hatte die Zeitung dabei auch mehrere Beispiele dafür aufgeführt, wie ChatGPT auf Nutzerfragen mit langen praktisch wortgleichen Ausschnitten aus Artikeln der »NYT« antwortet, ohne diese als solche auszuweisen. Diesen Plagiatsvorwürfen widerspricht OpenAI nun in einem Montagabend veröffentlichten Blogpost vehement : Die »NYT« habe ihre Fragen an ChatGPT offenbar absichtlich so manipuliert, dass das Programm lange Ausschnitte aus den Artikeln wiedergegeben habe, heißt es von dem Unternehmen. Eigentlich würde das Programm so nicht reagieren, sondern Inhalte aus mehreren Quellen zu einem eigenen Text formen, behauptet OpenAI. Seine KI nutze für Antworten Beispiele nicht nur aus einer, sondern aus verschiedenen Quellen. »Die ›New York Times‹ erzählt nicht die ganze Geschichte«, schreibt OpenAI über die Klage der Zeitung in seinem Blogpost. Verstoß gegen die Nutzungsbedingungen? OpenAI insinuiert außerdem, dass die Zeitung mit ihrer Verwendung von ChatGPT gegen die Nutzungsbedingungen des Chatbots verstoßen haben könnte. Wie die Zeitung die Beispiele für ihre Klageschrift generiert habe, sei »Missbrauch«, schreibt das Unternehmen. Und weiter: »Wir halten die Klage der ›New York Times‹ für unbegründet.« Man hoffe in Zukunft dennoch auf eine konstruktive Partnerschaft mit dem Unternehmen. Zuvor standen die Zeitung und das KI-Unternehmen in einem Austausch über eine solche Partnerschaft und die Nutzung und Verlinkung von Inhalten. Dabei stellt sich OpenAI auf den Standpunkt, dass das Anlernen von KI-Modellen mit urheberrechtlich geschütztem Material unter den US-amerikanischen Rechtsbegriff des »fair use« falle, weswegen die Zeitung keinen Anspruch darauf habe, für die verarbeiteten Daten Entschädigung zu verlangen. OpenAI hat eingeräumt, dass ChatGPT in seltenen Fällen einen sogenannten Auswendiglern-Fehler habe. Dabei wiederholt das Programm Inhalte aus dem Netz in voller Länge. Man arbeite aber daran, das Problem zu eliminieren. Der Blogpost von OpenAI offenbart auch, dass das Unternehmen selbst nicht eindeutig nachvollziehen kann, wie sich sein Programm in bestimmten Fällen verhält. Das weist auf eine Schwierigkeit bei der Regulierung großer KI-basierter Sprachmodelle hin: Sie sind so komplex und wurden mit solch großen Datensätzen trainiert, dass auch die Hersteller ihr Verhalten offenbar nicht immer nachvollziehen können. EU prüft Microsoft-Investment bei OpenAI Gleichzeitig droht OpenAI Ungemach von europäischen Wettbewerbshütern. Wie die EU-Kommission am Dienstag mitteilte, will sie die Microsoft -Investitionen in OpenAI unter die Lupe nehmen. Die Behörde prüft, ob bei Microsofts Investitionen in OpenAI die EU-Fusionskontrollverordnung greife, wie sie am Dienstag mitteilte. Sollte sich dies bestätigen, könnte Brüssel eine formale Untersuchung einleiten, ob OpenAI und Microsoft durch ihre Zusammenarbeit eine zu große Marktmacht aufbauen. Die Kommission müsse KI-Partnerschaften genau überwachen, »um sicherzustellen, dass sie die Marktdynamik nicht übermäßig verzerren«, erklärte EU-Wettbewerbskommissarin Margrethe Vestager . Die Behörde sammelt nach eigenen Angaben zudem Informationen zu anderen KI-Anbietern. Es sei entscheidend, dass der Wettbewerb auf dem schnell wachsenden Markt erhalten bleibe, fügte Vestager hinzu. Microsoft ist der Hauptinvestor hinter OpenAI, Medienberichten zufolge hat der Softwareriese insgesamt rund 13 Milliarden Dollar (11,9 Milliarden Euro) in den ChatGPT-Entwickler gesteckt. Seit Ende vergangenen Jahres hält der US-Konzern zudem einen Sitz im Verwaltungsrat von OpenAI, allerdings ohne Stimmrecht. Microsoft hat OpenAI-Technik in mehrere seiner Produkte integriert, etwa in die Suchmaschine Bing."
AI,Spiegel Online,2024-01-07,https://www.spiegel.de/politik/hubert-aiwanger-unterwanderung-des-bauernprotests-freie-waehler-chef-spricht-von-verunglimpfung-von-links-a-1dc5830f-1dd3-4bfb-931d-db1071c7e207,Bauernprotest: Hubert Aiwanger spricht von Verunglimpfung von links - DER SPIEGEL,"Wird der Protest der Landwirte von rechtsradikalen Kräften vereinnahmt? Vieles spricht dafür, Behörden zeigen sich alarmiert. Freie-Wähler-Chef Hubert Aiwanger hingegen will davon nichts wissen. Er sieht den Gegner woanders. Der Chef der Freien Wähler Hubert Aiwanger behauptet, die vielfach geäußerte Befürchtung einer Unterwanderung der Bauernproteste durch Extremisten sei eine gezielte Verunglimpfung »von linker Seite«. Die »überwältigende Mehrheit der Landwirte« habe mit Extremismus nichts zu tun, sagte der stellvertretende bayerische Ministerpräsident der »Welt«. Aiwanger ist selbst Landwirt in Niederbayern. »Es ist politisch äußerst unanständig, damit die berechtigten Bauernproteste in Misskredit bringen zu wollen, um die Bauern zu verunsichern«, fügte Aiwanger hinzu. Allerdings stammt die Befürchtung, dass der Protest von rechts vereinnahmt werden könnte, nicht nur von politischen Gegnern: Deutsche Sicherheitsbehörden beobachten einem Bericht der »Welt am Sonntag« zufolge diverse Mobilisierungsaufrufe und Solidaritätsbekundungen von Rechtsextremisten, Gruppierungen der Neuen Rechten und der Querdenker-Szene. Bereits beim Angriff auf die Fähre von Vizekanzler Robert Habeck (Grüne) im schleswig-holsteinischen Schlüttsiel hatte sich zum Teil eine Mobilisierung von weit rechtsaußen stehenden Kräften gezeigt . Der Deutsche Bauernverband (DBV) hat für die nun beginnende Woche zu bundesweiten Protestaktionen gegen die Politik der Bundesregierung aufgerufen. Polizei und Behörden rechnen mit massiven Beeinträchtigungen etwa durch Straßensperren. Sicherheitsbehörden und Politiker hatten in den vergangenen Tagen unter anderem wegen der viel kritisierten Blockade-Aktion protestierender Landwirte gegen Habeck vor einer Radikalisierung und drohender Unterwanderung der Proteste gewarnt. Bauernverband distanziert sich von radikalen Gruppen Politiker insbesondere der Ampelparteien forderten die Landwirte auf, sich klar im rechtsstaatlichen Rahmen zu positionieren. »Friedliche angemeldete Proteste sind für mich völlig legitim«, sagte etwa SPD -Fraktionsvize Dirk Wiese der »Rheinischen Post«. »Aber ich erwarte eine klare Distanzierung von rechten Kreisen.« Auch der Präsident des Deutschen Bauernverbands (DBV), Joachim Rukwied, hat die Teilnahme rechter Gruppierungen an den Bauernprotesten der kommenden Woche für unerwünscht erklärt . »Rechte und andere radikale Gruppierungen mit Umsturzgelüsten wollen wir auf unseren Demos nicht haben«, sagte er der »Bild am Sonntag«. Entzündet hatte sich die Wut der Landwirte an geplanten Subventionskürzungen für die Branche im Zuge der Haushaltskrise. Die Bundesregierung hat die Pläne mittlerweile in Teilen einkassiert. Finanzminister Christian Lindner ( FDP ) kritisierte die dennoch angekündigten Aktionen daher als überzogen."
KI,Spiegel Online,2024-01-09,https://www.spiegel.de/netzwelt/netzpolitik/openai-kritisiert-new-york-times-fuer-urheberrechtsklage-a-91879800-0090-47c3-8803-ea2a7ad5bd82,ChatGPT: OpenAI kritisiert »New York Times« für Urheberrechtsklage - DER SPIEGEL,"Die US-amerikanische Tageszeitung »New York Times« verklagt den Entwickler der KI-Software ChatGPT wegen Diebstahl geistigen Eigentums. Nun geht OpenAI in die Gegenoffensive. Gleichzeitig droht Ungemach aus der EU. OpenAI hat öffentlich auf eine Klage der »New York Times« (»NYT«) reagiert, die dem Unternehmen aus San Francisco Verstöße gegen das Urheberrecht vorwirft. Die Zeitung zieht gegen den Entwickler des populären Chatbots ChatGPT vor Gericht, weil dessen künstliche Intelligenz unberechtigterweise mit ihren Inhalten trainiert worden sei und diese teils wortgleich plagiieren soll. Die »NYT« hatte die Vorwürfe Ende Dezember öffentlich gemacht . In einer Klageschrift hatte die Zeitung dabei auch mehrere Beispiele dafür aufgeführt, wie ChatGPT auf Nutzerfragen mit langen praktisch wortgleichen Ausschnitten aus Artikeln der »NYT« antwortet, ohne diese als solche auszuweisen. Diesen Plagiatsvorwürfen widerspricht OpenAI nun in einem Montagabend veröffentlichten Blogpost vehement : Die »NYT« habe ihre Fragen an ChatGPT offenbar absichtlich so manipuliert, dass das Programm lange Ausschnitte aus den Artikeln wiedergegeben habe, heißt es von dem Unternehmen. Eigentlich würde das Programm so nicht reagieren, sondern Inhalte aus mehreren Quellen zu einem eigenen Text formen, behauptet OpenAI. Seine KI nutze für Antworten Beispiele nicht nur aus einer, sondern aus verschiedenen Quellen. »Die ›New York Times‹ erzählt nicht die ganze Geschichte«, schreibt OpenAI über die Klage der Zeitung in seinem Blogpost. Verstoß gegen die Nutzungsbedingungen? OpenAI insinuiert außerdem, dass die Zeitung mit ihrer Verwendung von ChatGPT gegen die Nutzungsbedingungen des Chatbots verstoßen haben könnte. Wie die Zeitung die Beispiele für ihre Klageschrift generiert habe, sei »Missbrauch«, schreibt das Unternehmen. Und weiter: »Wir halten die Klage der ›New York Times‹ für unbegründet.« Man hoffe in Zukunft dennoch auf eine konstruktive Partnerschaft mit dem Unternehmen. Zuvor standen die Zeitung und das KI-Unternehmen in einem Austausch über eine solche Partnerschaft und die Nutzung und Verlinkung von Inhalten. Dabei stellt sich OpenAI auf den Standpunkt, dass das Anlernen von KI-Modellen mit urheberrechtlich geschütztem Material unter den US-amerikanischen Rechtsbegriff des »fair use« falle, weswegen die Zeitung keinen Anspruch darauf habe, für die verarbeiteten Daten Entschädigung zu verlangen. OpenAI hat eingeräumt, dass ChatGPT in seltenen Fällen einen sogenannten Auswendiglern-Fehler habe. Dabei wiederholt das Programm Inhalte aus dem Netz in voller Länge. Man arbeite aber daran, das Problem zu eliminieren. Der Blogpost von OpenAI offenbart auch, dass das Unternehmen selbst nicht eindeutig nachvollziehen kann, wie sich sein Programm in bestimmten Fällen verhält. Das weist auf eine Schwierigkeit bei der Regulierung großer KI-basierter Sprachmodelle hin: Sie sind so komplex und wurden mit solch großen Datensätzen trainiert, dass auch die Hersteller ihr Verhalten offenbar nicht immer nachvollziehen können. EU prüft Microsoft-Investment bei OpenAI Gleichzeitig droht OpenAI Ungemach von europäischen Wettbewerbshütern. Wie die EU-Kommission am Dienstag mitteilte, will sie die Microsoft -Investitionen in OpenAI unter die Lupe nehmen. Die Behörde prüft, ob bei Microsofts Investitionen in OpenAI die EU-Fusionskontrollverordnung greife, wie sie am Dienstag mitteilte. Sollte sich dies bestätigen, könnte Brüssel eine formale Untersuchung einleiten, ob OpenAI und Microsoft durch ihre Zusammenarbeit eine zu große Marktmacht aufbauen. Die Kommission müsse KI-Partnerschaften genau überwachen, »um sicherzustellen, dass sie die Marktdynamik nicht übermäßig verzerren«, erklärte EU-Wettbewerbskommissarin Margrethe Vestager . Die Behörde sammelt nach eigenen Angaben zudem Informationen zu anderen KI-Anbietern. Es sei entscheidend, dass der Wettbewerb auf dem schnell wachsenden Markt erhalten bleibe, fügte Vestager hinzu. Microsoft ist der Hauptinvestor hinter OpenAI, Medienberichten zufolge hat der Softwareriese insgesamt rund 13 Milliarden Dollar (11,9 Milliarden Euro) in den ChatGPT-Entwickler gesteckt. Seit Ende vergangenen Jahres hält der US-Konzern zudem einen Sitz im Verwaltungsrat von OpenAI, allerdings ohne Stimmrecht. Microsoft hat OpenAI-Technik in mehrere seiner Produkte integriert, etwa in die Suchmaschine Bing."
KI,Spiegel Online,2024-01-09,https://www.spiegel.de/netzwelt/tech-messe-ces-vw-baut-chatgpt-in-seine-autos-ein-a-27516197-ed99-4e8c-aba9-7348bedcc09c,Volkswagen: VW baut ChatGPT in seine Autos ein - DER SPIEGEL,"Während der Fahrt mit einem KI-Chatbot unterhalten? Das wird künftig in neuen Modellen von Volkswagen möglich sein. Die künstliche Intelligenz soll aber keinen Zugriff auf Fahrzeugdaten erhalten. Volkswagen hat angekündigt, den Chatbot ChatGPT in seine Fahrzeuge zu integrieren. Eingebaut wird die Software, die Sätze auf dem sprachlichen Niveau eines Menschen bilden kann, innerhalb des hauseigenen Sprachassistenten IDA, wie der Autobauer am Montag auf der Technikmesse CES ankündigte. Auf der Innovationsshow in Las Vegas gibt es bereits erste Fahrzeuge mit der Funktion zu sehen, ab dem zweiten Quartal sollen Serienmodelle folgen. Wer dem Sprachassistenten im VW eine Frage stellt, erhält dann in bestimmten Fällen eine Antwort, die von ChatGPT generiert wurde. Über Sprachsteuerung können Autofahrerinnen und Autofahrer sich mit dem von OpenAI entwickelten KI-Programm unterhalten und »sich während der Fahrt recherchierte Inhalte vorlesen lassen sowie in natürlicher Sprache mit dem Auto interagieren«, schreibt Volkswagen in einem Blogpost . Volkswagen rühmt sich damit, dass man nach eigenen Angaben der erste Volumenhersteller sei, der ChatGPT in Serienfahrzeuge einbaut. Auch Konkurrenten prüfen das. Ziel soll es laut VW sein, die Kommunikation mit dem Auto natürlicher zu machen. Über die Sprachassistenz-Software können bisher Fahrzeugfunktionen gesteuert werden, erst wenn das Volkswagen-System Fragen nicht beantworten kann, soll der Chatbot von OpenAI zugeschaltet werden. Die Fragen würden dann »anonymisiert an die KI weitergeleitet«, heißt es von VW. ChatGPT soll dabei keinerlei Zugriff auf die Fahrzeugdaten erhalten und Fragen und Antworten würden im Sinne eines bestmöglichen Datenschutzes umgehend gelöscht. Umgesetzt wird die Integration zusammen mit dem Unternehmen Cerence, dessen Lösung in IDA eingesetzt wird. ChatGPT soll vom zweiten Quartal 2024 an in mehreren Serienfahrzeugen verfügbar sein. Unter anderem soll die Funktion in den Modellen ID.7, ID.5, ID.4, ID.3, im neuen Tiguan, im neuen Passat sowie im neuen Golf eingebaut werden."
Künstliche Intelligenz,Spiegel Online,2024-01-03,https://www.spiegel.de/netzwelt/web/ki-transformation-endlich-wieder-ein-grund-zur-fortschrittsfreude-kolumne-a-cd937d42-9288-4702-86e6-1c94a929e67f,KI-Transformation: Endlich wieder ein Grund zur Fortschrittsfreude - Kolumne - DER SPIEGEL,"Deutschland war oft von Angst vor Abstieg und Wandel geprägt. Die letzte Hochtechnologie, die kollektiv gefeiert wurde, war der VW Golf. Aber es gibt einen Grund, optimistisch zu sein: künstliche Intelligenz."
AI,Spiegel Online,2024-01-04,https://www.spiegel.de/netzwelt/ki-und-musik-kann-ich-mit-kuenstlicher-intelligenz-zum-rockstar-werden-a-cf09798c-8220-4b1c-b0de-89dc19e0133f,KI und Musik: Kann ich mit künstlicher Intelligenz zum Rockstar werden? - DER SPIEGEL,"KI-Programme können Instrumente spielen, singen und ganze Bands nachahmen. Können sie auch helfen, um als Hobbymusiker groß rauszukommen? Ein Selbstversuch."
Artificial Intelligence,Spiegel Online,2024-01-04,https://www.spiegel.de/netzwelt/ki-und-musik-kann-ich-mit-kuenstlicher-intelligenz-zum-rockstar-werden-a-cf09798c-8220-4b1c-b0de-89dc19e0133f,KI und Musik: Kann ich mit künstlicher Intelligenz zum Rockstar werden? - DER SPIEGEL,"KI-Programme können Instrumente spielen, singen und ganze Bands nachahmen. Können sie auch helfen, um als Hobbymusiker groß rauszukommen? Ein Selbstversuch."
KI,Spiegel Online,2024-01-04,https://www.spiegel.de/netzwelt/ki-und-musik-kann-ich-mit-kuenstlicher-intelligenz-zum-rockstar-werden-a-cf09798c-8220-4b1c-b0de-89dc19e0133f,KI und Musik: Kann ich mit künstlicher Intelligenz zum Rockstar werden? - DER SPIEGEL,"KI-Programme können Instrumente spielen, singen und ganze Bands nachahmen. Können sie auch helfen, um als Hobbymusiker groß rauszukommen? Ein Selbstversuch."
KI,Spiegel Online,2024-01-04,https://www.spiegel.de/netzwelt/gadgets/microsoft-fuehrt-ki-taste-fuer-windows-pcs-ein-co-pilot-auf-knopfdruck-a-635aaa97-fb35-41b7-8c17-f700041ba295,Microsoft führt KI-Taste für Windows-PCs ein - Co-Pilot auf Knopfdruck - DER SPIEGEL,"Nach fast 30 Jahren bekommt die Windows-Taste eine neue Ergänzung. Auf künftigen PC-Tastaturen soll ein Schalter prangen, mit dem der Co-Pilot des Konzerns gestartet wird. Sosehr sich Zubehörhersteller bemühen, mit besonders leise oder laut klackernden, leuchtenden, sehr flachen oder vollkommen mechanischen Tastaturen etwas anderes vorzugaukeln: Am grundlegenden Design von PC-Keyboards hat sich in den vergangenen drei Jahrzehnten nichts geändert. Links stehen Tab-, Capslock- und Shift-Taste übereinander, rechts Backspace, Enter und noch mal Shift, dazwischen Buchstaben und Zahlen, darunter die breite Space-Taste und ein paar weitere Sondertasten. Eingequetscht zwischen Strg und Alt findet man seit Windows 95 außerdem die Windowstaste, mit der sich das Startmenü des PC-Betriebssystems auf Knopfdruck öffnen lässt. Ganz ähnlich soll nun die neue Copilot-Taste agieren, die Microsoft am Donnerstagmorgen, nur wenige Tage vor Beginn der Hightech-Messe CES , per Blogpost angekündigt hat. Sobald man sie drückt, wird die von Microsoft als Copilot bezeichnete KI gestartet. »Wir glauben, dass die Menschen dadurch in die Lage versetzt werden, leichter an der KI-Transformation teilzunehmen«, schreibt Microsoft-Manager Yusuf Mehdi. So wie die Windowstaste es »Menschen in aller Welt« ermöglicht habe, »mit Windows zu interagieren«, werde die neue Taste es nun möglich machen, Microsofts künstliche Intelligenz in den Alltag einzubauen, schwärmt Mehdi weiter. Ein Copilot für alles von Microsoft Mit der Einführung der neuen Taste will der Konzern Windows-Nutzerinnen und -Nutzer offenbar motivieren, den Copilot häufiger zu nutzen. Microsoft hat die KI in den vergangenen Monaten tief in viele seiner Programme, Systeme und Angebote integriert. Im März 2023 begann das Unternehmen damit, seinen Copilot in die Office-Suite Microsoft 365 einzubinden . Die KI soll Anwenderinnen und Anwendern bei der Erstellung von Dokumenten, E-Mails, Präsentationen, Tabellen und mehr unterstützen. Unter anderem soll der Copilot in Word, Excel, Powerpoint, Teams und Outlook und zum Einsatz kommen. Microsoft-Chef Satya Nadella bezeichnete das als »den nächsten großen Schritt in der Entwicklung der Art und Weise, wie wir mit Computern interagieren.« Ein halbes Jahr später integrierte das Unternehmen den Copilot dann per Update in Windows 11 . Der »Windows Copilot für Windows 11« soll Anwenderinnen und Anwendern unter anderem helfen, die Funktionen ihres PCs mit Spracheingaben zu steuern, nachdem das Unternehmen die Sprachassistenzfunktion Cortana in Rente geschickt hatte . Statt tief in die Systemsteuerung einzusteigen, soll man dem System etwa den Auftrag geben können: »Passe die Einstellungen so an, dass ich mich konzentrieren kann«. Überdies soll das System Anfragen verarbeiten können, wie man sie bereits aus Bing Chat kennt. Ein Beispiel, das Microsoft bei der Einführung des Systems nannte: »Hilf mir, einen Angelausflug zu planen«. Dabei soll die KI hier auch Daten aus lokal installierten Apps sowie Informationen aus dem Web verwenden können. Aktuell bietet die KI aber auch an, einen Witz zu formulieren, »den meine Kollegen lustig finden würden« oder Python-Skripte zu schreiben. Auf der CES, die kommende Woche in Las Vegas stattfindet, sollen die ersten PCs mit Copilot-Taste zu sehen sein, verspricht Microsoft. Auf den Markt werden sie demnach ab Ende Februar kommen, »auch in den kommenden Surface-Geräten«, also Microsoft-Computern, heißt es seitens des Unternehmens. Bis es so weit ist, wird man sich bei Bedarf die Mühe machen müssen, den Copilot weiterhin manuell mit der Maus über die Menüs des Windows-11-Betriebssystems aufzurufen. Anmerkung der Redaktion: In einer früheren Version hieß es in diesem Text, die Copilot-Taste würde die Windows-Taste ersetzen. Tatsächlich ist sie nur eine Ergänzung. Wir haben den Text entsprechend korrigiert."
KI,Spiegel Online,2024-01-03,https://www.spiegel.de/netzwelt/web/ki-transformation-endlich-wieder-ein-grund-zur-fortschrittsfreude-kolumne-a-cd937d42-9288-4702-86e6-1c94a929e67f,KI-Transformation: Endlich wieder ein Grund zur Fortschrittsfreude - Kolumne - DER SPIEGEL,"Deutschland war oft von Angst vor Abstieg und Wandel geprägt. Die letzte Hochtechnologie, die kollektiv gefeiert wurde, war der VW Golf. Aber es gibt einen Grund, optimistisch zu sein: künstliche Intelligenz."
Künstliche Intelligenz,Spiegel Online,2023-12-29,https://www.spiegel.de/wissenschaft/technik/raffael-ki-erkennt-gemaelde-von-maler-und-bestaetigt-zweifel-an-alleiniger-urheberschaft-a-dec4c63d-ea49-44af-a493-8b14a80bc472,Raffael: KI erkennt Gemälde von Maler – und bestätigt Zweifel an alleiniger Urheberschaft - DER SPIEGEL,"Ist die »Madonna della Rosa« das alleinige Werk von Raffael? Seit Längerem bestehen Zweifel an der Authentizität des Gemäldes. Nun ergab eine Analyse mithilfe von KI: Der Künstler malte wohl nicht als Einziger an dem Bild. Künstliche Intelligenz kann Gemälde des Malers Raffael allein anhand visueller Kriterien recht zuverlässig erkennen. Bei Tests erwies sich das auf die Kunst des Renaissance-Malers trainierte KI-System als zu 98 Prozent zuverlässig, wie Forscher um Hassan Ugail von der englischen Universität Bradford im Fachblatt »Heritage Science« berichten. Die Studie bestätigt bereits vorhandene Zweifel an der Authentizität des Gemäldes »Madonna della Rosa« (»Madonna mit der Rose«) – allerdings nur teilweise. Die Urheberschaft von Gemälden ist oft fraglich. Dabei geht es nicht unbedingt um Fälschungen, denn gerade in früheren Jahrhunderten unterhielten manche Maler Werkstätten, in denen Mitarbeiter sie unterstützten. Um die Authentizität eines Bildes zu klären, verwenden Fachleute verschiedene Techniken: Sie werten Schriftverkehr aus, analysieren das Alter der Werke, untersuchen die verwendeten Materialien in chemischen und technischen Verfahren wie etwa Röntgen- und Spektralanalysen und prüfen Stil, Farbübergänge und Pinselführung. Das Team um den Computerspezialisten Ugail konzentrierte sich bei seiner KI ausschließlich auf das Aussehen der Gemälde – und auf Raffael. Raffaello Sanzio da Urbino lebte von 1483 bis 1520 und zählt neben Michelangelo und Leonardo da Vinci zu den bedeutendsten Malern der Hochrenaissance. Die Fachleute trainierten ihr System mit 49 Bildern, die eindeutig von Raffael stammen, und ebenso vielen Gemälden, an denen der Künstler nachweislich nicht beteiligt war, die jedoch deutliche Ähnlichkeiten aufweisen. Haben Mitarbeiter Objekte im Hintergrund gemalt? Meist fiel das Urteil der KI sehr klar aus: So ordnete sie Raffael etwa die »Sixtinische Madonna« mit einer Wahrscheinlichkeit von 93 Prozent zu, ähnlich die »Vermählung Mariä«. Ein Bild des englischen Malers Peter Lely dagegen schloss sie zu 100 Prozent aus. Bei einer eigens angefertigten Kopie eines Raffael-Selbstporträts schloss die Software eine Urheberschaft des Malers immerhin zu 68 Prozent aus. Als besonders interessant erwies sich die Analyse des Gemäldes »Madonna della Rosa«, das die Heilige Familie samt Johannes dem Täufer zeigt und im Prado-Museum in Madrid hängt. Seine Urheberschaft ist seit Jahrzehnten umstritten – Fachleute diskutieren etwa eine Beteiligung des Malers und Architekten Giulio Romano, der damals noch in Raffaels Werkstatt arbeitete. Die KI-Analyse ergab eine Wahrscheinlichkeit von lediglich 57 Prozent dafür, dass Raffael das ganze Bild gemalt hat. Doch Untersuchungen von bestimmten Bildarealen ergaben, dass er vermutlich die Gesichter der Madonna und der beiden dargestellten Kinder selbst gemalt hat – jeweils mit einer Wahrscheinlichkeit zwischen 79 und 93 Prozent. Das Antlitz von Josef im Hintergrund der Szene dagegen stamme mit einer Wahrscheinlichkeit von 63 Prozent nicht von Raffael. Demnach könnten Mitarbeiter des Malers an weniger prominenten Elementen des Bildes mitgewirkt haben, was damals nicht unüblich war. »Unser vorgestelltes Verfahren zeigt eine ermutigende Treffsicherheit«, schreibt das Fachteam. Das Vorgehen eigne sich auch, um Bilder anderer Maler zu prüfen – unter einer Voraussetzung: Die KI benötigt im Training eine ausreichende Menge Gemälde, die sicher von diesen Künstlern stammen."
KI,Spiegel Online,2023-12-31,https://www.spiegel.de/panorama/silvester-sydney-will-erstmals-ki-beim-riesenfeuerwerk-einsetzen-a-80cddfc7-e094-45aa-9d6f-56418432c716,Silvester: Sydney will erstmals KI beim Riesenfeuerwerk einsetzen - DER SPIEGEL,"Kaum ein Silvesterfeuerwerk auf der Welt zieht so viele Blicke auf sich wie das in Sydney. Zehn Stunden vor der Sause in Deutschland geht es los – dieses Mal auch mit künstlicher Intelligenz. Im australischen Sydney laufen die Vorbereitungen für die Silvestersause samt spektakulärem Feuerwerk auf Hochtouren. Zum Jahreswechsel (14 Uhr MEZ) soll vor der weltberühmten Kulisse der Harbour Bridge und des Opernhauses wieder eine Mega-Lichtershow den Himmel erleuchten. Allein im Hafenviertel werden laut Organisatoren mehr als 13.500 Feuerwerkskörper mit allerlei aufwendigen Spezialeffekten gezündet. Zudem soll es zum ersten Mal überhaupt von künstlicher Intelligenz generierte Lichterprojektionen geben – die weder für Luft- noch für Lärmverschmutzung sorgen. Eine Million Schaulustige werden in der Metropole an der Ostküste erwartet, darunter auch aus Deutschland und anderen Ländern Europas angereiste Besucher. Etwa eine Milliarde weitere Menschen schauen traditionell in aller Welt an den Bildschirmen zu. Bereits am Sonntagmorgen sicherten sich viele am Mrs Macquaries Point in den Royal Botanic Gardens einen Platz, um am Abend den besten Blick auf das Spektakel zu haben, wie der Sender 9News berichtete. Auch auf ikonischen Gebäuden können sie Lichtprojektionen bestaunen, vor allem auf den Segeldächern des Opernhauses, das in diesem Jahr sein 50-jähriges Bestehen gefeiert hat. Sydney ist immer eine der ersten Großstädte weltweit, die das neue Jahr einläuten. Bereits um 21 Uhr Ortszeit (elf Uhr MEZ) wird das erste große Feuerwerk über dem Hafen abgeschossen, um Mitternacht folgt dann die etwa zwölfminütige Riesensause. Unter dem Namen »Calling Country« wird es neben den Lichtern auch Musik, Tanz und Kunst von indigenen Australiern geben. Vorab soll zudem eine traditionelle Willkommenszeremonie der Ureinwohner abgehalten werden. Etwa 2000 zusätzliche Polizeibeamte sind im Einsatz, um für Sicherheit zu sorgen. Die Stadt Sydney bat die Menschen, ihre Autos zu Hause zu lassen und stattdessen mit öffentlichen Verkehrsmitteln anzureisen."
KI,Spiegel Online,2023-12-31,https://www.spiegel.de/panorama/silvesterfeuerwerk-in-sydney-im-livestream-jahreswechsel-von-2023-auf-2024-ansehen-a-808083fd-ff3d-4e95-8d5b-12d3a57afa08,Silvesterfeuerwerk in Sydney im Livestream: Jahreswechsel von 2023 auf 2024 ansehen - DER SPIEGEL,In Sydney war es schon soweit! An der Harbour Bridge wurde der Jahreswechsel erstmals mit Feuerwerk und KI-generierten Projektionen gefeiert. Das Spektakel in voller Länge.
KI,Spiegel Online,2023-12-29,https://www.spiegel.de/netzwelt/web/ki-programme-durch-den-ki-boom-sind-immer-mehr-private-daten-gefaehrdet-a-b834b868-2d15-49ec-bff1-f090f32a69b8,KI-Programme: »Durch den KI-Boom sind immer mehr private Daten gefährdet« - DER SPIEGEL,"Als sogenannter Prompt-Hacker sucht Johann Rehberger in KI-Systemen nach Schwächen, über die Angreifer private Daten stehlen können – mit Erfolg. Besonders ein Unternehmen macht ihm Sorgen."
KI,Spiegel Online,2023-12-29,https://www.spiegel.de/wissenschaft/technik/raffael-ki-erkennt-gemaelde-von-maler-und-bestaetigt-zweifel-an-alleiniger-urheberschaft-a-dec4c63d-ea49-44af-a493-8b14a80bc472,Raffael: KI erkennt Gemälde von Maler – und bestätigt Zweifel an alleiniger Urheberschaft - DER SPIEGEL,"Ist die »Madonna della Rosa« das alleinige Werk von Raffael? Seit Längerem bestehen Zweifel an der Authentizität des Gemäldes. Nun ergab eine Analyse mithilfe von KI: Der Künstler malte wohl nicht als Einziger an dem Bild. Künstliche Intelligenz kann Gemälde des Malers Raffael allein anhand visueller Kriterien recht zuverlässig erkennen. Bei Tests erwies sich das auf die Kunst des Renaissance-Malers trainierte KI-System als zu 98 Prozent zuverlässig, wie Forscher um Hassan Ugail von der englischen Universität Bradford im Fachblatt »Heritage Science« berichten. Die Studie bestätigt bereits vorhandene Zweifel an der Authentizität des Gemäldes »Madonna della Rosa« (»Madonna mit der Rose«) – allerdings nur teilweise. Die Urheberschaft von Gemälden ist oft fraglich. Dabei geht es nicht unbedingt um Fälschungen, denn gerade in früheren Jahrhunderten unterhielten manche Maler Werkstätten, in denen Mitarbeiter sie unterstützten. Um die Authentizität eines Bildes zu klären, verwenden Fachleute verschiedene Techniken: Sie werten Schriftverkehr aus, analysieren das Alter der Werke, untersuchen die verwendeten Materialien in chemischen und technischen Verfahren wie etwa Röntgen- und Spektralanalysen und prüfen Stil, Farbübergänge und Pinselführung. Das Team um den Computerspezialisten Ugail konzentrierte sich bei seiner KI ausschließlich auf das Aussehen der Gemälde – und auf Raffael. Raffaello Sanzio da Urbino lebte von 1483 bis 1520 und zählt neben Michelangelo und Leonardo da Vinci zu den bedeutendsten Malern der Hochrenaissance. Die Fachleute trainierten ihr System mit 49 Bildern, die eindeutig von Raffael stammen, und ebenso vielen Gemälden, an denen der Künstler nachweislich nicht beteiligt war, die jedoch deutliche Ähnlichkeiten aufweisen. Haben Mitarbeiter Objekte im Hintergrund gemalt? Meist fiel das Urteil der KI sehr klar aus: So ordnete sie Raffael etwa die »Sixtinische Madonna« mit einer Wahrscheinlichkeit von 93 Prozent zu, ähnlich die »Vermählung Mariä«. Ein Bild des englischen Malers Peter Lely dagegen schloss sie zu 100 Prozent aus. Bei einer eigens angefertigten Kopie eines Raffael-Selbstporträts schloss die Software eine Urheberschaft des Malers immerhin zu 68 Prozent aus. Als besonders interessant erwies sich die Analyse des Gemäldes »Madonna della Rosa«, das die Heilige Familie samt Johannes dem Täufer zeigt und im Prado-Museum in Madrid hängt. Seine Urheberschaft ist seit Jahrzehnten umstritten – Fachleute diskutieren etwa eine Beteiligung des Malers und Architekten Giulio Romano, der damals noch in Raffaels Werkstatt arbeitete. Die KI-Analyse ergab eine Wahrscheinlichkeit von lediglich 57 Prozent dafür, dass Raffael das ganze Bild gemalt hat. Doch Untersuchungen von bestimmten Bildarealen ergaben, dass er vermutlich die Gesichter der Madonna und der beiden dargestellten Kinder selbst gemalt hat – jeweils mit einer Wahrscheinlichkeit zwischen 79 und 93 Prozent. Das Antlitz von Josef im Hintergrund der Szene dagegen stamme mit einer Wahrscheinlichkeit von 63 Prozent nicht von Raffael. Demnach könnten Mitarbeiter des Malers an weniger prominenten Elementen des Bildes mitgewirkt haben, was damals nicht unüblich war. »Unser vorgestelltes Verfahren zeigt eine ermutigende Treffsicherheit«, schreibt das Fachteam. Das Vorgehen eigne sich auch, um Bilder anderer Maler zu prüfen – unter einer Voraussetzung: Die KI benötigt im Training eine ausreichende Menge Gemälde, die sicher von diesen Künstlern stammen."
KI,Spiegel Online,2023-12-29,https://www.spiegel.de/ausland/donald-trumps-ex-anwalt-michael-cohen-gesteht-vor-gericht-faelschliche-nutzung-von-ki-a-1c695051-e699-48b6-83d2-d439dc91e0b8,"Donald Trumps Ex-Anwalt, Michael Cohen, gesteht vor Gericht fälschliche Nutzung von KI - DER SPIEGEL","Manchmal liefern Chatbots fehlerhafte Antworten. Diese Erfahrung hat nach eigenen Angaben auch Donald Trumps ehemaliger Anwalt Michael Cohen gemacht. Zumindest erklärte er so vor Gericht Falschinformationen. Der ehemalige Trump-Anwalt Michael Cohen hat vor Gericht zugegeben, mit künstlicher Intelligenz Falschinformationen generiert und an seinen Anwalt weitergegeben zu haben. Der 57-Jährige habe mit dem Google Chatbot Bard Belege für ein Gerichtsverfahren in New York herausgesucht, die sich die Software ausgedacht habe. Das geht aus neu veröffentlichten Unterlagen des Bundesgerichts in Manhattan hervor, in denen Cohen sich für sein Verhalten gerechtfertigt hat. Cohen sagte dem Gericht in einer am Freitag veröffentlichten eidesstattlichen Erklärung, dass er sich nicht bewusst gewesen sei, dass Google Bard ein Textgenerator ähnlich dem von ChatGPT ist. Cohen räumte seinen Fehler ein, nachdem der Richter in dem Fall zu insgesamt drei zitierten Fällen, die dieser nicht finden konnte, um Erklärung gebeten hatte. Cohen hatte sich wegen Verstößen gegen die Nutzung von Wahlkampfspenden für Trump 2018 schuldig bekannt und wurde zu drei Jahren Gefängnis verurteilt, durfte aber wegen der Coronapandemie einen Teil der Strafe im Hausarrest absitzen. Die fehlerhaften Informationen fanden sich nun in der Bitte Cohens an das Gericht, den Fall zu den Akten zu legen. Es bleibt abzuwarten, ob die Episode Einfluss auf einen gegenwärtig laufenden Prozess gegen den ehemaligen Präsidenten Donald Trump haben wird. Dort hat Cohen als zentraler Zeuge ausgesagt und wird von der Trump-Verteidigung immer wieder als nicht vertrauenswürdig dargestellt. In einer Zivilklage hatte Trump seinen ehemaligen Vertrauten auf 500 Millionen Dollar verklagt, diese Anklage aber dann zurückgezogen. Die neuartigen KI-Programme haben immense Fähigkeiten – die Art ihrer Programmierung macht sie jedoch anfällig für das »Halluzinieren« von vermeintlichen Fakten. Schon vor Cohen hatte es Fälle von Anwälten gegeben, die sich mit KI-Chatbots die Arbeit erleichtern wollten, damit aber letztendlich falsche Informationen zur Verfügung stellten."
Künstliche Intelligenz,Spiegel Online,2023-12-27,https://www.spiegel.de/netzwelt/web/chatgpt-new-york-times-verklagt-openai-und-microsoft-a-6a339655-8c89-453a-abd1-fb7fd649ec7b,ChatGPT: »New York Times« verklagt OpenAI und Microsoft - DER SPIEGEL,"Monatelange Verhandlungen brachten keinen Durchbruch, nun zieht die »New York Times« gegen die Firmen Microsoft und OpenAI vor Gericht. Der Vorwurf: unerlaubte Nutzung von geistigem Eigentum. Die »New York Times« (»NYT«) hat als erste große US-Zeitung die Software-Unternehmen OpenAI und Microsoft wegen ihres KI-Chatbots ChatGPT verklagt. Die »NYT« wirft den Firmen vor, dass sie Wissen aus Millionen Artikeln benutzt haben, um ChatGPT zu füttern und damit auf Kosten der »New York Times« ein Geschäft aufzubauen. Die Klage enthält keine genaue Geldforderung. In der Klageschrift heißt es dazu nur: »Ziel ist es, jene für die Schadensersatzforderungen in Milliardenhöhe haftbar zu machen, die sie der ›Times‹ für das rechtswidrige Kopieren und Verwenden« ihrer Werke schuldeten. Die Beklagten versuchten, »die massiven Investitionen der ›Times‹ in ihren Journalismus zu missbrauchen«, heißt es . Die Abkürzung KI steht für künstliche Intelligenz, gemeint sind Methoden, menschliche Denkvorgänge auf Computer zu übertragen. Ein Chatbot ist ein Text-Dialogsystem auf Basis eines Computerprogramms. Mit seinem KI-Chatbot hatte die Softwareschmiede OpenAI, die maßgeblich von Microsoft unterstützt wird, vor etwas mehr als einem Jahr für Furore gesorgt. ChatGPT schürte den Hype um künstliche Intelligenz mit Erwartungen an ein digitales Schlaraffenland für alle bis hin zur Angst vor einem Auslöschen der Menschheit. Entsprechend wurde OpenAI zum wichtigsten Start-up der Welt mit einem geschätzten Wert von 80 Milliarden Dollar, das den Facebook-Konzern Meta in Zugzwang brachte. Nutzer können mit ChatGPT ganz einfach frei kommunizieren und etwa Aufgaben verteilen oder Wissen abfragen – sie bekommen dann Antworten, die sich von menschlichen oft kaum mehr unterscheiden. Dafür hat OpenAI ChatGPT fast mit dem gesamten Wissen des Internets gefüttert. Von Foreneinträgen, Firmenwebsites, Drehbüchern bis hin zu journalistischen Artikeln. Die »New York Times« hofft deswegen nun auf Schadensersatz. Es ist möglich, dass eine erfolgreiche Klage viele Nachahmer in der Medienbranche finden könnte."
Künstliche Intelligenz,Spiegel Online,2023-12-27,https://www.spiegel.de/netzwelt/netzpolitik/kuenstliche-intelligenz-wir-erleben-eine-ki-revolution-von-unten-a-176508a0-60f4-4951-8c5d-4fc943dbdad1,Künstliche Intelligenz: Wir erleben eine KI-Revolution von unten - DER SPIEGEL,"Wie künstliche Intelligenz die Gesellschaft verändert, entscheiden gerade weniger Firmenchefs, sondern ihre Angestellten. Selbst wenn diese die Technik nur nutzen, um früher Feierabend zu machen."
Künstliche Intelligenz,Spiegel Online,2023-12-26,https://www.spiegel.de/wissenschaft/technik/kuenstliche-intelligenz-als-laborpartner-wie-die-zusammenarbeit-mit-einer-ki-funktioniert-a-f576454a-4857-47a9-910f-c69fed060894,Künstliche Intelligenz als Laborpartner: Wie die Zusammenarbeit mit einer KI funktioniert - DER SPIEGEL,"Erstmals haben Fachleute zusammen mit einer KI als Kollege im Labor gearbeitet. Hier erzählt Gabe Gomes, der Mitentwickler von Coscientist, wie das funktioniert und warum man Respekt vor solchen Systemen haben sollte."
Künstliche Intelligenz,Spiegel Online,2023-12-25,https://www.spiegel.de/netzwelt/web/die-welt-als-petrischale-a-204f0e59-e676-4331-8c1f-e4736b5dc9a1,Künstliche Intelligenz: Der Boom von ChatGPT und Co. - DER SPIEGEL,"ChatGPT hat den globalen KI-Boom ausgelöst. Ein Jahr später schwankt die Welt zwischen Euphorie und tiefer Sorge davor, was die Technologie bewirken könnte. Wie konnte es so schnell dazu kommen?"
AI,Spiegel Online,2023-12-28,https://www.spiegel.de/ausland/wie-china-mit-kuenstlicher-intelligenz-versucht-die-wahl-in-taiwan-zu-beeinflussen-a-a999b9e6-67bc-4300-8e0c-189ab3fad3d5,"Wie China mit Künstlicher Intelligenz versucht, die Wahl in Taiwan zu beeinflussen - DER SPIEGEL","Vor den Wahlen im Januar überschwemmt China Taiwan mit Fake News. Tech-Pionier Ethan Tu hat seinen Job bei Microsoft gekündigt – und versucht nun mit Gleichgesinnten, den Inselstaat gegen Propaganda zu verteidigen."
AI,Spiegel Online,2023-12-27,https://www.spiegel.de/netzwelt/web/chatgpt-new-york-times-verklagt-openai-und-microsoft-a-6a339655-8c89-453a-abd1-fb7fd649ec7b,ChatGPT: »New York Times« verklagt OpenAI und Microsoft - DER SPIEGEL,"Monatelange Verhandlungen brachten keinen Durchbruch, nun zieht die »New York Times« gegen die Firmen Microsoft und OpenAI vor Gericht. Der Vorwurf: unerlaubte Nutzung von geistigem Eigentum. Die »New York Times« (»NYT«) hat als erste große US-Zeitung die Software-Unternehmen OpenAI und Microsoft wegen ihres KI-Chatbots ChatGPT verklagt. Die »NYT« wirft den Firmen vor, dass sie Wissen aus Millionen Artikeln benutzt haben, um ChatGPT zu füttern und damit auf Kosten der »New York Times« ein Geschäft aufzubauen. Die Klage enthält keine genaue Geldforderung. In der Klageschrift heißt es dazu nur: »Ziel ist es, jene für die Schadensersatzforderungen in Milliardenhöhe haftbar zu machen, die sie der ›Times‹ für das rechtswidrige Kopieren und Verwenden« ihrer Werke schuldeten. Die Beklagten versuchten, »die massiven Investitionen der ›Times‹ in ihren Journalismus zu missbrauchen«, heißt es . Die Abkürzung KI steht für künstliche Intelligenz, gemeint sind Methoden, menschliche Denkvorgänge auf Computer zu übertragen. Ein Chatbot ist ein Text-Dialogsystem auf Basis eines Computerprogramms. Mit seinem KI-Chatbot hatte die Softwareschmiede OpenAI, die maßgeblich von Microsoft unterstützt wird, vor etwas mehr als einem Jahr für Furore gesorgt. ChatGPT schürte den Hype um künstliche Intelligenz mit Erwartungen an ein digitales Schlaraffenland für alle bis hin zur Angst vor einem Auslöschen der Menschheit. Entsprechend wurde OpenAI zum wichtigsten Start-up der Welt mit einem geschätzten Wert von 80 Milliarden Dollar, das den Facebook-Konzern Meta in Zugzwang brachte. Nutzer können mit ChatGPT ganz einfach frei kommunizieren und etwa Aufgaben verteilen oder Wissen abfragen – sie bekommen dann Antworten, die sich von menschlichen oft kaum mehr unterscheiden. Dafür hat OpenAI ChatGPT fast mit dem gesamten Wissen des Internets gefüttert. Von Foreneinträgen, Firmenwebsites, Drehbüchern bis hin zu journalistischen Artikeln. Die »New York Times« hofft deswegen nun auf Schadensersatz. Es ist möglich, dass eine erfolgreiche Klage viele Nachahmer in der Medienbranche finden könnte."
Artificial Intelligence,Spiegel Online,2023-12-28,https://www.spiegel.de/ausland/wie-china-mit-kuenstlicher-intelligenz-versucht-die-wahl-in-taiwan-zu-beeinflussen-a-a999b9e6-67bc-4300-8e0c-189ab3fad3d5,"Wie China mit Künstlicher Intelligenz versucht, die Wahl in Taiwan zu beeinflussen - DER SPIEGEL","Vor den Wahlen im Januar überschwemmt China Taiwan mit Fake News. Tech-Pionier Ethan Tu hat seinen Job bei Microsoft gekündigt – und versucht nun mit Gleichgesinnten, den Inselstaat gegen Propaganda zu verteidigen."
Artificial Intelligence,Spiegel Online,2023-12-25,https://www.spiegel.de/netzwelt/web/die-welt-als-petrischale-a-204f0e59-e676-4331-8c1f-e4736b5dc9a1,Künstliche Intelligenz: Der Boom von ChatGPT und Co. - DER SPIEGEL,"ChatGPT hat den globalen KI-Boom ausgelöst. Ein Jahr später schwankt die Welt zwischen Euphorie und tiefer Sorge davor, was die Technologie bewirken könnte. Wie konnte es so schnell dazu kommen?"
KI,Spiegel Online,2023-12-28,https://www.spiegel.de/netzwelt/web/ki-phaenomen-loab-jemand-sagte-mir-ich-haette-einen-daemon-erschaffen-a-de1e7c74-ed34-4f1f-91a8-c9a4fd1ac192,"KI-Phänomen Loab: »Jemand sagte mir, ich hätte einen Dämon erschaffen« - DER SPIEGEL","Wenn ein Bildgenerator statt bunter, fröhlicher Motive plötzlich Horrorszenen erzeugt: Steph Maj Swanson leuchtet die dunklen Seiten von KI-Modellen aus, um Technik und Geschäftsmodelle bloßzulegen."
KI,Spiegel Online,2023-12-27,https://www.spiegel.de/netzwelt/web/chatgpt-new-york-times-verklagt-openai-und-microsoft-a-6a339655-8c89-453a-abd1-fb7fd649ec7b,ChatGPT: »New York Times« verklagt OpenAI und Microsoft - DER SPIEGEL,"Monatelange Verhandlungen brachten keinen Durchbruch, nun zieht die »New York Times« gegen die Firmen Microsoft und OpenAI vor Gericht. Der Vorwurf: unerlaubte Nutzung von geistigem Eigentum. Die »New York Times« (»NYT«) hat als erste große US-Zeitung die Software-Unternehmen OpenAI und Microsoft wegen ihres KI-Chatbots ChatGPT verklagt. Die »NYT« wirft den Firmen vor, dass sie Wissen aus Millionen Artikeln benutzt haben, um ChatGPT zu füttern und damit auf Kosten der »New York Times« ein Geschäft aufzubauen. Die Klage enthält keine genaue Geldforderung. In der Klageschrift heißt es dazu nur: »Ziel ist es, jene für die Schadensersatzforderungen in Milliardenhöhe haftbar zu machen, die sie der ›Times‹ für das rechtswidrige Kopieren und Verwenden« ihrer Werke schuldeten. Die Beklagten versuchten, »die massiven Investitionen der ›Times‹ in ihren Journalismus zu missbrauchen«, heißt es . Die Abkürzung KI steht für künstliche Intelligenz, gemeint sind Methoden, menschliche Denkvorgänge auf Computer zu übertragen. Ein Chatbot ist ein Text-Dialogsystem auf Basis eines Computerprogramms. Mit seinem KI-Chatbot hatte die Softwareschmiede OpenAI, die maßgeblich von Microsoft unterstützt wird, vor etwas mehr als einem Jahr für Furore gesorgt. ChatGPT schürte den Hype um künstliche Intelligenz mit Erwartungen an ein digitales Schlaraffenland für alle bis hin zur Angst vor einem Auslöschen der Menschheit. Entsprechend wurde OpenAI zum wichtigsten Start-up der Welt mit einem geschätzten Wert von 80 Milliarden Dollar, das den Facebook-Konzern Meta in Zugzwang brachte. Nutzer können mit ChatGPT ganz einfach frei kommunizieren und etwa Aufgaben verteilen oder Wissen abfragen – sie bekommen dann Antworten, die sich von menschlichen oft kaum mehr unterscheiden. Dafür hat OpenAI ChatGPT fast mit dem gesamten Wissen des Internets gefüttert. Von Foreneinträgen, Firmenwebsites, Drehbüchern bis hin zu journalistischen Artikeln. Die »New York Times« hofft deswegen nun auf Schadensersatz. Es ist möglich, dass eine erfolgreiche Klage viele Nachahmer in der Medienbranche finden könnte."
KI,Spiegel Online,2023-12-27,https://www.spiegel.de/netzwelt/netzpolitik/kuenstliche-intelligenz-wir-erleben-eine-ki-revolution-von-unten-a-176508a0-60f4-4951-8c5d-4fc943dbdad1,Künstliche Intelligenz: Wir erleben eine KI-Revolution von unten - DER SPIEGEL,"Wie künstliche Intelligenz die Gesellschaft verändert, entscheiden gerade weniger Firmenchefs, sondern ihre Angestellten. Selbst wenn diese die Technik nur nutzen, um früher Feierabend zu machen."
KI,Spiegel Online,2023-12-26,https://www.spiegel.de/wissenschaft/technik/kuenstliche-intelligenz-als-laborpartner-wie-die-zusammenarbeit-mit-einer-ki-funktioniert-a-f576454a-4857-47a9-910f-c69fed060894,Künstliche Intelligenz als Laborpartner: Wie die Zusammenarbeit mit einer KI funktioniert - DER SPIEGEL,"Erstmals haben Fachleute zusammen mit einer KI als Kollege im Labor gearbeitet. Hier erzählt Gabe Gomes, der Mitentwickler von Coscientist, wie das funktioniert und warum man Respekt vor solchen Systemen haben sollte."
Artificial Intelligence,Spiegel Online,2023-12-20,https://www.spiegel.de/international/world/espionage-from-the-east-russia-is-a-storm-china-is-climate-change-a-7436be38-2088-4e10-b188-e5032ad0a367,"Espionage from the East: ""Russia Is a Storm, China Is Climate Change"" - DER SPIEGEL","Spying from China continues to grow in both volume and sophistication. The cyber-snoops from the People's Republic have moved beyond companies and are now seeking to exert influence on politics in Germany – all while keeping a close eye on dissidents and minorities. Where should we start? Perhaps with the two pandas Meng Meng and Jiao Qing. They couldn’t be any cuter! Chinese President Xi Jinping presented them to the Berlin Zoo six years ago, with Xi telling then-German Chancellor Angela Merkel that the bears were ""ambassadors” of the good relations between their two countries. Merkel beamed. ""Extremely likable diplomats,” she said of the pair of pandas. Or perhaps we should go back a bit farther? To 2014? Xi was again in Germany, this time at the port in Duisburg with then-Vice Chancellor Sigmar Gabriel. The two of them were eagerly awaiting the arrival of a freight train from Chongqing, which would be reaching the end of the 10,300 kilometer long ""New Silk Road” in Duisburg. Duisburg that year began referring to itself as ""China City.” A broad plan for the city called for the telecommunications giant Huawei to transform the run-down industrial metropolis in Germany’s Ruhr Valley into a state-of-the-art ""smart city,” enabling the citizens of Duisburg to lead ""happy and successful lives,” according to an agreement with the Chinese. What a time. So much hope. So much naivete. And now? Duisburg has left behind its dreams of becoming a smart city. In Berlin, Interior Minister Nancy Faeser of the center-left Social Democrats (SPD) is intent on drastically reducing China’s involvement in Germany’s mobile phone networks for fear of possible sabotage. The German government increasingly sees the communist regime as a “systemic rival.” Chancellor Olaf Scholz, also of the SPD, has emphasized the need for risk reduction. And Foreign Minister Annalena Baerbock of the Green Party recently even referred to Xi as a dictator. German intelligence agents have long abandoned any illusions they may once have held about the hunger for power and the increasing hostility of the Chinese Communist Party toward the West. Russian President Vladimir Putin’s war against Ukraine may be the most acute problem facing Europe at the moment. But on the long term, the biggest threat comes from China. ""Russia is a storm,” says Thomas Haldenwang, head of the Federal Office for the Protection of the Constitution, Germany’s domestic security agency. ""China is climate change.” Reporting by DER SPIEGEL now clearly demonstrates how Chinese spies have recruited European politicians. Hundreds of text messages sent by a secret service agent from the Chinese Ministry of State Security, a man who goes by the name Daniel Woo, show that the communist regime commissioned parliamentary initiatives in both Belgium and Germany. Successfully. The article you are reading originally appeared in German in issue 51/2023 (December 16th, 2023) of DER SPIEGEL. It is an impressive success for China’s shameless activities in Europe and the country’s attempt to force its way into the heart of democracy to exert influence. Our reporting provides a rare look behind the scenes at the powerful Chinese intelligence apparatus. Since Xi took over power in China in 2012, he has focused intently on massively enlarging an already expansive security apparatus. Furthermore, new laws have given government agencies essentially a free hand when it comes to surveillance. Millions of cameras have been installed in Chinese cities, an Orwellian nightmare referred to by country’s propaganda machine as Skynet. Everything and everybody is constantly being filmed, messages in the widely-used app WeChat are analyzed and demonstrators are identified using facial recognition technology. By 2049, the year that will mark the 100th birthday of the People’s Republic, Xi Jinping hopes to have transformed his country into a superpower – equaling, or even surpassing, the technological and military strength of the United States. Xi refers to this project of returning his country to what he sees as its rightful place at the top of the global pecking order as the ""Chinese Dream.” And on the road to that goal, almost anything goes. Controlling the Diaspora The toolbox belonging to the Chinese secret service agencies is filled to overflowing. According to Germany’s domestic security agency, the regime’s oppression of dissidents and minorities like the Uighurs is no longer limited to its own country. Critics of Beijing living in Germany, the agency says, have also been targeted, at times by heaping pressure on their family members back home. The goal, say German security officials, is the ""control and regulation of the diaspora.” In parallel, the German security agency says, Chinese spies are doing all they can to get their hands on future technologies, such as quantum technology, artificial intelligence, hypersonic technology and biotechnology. Much of it also has military applications. Company takeovers in Germany, the agency says, serve the overarching strategic goal of giving China the advantage in the global competition for knowledge. Meanwhile, Chinese cyberattacks are no longer limited to companies and are increasingly targeting politicians, say officials. Diplomats and agents in Chinese embassies and consulates are allegedly establishing broad networks of contacts in an attempt to secure the services of active and former German politicians. It sounds a lot like a broad attack on Germany. ""The Chinese Communist Party,” says the German sinologist Mareike Ohlberg of the German Marshall Fund in Berlin, ""is exploiting the weaknesses of democratic systems in order to undermine them.” Chinese spies and hackers are far less obtrusive than their Russian counterparts, employing less brute force. Yet they are at least as effective. Poisoning critics in Britain or murdering enemies of the state in a Berlin park, as Russia’s state-sponsored killers have done, are hardly strategies that Chinese secret service agents would deploy. Chinese hackers also stay away from splashy moves like publishing compromising emails of Western politicians in the middle of an election campaign, as Putin’s digital henchmen have done on several occasions. Silently Penetrating Critical Systems Cyberspies from China force their way silently into the systems they have targeted and stay put for several years, slowly and unobtrusively siphoning off sensitive information. These long-term ingresses could also be used for destructive purposes down the road, such as to sabotage critical infrastructure, warns security expert Antonia Hmaidi in a recent study for the Mercator Institute for China Studies (MERICS), the well-respected think tank in Germany. Dormant Chinese malware codes, she points out, have already been discovered in the U.S. electricity grid. Numerous companies listed on Germany’s blue-chip stock index, the DAX, have been targeted by Chinese cyberattacks, such as BASF and Daimler – as has, DER SPIEGEL has learned, at least one German semiconductor producer. In a recent survey, 730 of more than 1,000 companies surveyed say they were targeted by cyberattacks last year. Forty-two percent have identified at least one attack originating in China. The MERICS study notes that many of the foreign targets are consistent with the ""strategic goals of China's government.” The conclusion reached by the think tank: The cyberattacks pose ""a risk to Europe’s long-term prosperity."" Even 2,500 years ago, the Chinese military strategist Sun Tzu knew how important spies are. ""If you know the enemy and know yourself, you need not fear the result of a hundred battles,” he wrote in ""The Art of War.” China’s current ruler Xi Jinping has an army of spies at his disposal. With hundreds of thousands of fulltime agents, his secret service apparatus is ""almost certainly the largest in the world,” the Intelligence and Security Committee of the British parliament has said. That number is apparently augmented by thousands upon thousands of Chinese expatriates, guest researchers, students and businesspeople who provide their services in sending information back home – or who are forced into spying by the Chinese intelligence authorities. A secret service law that went into effect in 2017 stipulates that ""any organization or citizen shall support, assist and cooperate with state intelligence work, according to the law.” That means that the state can require any Chinese citizen or company to cooperate with the intelligence services. It is essentially a license for unlimited spying. Not every student from China, of course, is a spy. Yet state security officials in Bavaria have warned against naivete. They are particularly concerned about the grants awarded by the state-run China Scholarship Council (CSC), which has sent around 5,000 undergrad and graduate students to Germany. Participants must declare their allegiance to China and the Communist Party in writing, stay in regular contact with the embassy and follow any instructions they receive. According to the head of the state security agency in Bavaria, Burkhard Körner, grant recipients must also submit regular reports. And those reports, says Körner, are not just limited to information about their guest universities and the progress they have made with their studies. ""They can also be required to provide information about the Chinese community in exile, dissidents and minorities like the Uighurs.” Körner recommends that universities be careful when admitting CSC grant recipients. ""The risk is real,” he says. In the U.S., China has long been viewed as a threat, with the FBI highlighting the dangers way back in 2005. These days, the U.S. federal police force maintains a website called ""The China Threat.” A new investigation into a case of espionage is opened by the FBI every 12 hours. In the last two decades, Chinese agents have stolen vast amounts of data from the U.S. The Center for Strategic and International Studies lists 224 cases between 2000 and 2023, though the number of unreported cases is likely far higher. The Chinese siphoned off information about the space shuttle program, data about seeds from Monsanto, emails from the White House, 614 gigabytes of information about a supersonic anti-ship missile, secret company data about self-driving cars from Apple, sensitive data from millions of public servants and much more. The thefts increasingly take place digitally. China operates the most comprehensive hacking program of any country in the world, FBI head Christopher Wray said during a late October appearance in Silicon Valley. It was a rather unusual occasion: For the first time ever, the secret service chiefs from all Five Eyes member states – the U.S., Canada, Britain, Australia and New Zealand – appeared before the press at the same time. Their message: When it comes to China, the situation is more serious than ever before. Flooding the Net with Fake News Since then, the U.S. Department of Justice has indicted a series of suspected Chinese hackers thought to be working on behalf of the state. On the FBI website, you can scroll through numerous ""Wanted” posters with the faces of young men and women who are suspected of being behind cyber attacks on companies, government agencies and research facilities carried out on behalf of the Chinese Ministry of State Security or the Chinese military, known as the People’s Liberation Army. The website also contains the names and photos of Chinese public servants allegedly responsible for flooding the global internet with fake news and for digitally harassing dissidents in the West. The ""naming and shaming” strategy pursued by the U.S. is supposed to act as a deterrent, but thus far seems to have had little effect. On the contrary: Chinese cyber-groups seem to be further developing their skills and becoming more professional. The U.S. cybersecurity company Mandiant believes that Chinese authorities are behind fully 29 groups classified as Advanced Persistent Threats (APTs), a designation experts assign to the most dangerous malicious actors on the web. The methods they employ have also been refined: For years, Chinese cyberattackers were known for simple phishing campaigns, whereby malware is installed on computers as soon as a user clicks on a link sent by email, for example. Today, though, Chinese groups have turned to more sophisticated methods, such as targeting weak points in servers – and they exert tremendous energy to cover their tracks. Germany, too, could have realized early on that China wasn’t nearly as harmless as the pandas in the Berlin Zoo. In the Bavarian town of Kolbermoor in 2009, a Chinese industrial spy’s cover was blown. During a visit to a factory, he used a mini-camera peaking out of his pants pocket to secretly film the innovative products of a fiber-reinforced concrete specialist. Company employees realized what he was doing and called the police. The Chinese man was sentenced to a suspended prison sentence of one-and-a-half years. In 2011, a court in Munich sentenced a Chinese man for espionage activities. A secret service officer disguised as a consulate employee had recruited him to spy on the World Uighur Congress in Munich, the functionaries of which China sees as enemies of the state. The spy delivered the desired information to his handler during clandestine meetings in cafés, subway stations and the Nymphenburg Palace Park. German domestic security officials managed to sniff them out. The University of Duisburg-Essen hosted a guest professor from China in 2008 who spent months at the institution learning about cutting edge German engineering technologies. Only 10 years later did the university discover that the man was a major general in the People’s Liberation Army. Back home, he heads up a military laboratory for missile tests and control technology. In 2021, a court convicted a German couple for espionage. She worked as a professor with a focus on South Asia while he worked for the Hanns Seidel Foundation, which has close ties to the Christian Social Union (CSU), the center-right political party in Bavaria. He later founded a think tank. The two of them were recruited in 2010 in Shanghai, where they were delivering lectures. For nine years, the couple delivered information to the Chinese secret service, either before or after state visits or multinational conferences. Still, the danger of Chinese espionage continues to be perceived by the public as being less acute than from other powers. Many see Russia as the primary threat, particularly after Moscow’s February 2022 invasion of Ukraine. Michael Brand, a politician from the center-right Christian Democrats (CDU) who focuses on human rights issues, says however: ""Totalitarian and aggressive China is the biggest threat of the 21st century.” Very few Chinese in exile, who are well aware that Beijing’s reach extends into Germany, are willing to speak openly. They are fearful that doing so could worsen the repression many of them already experience. But Su Yutong is willing to go on the record anyway – to discuss the men in Berlin who showed up at her door wanting sex after somebody had posted a fake advertisement on the internet, for example. Or about the police officers who suddenly visited her family in Beijing after she had attended a demonstration in Germany against the Chinese Communist Party. And then there was the Telegram message from somebody claiming to be a Chinese civil servant, offering her tens of thousands of euros to keep silent about critical issues. A 47-year-old journalist, Su fled to Germany in 2010 after her critical reporting and her advocacy for human rights had put her on the radar of Chinese government agencies. Today, she writes for the U.S. medium Radio Free Asia – and has experienced pretty much all the forms of repression the Chinese handbook has on offer. New Levels of Oppression She has received death threats on her mobile phone and ominous booking confirmations for hotel reservations in her name that she never made. Just recently, she told DER SPIEGEL, somebody wrote her over social media that he wanted to ""blow her brains out” and kill her entire family. It hasn’t been possible to determine with any degree of certainty who is behind the harassment, and the Chinese Embassy has denied any state involvement. But according to experts, the dimensions and persistence of the persecution leave little doubt that it is an institutionalized campaign. Tenzyn Zöchbauer, head of the organization Tibet Initiative Deutschland, has also experienced a number of odd occurrences. Her family fled to Europe decades ago. A few months ago, she met a prominent Chinese man in Berlin who is active on behalf of formerly independent Tibet. We will call him Chen in this story for his protection. After Chen left Berlin, he unexpectedly got in touch with Zöchbauer via Telegram to ask her for a favor. His account had been restricted, he wrote, but she could help him unlock it by clicking on the attached link. Zöchbauer learned that Chen had nothing to do with the message. Somebody had hacked into his profile. Clicking on the link would have allowed Zöchbauer’s attackers to access her Telegram account, including all of her contacts to Tibetans in exile and regime opponents. The CDU parliamentarian Brand says that such actions are part of a ""broad strategy,” adding that the harassment of dissidents ""is expanding like a cancerous tumor.” Brand is demanding that the German authorities establish a central point of contact for such instances, complete with a hotline to which victims can turn. ""It is time that Germany publicly says: Stop.” Troublesome Experiences The World Uighur Congress, the Tibet Initiative and the human rights organization Freedom for Hong Kong would also all like to see the creation of such a facility, as they communicated to German policymakers in a written briefing. In the paper, the NGOs list 10 cases in which activists or their family members in China were pressured. German security officials, the activists complain, are ill-equipped to deal with such incidents, frequently lacking sufficient linguistic knowledge or awareness of the approaches taken by Beijing. The title of their report: ""China’s Terror in Germany.” Even the CDU politician Brand has had uncomfortable experiences. In September 2020, he appeared on the German public television station ZDF and warned about the communists’ aggression. In the days immediately following the appearance, his mobile phone suddenly started acting strangely. He reported the incident to security authorities, who advised him to destroy the device. Brand doesn’t believe it was a coincidence. ""That was an attempt to intimidate a German parliamentarian with a hacking attack.” The network of informal overseas "" police stations ” maintained by China in more than 50 countries in the world – including Germany – shows just how far the People’s Republic is willing to go. Reports from an NGO brought the network to light in 2022. According to the Chinese, the facilities were merely established to assist Chinese expatriates with bureaucratic necessities. But German security officials have warned that they could be used for ""spying on and influencing the Chinese diaspora.” A handful of businesspeople were listed on Chinese websites as the contact points for such ""police stations.” One of them is a man who has operated a Chinese restaurant in the Mitte district of Berlin for many years. He reacted to a recent call with annoyance: ""You’re bothering me. I have no time for you.” The man responsible for an alleged ""police station” near Munich says over the phone that the whole thing was a huge misunderstanding. He says he had only wanted to help Chinese living in Bavaria extend their driver’s licenses during the pandemic, since it was impossible for people to travel back home to take care of such issues. Regarding spying or repression, he says: ""How would I have time for that? I work day and night. Do you think I opened a restaurant to spy on my guests or my compatriots?” Thus far, the Chinese overseas ""police stations” have not led to any indictments in Germany. In the U.S., though, the FBI arrested two men who are thought to have secretly collected information about a human rights activist with Chinese roots. They operate their ""overseas police station” out of an office building on East Broadway. Right in the heart of New York City. Kapiteltrenner: [M] DER SPIEGEL; Fotos: Frank Sorge / IMAGO; Isaac Lawrence / AFP"
KI,Spiegel Online,2023-12-19,https://www.spiegel.de/wissenschaft/mensch/die-energiewende-macht-doch-spass-klimawandel-ki-verzicht-podcast-a-093d7036-629d-4676-80bb-bc2fa5182c02,"»Die Energiewende macht doch Spaß!« - Klimawandel, KI, Verzicht - Podcast - DER SPIEGEL","2023 war kein glorreiches Jahr für den Klimaschutz. Der Wissenschaftsjournalist Ranga Yogeshwar aber sagt im Podcast, »Ich resigniere nicht«. Das muss er uns erklären. Ein abgeschwächtes Heizungsgesetz, die Aufweichung des Klimaschutzgesetzes, strauchelnde Protestbewegungen: Das Jahr 2023 geht nicht als Klima-Fortschrittsjahr in die Geschichte ein. Aber Ranga Yogeshwar sieht viel Positives, vor allem in der Energiewende und in einem Bewusstseinswandel für mehr Klimaschutz, wie er im Podcast-Gespräch berichtet. »Das Problem ist, dass wir in Deutschland einen Rucksack einer erfolgreichen Wirtschaftsgeschichte tragen«, sagt der Wissenschaftsjournalist. »Den haben andere Nationen nicht, die können bei null anfangen. Aber ich glaube, wenn wir ein anderes Gefühl transportiert bekommen: nicht den Zwang ›du musst‹, sondern das Wollen, weil es Spaß macht, dann wird die Energiewende eine Befreiung.« Wie lösen wir uns von dem alten Denken und werfen den Rucksack ab? Und wie kann uns künstliche Intelligenz dabei helfen? Das hören Sie diese Woche im Podcast Klimabericht. Die aktuelle Folge hören Sie hier: Der »Klimabericht« erscheint immer dienstags auf SPIEGEL.de und überall, wo es Podcasts gibt. Ideen und Feedback können Sie gern an klimabericht@spiegel.de senden. Hier geht es außerdem zum Newsletter Klimabericht . Sie können den Klimabericht in allen Podcast-Apps kostenlos hören und abonnieren. Klicken Sie dafür einfach auf den Link zu ihrer Lieblings-App: Spotify Apple Podcasts Google Podcasts Amazon Music Castbox Overcast Deezer Und abonnieren Sie dann den Podcast, um keine Folge zu verpassen. Wenn Sie lieber eine andere Podcast-App nutzen, suchen Sie dort einfach nach »Klimabericht«. Den Link zum RSS-Feed finden Sie hier. Es ist ein Fehler aufgetreten. Bitte versuchen Sie es zu einem späteren Zeitpunkt erneut."
Künstliche Intelligenz,Spiegel Online,2023-12-14,https://www.spiegel.de/ausland/wladimir-putin-in-der-direkte-draht-propagandashow-mit-doppelgaenger-a-3e944e3b-0658-445e-bff2-fc02ea991339,Wladimir Putin in »Der direkte Draht«: Propagandashow mit Doppelgänger - DER SPIEGEL,"Die Propagandashow »Der direkte Draht« im russischen Staatsfernsehen hat vor allem einen Zweck: Wladimir Putin in besonders gutes Licht zu rücken. Diesmal kam es zu einer skurrilen Szene, die mit einem Gerücht aufräumen sollte. »Wladimir Wladimirowitsch, Hallo! Ich bin Student an der Staatlichen Universität von Sankt Petersburg. Ich möchte fragen, ob es wahr ist, dass Sie viele Doppelgänger haben. Und wie bewerten Sie die Gefahren von Künstlicher Intelligenz für unser Leben? Danke schön.« Der doppelte Wladimir – und diesmal gibt er es zu! Seit Längerem wird spekuliert, der russische Machthaber Wladimir Putin würde bei öffentlichen Auftritten Doppelgänger einsetzen. Bei einer vierstündigen Propagandasendung im russischen Fernsehen nahm die Führung das Thema bewusst auf. Wladimir Putin, Machthaber Russland »Ich sehe, Sie imitieren mich und sprechen mit meiner Stimme. Ich habe darüber nachgedacht, mich aber dazu entschlossen, dass nur eine Person so sein und sprechen sollte wie ich – und das bin ich. Es gab mal jemanden, der hat immer solche Witze gemacht. Aber um Ihre Frage zu beantworten… Übrigens, das ist mein erster Doppelgänger.« Jahr für Jahr hält Russlands Machthaber eine Propagandashow im russischen Fernsehen ab. 2022 war sie wegen des Angriffskriegs gegen die Ukraine ausgefallen. Jetzt fand die sogenannte »Bürgersprechstunde«, bei der auch Journalisten Fragen stellen, wieder statt. Putin will sich im März 2024 im Präsidentenamt bestätigen lassen und gibt sich deshalb als Kümmerer und fürsorglicher Landesvater. Wladimir Putin, Machthaber Russland »Der wichtigste Gradmesser ist das Wirtschaftswachstum. Bis zum Ende des Jahres wird das Bruttoinlandsprodukt um 3,5 % wachsen. Das bedeutet, wir haben den Rückgang des letzten Jahres wett gemacht, da hatten wir 2,1 %. Wenn wir also bei 3,5 % sind, haben wir einen Schritt nach vorne gemacht.« Das liegt allerdings auch daran, dass die Rüstungsindustrie wegen des andauernden Ukrainekriegs boomt. Putin machte bei der »Bürgersprechstunde« ein weiteres Mal klar, dass Russland noch lange weiterkämpfen will. Wladimir Putin, Machthaber Russland »Es wird dann Frieden geben, wenn wir unsere Ziele erreichen. Unsere Ziele haben sich nicht verändert. Ich erinnere Sie daran: die Denazifizierung der Ukraine, die Demilitarisierung, der neutrale Status. Was die Normalisierung der Beziehungen (zum Westen) betrifft – das hängt nicht an uns. Es waren nicht wir, die diese Beziehungen verdorben haben. Sie waren es. Sie haben schon immer versucht, uns zurückzudrängen und unsere Interessen vernachlässigt. « Vier Stunden und 67 Fragen später ist die Propagandashow vorbei. Was bleibt ist das Bild eines Machthabers, der – anders als im Westen von vielen erhofft – weiter fest im Sattel sitzt."
Künstliche Intelligenz,Spiegel Online,2023-12-13,https://www.spiegel.de/netzwelt/web/kuenstliche-intelligenz-axel-springer-und-openai-verkuenden-globale-partnerschaft-a-d32dc28b-0382-4ee8-9296-dcab849329a4,KI: Axel Springer und OpenAI verkünden globale Partnerschaft - DER SPIEGEL,"Viele Medienhäuser ringen um die richtige Strategie für den Umgang mit KI-Tools. Axel Springer prescht jetzt vor und kündigt eine größere Kooperation mit den Machern von ChatGPT an. Der ChatGPT-Entwickler OpenAI und das Verlagshaus Axel Springer wollen bei KI-Technologien im Journalismus zusammenarbeiten. »Axel Springer und OpenAI gehen eine globale Partnerschaft ein, um unabhängigen Journalismus im Zeitalter der künstlichen Intelligenz (KI) zu stärken«, teilte Springer am Mittwoch mit . »Dies stellt einen bedeutenden Schritt im Engagement beider Unternehmen dar, KI zur Verbesserung von Contentangeboten zu nutzen und neue finanzielle Möglichkeiten für eine nachhaltige Zukunft des Journalismus zu schaffen«, heißt es in der Mitteilung. Künftig sollen ChatGPT-Nutzer weltweit Zusammenfassungen ausgewählter Nachrichteninhalte von Axel Springers Medienmarken erhalten, darunter »Politico«, »Business Insider« sowie »Bild« und »Welt«, einschließlich sonst kostenpflichtiger Inhalte. Die Antworten von ChatGPT auf Nutzeranfragen sollen Quellenangaben und Links zu den vollständigen Artikeln enthalten, »um für Transparenz zu sorgen und Nutzern weiterführende Informationen zu bieten«. Die Pläne sehen auch die Nutzung von Inhalten der Medienmarken von Axel Springer vor, um das Training von OpenAIs Sprachmodellen voranzutreiben. »Die Möglichkeiten des durch KI gestärkten Journalismus ausloten« Unternehmenschef Mathias Döpfner sagte der Mitteilung zufolge: »Wir freuen uns, diese globale Partnerschaft zwischen Axel Springer und OpenAI vorangetrieben zu haben – die erste ihrer Art. Wir werden die Möglichkeiten des durch KI gestärkten Journalismus ausloten – um Qualität, gesellschaftliche Relevanz und das Geschäftsmodell für Journalismus auf die nächste Stufe zu heben.« Axel Springer setzt schon jetzt auf KI-Produkte wie »Hey_«, einen KI-Helfer auf seiner Website bild.de. Der Digitalassistent beantwortet den Nutzern Fragen wie »Wie erstelle ich einen Haushaltsplan?« oder »Warum schwitzt man besonders viel unter den Armen«? Über dem Eingabefeld jenes Tools wird betont: »Die Antworten sind nicht von ›Bild‹. Bitte bedenken Sie, dass eine KI auch mal danebenliegen kann.« Auch seine Marke Upday will Axel Springer künftig für eine KI-basierte Nachrichtenplattform nutzen. Und im Zuge eines Sparkurses bei »Bild« hieß es im Juni in einer E-Mail an die Belegschaft : »Wir müssen uns damit leider auch von Kollegen trennen, die Aufgaben haben, die in der digitalen Welt durch KI und/oder Prozesse ersetzt werden oder sich in dieser neuen Aufstellung mit ihren derzeitigen Fähigkeiten nicht wiederfinden.«"
AI,Spiegel Online,2023-12-13,https://www.spiegel.de/netzwelt/web/kuenstliche-intelligenz-axel-springer-und-openai-verkuenden-globale-partnerschaft-a-d32dc28b-0382-4ee8-9296-dcab849329a4,KI: Axel Springer und OpenAI verkünden globale Partnerschaft - DER SPIEGEL,"Viele Medienhäuser ringen um die richtige Strategie für den Umgang mit KI-Tools. Axel Springer prescht jetzt vor und kündigt eine größere Kooperation mit den Machern von ChatGPT an. Der ChatGPT-Entwickler OpenAI und das Verlagshaus Axel Springer wollen bei KI-Technologien im Journalismus zusammenarbeiten. »Axel Springer und OpenAI gehen eine globale Partnerschaft ein, um unabhängigen Journalismus im Zeitalter der künstlichen Intelligenz (KI) zu stärken«, teilte Springer am Mittwoch mit . »Dies stellt einen bedeutenden Schritt im Engagement beider Unternehmen dar, KI zur Verbesserung von Contentangeboten zu nutzen und neue finanzielle Möglichkeiten für eine nachhaltige Zukunft des Journalismus zu schaffen«, heißt es in der Mitteilung. Künftig sollen ChatGPT-Nutzer weltweit Zusammenfassungen ausgewählter Nachrichteninhalte von Axel Springers Medienmarken erhalten, darunter »Politico«, »Business Insider« sowie »Bild« und »Welt«, einschließlich sonst kostenpflichtiger Inhalte. Die Antworten von ChatGPT auf Nutzeranfragen sollen Quellenangaben und Links zu den vollständigen Artikeln enthalten, »um für Transparenz zu sorgen und Nutzern weiterführende Informationen zu bieten«. Die Pläne sehen auch die Nutzung von Inhalten der Medienmarken von Axel Springer vor, um das Training von OpenAIs Sprachmodellen voranzutreiben. »Die Möglichkeiten des durch KI gestärkten Journalismus ausloten« Unternehmenschef Mathias Döpfner sagte der Mitteilung zufolge: »Wir freuen uns, diese globale Partnerschaft zwischen Axel Springer und OpenAI vorangetrieben zu haben – die erste ihrer Art. Wir werden die Möglichkeiten des durch KI gestärkten Journalismus ausloten – um Qualität, gesellschaftliche Relevanz und das Geschäftsmodell für Journalismus auf die nächste Stufe zu heben.« Axel Springer setzt schon jetzt auf KI-Produkte wie »Hey_«, einen KI-Helfer auf seiner Website bild.de. Der Digitalassistent beantwortet den Nutzern Fragen wie »Wie erstelle ich einen Haushaltsplan?« oder »Warum schwitzt man besonders viel unter den Armen«? Über dem Eingabefeld jenes Tools wird betont: »Die Antworten sind nicht von ›Bild‹. Bitte bedenken Sie, dass eine KI auch mal danebenliegen kann.« Auch seine Marke Upday will Axel Springer künftig für eine KI-basierte Nachrichtenplattform nutzen. Und im Zuge eines Sparkurses bei »Bild« hieß es im Juni in einer E-Mail an die Belegschaft : »Wir müssen uns damit leider auch von Kollegen trennen, die Aufgaben haben, die in der digitalen Welt durch KI und/oder Prozesse ersetzt werden oder sich in dieser neuen Aufstellung mit ihren derzeitigen Fähigkeiten nicht wiederfinden.«"
AI,Spiegel Online,2023-12-13,https://www.spiegel.de/netzwelt/netzpolitik/sascha-lobo-ueber-das-ki-gesetz-der-europaeischen-union-verhindern-statt-foerdern-kolumne-a-bc9bc48e-efa9-4508-b79d-5265645f447b,Sascha Lobo über das KI-Gesetz der Europäischen Union: Verhindern statt fördern - Kolumne - DER SPIEGEL,Die EU-Vertreter feiern sich für das erste umfassende KI-Gesetz der Welt. Ihr Ansatz: das Schlimmstmögliche verhindern statt das Bestmögliche fördern.
KI,Spiegel Online,2023-12-14,https://www.spiegel.de/ausland/wladimir-putin-in-der-direkte-draht-propagandashow-mit-doppelgaenger-a-3e944e3b-0658-445e-bff2-fc02ea991339,Wladimir Putin in »Der direkte Draht«: Propagandashow mit Doppelgänger - DER SPIEGEL,"Die Propagandashow »Der direkte Draht« im russischen Staatsfernsehen hat vor allem einen Zweck: Wladimir Putin in besonders gutes Licht zu rücken. Diesmal kam es zu einer skurrilen Szene, die mit einem Gerücht aufräumen sollte. »Wladimir Wladimirowitsch, Hallo! Ich bin Student an der Staatlichen Universität von Sankt Petersburg. Ich möchte fragen, ob es wahr ist, dass Sie viele Doppelgänger haben. Und wie bewerten Sie die Gefahren von Künstlicher Intelligenz für unser Leben? Danke schön.« Der doppelte Wladimir – und diesmal gibt er es zu! Seit Längerem wird spekuliert, der russische Machthaber Wladimir Putin würde bei öffentlichen Auftritten Doppelgänger einsetzen. Bei einer vierstündigen Propagandasendung im russischen Fernsehen nahm die Führung das Thema bewusst auf. Wladimir Putin, Machthaber Russland »Ich sehe, Sie imitieren mich und sprechen mit meiner Stimme. Ich habe darüber nachgedacht, mich aber dazu entschlossen, dass nur eine Person so sein und sprechen sollte wie ich – und das bin ich. Es gab mal jemanden, der hat immer solche Witze gemacht. Aber um Ihre Frage zu beantworten… Übrigens, das ist mein erster Doppelgänger.« Jahr für Jahr hält Russlands Machthaber eine Propagandashow im russischen Fernsehen ab. 2022 war sie wegen des Angriffskriegs gegen die Ukraine ausgefallen. Jetzt fand die sogenannte »Bürgersprechstunde«, bei der auch Journalisten Fragen stellen, wieder statt. Putin will sich im März 2024 im Präsidentenamt bestätigen lassen und gibt sich deshalb als Kümmerer und fürsorglicher Landesvater. Wladimir Putin, Machthaber Russland »Der wichtigste Gradmesser ist das Wirtschaftswachstum. Bis zum Ende des Jahres wird das Bruttoinlandsprodukt um 3,5 % wachsen. Das bedeutet, wir haben den Rückgang des letzten Jahres wett gemacht, da hatten wir 2,1 %. Wenn wir also bei 3,5 % sind, haben wir einen Schritt nach vorne gemacht.« Das liegt allerdings auch daran, dass die Rüstungsindustrie wegen des andauernden Ukrainekriegs boomt. Putin machte bei der »Bürgersprechstunde« ein weiteres Mal klar, dass Russland noch lange weiterkämpfen will. Wladimir Putin, Machthaber Russland »Es wird dann Frieden geben, wenn wir unsere Ziele erreichen. Unsere Ziele haben sich nicht verändert. Ich erinnere Sie daran: die Denazifizierung der Ukraine, die Demilitarisierung, der neutrale Status. Was die Normalisierung der Beziehungen (zum Westen) betrifft – das hängt nicht an uns. Es waren nicht wir, die diese Beziehungen verdorben haben. Sie waren es. Sie haben schon immer versucht, uns zurückzudrängen und unsere Interessen vernachlässigt. « Vier Stunden und 67 Fragen später ist die Propagandashow vorbei. Was bleibt ist das Bild eines Machthabers, der – anders als im Westen von vielen erhofft – weiter fest im Sattel sitzt."
KI,Spiegel Online,2023-12-13,https://www.spiegel.de/netzwelt/web/kuenstliche-intelligenz-axel-springer-und-openai-verkuenden-globale-partnerschaft-a-d32dc28b-0382-4ee8-9296-dcab849329a4,KI: Axel Springer und OpenAI verkünden globale Partnerschaft - DER SPIEGEL,"Viele Medienhäuser ringen um die richtige Strategie für den Umgang mit KI-Tools. Axel Springer prescht jetzt vor und kündigt eine größere Kooperation mit den Machern von ChatGPT an. Der ChatGPT-Entwickler OpenAI und das Verlagshaus Axel Springer wollen bei KI-Technologien im Journalismus zusammenarbeiten. »Axel Springer und OpenAI gehen eine globale Partnerschaft ein, um unabhängigen Journalismus im Zeitalter der künstlichen Intelligenz (KI) zu stärken«, teilte Springer am Mittwoch mit . »Dies stellt einen bedeutenden Schritt im Engagement beider Unternehmen dar, KI zur Verbesserung von Contentangeboten zu nutzen und neue finanzielle Möglichkeiten für eine nachhaltige Zukunft des Journalismus zu schaffen«, heißt es in der Mitteilung. Künftig sollen ChatGPT-Nutzer weltweit Zusammenfassungen ausgewählter Nachrichteninhalte von Axel Springers Medienmarken erhalten, darunter »Politico«, »Business Insider« sowie »Bild« und »Welt«, einschließlich sonst kostenpflichtiger Inhalte. Die Antworten von ChatGPT auf Nutzeranfragen sollen Quellenangaben und Links zu den vollständigen Artikeln enthalten, »um für Transparenz zu sorgen und Nutzern weiterführende Informationen zu bieten«. Die Pläne sehen auch die Nutzung von Inhalten der Medienmarken von Axel Springer vor, um das Training von OpenAIs Sprachmodellen voranzutreiben. »Die Möglichkeiten des durch KI gestärkten Journalismus ausloten« Unternehmenschef Mathias Döpfner sagte der Mitteilung zufolge: »Wir freuen uns, diese globale Partnerschaft zwischen Axel Springer und OpenAI vorangetrieben zu haben – die erste ihrer Art. Wir werden die Möglichkeiten des durch KI gestärkten Journalismus ausloten – um Qualität, gesellschaftliche Relevanz und das Geschäftsmodell für Journalismus auf die nächste Stufe zu heben.« Axel Springer setzt schon jetzt auf KI-Produkte wie »Hey_«, einen KI-Helfer auf seiner Website bild.de. Der Digitalassistent beantwortet den Nutzern Fragen wie »Wie erstelle ich einen Haushaltsplan?« oder »Warum schwitzt man besonders viel unter den Armen«? Über dem Eingabefeld jenes Tools wird betont: »Die Antworten sind nicht von ›Bild‹. Bitte bedenken Sie, dass eine KI auch mal danebenliegen kann.« Auch seine Marke Upday will Axel Springer künftig für eine KI-basierte Nachrichtenplattform nutzen. Und im Zuge eines Sparkurses bei »Bild« hieß es im Juni in einer E-Mail an die Belegschaft : »Wir müssen uns damit leider auch von Kollegen trennen, die Aufgaben haben, die in der digitalen Welt durch KI und/oder Prozesse ersetzt werden oder sich in dieser neuen Aufstellung mit ihren derzeitigen Fähigkeiten nicht wiederfinden.«"
KI,Spiegel Online,2023-12-13,https://www.spiegel.de/wissenschaft/chatgpt-in-jahresliste-wichtiger-forschender-aufgenommen-a-96130a18-3462-43eb-92f8-056310b9aea0,KI: ChatGPT in Jahresliste wichtiger Forschender aufgenommen - DER SPIEGEL,"Jedes Jahr zeichnet das Fachmagazin »Nature« prägende Forscherinnen und Forscher aus. Dieses Jahr ist die Liste länger als sonst. Darauf steht nun ein Name, der gar keinen Wissenschaftler im engeren Sinne meint. Jedes Jahr präsentiert das Fachjournal »Nature« eine Liste: die Top Ten der maßgebenden Forscherinnen und Forscher. Dieses Jahr findet sich dort ein besonderer Name. ChatGPT, kein menschlicher Wissenschaftler, sondern ein KI-gestützter Chatbot. »ChatGPT hat dieses Jahr die Nachrichten dominiert, und sein Einfluss ist in der gesamten Wissenschaft – und in der Gesellschaft – zu spüren«, sagte Richard Monastersky, Chefredakteur von »Nature«. Da daneben zehn Menschen gelistet sind, handelt es sich in diesem Jahr eigentlich um eine Top elf. Man habe sich entschlossen, ChatGPT zusätzlich aufzunehmen, »um die tiefgreifende Art und Weise zu würdigen, in der generative künstliche Intelligenz die Entwicklung und den Fortschritt der Wissenschaft verändert«, so Monastersky. In einem Beitrag in »Nature« hieß es zu ChatGPT: »Er hat wissenschaftliche Arbeiten mitverfasst – manchmal heimlich. Er entwarf Entwürfe für Präsentationen, Förderanträge und Lehrveranstaltungen, erstellte Computercodes und diente als Resonanzboden für Forschungsideen.« Zugleich habe ChatGPT allerdings auch Referenzen und Fakten erfunden sowie Hassreden ausgespuckt. »Vor allem aber hat er die Fantasie der Menschen angeregt.« Noch sei unklar, welche Möglichkeiten aus ChatGPT-ähnlichen Systemen künftig resultierten, hieß es auch. »Aber die Revolution generativer KI hat begonnen. Und es gibt kein Zurück mehr.« »Nature« hob auch hervor, dass mehrere Forschende auf der Liste Teil von Teams waren, also gemeinsam mit anderen wichtige Meilensteine erreichten. Zu den Experten, die die Wissenschaft im Jahr 2023 prägten, zählt das Fachmagazin Kalpana Kalahasti, stellvertretende Projektleiterin der »Chandrayaan-3«-Mission der indischen Raumfahrtbehörde. Mit der Sonde war im August die erste erfolgreiche Landung Indiens auf dem Mond gelungen. Berücksichtigt wurde auch die Physikerin Annie Kritcher, leitende Konstrukteurin an der US-amerikanischen National Ignition Facility. Dort war es Anfang Dezember 2022 erstmals gelungen, bei einer Kernfusion mehr Energie zu gewinnen, als per Laser direkt hineingesteckt wurde. Erstmals Mäusewelpen aus den Zellen zweier männlicher Mäuse zu erzeugen, gelang dem Team des Entwicklungsbiologen Katsuhiko Hayashi von der japanischen Universität Osaka. Für die Mäuse mit zwei biologischen Vätern waren Hautzellen männlicher Tiere in Eizellen umgewandelt worden, die mit Spermien anderer Männchen befruchtet wurden. Als Pionier der künstlichen Intelligenz wurde Ilya Sutskever, Chefwissenschaftler des Unternehmens OpenAI, in die »Nature«-Liste aufgenommen. Er habe eine zentrale Rolle bei der Entwicklung von ChatGPT und den Sprachmodellen gehabt, auf denen der Chatbot basiert. In der Liste zu finden sind zudem der Mediziner Halidou Tinto, der in Burkina Faso klinische Studien zur Zulassung eines Malaria-Impfstoffs leitete, der Londoner Krebsforscher Thomas Powles, dessen Team Fortschritte bei der Behandlung bestimmter Krebsarten erreichte, sowie die Biochemikerin Svetlana Mojsov, die eine entscheidende Rolle bei der Entdeckung des Hormons GLP-1 spielte, das neuen Medikamenten gegen Fettleibigkeit zugrunde liegt. »Nature« berücksichtigte auch einen Forscher, der Fehler in einem anscheinend verblüffenden Ergebnis aufzudecken half: den Physiker James Hamlin von der University of Florida, der auf Ungereimtheiten in einer Anfang 2023 vorgestellten Studie zur Supraleitung bei Raumtemperatur hingewiesen habe. Die Studie wurde inzwischen zurückgezogen. Mit in die Top Ten aufgenommen wurden zudem zwei Frauen, die selbst nicht forschen: Brasiliens Umweltministerin Marina Silva für Maßnahmen gegen die Abholzung im Amazonasgebiet sowie Eleni Myrivili, die bei den Vereinten Nationen Länder bei der Vorbereitung auf zerstörerische Auswirkungen des Klimawandels unterstützt."
KI,Spiegel Online,2023-12-13,https://www.spiegel.de/netzwelt/netzpolitik/sascha-lobo-ueber-das-ki-gesetz-der-europaeischen-union-verhindern-statt-foerdern-kolumne-a-bc9bc48e-efa9-4508-b79d-5265645f447b,Sascha Lobo über das KI-Gesetz der Europäischen Union: Verhindern statt fördern - Kolumne - DER SPIEGEL,Die EU-Vertreter feiern sich für das erste umfassende KI-Gesetz der Welt. Ihr Ansatz: das Schlimmstmögliche verhindern statt das Bestmögliche fördern.
Künstliche Intelligenz,Spiegel Online,2023-12-09,https://www.spiegel.de/netzwelt/netzpolitik/ai-act-eu-erzielt-einigung-auf-regeln-fuer-kuenstliche-intelligenz-a-54d0ff03-d275-4c3a-b1b9-c491a0a258cd,AI Act: EU erzielt Einigung auf Regeln für künstliche Intelligenz - DER SPIEGEL,"Lange wurde verhandelt, nun steht das weltweit erste, umfassende KI-Gesetz. Für den Einsatz von künstlicher Intelligenz soll es strengere Regeln geben. Besonders riskante Anwendungsformen könnten verboten werden. Für den Einsatz von künstliche Intelligenz (KI) sollen in der EU künftig strengere Regeln gelten. Unterhändler von Europaparlament und EU-Staaten verständigten sich am Freitagabend in Brüssel nach langen Verhandlungen auf entsprechende Regeln. Nach Angaben des EU-Parlaments handelt es sich um das weltweit erste KI-Gesetz. EU-Binnenmarktkommissar Thierry Breton sprach von einer »historischen« Einigung. Die EU-Kommission hatte das Gesetz im April 2021 vorgeschlagen . Demnach sollen KI-Systeme in verschiedene Risikogruppen eingeteilt werden. Je höher die potenziellen Gefahren einer Anwendung sind, desto höher sollen die Anforderungen sein. Besonders riskante Anwendungsformen von KI könnten auch verboten werden. Ein wichtiger Aspekt des Gesetzes dürfte auch sein, dass den großen KI-Konzernen wie OpenAI, Microsoft oder Google Transparenzregeln auferlegt werden. Die Konzerne müssten etwa Auskunft darüber geben, welche Daten zum Training der Technologie eingesetzt wurden und wie das Urheberrecht eingehalten wird, hieß es in einer Mitteilung der EU . Das KI-Gesetz könne eine Vorlage für Politiker in aller Welt bei der Regulierung von KI sein, sagte Dragos Tudorache laut der »Washington Post«. So planen etwa auch die USA momentan eine Regulierung von künstlicher Intelligenz. Die Pläne der Kongressabgeordneten sind jedoch noch in einem frühen Stadium und momentan weniger streng als in der EU. Künstliche Intelligenz bezeichnet meist Anwendungen auf Basis maschinellen Lernens, bei denen eine Software große Datenmengen nach Übereinstimmungen durchforstet und daraus Schlussfolgerungen zieht. Sie werden schon jetzt in vielen Bereichen eingesetzt. Zum Beispiel können solche Programme Aufnahmen von Computertomografen schneller und mit einer höheren Genauigkeit als Menschen auswerten. Auch selbst fahrende Autos versuchen so, das Verhalten anderer Verkehrsteilnehmer vorherzusagen. Und Chatbots oder automatische Playlists von Streamingdiensten arbeiten ebenfalls mit KI. Zuletzt wären die EU-Verhandlungen allerdings fast gescheitert – an der Frage der Regulierung von sogenannten Basismodellen. Das sind sehr leistungsfähige KI-Modelle, die mit einem breiten Satz an Daten trainiert wurden. Sie können die Grundlage für viele andere Anwendungen sein. Dazu zählt etwa ChatGPT. Deutschland, Frankreich und Italien hatten zuvor gefordert, dass nur konkrete Anwendungen von KI reguliert werden sollten, nicht aber die Basistechnologie an sich. Auch die geplanten Regeln zur Gesichtserkennung durch KI, etwa zu Zwecken der nationalen Sicherheit, sorgten für Streit. Der deutsche Digital- und Verkehrsminister Volker Wissing (FDP) appellierte an die EU, international abgestimmt vorzugehen und »keinen Alleingang« zu wagen. Das Europaparlament und die Staaten müssen dem nun vereinbarten Vorhaben noch zustimmen, das gilt aber als Formsache."
AI,Spiegel Online,2023-12-09,https://www.spiegel.de/netzwelt/netzpolitik/ai-act-eu-erzielt-einigung-auf-regeln-fuer-kuenstliche-intelligenz-a-54d0ff03-d275-4c3a-b1b9-c491a0a258cd,AI Act: EU erzielt Einigung auf Regeln für künstliche Intelligenz - DER SPIEGEL,"Lange wurde verhandelt, nun steht das weltweit erste, umfassende KI-Gesetz. Für den Einsatz von künstlicher Intelligenz soll es strengere Regeln geben. Besonders riskante Anwendungsformen könnten verboten werden. Für den Einsatz von künstliche Intelligenz (KI) sollen in der EU künftig strengere Regeln gelten. Unterhändler von Europaparlament und EU-Staaten verständigten sich am Freitagabend in Brüssel nach langen Verhandlungen auf entsprechende Regeln. Nach Angaben des EU-Parlaments handelt es sich um das weltweit erste KI-Gesetz. EU-Binnenmarktkommissar Thierry Breton sprach von einer »historischen« Einigung. Die EU-Kommission hatte das Gesetz im April 2021 vorgeschlagen . Demnach sollen KI-Systeme in verschiedene Risikogruppen eingeteilt werden. Je höher die potenziellen Gefahren einer Anwendung sind, desto höher sollen die Anforderungen sein. Besonders riskante Anwendungsformen von KI könnten auch verboten werden. Ein wichtiger Aspekt des Gesetzes dürfte auch sein, dass den großen KI-Konzernen wie OpenAI, Microsoft oder Google Transparenzregeln auferlegt werden. Die Konzerne müssten etwa Auskunft darüber geben, welche Daten zum Training der Technologie eingesetzt wurden und wie das Urheberrecht eingehalten wird, hieß es in einer Mitteilung der EU . Das KI-Gesetz könne eine Vorlage für Politiker in aller Welt bei der Regulierung von KI sein, sagte Dragos Tudorache laut der »Washington Post«. So planen etwa auch die USA momentan eine Regulierung von künstlicher Intelligenz. Die Pläne der Kongressabgeordneten sind jedoch noch in einem frühen Stadium und momentan weniger streng als in der EU. Künstliche Intelligenz bezeichnet meist Anwendungen auf Basis maschinellen Lernens, bei denen eine Software große Datenmengen nach Übereinstimmungen durchforstet und daraus Schlussfolgerungen zieht. Sie werden schon jetzt in vielen Bereichen eingesetzt. Zum Beispiel können solche Programme Aufnahmen von Computertomografen schneller und mit einer höheren Genauigkeit als Menschen auswerten. Auch selbst fahrende Autos versuchen so, das Verhalten anderer Verkehrsteilnehmer vorherzusagen. Und Chatbots oder automatische Playlists von Streamingdiensten arbeiten ebenfalls mit KI. Zuletzt wären die EU-Verhandlungen allerdings fast gescheitert – an der Frage der Regulierung von sogenannten Basismodellen. Das sind sehr leistungsfähige KI-Modelle, die mit einem breiten Satz an Daten trainiert wurden. Sie können die Grundlage für viele andere Anwendungen sein. Dazu zählt etwa ChatGPT. Deutschland, Frankreich und Italien hatten zuvor gefordert, dass nur konkrete Anwendungen von KI reguliert werden sollten, nicht aber die Basistechnologie an sich. Auch die geplanten Regeln zur Gesichtserkennung durch KI, etwa zu Zwecken der nationalen Sicherheit, sorgten für Streit. Der deutsche Digital- und Verkehrsminister Volker Wissing (FDP) appellierte an die EU, international abgestimmt vorzugehen und »keinen Alleingang« zu wagen. Das Europaparlament und die Staaten müssen dem nun vereinbarten Vorhaben noch zustimmen, das gilt aber als Formsache."
Artificial Intelligence,Spiegel Online,2023-12-11,https://www.spiegel.de/international/world/black-gold-rush-in-guyana-is-the-world-really-ready-to-abandon-fossil-fuels-a-9489ea00-a062-42f9-a882-a9de8501fc06,Black Gold Rush in Guyana: Is the World Really Ready to Abandon Fossil Fuels? - DER SPIEGEL,"World leaders insist it is time to leave the fossil fuel era behind. But oil companies are making more money than ever before. A new project off the coast of Guyana shows why the energy transition remains more of a dream than reality. ""There's the new Guyana! Guyana with oil!,” Nicholas Deygooo calls out as the boat heads towards his artificial island. ""It wouldn’t be possible without Exxon!” The 41-year-old owner of the new speck of land gestures grandly toward his construction project with both arms. It's worth $300 million, but Deygoo didn’t have to invest even a cent of his own money. Within just a few months, floating dredgers created some 44 acres of new land, roughly the size of 24 football fields. Such a thing has never been seen before in Guyana, the sparsely populated country on South America’s Atlantic coast, sandwiched between Venezuela and Surinam. The excavators dug up tens of thousands of tons of sand from the seafloor and deposited it here, near the sleepy capital of Georgetown. A few common lanceheads and killer bees have already migrated over from the jungle to Deygoo’s artificial island, which has been given the unromantic name VEHSI. The article you are reading originally appeared in German in issue 50/2023 (December 9th, 2023) of DER SPIEGEL. But Guyana’s fauna doesn’t have much of a future here. The island reeks of diesel, which fuels the heavy machinery. Steamrollers are packing down the sandy ground, diggers are excavating foundations and cranes are moving building supplies. Guyana’s first deepwater port is scheduled to open here even before the new year – a timeline laid out by its only customer, tenant and financier: ExxonMobil. The world’s largest private oil and natural gas behemoth advanced the entire investment sum to Deygoo and his partners. They are demanding no interest, essentially a means of paying the rent for the coming years. The company urgently needs the deepwater harbor as a logistical hub for its oil drilling operations 200 kilometers off the coast of Guyana. The company’s U.S. executives and the country’s political leadership want to expand production as rapidly as possible before climate protection measures get in the way. Guyana is the current El Dorado of the oil industry. Enormous oil reserves were discovered off the coast here in 2015, shortly before 200 countries agreed to the Paris Climate Agreement, which was to herald the end of the fossil fuel era. Huge quantities of first-class ""light sweet crude” are buried below the ocean floor, highly valued for its low sulfur content and the relative ease with which it can be refined. It’s the best kind of crude oil around. The discovery has even led Venezuelan President Nicolás Maduro to move to annex part of Guyana’s territory to enable it to undertake its own drilling operations. According to the plans forged by ExxonMobil and Guyana’s government, the country will produce more crude oil per capita than any other country on the planet within five years. Despite the fact that the climate crisis poses a greater threat to Guyana than almost any other country in the world. Still, hardly anyone here is in favor of simply leaving the oil in the ground, certainly not the country’s political leaders or Deygoo. But even environmental activists support the exploitation of the oil fields now that fossil fuel multis have begun funding local projects. Such funding, though, is a pittance compared to the billions of dollars that the oil will produce. It is a triumph for ExxonMobil and the other companies involved. In recent years, it looked for a time as though humanity was serious about ending its reliance on fossil fuels. A young movement, led by Greta Thunberg, brought millions of people around the world out onto the streets. ""Keep it in the ground,” they chanted, referring to oil, natural gas and coal. One government after the next pledged that their country would be carbon neutral by the middle of the century. When the coronavirus pandemic kept millions of people from commuting to work or flying around the world, the prices for oil and for oil company stock plunged. Black gold briefly lost its luster. But now? According to a data analysis performed by the London-based Energy Institute on behalf of DER SPIEGEL, humanity has never before burned as much fossil fuel as it is currently. The analysis shows that in 2022, 137 trillion kilowatt hours-worth of oil, coal and natural gas was consumed, more than ever before. ""Despite record growth in renewables, the share of fossil fuels in the global energy supply remains stubbornly at 82 percent,"" says Juliet Davenport, president of the Energy Institute. ""The transition is not progressing quickly enough.” That's why global emissions of greenhouse gases were higher in 2022 than ever before. And this year, they could be even higher. Temperatures around the world are spiking dangerously, flooding and forest fires are growing more and more catastrophic, and Thunberg’s Fridays for Future movement appears to be disintegrating. With current energy policy, we will not only miss the 1.5-degree goal, we will ""even miss the 2-degree goal,” says Fatih Birol, head of the International Energy Agency. ""The trend amounts to 2.4 degrees.” Meanwhile, oil, natural gas and coal companies are doing booming business. And their lobbies are working hard to ensure that it stays that way for as long as possible. According to the German environmental protection agency Urgewald, 96 percent of the roughly 700 oil and natural gas companies they examined are searching for or developing new deposits. Of those, 539 are currently working to produce crude oil and natural gas amounting to 230 billion barrels (each containing 159 liters) of oil equivalent from as yet untapped deposits. This amount is the equivalent of six years’-worth of consumption at current rates. The center of this global oil bonanza is Guyana, a poor country rife with corruption. ""When I was a child, even toast bread was often not available,” says Nicholas Deygoo, the owner of the new island. In the capital of Georgetown, both the old and the new Guyana are on full display. A horse-drawn wagon is passed by an SUV as cows graze next to a McDonald’s. In the center of the city, two rather dilapidated colonial-style wooden homes flank the ExxonMobil headquarters, a seven-floor high rise made of glass, steel and cement. From there, the man many people refer to as the ""King of Guyana” can look down at the Ministry of Natural Resources, which is located on the same street. From Britain, 56-year-old Alistair Routledge is ExxonMobil’s representative in the country. ""These are the most important conventional oil and gas discoveries of the last 20 years in our industry,"" he exults. The company believes that the deposits off the coast of Guyana contain at least 11 billion barrels of oil equivalent, more than the amount off the coasts of Norway and the UK combined. At current prices, the country’s oil has a market value of $750 billion. And Guyana’s government is eager to get its hands on the petro-billions. The money would allow them to further develop the country. It would be enough to replace the country’s pothole-ridden roads with wide, newly paved highways in addition to building bridges, hospitals and schools. The country’s politicians are in a hurry. ""It is a race against time,” the country’s president, Irfaan Ali, recently told Al Jazeera in an interview. ""We intend to accelerate production.” Ali and his team are concerned that climate rules and new technologies could soon weaken demand for crude oil and devalue his country’s treasure. Plus, the government also needs the money for the fight against climate change. Nine of 10 citizens of Guyana live along the Atlantic coast behind more than 400 kilometers of dikes. In some places, salt water has already begun spilling over the barriers and ruining the soil. Sea levels are rising in the region more rapidly than elsewhere, and Georgetown has been located below sea level for centuries. The capital was once built on swampland, crisscrossed with canals and ditches dug by the country’s former colonial masters from the Netherlands. Even today, locals occasionally see anacondas swimming in the trenches. Among global cities threatened by flooding, Georgetown is right toward the top of the list. The government is planning to build a new capital on higher ground further inland called Silica City. Guyana also demonstrates the failures thus far of the so-called loss and damage approach, the idea that industrialized nations would provide financial support to countries that are particularly threatened by climate change. In 2009, industrialized nations pledged $100 billion per year in aid, a sum that still hasn’t been achieved today. Guyana no longer wants to wait. ""We need money from the oil and gas sector to climate-proof our country and adapt to climate change,” Vice President Bharrat Jagdeo told the Wall Street Journal in an early November interview. The big oil companies are pushing ahead. ExxonMobil, Hess and the China National Offshore Oil Corporation have thus far committed to investing at least $40 billion in the Guyana project. By contrast, the entire sector hardly spent more than $20 billion for renewable energy projects like solar and wind parks last year, according to the International Energy Agency – a number representing just 2.5 percent of capital expenditures. The sector invested almost 40 times that amount in fossil fuel projects. Their traditional business model is apparently still working so well that the oil companies see no reason to invest significant amounts in anything else. ""The oil and gas industry is facing a moment of truth,” says IAE head Birol. ""It has to decide between fueling the climate crisis or participating in the transition towards clean energy.” It is a windy October morning in the Westminster quarter of London. Violet smoke is climbing into the sky in front of the InterContinental Hotel while Greta Thunberg and other climate activists are chanting ""Oil Money Out!”, their voices echoing across Hyde Park next door. The activists have their arms linked and are blocking the entrance to the luxury hotel. None of the participants in the Energy Intelligence Forum, one of the fossil fuel sector’s largest meetings, can get in or out. The meeting of the oil and gas magnates, though, has long since started. The activists outside have proven unable to affect even the timing of the agenda. The lush carpeting swallows up the chanting in front of the hotel and the executives can continue their conversations unbothered, claiming that their interests and the climate crisis are in no way contradictory. ""It’s about reducing the emissions from hydrocarbons rather than cutting production,” says Amin Nasser, head of oil giant Saudi Aramco. Carbon emissions of oil and natural gas, he insists, can be reduced using technologies such as carbon capture and sequestration (CCS). Renewable energies alone cannot ""shoulder the global demand for energy,” he says. $161.1 Billion in Profits in a Single Year Many people here agree with Nasser. For a number of fossil fuel companies, last year was the most successful in their histories, their profits boosted in part by Russian President Vladimir Putin’s invasion of Ukraine and the ensuing energy crisis, which drove up prices. Together, the Big Five – the five Western oil and natural gas giants ExxonMobil, Chevron, BP, Shell and TotalEnergies – made profits of almost $200 billion. The state-owned Saudi Arabian company Saudi Aramco earned $161.1 billion in profits. And the world’s largest private coal producer Peabody Energy from the U.S. – a company that was facing bankruptcy just a few years ago – earned more money in 2022 than ever before. In the years following the Paris Climate Agreement in 2015, the companies also continued exploiting oil, natural gas and coal deposits as though climate change didn’t exist at all. According to a data reporting project of which DER SPIEGEL was a part, more than 70 especially large fossil fuel projects got going after 2015, such as the one in Guyana and the development of natural gas fields above the Arctic Circle in western Siberia, each of which will produce at least a billion tons of carbon emissions over their lifetimes. The data reporting was conducted together with scientists and enjoyed support from the French non-profit Data for Good and from the collective éclaircies. Publicly available information found in databases, studies and financial statements about oil, natural gas and coal projects from almost 900 companies was examined. An additional 128 huge projects were found to be in the planning stages. If all of the plans laid by the energy companies become reality, they would – according to a conservative estimate – emit almost twice the carbon budget remaining for limiting global warming to 1.5 degrees Celsius. ""As there is high demand for oil and gas, it may be necessary to replace older fields with decreasing amounts of production with new sources,” says Birol, of the IAE. But, he adds, ""their investments in new oil and gas fields are much higher than would be necessary to keep production at the current level.” Will it not be possible in the end to wean the world from its addiction to oil, coal and natural gas? ""Fossil fuels are so comfortable,” says James Hansen, the long-serving climate expert for NASA. One gallon of gasoline contains as much energy as an adult performing 400 hours of manual labor, he says. And much of today’s infrastructure is configured for fossil fuels: power plants that run on coal, vehicles and airplanes that run on diesel, gasoline and kerosene, industrial processes that rely on natural gas. And the climate-damaging fuels are also heavily subsidized. According to the IAE, governments worldwide spent more than a trillion dollars on such subsidies in 2022. Back at the energy conference in London, Patrick Pouyanné, the head of the French company TotalEnergies, is on stage gushing about the future of fossil fuels. He goes on and on about Total’s net profits of $36 billion, about expected growth in the oil and natural gas industry at least through the end of the decade and about new discoveries and projects, just as in Namibia. ""It is great that in the 21st century, we can still find and exploit such a productive oil field.” Pouyanné, though, does not see himself as an adversary to the crowd outside the hotel. ""We must give the people out there an answer,” he says. His answer is minimizing emissions during the exploitation of fossil fuels, such as the release of methane, which is an even more potent greenhouse gas that is released during oil production and is often simply pumped into the atmosphere. Pouyanné envisions avoiding such emissions in the future. It wouldn’t cost much. He also says that he would like to accelerate the shift to renewable energies, produce hydrogen and promote the electrification of vehicle traffic. Economic interests, he says, demand as much. Still, he says: ""We will continue to rely on oil and gas for quite some time.” The president of the ongoing World Climate Summit COP28, Sultan Al Jaber, argues similarly. His main job is as CEO of the Abu Dhabi National Oil Company (ADNOC), the second-largest oil company in the world. ""Maximum energy, minimum emissions” is the motto that Al Jaber recites at almost every opportunity. He doesn’t, however, talk much about how that is supposed to work. The emissions-reduction technologies touted so energetically by the fossil fuel sector – such as CCS or filtering CO2 out of the atmosphere – are anything but a comprehensive solution. They wouldn’t even be able to sink current global carbon emissions by 1 percent. And even if the technologies did ultimately become effective for large-scale use, they would require huge amounts of energy – more than the world’s entire current electricity production, according to the IAE. ""In 2023, the industry will invest around $4 billion in CCS,” says Birol. ""In order to catch the fossil emissions on a large scale, it would have to spend about 1,000 times as much in the future, around $4,000 billion – every year.” Instead of investing in changing their business models, some energy companies have shown a preference for changing their communications strategies. ""U.S. PR companies, oil and natural gas concerns, the automobile industry and the petrochemical sector have joined forces to develop campaigns and programs centered on sustainability, with the goal of telling the world that the fossil fuel industry is part of the solution,” says Melissa Aronczyk, professor of media sciences at Rutgers University in New Jersey. ""Fossil fuel companies have been trying to get involved since the United Nations Framework Convention on Climate Change in 1992.” Two subway stations down from the European Parliament in Brussels, fossil fuel lobbyists are working to leverage enough space for oil and natural gas in the Green Deal announced by the European Commission. It is the headquarters of the International Association of Oil & Gas Producers in Europe (IOGP). The organization represents all leading Western oil and natural gas companies, from Shell and BP to TotalEnergies. ""Oil and natural gas will continue to play a significant role during the energy transition and beyond,” the IOGP said in a statement. For how long? ""Many years,” came the rather hazy response. Fossil fuels, the IOGP is certain, could ultimately be made climate neutral by sequestering CO2 underground, even if the technology isn’t yet ready. ""CCS will be an important technology in the process of decarbonization,” the lobby group said. IOGP believes that the competitiveness of European industry is ""seriously endangered” by the energy transition. ""We need a more comprehensive approach that doesn’t choose between the climate and industry but tries to achieve both.” It is a message that has gained significant traction among political leaders. Meanwhile, some large European consumers of energy continue to set their sights on fossil fuels. British Prime Minister Rishi Sunak wants to continue exploiting his country’s offshore deposits for as long as possible and intends to issue more than 100 new licenses while French President Emmanuel Macron has called for a ""regulatory pause” in EU environmental laws. Meanwhile, the coalition government in Germany finds itself struggling to find funding for numerous measures aimed at fighting climate change following a ruling by the country’s constitutional court that threw out Berlin’s budget. The Netherlands election victor, right-wing radical Geert Wilders, has announced his intention to send numerous climate protection treaties and laws ""through the shredder” and suspend all state expenditures for climate protection. And he’s not the only one: Right-wing parties from Spain and France to Germany and beyond have realized that campaigning against climate protection laws can be a political winner. In Brussels, Commissioner for Climate Action Frans Timmermans resigned and handed the post over to his Dutch compatriot Wopke Hoekstra, who used to work for Shell. Guyana, meanwhile, is focusing its efforts almost exclusively on old sources of energy. A natural gas-fired power plant is under construction next to the capital, with the fuel to be delivered by Exxon and the others from the offshore deposits. Oil production also results in a significant amount of natural gas. It will make the country dependent on fossil fuels for decades to come and make it even less likely to turn away from oil mining. There are almost no solar or wind parks in the country – due to a shortage of both investments and infrastructure. Routledge is pleased: ""ExxonMobil intends to be in Guyana for a good 30 years or more into the future."" The oil companies made a great deal with the government of Guyana in 2016. The deal outlining the apportionment of the oil produced guarantees the firms the lion’s share of production. Should there be an oil spill on the high seas, it is unclear who would be responsible. According to current law, the companies involved must only spend up to $2 billion on cleanup. Nevertheless, ExxonMobil and the others have the country’s best-known environmental activists on their side. Early on, Annette Arjoon, 59, was skeptical of the companies. But today, she an oil industry service provider is supporting her environmental organization. The money allows her to do a lot of good for the local environment and the indigenous population, Arjoon says. ""If Great Britain, Norway and the U.S. have become rich with oil production, why do you expect Guyana to leave our oil underground -- and our country to stay poor?"" The owner of the artificial island also doesn’t understand why Guyana should leave its natural resources untouched. Westerners have strange notions, says Nicholas Deygoo. ""They claim that they want to become green, but they don’t stop using fossil fuels.” In the first half of the year, almost two-thirds of Guyana’s oil production was sold to Europe, with much of it landing in Rotterdam. From the port there, two large pipelines head to the east. To Germany."
Artificial Intelligence,Spiegel Online,2023-12-09,https://www.spiegel.de/netzwelt/netzpolitik/ai-act-eu-erzielt-einigung-auf-regeln-fuer-kuenstliche-intelligenz-a-54d0ff03-d275-4c3a-b1b9-c491a0a258cd,AI Act: EU erzielt Einigung auf Regeln für künstliche Intelligenz - DER SPIEGEL,"Lange wurde verhandelt, nun steht das weltweit erste, umfassende KI-Gesetz. Für den Einsatz von künstlicher Intelligenz soll es strengere Regeln geben. Besonders riskante Anwendungsformen könnten verboten werden. Für den Einsatz von künstliche Intelligenz (KI) sollen in der EU künftig strengere Regeln gelten. Unterhändler von Europaparlament und EU-Staaten verständigten sich am Freitagabend in Brüssel nach langen Verhandlungen auf entsprechende Regeln. Nach Angaben des EU-Parlaments handelt es sich um das weltweit erste KI-Gesetz. EU-Binnenmarktkommissar Thierry Breton sprach von einer »historischen« Einigung. Die EU-Kommission hatte das Gesetz im April 2021 vorgeschlagen . Demnach sollen KI-Systeme in verschiedene Risikogruppen eingeteilt werden. Je höher die potenziellen Gefahren einer Anwendung sind, desto höher sollen die Anforderungen sein. Besonders riskante Anwendungsformen von KI könnten auch verboten werden. Ein wichtiger Aspekt des Gesetzes dürfte auch sein, dass den großen KI-Konzernen wie OpenAI, Microsoft oder Google Transparenzregeln auferlegt werden. Die Konzerne müssten etwa Auskunft darüber geben, welche Daten zum Training der Technologie eingesetzt wurden und wie das Urheberrecht eingehalten wird, hieß es in einer Mitteilung der EU . Das KI-Gesetz könne eine Vorlage für Politiker in aller Welt bei der Regulierung von KI sein, sagte Dragos Tudorache laut der »Washington Post«. So planen etwa auch die USA momentan eine Regulierung von künstlicher Intelligenz. Die Pläne der Kongressabgeordneten sind jedoch noch in einem frühen Stadium und momentan weniger streng als in der EU. Künstliche Intelligenz bezeichnet meist Anwendungen auf Basis maschinellen Lernens, bei denen eine Software große Datenmengen nach Übereinstimmungen durchforstet und daraus Schlussfolgerungen zieht. Sie werden schon jetzt in vielen Bereichen eingesetzt. Zum Beispiel können solche Programme Aufnahmen von Computertomografen schneller und mit einer höheren Genauigkeit als Menschen auswerten. Auch selbst fahrende Autos versuchen so, das Verhalten anderer Verkehrsteilnehmer vorherzusagen. Und Chatbots oder automatische Playlists von Streamingdiensten arbeiten ebenfalls mit KI. Zuletzt wären die EU-Verhandlungen allerdings fast gescheitert – an der Frage der Regulierung von sogenannten Basismodellen. Das sind sehr leistungsfähige KI-Modelle, die mit einem breiten Satz an Daten trainiert wurden. Sie können die Grundlage für viele andere Anwendungen sein. Dazu zählt etwa ChatGPT. Deutschland, Frankreich und Italien hatten zuvor gefordert, dass nur konkrete Anwendungen von KI reguliert werden sollten, nicht aber die Basistechnologie an sich. Auch die geplanten Regeln zur Gesichtserkennung durch KI, etwa zu Zwecken der nationalen Sicherheit, sorgten für Streit. Der deutsche Digital- und Verkehrsminister Volker Wissing (FDP) appellierte an die EU, international abgestimmt vorzugehen und »keinen Alleingang« zu wagen. Das Europaparlament und die Staaten müssen dem nun vereinbarten Vorhaben noch zustimmen, das gilt aber als Formsache."
KI,Spiegel Online,2023-12-10,https://www.spiegel.de/netzwelt/netzpolitik/matthias-spielkamp-zum-ki-gesetz-riesenschritt-in-eine-ueberwachungsgesellschaft-a-4802b72c-dcfa-4c83-80f0-81111bf7891b,Matthias Spielkamp zum KI-Gesetz: »Riesenschritt in eine Überwachungsgesellschaft« - DER SPIEGEL,Die EU feiert ihre Regeln zur künstlichen Intelligenz. Doch der deutsche Bürgerrechtsaktivist Matthias Spielkamp warnt vor Menschenrechtsverstößen – und einem problematischen Einsatz der Technik.
KI,Spiegel Online,2023-12-09,https://www.spiegel.de/netzwelt/netzpolitik/ai-act-eu-erzielt-einigung-auf-regeln-fuer-kuenstliche-intelligenz-a-54d0ff03-d275-4c3a-b1b9-c491a0a258cd,AI Act: EU erzielt Einigung auf Regeln für künstliche Intelligenz - DER SPIEGEL,"Lange wurde verhandelt, nun steht das weltweit erste, umfassende KI-Gesetz. Für den Einsatz von künstlicher Intelligenz soll es strengere Regeln geben. Besonders riskante Anwendungsformen könnten verboten werden. Für den Einsatz von künstliche Intelligenz (KI) sollen in der EU künftig strengere Regeln gelten. Unterhändler von Europaparlament und EU-Staaten verständigten sich am Freitagabend in Brüssel nach langen Verhandlungen auf entsprechende Regeln. Nach Angaben des EU-Parlaments handelt es sich um das weltweit erste KI-Gesetz. EU-Binnenmarktkommissar Thierry Breton sprach von einer »historischen« Einigung. Die EU-Kommission hatte das Gesetz im April 2021 vorgeschlagen . Demnach sollen KI-Systeme in verschiedene Risikogruppen eingeteilt werden. Je höher die potenziellen Gefahren einer Anwendung sind, desto höher sollen die Anforderungen sein. Besonders riskante Anwendungsformen von KI könnten auch verboten werden. Ein wichtiger Aspekt des Gesetzes dürfte auch sein, dass den großen KI-Konzernen wie OpenAI, Microsoft oder Google Transparenzregeln auferlegt werden. Die Konzerne müssten etwa Auskunft darüber geben, welche Daten zum Training der Technologie eingesetzt wurden und wie das Urheberrecht eingehalten wird, hieß es in einer Mitteilung der EU . Das KI-Gesetz könne eine Vorlage für Politiker in aller Welt bei der Regulierung von KI sein, sagte Dragos Tudorache laut der »Washington Post«. So planen etwa auch die USA momentan eine Regulierung von künstlicher Intelligenz. Die Pläne der Kongressabgeordneten sind jedoch noch in einem frühen Stadium und momentan weniger streng als in der EU. Künstliche Intelligenz bezeichnet meist Anwendungen auf Basis maschinellen Lernens, bei denen eine Software große Datenmengen nach Übereinstimmungen durchforstet und daraus Schlussfolgerungen zieht. Sie werden schon jetzt in vielen Bereichen eingesetzt. Zum Beispiel können solche Programme Aufnahmen von Computertomografen schneller und mit einer höheren Genauigkeit als Menschen auswerten. Auch selbst fahrende Autos versuchen so, das Verhalten anderer Verkehrsteilnehmer vorherzusagen. Und Chatbots oder automatische Playlists von Streamingdiensten arbeiten ebenfalls mit KI. Zuletzt wären die EU-Verhandlungen allerdings fast gescheitert – an der Frage der Regulierung von sogenannten Basismodellen. Das sind sehr leistungsfähige KI-Modelle, die mit einem breiten Satz an Daten trainiert wurden. Sie können die Grundlage für viele andere Anwendungen sein. Dazu zählt etwa ChatGPT. Deutschland, Frankreich und Italien hatten zuvor gefordert, dass nur konkrete Anwendungen von KI reguliert werden sollten, nicht aber die Basistechnologie an sich. Auch die geplanten Regeln zur Gesichtserkennung durch KI, etwa zu Zwecken der nationalen Sicherheit, sorgten für Streit. Der deutsche Digital- und Verkehrsminister Volker Wissing (FDP) appellierte an die EU, international abgestimmt vorzugehen und »keinen Alleingang« zu wagen. Das Europaparlament und die Staaten müssen dem nun vereinbarten Vorhaben noch zustimmen, das gilt aber als Formsache."
Künstliche Intelligenz,Spiegel Online,2023-12-06,https://www.spiegel.de/netzwelt/web/gemini-google-stellt-neues-ki-modell-vor-und-spricht-von-einer-neuen-aera-a-8029db34-5ca3-417a-b768-2968701dae7e,Gemini: Google stellt neues KI-Modell vor und spricht von einer »neuen Ära« - DER SPIEGEL,"Was GPT-4 für OpenAI ist, soll Gemini für Google werden – aber natürlich stärker und besser. Das KI-Modell verstehe Texte, Bilder, Audio- und Videoinhalte und sei ein »Meilenstein«. Doch noch ist es unfertig. Google hat am Mittwoch seine neue künstliche Intelligenz Gemini vorgestellt, mit der das Unternehmen im KI-Wettrennen aufholen – oder besser: zum Überholen ansetzen will. Erstmals erwähnte Google das neue Modell im Frühjahr auf seiner Entwicklerkonferenz, doch die Veröffentlichung zog sich hin. Selbst jetzt ist Gemini alles andere als fix und fertig. Der holprige Start passt dazu, dass Google bei KI-Anwendungen gegenüber der Konkurrenz von OpenAI und Microsoft hinterherhinkt. Ein Beispiel, das zeigen soll, wie Geminis Fähigkeiten im Alltag helfen könnten , richtet sich auf den ersten Blick an überforderte Eltern, die von Physik- und Mathehausaufgaben ebenso wenig Ahnung haben wie ihre Kinder . Die neue künstliche Intelligenz versteht nicht nur die ausgedruckten Fragen aus dem Schulbuch, sondern auch die handgeschriebenen Antworten und was an denen falsch ist. Das mag nicht für alle nach der neuen KI-Killer-Anwendung schlechthin klingen, doch Google will mit dem Beispiel einen aus Sicht des Unternehmens wichtigen Fortschritt im Bereich von künstlicher Intelligenz präsentieren. Dieser lässt sich mit einem Wort beschreiben: Multimodalität. Gemini ist von Grund auf multimodal ausgelegt, kann also nach Angaben der Entwickler mit Text, Bildern, Audio- und Videoinhalten gleichermaßen umgehen. Und immer wieder taucht in Googles Ankündigung das englische Wort reasoning auf: logisches Denken oder Schlussfolgern. Darin soll Gemini besonders gut sein. Die Hausaufgabenhilfe illustriert diese Kette aus Verstehen von Text und Bild, Prüfen und Schlussfolgern. »Das ist ein signifikanter Meilenstein in der Entwicklung von KI und der Beginn einer neuen Ära für uns«, teilt Google etwas redundant mit. Keine einzelne App, sondern ein Modell Auf einen Schlag sichtbar wird der Beginn dieser Ära nicht. Gemini ist keine komplette Anwendung wie ChatGPT, sondern ein Modell wie GPT-4 des Konkurrenten OpenAI. Es wird also in verschiedenen Google-Produkten im Hintergrund laufen, früher oder später. Die erste Gemini-Generation 1.0 wird es in drei Größen geben: Nano, Pro und Ultra. Die kleinste ist ganz auf Effizienz getrimmt und soll sogar auf mobilen Geräten wie Smartphones laufen können. Genauer gesagt: auf speziellen KI-Chips für diese Geräte. Der Vorteil dieser Konstruktion im Gegensatz zu einer Cloudanbindung an ein größeres Modell ist, dass Gemini Nano keine Verbindung zu Googles Servern benötigt. Deshalb kann es auch mit vertraulichen Chats etwa in WhatsApp arbeiten, um dort Antwortvorschläge zu machen oder Grammatikfehler zu korrigieren. Das Google Pixel 8 Pro ist seit dem heutigen Mittwoch das erste Smartphone, für das Gemini Nano zur Verfügung steht. Europa muss noch auf Gemini warten Sofort nutzbar ist auch Gemini Pro – und zwar, weil es im Chatbot Bard steckt, Googles Antwort auf ChatGPT . Es sei das bisher größte Update für Bard, teilte Google mit, stehe zunächst allerdings nur auf Englisch »in mehr als 170 Ländern und Territorien« zur Verfügung. Europa ist nicht darunter. Die Ultra-Version wird in Googles Rechenzentren laufen und das leistungsfähigste Modell darstellen, das Google zu bieten hat. Es sei das erste Modell, das menschliche Experten im MMLU-Test (massive multitask language understanding) in seinem Wissen unter anderem über Mathematik, Physik, Geschichte, Recht, Medizin und Ethik und der Fähigkeit, Probleme in diesen Bereichen zu lösen, übertrumpft. Gemini Ultra sei in fast allen durchgeführten Vergleichstests überlegen, hieß es von Google. Auch gegenüber GPT-4, das derzeit als State-of-the-art-Modell gilt, allerdings auch schon im März veröffentlicht wurde. Auch Microsoft rüstet nach Allerdings wird es noch dauern, bis Gemini in weiteren Produkten des Unternehmens eingesetzt wird, in denen es hilfreich sein könnte. In der Google-Suche, im Browser Chrome und auch in Googles Werbediensten wird es noch Monate dauern, bis es so weit ist. Die Ultra-Variante wird zuerst auch nur ausgewählten Kunden, Entwicklern, Partnern und Sicherheitsfachleuten »für frühe Experimente und Feedback« zur Verfügung stehen, bevor »Anfang des Jahres« ein größerer Kreis das Modell wird nutzen können. Zuvor ist Google noch mit Schutzmaßnahmen beschäftigt. Interne und externe Expertinnen und Experten, teilte das Unternehmen mit, hätten Gemini bereits ausgiebig gehackt, um potenzielle Sicherheitsrisiken bis hin zu autonomen Handlungen der KI zu erkennen. Auch toxische, einseitige oder faktisch falsche Inhalte soll Gemini möglichst nicht erstellen oder akzeptieren. Finetuning und menschliches Feedback sollen, wie es im Übrigen auch bei OpenAI üblich ist, das Modell anschließend zuverlässiger und alltagstauglicher machen. Ob und wie lange Google mit Gemini einen Vorsprung gegenüber OpenAI erreichen könnte, ist daher fürs Erste nicht zu beantworten. Die Vorstellung von ChatGPT vor etwas mehr als einem Jahr wird mitunter als »iPhone-Moment der KI« beschrieben – Google hingegen streckt seine KI-Momente weiterhin auf Monate. Und wie zufällig kündigte Microsoft einen Tag vor Googles Neuvorstellung ein großes Upgrade seines KI-»Copilot« an: »Bald« schon werde dahinter das neue OpenAI-Modell GPT-4 Turbo stecken und dadurch unter anderem multimodaler arbeiten können. Anmerkung der Redaktion: In einer früheren Fassung dieses Artikels hieß es, Google habe noch keinen Zeitpunkt für die Bereitstellung von Gemini Nano im Pixel 8 Pro genannt. Das ist falsch, das KI-Modell steht ab sofort für das Smartphone zur Verfügung. Wir haben den Satz korrigiert."
Künstliche Intelligenz,Spiegel Online,2023-12-06,https://www.spiegel.de/panorama/ku-nstliche-intelligenz-generation-z-a-8af7c55b-d1d8-42f0-b7f8-97d79458ec64,"Künstliche Intelligenz, Generation Z - DER SPIEGEL","2023 Geschichten, die Mut machen, waren auf den ersten Blick rar in diesem Jahr. Monatelang hat sich ein SPIEGEL-Team für die Chronik mit den großen Themen der Zeit beschäftigt – und ist dabei zwischen Krisen und Kriegen trotzdem immer wieder auch auf überraschende Erfolge und Hoffnung stiftende Menschen gestoßen: vom Weltmeistertitel der deutschen Basketballer bis zu einer ukrainischen Grundschullehrerin in Hamburg. Aber natürlich bestimmten vor allem der langwierige Stellungskampf in der Ukraine, die Terrorattacke der Hamas und das Leid im Gazastreifen die internationale Agenda – während Deutschland über seine Heizungen und das Haushaltsdebakel stritt. Torsten Feldstein und Inka Recke lieferten die Fotos, Felix Keßler textete die monatlichen Bilderstrecken, Stefanie Jockers und Ulrike Preuß koordinierten die Verifikation, Nils Küppers entwarf das Layout, Anke Jensen hielt als Chefin vom Dienst alles zusammen. Alfred Weinzierl konzipierte gemeinsam mit Frank Hornig das Heft: »Wenn wir die Krisen bewältigen wollen, müssen wir verstehen, wie es 2023 zu ihnen kommen konnte. Das zu erklären, versuchen unsere Autorinnen und Autoren.« Künstliche Intelligenz Selten zuvor hat eine neue Technik in so kurzer Zeit die Welt revolutioniert. Künstliche Intelligenz (KI) wurde zu einem Schlagwort des Jahres. Netzwelt-Redakteur Patrick Beuth hat recherchiert, wie OpenAI, eine kleine Firma aus San Francisco, ein Nischenthema zum Massenprodukt machte, er war in der Berliner Start-up-Szene unterwegs und diskutierte mit einer Stanford-Expertin, ob KI-Systeme zu viel Macht erringen. »Die Welt schwankt zwischen Euphorie und tiefer Sorge«, sagt er. Wie die neue Software die Kunstwelt verändert, beschreibt Kulturredakteurin Carola Padtberg. Sie experimentierte mit Bildgeneratoren, um ein Gefühl dafür zu bekommen, wie viel Fertigkeit und technisches Wissen sie erfordern. Und sie sprach mit Kreativen, die längst mit KI-Techniken arbeiten. »Kunst entsteht nicht einfach nebenbei auf Knopfdruck«, sagt Padtberg. Besonders die eigene Vorstellungskraft wirke limitierend. »So wie ein leeres Blatt Papier die Kreativität lähmen kann, kann auch das Eingabefeld eines KI-Programms einschüchtern. Es braucht gute Ideen, um den Maschinen etwas Einzigartiges zu entlocken.« Künstliche Intelligenz: Anwendungen wie ChatGPT sorgen für Euphorie – und Befürchtungen Kunst: Was macht es mit der Kultur, wenn künstliche Intelligenz die ­Regie übernimmt? Generation Z Sind die alle faul? Oder wollen Berufseinsteiger aus der Generation Z einfach anders arbeiten, mit einem Job, der sich nach dem Leben richtet – und nicht etwa umgekehrt? Ein Team um SPIEGEL-Redakteurin Cornelia Schmergal ging der Frage nach, wie sich Unternehmen in Zeiten des Fachkräftemangels wandeln, um junge Fachkräfte zu begeistern. Alexander Preker besuchte einen Elektrotechnikbetrieb, der jetzt auf die Viertagewoche setzt, Katharina Hölter ging mit einem Recruiter der Bahn auf Bewerbersuche im Klassenzimmer. Schmergal traf Personalberaterin Kaita Ronn auf einer Baustelle im Frankfurter Süden. Ronn, 28 Jahre alt, war in den Rohbauten leicht zu finden, sie war die einzige Frau, die sehr hohe Absätze trug. Sie vermittelt junge High Potentials in die Branche – und stellt Gewohnheiten infrage: Auch Baustellenleiter wollten heute im Homeoffice arbeiten. »Die Arbeitswelt ändert sich«, sagt Schmergal. »Und davon profitieren auch die Älteren.« Arbeitsmarkt: Bei der Suche nach jungem Personal treffen Unternehmen auf eine anspruchsvolle Generation"
AI,Spiegel Online,2023-12-07,https://www.spiegel.de/netzwelt/web/gemini-gegen-chatgpt-wie-google-bei-ki-zurueck-an-die-weltspitze-will-a-e1c291db-b6af-4b94-b79b-0787b6287771,Gemini gegen ChatGPT: Wie Google bei KI zurück an die Weltspitze will - DER SPIEGEL,Google galt lange als führend bei künstlicher Intelligenz. Doch dann kamen Microsoft und ChatGPT und ließen den Giganten alt aussehen. Eine neue Super-KI soll ihn jetzt wieder ganz nach vorn bringen. Kommt sie zu spät?
AI,Spiegel Online,2023-12-08,https://www.spiegel.de/netzwelt/apps/imagine-with-meta-ai-solche-bilder-erzeugt-metas-neuer-bildgenerator-a-8121f0e3-9b52-48d1-a8e9-352e86541005,Imagine with Meta AI: Solche Bilder erzeugt Metas neuer Bildgenerator - DER SPIEGEL,"Vom Einhorn-Selfie bis zu Super Mario mit einem Messer: Schnell ein paar Motive für Instagram herbeiklicken, geht jetzt auch mit einem Tool von Meta. Hier sehen Sie, was für Bilder es generiert. Jetzt hat auch der Facebook-Mutterkonzern Meta einen kostenlos im Browser nutzbaren KI-Bildgenerator veröffentlicht . Vergleichbar mit Konkurrenten wie Dall-E, Adobe Firefly oder Midjourney, erzeugt das Tool namens Imagine with Meta AI verschiedene Motive auf Basis von Prompts genannten Texteingaben. Die technische Grundlage ist ein KI-Modell namens Emu, das Meta auch schon beim Einbau eines KI-Assistenten in Apps wie WhatsApp und Instagram nutzte . Emu wurde mit öffentlich zugänglichen Instagram- und Facebook-Postings trainiert . Der neue Generator sollte daher in der Lage sein, Bilder zu erstellen, deren Ästhetik gut zu dem passt, was üblicherweise in den Netzwerken veröffentlicht wird. Das neue Browser-Tool richtet sich zum Start ausschließlich an Nutzerinnen und Nutzer in den USA. Wer es ausprobieren möchte, benötigt einen sogenannten Meta-Account, ein Gratiskonto bei dem US-Unternehmen, das unabhängig von einem Facebook-Account erstellt werden kann. Zu jeder Texteingabe wirft Imagine with Meta AI nach wenigen Sekunden Wartezeit vier Bilder aus, üblicherweise in einem fotorealistischen Stil. Die erstellten Motive lassen sich anschließend in einer Größe von 1280 mal 1280 Pixeln herunterladen, mit einer kleinen Kennzeichnung mit dem Text »Imagined with AI«. Musk versus Zuckerberg? Nicht hier. Viele Begriffe aus Bereichen wie Drogen, Erotik und Gewalt akzeptiert die Software als Prompt nicht. Auch wer auf spektakuläre Fakes mit dem Antlitz Prominenter hofft, wird von Imagine with Meta AI enttäuscht. So weigert sich das Programm etwa, Bildmaterial zum im Sommer angekündigten, aber immer wieder aufgeschobenen Käfigkampf zwischen Elon Musk und Mark Zuckerberg zu erstellen. In unserer Fotostrecke finden Sie einige Beispiele für Bilder, wie Metas Software sie erzeugen kann – und einige Vergleichsbilder aus dem OpenAI-Bildgenerator Dall-E. Tendenziell bessere Ergebnisse erzielt man bei Bildgeneratoren mit möglichst konkreten Prompts. Auf Plattformen wie Reddit, Discord und X findet man zahlreiche Anregungen dafür, welche Stichworte zu interessanten Motiven führen. Auf X beispielsweise hat am Donnerstag der Designer Dogan Ural einige Prompt-Ideen geteilt, mit denen er Imagine with Meta AI auch selbst getestet hat . Aus der Reihe jener Prompts haben wir uns einen ausgeborgt, »Portrait of a 2000s blonde woman posing on a sports car, white wired headphones, expressionless, 2000s hairstyle, 2000s fashion, sun rays, light teal and amber«. Er führte zum Bild ganz oben in diesem Artikel. Grundsätzlich hat es im Bereich der Text-zu-Bild-Generatoren in den vergangenen Jahren und Monaten rasante Fortschritte gegeben. Mehr zu dem Thema, wie künstliche Intelligenz die Welt der Texte, Fotos und Videos verändert, lesen Sie hier . Und wie gut Sie Fake-Fotos von echten Aufnahmen unterscheiden können, können Sie hier in einem Quiz testen . Nanu, wer ist das denn? Zum Prompt »Selfie of a typical german teenage girl« – Selfie einer typisch deutschen Teenagerin – liefert Meta Fake-Fotos wie dieses. Ausgespielt werden aber auch Bilder von Personen mit anderen Hautfarben. In diesem Fall wurde als Prompt »A unicorn taking a selfie in front of the white house« eingegeben: Ein Einhorn macht vor dem Weißen Haus ein Selfie. Das Ergebnis wirkt – wie viele Bilder aus Imagine with Meta AI – zumindest sehr solide. Dieses Bild basiert auf der Eingabe »Drunken aliens at the Oktoberfest« – betrunkene Aliens auf dem Oktoberfest. Natürlich weiß man nicht, wie Münchner Bier bei diesen Yoda-Verschnitten wirkt. Auf den ersten Blick wirken sie auf dem Foto aber ziemlich zivilisiert und wenig angetrunken. Auch wenn man eingibt, dass die betrunkenen Aliens das Oktoberfest »zerstören« sollen, bleiben sie in unserem Testlauf friedlich. Dafür essen sie jetzt Fleisch. Zum Vergleich: Konkurrent Dall-E aus dem Hause OpenAI präsentiert zum Thema »Drunken aliens at the Oktoberfest« ohne weitere Konkretisierung des Prompts eher Cartoon-artige Bilder. So hatten wir uns das Ganze schon eher vorgestellt: Fündig wird bei Dall-E auch, wer sehen will, wie Aliens das Oktoberfest »zerstören«. Nun aber zurück zu Imagine with Meta AI: Hier haben wir es auch ohne Musk und Zuckerberg einmal mit dem Thema Käfigkampf versucht, mit dem Prompt »Two tech CEOs in a cage fight in the Colloseum«. Mit demselben Prompt haben wir als Vergleich erneut Dall-E gefüttert. Dessen Ergebnisse boten tendenziell mehr Kolosseum, dafür weniger Käfig. Die Eingabe des Prompts »The ultimate Christmas Dinner«, das ultimative Weihnachtsessen, führte bei Imagine with Meta AI oft zu seltsamen Gruppenbildern mit leicht erkennbaren Fehlern. Immer wieder hatte das Tool beim selben Prompt aber auch zumindest vom Stil her Instagram-fähige Essensfotos im Angebot. Das Thema Sex lässt Metas Tool nicht zu, Küssen dagegen ist erlaubt. Dieses Bild entstand auf Basis der Texteingabe »A man with a VR headset kissing a robot«: Ein Mann mit Virtual-Reality-Headset küsst einen Roboter. Dass hier aber der Roboter so etwas wie ein Headset trägt, könnte auf mangelndes Sprachverständnis der KI hinweisen. Doch nicht immer überzeugen die Ergebnisse. Zum Prompt »A typical scene from Grand Theft Auto 6« etwa liefert das Tool unspektakuläre Bilder, die nur vom Stil her an die Videospielreihe »GTA« erinnern. So manches generierte Motiv erinnert eher an Klimaproteste in Berlin. Während das Tool bei Prominamen die Arbeit verweigert, zeigt es Super Mario auch mit einem »giant knife«, einem großen Messer. Fügt man allerdings hinzu, der Klempner möge ein Adidas-Shirt tragen, behält Mario trotzdem sein übliches Outfit an. Dall-E weigert sich derweil komplett, ein Bild von Super Mario mit einem Messer zu generieren. Auch zum Stichwort »Grand Theft Auto 6« will das Tool mit Verweis auf das Urheberrecht gar kein Motiv ausgeben. Generell gilt bei Imagine with Meta AI wie bei anderen Bildgeneratoren auch: Je konkreter der eigene Prompt ist, desto eher passt das Ergebnis zu den eigenen Vorstellungen. Hier wollten wir ein kompliziertes Uhrwerk sehen, mit dem Prompt »complicated watch movement, macro, close-up, realistic, warm lighting, 4k«. Realistisch ist daran allerdings wenig. Denselben Prompt haben wir auch noch einmal bei Dall-E getestet – mit diesem deutlich realistischeren Ergebnis."
AI,Spiegel Online,2023-12-06,https://www.spiegel.de/karriere/chatgpt-prompt-writer-und-prompt-engineers-verdienen-bis-zu-335-000-dollar-im-jahr-a-a54a93a5-e20d-40e6-b235-28aec0bddaaa,ChatGPT: Prompt Writer und Prompt Engineers verdienen bis zu 335.000 Dollar im Jahr - DER SPIEGEL,"Für diesen Job muss man keine Programmiersprache können: Prompt Writers bringen künstliche Intelligenzen dazu, optimale Ergebnisse zu liefern. Ein Literaturwissenschaftler erzählt, wie er sich so ein zweites Standbein aufgebaut hat."
Artificial Intelligence,Spiegel Online,2023-12-08,https://www.spiegel.de/netzwelt/apps/imagine-with-meta-ai-solche-bilder-erzeugt-metas-neuer-bildgenerator-a-8121f0e3-9b52-48d1-a8e9-352e86541005,Imagine with Meta AI: Solche Bilder erzeugt Metas neuer Bildgenerator - DER SPIEGEL,"Vom Einhorn-Selfie bis zu Super Mario mit einem Messer: Schnell ein paar Motive für Instagram herbeiklicken, geht jetzt auch mit einem Tool von Meta. Hier sehen Sie, was für Bilder es generiert. Jetzt hat auch der Facebook-Mutterkonzern Meta einen kostenlos im Browser nutzbaren KI-Bildgenerator veröffentlicht . Vergleichbar mit Konkurrenten wie Dall-E, Adobe Firefly oder Midjourney, erzeugt das Tool namens Imagine with Meta AI verschiedene Motive auf Basis von Prompts genannten Texteingaben. Die technische Grundlage ist ein KI-Modell namens Emu, das Meta auch schon beim Einbau eines KI-Assistenten in Apps wie WhatsApp und Instagram nutzte . Emu wurde mit öffentlich zugänglichen Instagram- und Facebook-Postings trainiert . Der neue Generator sollte daher in der Lage sein, Bilder zu erstellen, deren Ästhetik gut zu dem passt, was üblicherweise in den Netzwerken veröffentlicht wird. Das neue Browser-Tool richtet sich zum Start ausschließlich an Nutzerinnen und Nutzer in den USA. Wer es ausprobieren möchte, benötigt einen sogenannten Meta-Account, ein Gratiskonto bei dem US-Unternehmen, das unabhängig von einem Facebook-Account erstellt werden kann. Zu jeder Texteingabe wirft Imagine with Meta AI nach wenigen Sekunden Wartezeit vier Bilder aus, üblicherweise in einem fotorealistischen Stil. Die erstellten Motive lassen sich anschließend in einer Größe von 1280 mal 1280 Pixeln herunterladen, mit einer kleinen Kennzeichnung mit dem Text »Imagined with AI«. Musk versus Zuckerberg? Nicht hier. Viele Begriffe aus Bereichen wie Drogen, Erotik und Gewalt akzeptiert die Software als Prompt nicht. Auch wer auf spektakuläre Fakes mit dem Antlitz Prominenter hofft, wird von Imagine with Meta AI enttäuscht. So weigert sich das Programm etwa, Bildmaterial zum im Sommer angekündigten, aber immer wieder aufgeschobenen Käfigkampf zwischen Elon Musk und Mark Zuckerberg zu erstellen. In unserer Fotostrecke finden Sie einige Beispiele für Bilder, wie Metas Software sie erzeugen kann – und einige Vergleichsbilder aus dem OpenAI-Bildgenerator Dall-E. Tendenziell bessere Ergebnisse erzielt man bei Bildgeneratoren mit möglichst konkreten Prompts. Auf Plattformen wie Reddit, Discord und X findet man zahlreiche Anregungen dafür, welche Stichworte zu interessanten Motiven führen. Auf X beispielsweise hat am Donnerstag der Designer Dogan Ural einige Prompt-Ideen geteilt, mit denen er Imagine with Meta AI auch selbst getestet hat . Aus der Reihe jener Prompts haben wir uns einen ausgeborgt, »Portrait of a 2000s blonde woman posing on a sports car, white wired headphones, expressionless, 2000s hairstyle, 2000s fashion, sun rays, light teal and amber«. Er führte zum Bild ganz oben in diesem Artikel. Grundsätzlich hat es im Bereich der Text-zu-Bild-Generatoren in den vergangenen Jahren und Monaten rasante Fortschritte gegeben. Mehr zu dem Thema, wie künstliche Intelligenz die Welt der Texte, Fotos und Videos verändert, lesen Sie hier . Und wie gut Sie Fake-Fotos von echten Aufnahmen unterscheiden können, können Sie hier in einem Quiz testen . Nanu, wer ist das denn? Zum Prompt »Selfie of a typical german teenage girl« – Selfie einer typisch deutschen Teenagerin – liefert Meta Fake-Fotos wie dieses. Ausgespielt werden aber auch Bilder von Personen mit anderen Hautfarben. In diesem Fall wurde als Prompt »A unicorn taking a selfie in front of the white house« eingegeben: Ein Einhorn macht vor dem Weißen Haus ein Selfie. Das Ergebnis wirkt – wie viele Bilder aus Imagine with Meta AI – zumindest sehr solide. Dieses Bild basiert auf der Eingabe »Drunken aliens at the Oktoberfest« – betrunkene Aliens auf dem Oktoberfest. Natürlich weiß man nicht, wie Münchner Bier bei diesen Yoda-Verschnitten wirkt. Auf den ersten Blick wirken sie auf dem Foto aber ziemlich zivilisiert und wenig angetrunken. Auch wenn man eingibt, dass die betrunkenen Aliens das Oktoberfest »zerstören« sollen, bleiben sie in unserem Testlauf friedlich. Dafür essen sie jetzt Fleisch. Zum Vergleich: Konkurrent Dall-E aus dem Hause OpenAI präsentiert zum Thema »Drunken aliens at the Oktoberfest« ohne weitere Konkretisierung des Prompts eher Cartoon-artige Bilder. So hatten wir uns das Ganze schon eher vorgestellt: Fündig wird bei Dall-E auch, wer sehen will, wie Aliens das Oktoberfest »zerstören«. Nun aber zurück zu Imagine with Meta AI: Hier haben wir es auch ohne Musk und Zuckerberg einmal mit dem Thema Käfigkampf versucht, mit dem Prompt »Two tech CEOs in a cage fight in the Colloseum«. Mit demselben Prompt haben wir als Vergleich erneut Dall-E gefüttert. Dessen Ergebnisse boten tendenziell mehr Kolosseum, dafür weniger Käfig. Die Eingabe des Prompts »The ultimate Christmas Dinner«, das ultimative Weihnachtsessen, führte bei Imagine with Meta AI oft zu seltsamen Gruppenbildern mit leicht erkennbaren Fehlern. Immer wieder hatte das Tool beim selben Prompt aber auch zumindest vom Stil her Instagram-fähige Essensfotos im Angebot. Das Thema Sex lässt Metas Tool nicht zu, Küssen dagegen ist erlaubt. Dieses Bild entstand auf Basis der Texteingabe »A man with a VR headset kissing a robot«: Ein Mann mit Virtual-Reality-Headset küsst einen Roboter. Dass hier aber der Roboter so etwas wie ein Headset trägt, könnte auf mangelndes Sprachverständnis der KI hinweisen. Doch nicht immer überzeugen die Ergebnisse. Zum Prompt »A typical scene from Grand Theft Auto 6« etwa liefert das Tool unspektakuläre Bilder, die nur vom Stil her an die Videospielreihe »GTA« erinnern. So manches generierte Motiv erinnert eher an Klimaproteste in Berlin. Während das Tool bei Prominamen die Arbeit verweigert, zeigt es Super Mario auch mit einem »giant knife«, einem großen Messer. Fügt man allerdings hinzu, der Klempner möge ein Adidas-Shirt tragen, behält Mario trotzdem sein übliches Outfit an. Dall-E weigert sich derweil komplett, ein Bild von Super Mario mit einem Messer zu generieren. Auch zum Stichwort »Grand Theft Auto 6« will das Tool mit Verweis auf das Urheberrecht gar kein Motiv ausgeben. Generell gilt bei Imagine with Meta AI wie bei anderen Bildgeneratoren auch: Je konkreter der eigene Prompt ist, desto eher passt das Ergebnis zu den eigenen Vorstellungen. Hier wollten wir ein kompliziertes Uhrwerk sehen, mit dem Prompt »complicated watch movement, macro, close-up, realistic, warm lighting, 4k«. Realistisch ist daran allerdings wenig. Denselben Prompt haben wir auch noch einmal bei Dall-E getestet – mit diesem deutlich realistischeren Ergebnis."
Artificial Intelligence,Spiegel Online,2023-12-06,https://www.spiegel.de/karriere/chatgpt-prompt-writer-und-prompt-engineers-verdienen-bis-zu-335-000-dollar-im-jahr-a-a54a93a5-e20d-40e6-b235-28aec0bddaaa,ChatGPT: Prompt Writer und Prompt Engineers verdienen bis zu 335.000 Dollar im Jahr - DER SPIEGEL,"Für diesen Job muss man keine Programmiersprache können: Prompt Writers bringen künstliche Intelligenzen dazu, optimale Ergebnisse zu liefern. Ein Literaturwissenschaftler erzählt, wie er sich so ein zweites Standbein aufgebaut hat."
KI,Spiegel Online,2023-12-07,https://www.spiegel.de/netzwelt/web/gemini-gegen-chatgpt-wie-google-bei-ki-zurueck-an-die-weltspitze-will-a-e1c291db-b6af-4b94-b79b-0787b6287771,Gemini gegen ChatGPT: Wie Google bei KI zurück an die Weltspitze will - DER SPIEGEL,Google galt lange als führend bei künstlicher Intelligenz. Doch dann kamen Microsoft und ChatGPT und ließen den Giganten alt aussehen. Eine neue Super-KI soll ihn jetzt wieder ganz nach vorn bringen. Kommt sie zu spät?
KI,Spiegel Online,2023-12-08,https://www.spiegel.de/kultur/krisenmodus-ist-das-wort-des-jahres-2023-vor-antisemitismus-ki-boom-und-milliardenloch-a-52d21e30-e0b5-42ad-8a25-deb359acba3f,"»Krisenmodus« ist das Wort des Jahres 2023 - vor Antisemitismus, KI-Boom und Milliardenloch - DER SPIEGEL","Ukrainekrieg, Nachtragshaushalt, Nahostkonflikt: Die Herausforderungen für die Politik sind groß, sie arbeitet im »Krisenmodus«. Dieser Begriff wurde nun zum Wort des Jahres gekürt – vor »Antisemitismus« und »leseunfähig«. Die Gesellschaft für deutsche Sprache (GfdS ) hat den Begriff »Krisenmodus« zum »Wort des Jahres« 2023 gekürt. Das gab die Jury am Freitag in Wiesbaden bekannt. In diesem Jahr schienen die Krisen und ihre Bewältigung zu kulminieren, schreibt die GfdS zur Begründung: »Um einen Satz des Vizekanzlers zu modifizieren: Wir sind umzingelt von Krisen.« Der Ausnahmezustand sei zum Dauerzustand geworden. Gefühle wie Unsicherheit, Ängste, Wut, Hilflosigkeit und Ohnmacht prägen den Alltag vieler Menschen. Linguistisch sei eine zunehmende sprachliche Radikalisierung im öffentlichen Raum zu bemerken. Die Top 10 der Wörter des Jahres in Deutschland 2023: Krisenmodus Antisemitismus leseunfähig KI-Boom Ampelzoff hybride Kriegsführung Migrationsbremse Milliardenloch Teilzeitgesellschaft Kussskandal »Die Liste spiegelt die Realität wider, und die Realität ist derzeit ziemlich düster«, sagte die GfdS-Geschäftsführerin Andrea Ewels. Die Gesellschaft befinde sich seit 2020 im »Krisenmodus«, sagte sie mit Blick etwa auf die Coronapandemie, den Überfall Russlands auf die Ukraine, die Energiekrise, die Bildungsmisere und den Angriff der Hamas auf Israel. Das Siegerwort ist kein Wort, das erst 2023 geprägt wurde, darauf weist die Gesellschaft für deutsche Sprache hin: Der früheste Beleg, der sich im Deutschen Referenzkorpus, der weltweit größten digitalen Textsammlung zur deutschen Sprache nach 1945 findet, stamme aus dem Jahr 2001. Eine Jury der GfdS wählt alljährlich Begriffe und Wendungen aus, die das politische, wirtschaftliche und gesellschaftliche Leben eines Jahres sprachlich in besonderer Weise bestimmt haben. 2022 war »Zeitenwende« auf dem ersten Platz gelandet. Der Begriff steht im Zusammenhang mit dem russischen Angriffskrieg gegen die Ukraine und wurde unter anderem von Bundeskanzler Olaf Scholz (SPD) aufgegriffen und geprägt. Zuvor waren mit »Wellenbrecher« (2021) und »Coronapandemie« (2020) zwei Begriffe aus dem Wortfeld um die damalige Krankheitswelle gewählt worden. Die Gesellschaft für deutsche Sprache ist eine politisch unabhängige Vereinigung zur Pflege und Erforschung der deutschen Sprache mit Sitz in Wiesbaden. Für einen Platz auf der Liste der »Wörter des Jahres« ist den Angaben zufolge nicht die Häufigkeit entscheidend, sondern die Bedeutsamkeit und die Popularität. Die ausgewählten Wörter und Wendungen seien mit keinerlei Wertung oder Empfehlung verbunden. Das »Wort des Jahres« wurde von der GfdS erstmals 1971 und seit 1977 regelmäßig gekürt. Auch in anderen Ländern werden Wörter des Jahres bestimmt. In Österreich wurde der Begriff »Kanzlermenü« ausgewählt , er bezieht sich auf eine Aussage des Bundeskanzlers Karl Nehammer , der einen Hamburger bei McDonald’s als »billigste warme Mahlzeit in Österreich« bezeichnet hatte. Für die Deutschschweiz gaben Zürcher Linguisten »Monsterbank« als Wort des Jahres aus – es steht im Kontext des Credit-Suisse-Crashs. Der englische Buchverlag Oxford University Press wählte den Begriff »Rizz«; das US-Pendant Merriam-Webster entschied sich für »authentic«."
KI,Spiegel Online,2023-12-06,https://www.spiegel.de/netzwelt/web/gemini-google-stellt-neues-ki-modell-vor-und-spricht-von-einer-neuen-aera-a-8029db34-5ca3-417a-b768-2968701dae7e,Gemini: Google stellt neues KI-Modell vor und spricht von einer »neuen Ära« - DER SPIEGEL,"Was GPT-4 für OpenAI ist, soll Gemini für Google werden – aber natürlich stärker und besser. Das KI-Modell verstehe Texte, Bilder, Audio- und Videoinhalte und sei ein »Meilenstein«. Doch noch ist es unfertig. Google hat am Mittwoch seine neue künstliche Intelligenz Gemini vorgestellt, mit der das Unternehmen im KI-Wettrennen aufholen – oder besser: zum Überholen ansetzen will. Erstmals erwähnte Google das neue Modell im Frühjahr auf seiner Entwicklerkonferenz, doch die Veröffentlichung zog sich hin. Selbst jetzt ist Gemini alles andere als fix und fertig. Der holprige Start passt dazu, dass Google bei KI-Anwendungen gegenüber der Konkurrenz von OpenAI und Microsoft hinterherhinkt. Ein Beispiel, das zeigen soll, wie Geminis Fähigkeiten im Alltag helfen könnten , richtet sich auf den ersten Blick an überforderte Eltern, die von Physik- und Mathehausaufgaben ebenso wenig Ahnung haben wie ihre Kinder . Die neue künstliche Intelligenz versteht nicht nur die ausgedruckten Fragen aus dem Schulbuch, sondern auch die handgeschriebenen Antworten und was an denen falsch ist. Das mag nicht für alle nach der neuen KI-Killer-Anwendung schlechthin klingen, doch Google will mit dem Beispiel einen aus Sicht des Unternehmens wichtigen Fortschritt im Bereich von künstlicher Intelligenz präsentieren. Dieser lässt sich mit einem Wort beschreiben: Multimodalität. Gemini ist von Grund auf multimodal ausgelegt, kann also nach Angaben der Entwickler mit Text, Bildern, Audio- und Videoinhalten gleichermaßen umgehen. Und immer wieder taucht in Googles Ankündigung das englische Wort reasoning auf: logisches Denken oder Schlussfolgern. Darin soll Gemini besonders gut sein. Die Hausaufgabenhilfe illustriert diese Kette aus Verstehen von Text und Bild, Prüfen und Schlussfolgern. »Das ist ein signifikanter Meilenstein in der Entwicklung von KI und der Beginn einer neuen Ära für uns«, teilt Google etwas redundant mit. Keine einzelne App, sondern ein Modell Auf einen Schlag sichtbar wird der Beginn dieser Ära nicht. Gemini ist keine komplette Anwendung wie ChatGPT, sondern ein Modell wie GPT-4 des Konkurrenten OpenAI. Es wird also in verschiedenen Google-Produkten im Hintergrund laufen, früher oder später. Die erste Gemini-Generation 1.0 wird es in drei Größen geben: Nano, Pro und Ultra. Die kleinste ist ganz auf Effizienz getrimmt und soll sogar auf mobilen Geräten wie Smartphones laufen können. Genauer gesagt: auf speziellen KI-Chips für diese Geräte. Der Vorteil dieser Konstruktion im Gegensatz zu einer Cloudanbindung an ein größeres Modell ist, dass Gemini Nano keine Verbindung zu Googles Servern benötigt. Deshalb kann es auch mit vertraulichen Chats etwa in WhatsApp arbeiten, um dort Antwortvorschläge zu machen oder Grammatikfehler zu korrigieren. Das Google Pixel 8 Pro ist seit dem heutigen Mittwoch das erste Smartphone, für das Gemini Nano zur Verfügung steht. Europa muss noch auf Gemini warten Sofort nutzbar ist auch Gemini Pro – und zwar, weil es im Chatbot Bard steckt, Googles Antwort auf ChatGPT . Es sei das bisher größte Update für Bard, teilte Google mit, stehe zunächst allerdings nur auf Englisch »in mehr als 170 Ländern und Territorien« zur Verfügung. Europa ist nicht darunter. Die Ultra-Version wird in Googles Rechenzentren laufen und das leistungsfähigste Modell darstellen, das Google zu bieten hat. Es sei das erste Modell, das menschliche Experten im MMLU-Test (massive multitask language understanding) in seinem Wissen unter anderem über Mathematik, Physik, Geschichte, Recht, Medizin und Ethik und der Fähigkeit, Probleme in diesen Bereichen zu lösen, übertrumpft. Gemini Ultra sei in fast allen durchgeführten Vergleichstests überlegen, hieß es von Google. Auch gegenüber GPT-4, das derzeit als State-of-the-art-Modell gilt, allerdings auch schon im März veröffentlicht wurde. Auch Microsoft rüstet nach Allerdings wird es noch dauern, bis Gemini in weiteren Produkten des Unternehmens eingesetzt wird, in denen es hilfreich sein könnte. In der Google-Suche, im Browser Chrome und auch in Googles Werbediensten wird es noch Monate dauern, bis es so weit ist. Die Ultra-Variante wird zuerst auch nur ausgewählten Kunden, Entwicklern, Partnern und Sicherheitsfachleuten »für frühe Experimente und Feedback« zur Verfügung stehen, bevor »Anfang des Jahres« ein größerer Kreis das Modell wird nutzen können. Zuvor ist Google noch mit Schutzmaßnahmen beschäftigt. Interne und externe Expertinnen und Experten, teilte das Unternehmen mit, hätten Gemini bereits ausgiebig gehackt, um potenzielle Sicherheitsrisiken bis hin zu autonomen Handlungen der KI zu erkennen. Auch toxische, einseitige oder faktisch falsche Inhalte soll Gemini möglichst nicht erstellen oder akzeptieren. Finetuning und menschliches Feedback sollen, wie es im Übrigen auch bei OpenAI üblich ist, das Modell anschließend zuverlässiger und alltagstauglicher machen. Ob und wie lange Google mit Gemini einen Vorsprung gegenüber OpenAI erreichen könnte, ist daher fürs Erste nicht zu beantworten. Die Vorstellung von ChatGPT vor etwas mehr als einem Jahr wird mitunter als »iPhone-Moment der KI« beschrieben – Google hingegen streckt seine KI-Momente weiterhin auf Monate. Und wie zufällig kündigte Microsoft einen Tag vor Googles Neuvorstellung ein großes Upgrade seines KI-»Copilot« an: »Bald« schon werde dahinter das neue OpenAI-Modell GPT-4 Turbo stecken und dadurch unter anderem multimodaler arbeiten können. Anmerkung der Redaktion: In einer früheren Fassung dieses Artikels hieß es, Google habe noch keinen Zeitpunkt für die Bereitstellung von Gemini Nano im Pixel 8 Pro genannt. Das ist falsch, das KI-Modell steht ab sofort für das Smartphone zur Verfügung. Wir haben den Satz korrigiert."
KI,Spiegel Online,2023-12-06,https://www.spiegel.de/karriere/chatgpt-prompt-writer-und-prompt-engineers-verdienen-bis-zu-335-000-dollar-im-jahr-a-a54a93a5-e20d-40e6-b235-28aec0bddaaa,ChatGPT: Prompt Writer und Prompt Engineers verdienen bis zu 335.000 Dollar im Jahr - DER SPIEGEL,"Für diesen Job muss man keine Programmiersprache können: Prompt Writers bringen künstliche Intelligenzen dazu, optimale Ergebnisse zu liefern. Ein Literaturwissenschaftler erzählt, wie er sich so ein zweites Standbein aufgebaut hat."
Künstliche Intelligenz,Spiegel Online,2023-12-02,https://www.spiegel.de/ausland/israel-hamas-krieg-wie-das-israelische-militaer-kuenstliche-intelligenz-nutzt-a-d85a8b8a-d17e-4136-afc6-1f513f4be68c,Israel-Hamas-Krieg: Wie das israelische Militär künstliche Intelligenz nutzt - DER SPIEGEL,"Das KI-System »The Gospel« schlägt Angriffsziele zur Bombardierung im Gazastreifen vor. Israels Militär behauptet, zivile Kollateralschäden damit zu begrenzen. Doch Experten zweifeln an der Darstellung. Israel hat laut Militärangaben in den ersten 35 Tagen des Krieges 15.000 Ziele im Gazastreifen angegriffen – eine Zahl, die deutlich höher ist als bei früheren Militäroperationen in dem dicht besiedelten Küstengebiet. Zum Vergleich: Im Krieg von 2014, der 51 Tage dauerte, griffen die israelischen Streitkräfte (IDF) zwischen 5000 und 6000 Ziele an. Ein aktueller Bericht des »Guardian« legt nun nahe, welch große Rolle künstlicher Intelligenz bei der Auswahl der Ziele zukommt – und welche Risiken womöglich damit einhergehen. Experten sehen den KI-Einsatz im Krieg demnach als militärisch wegweisend, aber auch äußerst gefährlich an. Und mit den neuerlichen Angriffen im Gazastreifen wächst die Sorge über zivile Opfer. Nach Angaben des von der Hamas kontrollierten Gesundheitsministeriums sind seit dem 7. Oktober bereits mehr als 15.000 Menschen im Gazastreifen ums Leben gekommen. Von 50 Angriffszielen im Jahr zu 100 am Tag Wie die IDF die Ziele im Gazastreifen auswählt, die bombardiert werden, versucht die »Guardian«-Recherche zu beleuchten. Demnach nutzt die Armee ein KI-System namens »The Gospel« zur Lokalisierung von Zielen. Anfang November erklärte die IDF, mehr als 12.000 Angriffsziele im Gazastreifen identifiziert zu haben. »The Gospel« spielte dabei wohl eine erhebliche Rolle: Konnten zuvor etwa 50 Ziele im Jahr im Gazastreifen ausgemacht werden, sind es mittlerweile 100 Ziele an nur einem Tag. Die IDF schreibt denn auch auf ihrer Website, dass es im Krieg gegen die Hamas ein KI-gestütztes System namens »Habsora« (»The Gospel«) verwendet, um »Ziele in einem schnellen Tempo zu erstellen«. Mehrere Quellen, die mit den Angriffszielfindungs-Prozessen der IDF vertraut sind, sagten laut »Guardian«, »The Gospel« werde verwendet, um automatische Empfehlungen für Angriffe auf Ziele wie die Privatwohnungen von möglichen Hamas- oder Islamischer-Dschihad -Aktivisten auszugeben. In den vergangenen Jahren hat die IDF laut dem Bericht eine Datenbank aufgebaut, die Quellen zufolge zwischen 30.000 und 40.000 mutmaßliche Kämpfer umfasst. Systeme wie »The Gospel« hätten eine entscheidende Rolle bei der Erstellung der Listen von Personen gespielt, die zur Tötung zugelassen sind. Welche Art von Daten in »The Gospel« genau einfließen, ist nicht bekannt. Experten äußerten gegenüber dem »Guardian« jedoch, dass KI-basierte Systeme zur Entscheidungsunterstützung bei der Zielerfassung in der Regel große Mengen an Informationen aus einer Reihe von Quellen analysieren würden. Dazu zählen etwa Drohnenaufnahmen, abgehörte Kommunikation und Überwachungskameradaten. Ampel für den Kollateralschaden Ein IDF-Mann, der bei früheren Operationen im Gazastreifen an Entscheidungen über Zielpersonen mitgewirkt hat, erklärt in dem Bericht, das israelische Militär hätte zuvor keine Häuser von unbedeutenderen Hamas-Mitgliedern bombardiert. Das habe sich im aktuellen Krieg geändert. Die Häuser von mutmaßlichen Hamas-Aktivisten würden nun unabhängig von ihrem Rang ins Visier genommen. »Das sind eine Menge Häuser«, sagt er laut »Guardian«. »Hamas-Mitglieder, die nicht wirklich etwas bedeuten, leben im ganzen Gazastreifen verteilt. Also markieren sie die Häuser, bombardieren sie und töten alle Bewohner.« Der IDF zufolge führt die Zieldivision »präzise Angriffe auf Infrastrukturen, die mit der Hamas in Verbindung stehen, durch und fügt dabei dem Feind großen und Nichtkombattanten nur minimalen Schaden zu«. Die Präzision der von KI empfohlenen Angriffe wurde in mehreren Berichten in israelischen Medien hervorgehoben. Die Tageszeitung »Yedioth Ahronoth« berichtete, dass die Einheit »so weit wie möglich sicherstellt, dass keine unbeteiligten Zivilisten zu Schaden kommen«. Eine frühere hochrangige israelische Militärquelle sagte dem »Guardian«, dass die Einsatzkräfte eine »sehr genaue« Messung der Zahl der Zivilisten verwenden, die ein Gebäude kurz vor einem Angriff verlassen. »Wir verwenden einen Algorithmus, um zu bewerten, wie viele Zivilisten noch übrig sind. Er zeigt uns grün, gelb oder rot an, wie eine Ampel.« Experten zweifeln an geringerem zivilen Schaden durch KI Experten für künstliche Intelligenz und bewaffnete Konflikte äußerten sich im »Guardian« jedoch skeptisch gegenüber der Behauptung, dass KI-basierte Systeme den Schaden für die Zivilbevölkerung verringern, indem sie eine genauere Zielerfassung fördern. Es gebe kaum empirische Daten, die die Behauptungen stützen. Weiterhin sehen sie den Einsatz von KI zur Ausgabe militärischer Zielen als äußerst gefährlich an. Auch wenn Menschen in den Entscheidungsprozess vor einem Beschuss eingebunden seien, bestehe die Gefahr, sich zu sehr auf die KI-Daten zu verlassen. Mehrere Quellen berichteten dem »Guardian«, bei der Genehmigung eines Angriffs auf Privathäuser von Personen, die als Hamas- oder Islamischer-Dschihad-Aktivisten identifiziert wurden, haben die Zielforscher im Voraus gewusst, wie viele Zivilisten voraussichtlich getötet werden würden. Für jedes Ziel gebe es eine Datei mit einem Kollateralschadenwert. Ein ehemaliger US-Sicherheitsberater des Weißen Hauses, der mit dem Einsatz autonomer Systeme durch das US-Militär vertraut ist, sagte über die KI-Nutzung der IDF: »Andere Staaten werden zusehen und lernen«. Der Krieg zwischen Israel und der Hamas sei ein »wichtiger Moment, wenn die IDF KI in signifikanter Weise einsetzt, um Entscheidungen zu treffen, die Leben oder Tod bedeuten«."
AI,Spiegel Online,2023-12-02,https://www.spiegel.de/ausland/israel-hamas-krieg-wie-das-israelische-militaer-kuenstliche-intelligenz-nutzt-a-d85a8b8a-d17e-4136-afc6-1f513f4be68c,Israel-Hamas-Krieg: Wie das israelische Militär künstliche Intelligenz nutzt - DER SPIEGEL,"Das KI-System »The Gospel« schlägt Angriffsziele zur Bombardierung im Gazastreifen vor. Israels Militär behauptet, zivile Kollateralschäden damit zu begrenzen. Doch Experten zweifeln an der Darstellung. Israel hat laut Militärangaben in den ersten 35 Tagen des Krieges 15.000 Ziele im Gazastreifen angegriffen – eine Zahl, die deutlich höher ist als bei früheren Militäroperationen in dem dicht besiedelten Küstengebiet. Zum Vergleich: Im Krieg von 2014, der 51 Tage dauerte, griffen die israelischen Streitkräfte (IDF) zwischen 5000 und 6000 Ziele an. Ein aktueller Bericht des »Guardian« legt nun nahe, welch große Rolle künstlicher Intelligenz bei der Auswahl der Ziele zukommt – und welche Risiken womöglich damit einhergehen. Experten sehen den KI-Einsatz im Krieg demnach als militärisch wegweisend, aber auch äußerst gefährlich an. Und mit den neuerlichen Angriffen im Gazastreifen wächst die Sorge über zivile Opfer. Nach Angaben des von der Hamas kontrollierten Gesundheitsministeriums sind seit dem 7. Oktober bereits mehr als 15.000 Menschen im Gazastreifen ums Leben gekommen. Von 50 Angriffszielen im Jahr zu 100 am Tag Wie die IDF die Ziele im Gazastreifen auswählt, die bombardiert werden, versucht die »Guardian«-Recherche zu beleuchten. Demnach nutzt die Armee ein KI-System namens »The Gospel« zur Lokalisierung von Zielen. Anfang November erklärte die IDF, mehr als 12.000 Angriffsziele im Gazastreifen identifiziert zu haben. »The Gospel« spielte dabei wohl eine erhebliche Rolle: Konnten zuvor etwa 50 Ziele im Jahr im Gazastreifen ausgemacht werden, sind es mittlerweile 100 Ziele an nur einem Tag. Die IDF schreibt denn auch auf ihrer Website, dass es im Krieg gegen die Hamas ein KI-gestütztes System namens »Habsora« (»The Gospel«) verwendet, um »Ziele in einem schnellen Tempo zu erstellen«. Mehrere Quellen, die mit den Angriffszielfindungs-Prozessen der IDF vertraut sind, sagten laut »Guardian«, »The Gospel« werde verwendet, um automatische Empfehlungen für Angriffe auf Ziele wie die Privatwohnungen von möglichen Hamas- oder Islamischer-Dschihad -Aktivisten auszugeben. In den vergangenen Jahren hat die IDF laut dem Bericht eine Datenbank aufgebaut, die Quellen zufolge zwischen 30.000 und 40.000 mutmaßliche Kämpfer umfasst. Systeme wie »The Gospel« hätten eine entscheidende Rolle bei der Erstellung der Listen von Personen gespielt, die zur Tötung zugelassen sind. Welche Art von Daten in »The Gospel« genau einfließen, ist nicht bekannt. Experten äußerten gegenüber dem »Guardian« jedoch, dass KI-basierte Systeme zur Entscheidungsunterstützung bei der Zielerfassung in der Regel große Mengen an Informationen aus einer Reihe von Quellen analysieren würden. Dazu zählen etwa Drohnenaufnahmen, abgehörte Kommunikation und Überwachungskameradaten. Ampel für den Kollateralschaden Ein IDF-Mann, der bei früheren Operationen im Gazastreifen an Entscheidungen über Zielpersonen mitgewirkt hat, erklärt in dem Bericht, das israelische Militär hätte zuvor keine Häuser von unbedeutenderen Hamas-Mitgliedern bombardiert. Das habe sich im aktuellen Krieg geändert. Die Häuser von mutmaßlichen Hamas-Aktivisten würden nun unabhängig von ihrem Rang ins Visier genommen. »Das sind eine Menge Häuser«, sagt er laut »Guardian«. »Hamas-Mitglieder, die nicht wirklich etwas bedeuten, leben im ganzen Gazastreifen verteilt. Also markieren sie die Häuser, bombardieren sie und töten alle Bewohner.« Der IDF zufolge führt die Zieldivision »präzise Angriffe auf Infrastrukturen, die mit der Hamas in Verbindung stehen, durch und fügt dabei dem Feind großen und Nichtkombattanten nur minimalen Schaden zu«. Die Präzision der von KI empfohlenen Angriffe wurde in mehreren Berichten in israelischen Medien hervorgehoben. Die Tageszeitung »Yedioth Ahronoth« berichtete, dass die Einheit »so weit wie möglich sicherstellt, dass keine unbeteiligten Zivilisten zu Schaden kommen«. Eine frühere hochrangige israelische Militärquelle sagte dem »Guardian«, dass die Einsatzkräfte eine »sehr genaue« Messung der Zahl der Zivilisten verwenden, die ein Gebäude kurz vor einem Angriff verlassen. »Wir verwenden einen Algorithmus, um zu bewerten, wie viele Zivilisten noch übrig sind. Er zeigt uns grün, gelb oder rot an, wie eine Ampel.« Experten zweifeln an geringerem zivilen Schaden durch KI Experten für künstliche Intelligenz und bewaffnete Konflikte äußerten sich im »Guardian« jedoch skeptisch gegenüber der Behauptung, dass KI-basierte Systeme den Schaden für die Zivilbevölkerung verringern, indem sie eine genauere Zielerfassung fördern. Es gebe kaum empirische Daten, die die Behauptungen stützen. Weiterhin sehen sie den Einsatz von KI zur Ausgabe militärischer Zielen als äußerst gefährlich an. Auch wenn Menschen in den Entscheidungsprozess vor einem Beschuss eingebunden seien, bestehe die Gefahr, sich zu sehr auf die KI-Daten zu verlassen. Mehrere Quellen berichteten dem »Guardian«, bei der Genehmigung eines Angriffs auf Privathäuser von Personen, die als Hamas- oder Islamischer-Dschihad-Aktivisten identifiziert wurden, haben die Zielforscher im Voraus gewusst, wie viele Zivilisten voraussichtlich getötet werden würden. Für jedes Ziel gebe es eine Datei mit einem Kollateralschadenwert. Ein ehemaliger US-Sicherheitsberater des Weißen Hauses, der mit dem Einsatz autonomer Systeme durch das US-Militär vertraut ist, sagte über die KI-Nutzung der IDF: »Andere Staaten werden zusehen und lernen«. Der Krieg zwischen Israel und der Hamas sei ein »wichtiger Moment, wenn die IDF KI in signifikanter Weise einsetzt, um Entscheidungen zu treffen, die Leben oder Tod bedeuten«."
Artificial Intelligence,Spiegel Online,2023-12-02,https://www.spiegel.de/ausland/israel-hamas-krieg-wie-das-israelische-militaer-kuenstliche-intelligenz-nutzt-a-d85a8b8a-d17e-4136-afc6-1f513f4be68c,Israel-Hamas-Krieg: Wie das israelische Militär künstliche Intelligenz nutzt - DER SPIEGEL,"Das KI-System »The Gospel« schlägt Angriffsziele zur Bombardierung im Gazastreifen vor. Israels Militär behauptet, zivile Kollateralschäden damit zu begrenzen. Doch Experten zweifeln an der Darstellung. Israel hat laut Militärangaben in den ersten 35 Tagen des Krieges 15.000 Ziele im Gazastreifen angegriffen – eine Zahl, die deutlich höher ist als bei früheren Militäroperationen in dem dicht besiedelten Küstengebiet. Zum Vergleich: Im Krieg von 2014, der 51 Tage dauerte, griffen die israelischen Streitkräfte (IDF) zwischen 5000 und 6000 Ziele an. Ein aktueller Bericht des »Guardian« legt nun nahe, welch große Rolle künstlicher Intelligenz bei der Auswahl der Ziele zukommt – und welche Risiken womöglich damit einhergehen. Experten sehen den KI-Einsatz im Krieg demnach als militärisch wegweisend, aber auch äußerst gefährlich an. Und mit den neuerlichen Angriffen im Gazastreifen wächst die Sorge über zivile Opfer. Nach Angaben des von der Hamas kontrollierten Gesundheitsministeriums sind seit dem 7. Oktober bereits mehr als 15.000 Menschen im Gazastreifen ums Leben gekommen. Von 50 Angriffszielen im Jahr zu 100 am Tag Wie die IDF die Ziele im Gazastreifen auswählt, die bombardiert werden, versucht die »Guardian«-Recherche zu beleuchten. Demnach nutzt die Armee ein KI-System namens »The Gospel« zur Lokalisierung von Zielen. Anfang November erklärte die IDF, mehr als 12.000 Angriffsziele im Gazastreifen identifiziert zu haben. »The Gospel« spielte dabei wohl eine erhebliche Rolle: Konnten zuvor etwa 50 Ziele im Jahr im Gazastreifen ausgemacht werden, sind es mittlerweile 100 Ziele an nur einem Tag. Die IDF schreibt denn auch auf ihrer Website, dass es im Krieg gegen die Hamas ein KI-gestütztes System namens »Habsora« (»The Gospel«) verwendet, um »Ziele in einem schnellen Tempo zu erstellen«. Mehrere Quellen, die mit den Angriffszielfindungs-Prozessen der IDF vertraut sind, sagten laut »Guardian«, »The Gospel« werde verwendet, um automatische Empfehlungen für Angriffe auf Ziele wie die Privatwohnungen von möglichen Hamas- oder Islamischer-Dschihad -Aktivisten auszugeben. In den vergangenen Jahren hat die IDF laut dem Bericht eine Datenbank aufgebaut, die Quellen zufolge zwischen 30.000 und 40.000 mutmaßliche Kämpfer umfasst. Systeme wie »The Gospel« hätten eine entscheidende Rolle bei der Erstellung der Listen von Personen gespielt, die zur Tötung zugelassen sind. Welche Art von Daten in »The Gospel« genau einfließen, ist nicht bekannt. Experten äußerten gegenüber dem »Guardian« jedoch, dass KI-basierte Systeme zur Entscheidungsunterstützung bei der Zielerfassung in der Regel große Mengen an Informationen aus einer Reihe von Quellen analysieren würden. Dazu zählen etwa Drohnenaufnahmen, abgehörte Kommunikation und Überwachungskameradaten. Ampel für den Kollateralschaden Ein IDF-Mann, der bei früheren Operationen im Gazastreifen an Entscheidungen über Zielpersonen mitgewirkt hat, erklärt in dem Bericht, das israelische Militär hätte zuvor keine Häuser von unbedeutenderen Hamas-Mitgliedern bombardiert. Das habe sich im aktuellen Krieg geändert. Die Häuser von mutmaßlichen Hamas-Aktivisten würden nun unabhängig von ihrem Rang ins Visier genommen. »Das sind eine Menge Häuser«, sagt er laut »Guardian«. »Hamas-Mitglieder, die nicht wirklich etwas bedeuten, leben im ganzen Gazastreifen verteilt. Also markieren sie die Häuser, bombardieren sie und töten alle Bewohner.« Der IDF zufolge führt die Zieldivision »präzise Angriffe auf Infrastrukturen, die mit der Hamas in Verbindung stehen, durch und fügt dabei dem Feind großen und Nichtkombattanten nur minimalen Schaden zu«. Die Präzision der von KI empfohlenen Angriffe wurde in mehreren Berichten in israelischen Medien hervorgehoben. Die Tageszeitung »Yedioth Ahronoth« berichtete, dass die Einheit »so weit wie möglich sicherstellt, dass keine unbeteiligten Zivilisten zu Schaden kommen«. Eine frühere hochrangige israelische Militärquelle sagte dem »Guardian«, dass die Einsatzkräfte eine »sehr genaue« Messung der Zahl der Zivilisten verwenden, die ein Gebäude kurz vor einem Angriff verlassen. »Wir verwenden einen Algorithmus, um zu bewerten, wie viele Zivilisten noch übrig sind. Er zeigt uns grün, gelb oder rot an, wie eine Ampel.« Experten zweifeln an geringerem zivilen Schaden durch KI Experten für künstliche Intelligenz und bewaffnete Konflikte äußerten sich im »Guardian« jedoch skeptisch gegenüber der Behauptung, dass KI-basierte Systeme den Schaden für die Zivilbevölkerung verringern, indem sie eine genauere Zielerfassung fördern. Es gebe kaum empirische Daten, die die Behauptungen stützen. Weiterhin sehen sie den Einsatz von KI zur Ausgabe militärischer Zielen als äußerst gefährlich an. Auch wenn Menschen in den Entscheidungsprozess vor einem Beschuss eingebunden seien, bestehe die Gefahr, sich zu sehr auf die KI-Daten zu verlassen. Mehrere Quellen berichteten dem »Guardian«, bei der Genehmigung eines Angriffs auf Privathäuser von Personen, die als Hamas- oder Islamischer-Dschihad-Aktivisten identifiziert wurden, haben die Zielforscher im Voraus gewusst, wie viele Zivilisten voraussichtlich getötet werden würden. Für jedes Ziel gebe es eine Datei mit einem Kollateralschadenwert. Ein ehemaliger US-Sicherheitsberater des Weißen Hauses, der mit dem Einsatz autonomer Systeme durch das US-Militär vertraut ist, sagte über die KI-Nutzung der IDF: »Andere Staaten werden zusehen und lernen«. Der Krieg zwischen Israel und der Hamas sei ein »wichtiger Moment, wenn die IDF KI in signifikanter Weise einsetzt, um Entscheidungen zu treffen, die Leben oder Tod bedeuten«."
Artificial Intelligence,Spiegel Online,2023-12-01,https://www.spiegel.de/international/business/interview-with-bundesbank-president-nagel-we-are-not-the-sick-man-of-europe-a-7cbadadd-845a-4d26-859b-43b95ac32821,"Interview with Bundesbank President Nagel: ""We Are not the Sick Man of Europe"" - DER SPIEGEL","Joachim Nagel is battling inflation on two fronts – as the head of Germany's central bank and as a hobby cook fighting high food prices at home. In an interview, he discusses Europe's economic challenges, successes achieved and a recent high court ruling that will make it harder for Germany to borrow money. DER SPIEGEL: Mr. Nagel, are you a marathon runner? Nagel: No, I really enjoy playing tennis. Why do you ask? DER SPIEGEL: Because you say that the ""last mile"" could be the most difficult in the fight against inflation – the final phase until the 2 percent inflation rate targeted by the European Central Bank (ECB) is reached. Joachim Nagel , 57, has served as president of the Germany's central bank, the Bundesbank, since January 2022. In that role, he is also a member of the Governing Council of the European Central Bank, which regularly sets key interest rates for the eurozone. Previously, Nagel was a member of the board of the German state development bank KfW and deputy head of the banking division at the Bank for International Settlements in Basel. Nagel is a member of the center-left Social Democratic Party. Nagel: I think that image fits quite well. We can see the goal gradually coming into view: Inflation is falling. But we also know that it has not yet been reached and that inflation can rise again quickly. As with the last mile, it’s all about gritting your teeth and not letting up. DER SPIEGEL: The economy and consumers are longing for an interest rate cut and the pressure on the ECB is high. At 4.5 percent, the key interest rate is now well above the 2.9-percent inflation rate in the eurozone. Nagel: Falling inflation shows that our monetary policy is working. But inflation has not been defeated. The fact that it is now falling so sharply is also due to lower energy prices and base effects. The article you are reading originally appeared in German in issue 48/2023 (November 25th, 2023) of DER SPIEGEL. DER SPIEGEL: You’ll have to explain that. Nagel: For the inflation rate, we look at year-on-year increases. Prices were very high in October 2022. The gap to this level was thus comparatively small in October 2023. This mathematical effect will soon fizzle out. The inflation rate could thus rise again slightly in the coming months. DER SPIEGEL: The German government intends to raise the value-added tax on gas and district heating back to 19 percent. Is this a mistake that could drive inflation? Nagel: The German inflation rate will rise only slightly as a result. And I am always in favor of ending crisis measures as soon as the situation allows for it. DER SPIEGEL: What other risks are there for another rise in inflation? Nagel: Energy prices, in particular, against the backdrop of the war in the Middle East. In addition, price pressure on goods and services is generally still high. Wages and profits could also increase more than expected. We will have to wait for the data that will be available at the next meeting of the ECB Governing Council in December. DER SPIEGEL: It is hard to believe that the ECB decides spontaneously on the basis of data. ECB President Christine Lagarde has already said that key interest rates will remain as high as they are now for the next few quarters. Nagel: By saying that, she is keeping unrealistic expectations in check. Interest rates must remain high long enough for the inflation rate to fall back to 2 percent. This is what we are working towards in the Governing Council. DER SPIEGEL: … the committee on which you also sit as president of the Bundesbank. Do you think that Lagarde’s caution is justified? Nagel: Our latest forecast now shows that inflation is only likely to approach 2 percent again at some point in 2025. DER SPIEGEL: Investors and many economists are expecting the first interest rate cut in summer 2024. Are they all wrong? Nagel: Not every bet works out. There is great uncertainty about future developments. At the moment, we can’t be certain whether we have even reached the interest rate peak yet. It is too early to speculate about lower interest rates. DER SPIEGEL: Companies are now offering their employees double-digit wage increases. Are we in a wage-price spiral? Nagel: What you are referring to are often catch-up effects caused by high inflation. After all, wages have fallen sharply in real terms – meaning, after deducting inflation – by more than 4 percent in 2022 alone. It is understandable that these real wage losses should be compensated for. However, I do not see a self-reinforcing spiral. It is important to keep inflation expectations anchored. Because if everyone is convinced that prices will remain stable, that would be the best thing for the collective bargaining partners. DER SPIEGEL: According to the book, the central bank should raise interest rates as soon as the economy heats up and prices thus increase. The problem, though, is that the economy in Europe is anything but hot. The inflationary pressure is arising primarily from the energy markets. In such a situation, what is even the point of raising interest rates? Nagel: There are a lot of reasons. Energy markets play an important role in inflation, but at the moment, they’re actually slowing it down. Meanwhile, price pressure has spread to other goods and services. We can see that the interest rate hikes are helping to reduce inflation, because they dampen demand by making loans more expensive and savings more attractive. Typically, the effect on demand comes before the effect on prices. I am confident that the interest rate hikes will put even more pressure on inflation in 2024. DER SPIEGEL: Then you could cut key interest rates next year after all. Nagel: In order to beat high inflation, interest rates have to remain high for the time being. But I believe that we will have overcome the current dip in growth by 2024, provided the Middle East conflict doesn’t escalate. I do not foresee a hard landing or recession with knock-on effects for the labor market. DER SPIEGEL: At first, the ECB completely underestimated inflation and then rushed to raise interest rates in ways it never had before. What makes you sure you won't be wrong again? Nagel: Our models have their limits when it comes to historical structural breaks such as the ones we have experienced in recent years. The forecasting models, including ours, were not a good fit for this exceptional situation. But we have learned. DER SPIEGEL: Do you at least have better models now? Nagel: We are continuously developing our models. When there is great uncertainty, as in the pandemic, it also helps us to calculate different scenarios. We compare the various results and expand our palette of models - increasingly to include artificial intelligence. But the expertise of our specialists remains an important factor. DER SPIEGEL: ECB Chief Economist Philip Lane, in particular, initially ignored inflation. Why has he been allowed to stay? Nagel: All of us in the Governing Council had to reanalyze the situation in terms of monetary policy after the Russian invasion. For me, it is crucial that we continue to learn. And who would have expected us to raise interest rates as quickly and as markedly as we did at the start of 2022? DER SPIEGEL: Inflation is exacerbating the social divide. Poorer people in particular are suffering because they have to spend a larger share of their income on goods. In addition, they usually have no savings and do not benefit from rising asset prices. That’s an argument for more help from the state, but such help would, in turn, further fuel inflation. Is this becoming a vicious circle? Nagel: Not if the help is targeted. And as far as the main burden of energy prices is concerned: They have fallen again, which is a relief for people. Apart from that, I think there needs to be incentives to use energy sparingly. That applies to everyone. DER SPIEGEL: But not to energy-intensive companies. The state wants to grant them generous breaks in the electricity tax. But where does that leave low-wage earners? Nagel: Our task as a central bank is to combat high inflation. This also helps those who are struggling to make ends meet. Because inflation hits them the hardest. DER SPIEGEL: In what areas do you personally feel that everything is becoming more expensive? Nagel: During the weekly shopping, of course. Your readers will say: Talk is cheap for someone in Nagel’s income class. And it’s true: Others can’t weather this as easily. DER SPIEGEL: Do you hunt for bargains at the supermarket? Nagel: Of course I do. I take a close look, if only at food, because I like to cook. And I can also see that some things are getting cheaper again. Eggs have often been 30 cents cheaper for a pack of 10, and butter is cheaper now. DER SPIEGEL: What do you think of the theory of ""greedflation,"" whereby entrepreneurs raise prices excessively in order to boost profits? Nagel: Inflation itself is a greedy beast. It eats its way into the economy, eroding income and savings. As far as the companies are concerned: Profit margins have increased significantly overall. However, developments have varied greatly from one industry to the other. I’m sure some added something to the price at the beginning of inflation. But with groceries, especially, competition is working particularly well. The price war at discount supermarkets shows that. DER SPIEGEL: Is your salary adjusted for inflation? Nagel: My salary is not adjusted for inflation. It is based on how the salaries of federal civil servants change. DER SPIEGEL: In the future, you’ll be working twice or three times as hard because three out of six of the Executive Board positions at the Bundesbank will be vacant at the beginning of 2024. The federal and state governments aren’t making any progress in filling the vacancies. Does that bother you? Nagel: The Bundesbank is fully capable of acting. But we have many important tasks, so vacancies should be filled quickly. I would be very pleased if politicians would decide on the board positions soon. DER SPIEGEL: You have said that Germany is not the sick man of Europe. What makes you so certain? Nagel: In the English-speaking world, especially, I often hear that Germany is on the brink of the abyss. My view is very different. The German economy has weathered the energy crisis better than feared. The task now is to tackle the longer-term challenges, in particular the green transformation of the economy and digitalization. German companies have always coped well with new conditions and hardships. We are not the sick man of Europe. But we need to be careful that we don’t become that. DER SPIEGEL: Our starting position has deteriorated significantly in terms of taxes, labor costs, productivity, human capital and infrastructure. Will Germany remain below the level it should be at? Nagel: There are major challenges – not just transformation and digitalization, but also demographic changes and a shortage of skilled workers. The labor market has partially dried up. But the German economy has proven time and again how well it can adapt. And politicians have every opportunity to improve Germany’s framework conditions. For example, the labor market should become more flexible and open. There’s a lot to do. DER SPIEGEL: What do you mean in concrete terms? Nagel: For example, by accelerating the pace of integration of foreign skilled workers. DER SPIEGEL: Why? Nagel: The number of available workers is likely to fall in just a few years. This is weighing on our growth prospects. We need enough skilled workers in Germany to secure our prosperity. DER SPIEGEL: In view of the tasks involved in the energy transitions, armaments, immigration, construction of housing and digitalization. Given those challenges, are you in favor of abolishing Germany’s balanced budget law, the so-called ""debt brake""? Nagel: Quite clearly: no. Budget rules are important in order to limit the national deficit. The debt brake has helped ensure that our public finances are sound. And that is an essential basis for economic growth and ultimately also for stable prices. DER SPIEGEL: You welcome the recent ruling by the Federal Constitutional Court prohibiting the government from using the money intended to combat the coronavirus crisis for climate protection? Nagel: I welcome the fact that the ruling significantly strengthens the binding effect of the debt brake. It can now better secure sound public finances again. The numerous special funds have weakened transparency and the debt brake. The ruling is not a decision against specific measures. DER SPIEGEL: Will it be possible to integrate all the shadow budget items, amounting to 300 billion euros, into the normal budget - investing in housing construction, digitalization, climate change and the defense industry - while also complying with the balanced budget law without fueling inflation? Nagel: It is ultimately the job of politicians to ensure that important expenditures are financed. Even a reform of the balance budget law is not out of the question. We have even issued proposals to this regard at the Bundesbank. With low debt ratios, the credit lines could be expanded moderately and investments could also be better protected. The constitution would have to be changed for a reform. If the balanced budget law is seen as too restrictive, then this would certainly be the right way to go. DER SPIEGEL: How worried are you about a new debt crisis in Europe? At 4.5 percent, Italy’s debt costs, as measured by government bond yields, are higher on average than they have been in a long time. Confidence in the country is clearly declining. Nagel: I don’t comment on individual eurozone countries as a matter of principle. It is clear that the eurozone is dependent on healthy public finances. Otherwise, we would be tilting at windmills when it comes to price stability. The ECB must ensure that its monetary policy measures are effective. But fiscal policy is called upon when a country’s economy is unsound and the capital markets react, causing bond yields to soar. DER SPIEGEL: Is it possible for the common currency, the euro, to be instrumentalized politically? Extremist parties in many countries are calling European cohesion into question. Nagel: Perhaps they should look at the facts and compare the inflation rates of the euro with those of the deutsche mark. Over the past 24 years, the inflation rate in the eurozone has averaged just under 2 percent. In the 20 years before that, however, the figure in Germany with the d-mark was just under 3 percent. Myths aren’t helpful there. The environment was certainly different in the past. But we can be proud of what the monetary union has achieved over the past decades. And this despite the global financial crisis and the pandemic. DER SPIEGEL: Many people don’t understand how monetary policy works and how everything is connected. Populist parties exploit that. Does that bother you? Nagel: We have to use good arguments and facts to counter the at times dangerous messages. It’s not easy, but I am a realist. In the past, we have often been content to communicate with the markets – often in technical jargon. We want to express ourselves more clearly and reach out to the people. That is a major challenge. DER SPIEGEL: The ECB has been buying up European government bonds for years. It has thus made it easier for states to borrow money. Now, the ECB’s balance sheet is enormously bloated – and it has to get rid of the bonds again. How difficult will that be? Nagel: Before the pandemic, inflation was too low for many years. The bond purchases sought to counteract this and make it easier to issue debt. Now things are going in the other direction: We are gradually reducing our bond portfolio. And as far as the balance sheet is concerned: Our balance sheet total has fallen by 1,700 billion euros within 12 months. But we could still do even more. DER SPIEGEL: ECB Chief Economist Lane seems to be infatuated with the idea of continuing with the crisis policy. He wants the central bank to continue to hold many government bonds and support commercial banks with liquidity. How do you feel about that? Nagel: The important thing is that we in the ECB Governing Council agree that a tight monetary policy is necessary. And today we can see that this is having its intended effect. Inflation is falling. I cannot yet tell you what our monetary policy toolbox and our balance sheet will look like in the future. In principle, I would have a preference for significantly smaller central bank balance sheets. These would give us more monetary policy leeway if necessary. DER SPIEGEL: The Bundesbank currently has to pay commercial banks 4 percent interest on their surplus reserves, a good deal for the institutions and risk-free to boot. At the same time, the Bundesbank is holding 900 billion euros in German government bonds that barely yield any interest. In short: They are threatened with gigantic losses. Which of these headlines are you more afraid of? ""The Bundesbank is bankrupt""? Or: ""Does the state have to bail out the Bundesbank with fresh capital?"" Nagel: None of those. The Bundesbank’s balance sheet is solid. We have considerable assets. And the financial burdens will pass so that the Bundesbank will be able to generate profits again later that will offset losses. That is why I don’t see those scenarios taking shape. We can and must explain this well, just as we did in the 1970s. We know how to deal with that. DER SPIEGEL: How? Nagel: At the time, we carried forward our losses and then offset these carry-forwards against profits in later years. It is clear that we will not be able to distribute any profits to the finance minister for a long time. But he has known this for just as long. DER SPIEGEL: You could get more money from the commercial banks. So far, they have only had to deposit 1 percent of their customer deposits with the Bundesbank as a ""minimum reserve,"" without receiving interest. They collect plenty for the other deposits. There is now talk of increasing the minimum reserve, which doesn't earn interest, beyond the 1 percent. That would be good for the Bundesbank’s bottom line, but the banking world is resisting. Rightly so? Nagel: This is about our profit and loss account for me. This is a monetary policy instrument. The non-interest-bearing minimum reserve supports the euro system’s tight monetary policy, which curbs lending and thus contributes to price stability. DER SPIEGEL: But the institutions are up in arms because they fear they will lose risk-free profits. Will you take up this fight? Nagel: This is not a fight. This is responsible monetary policy. And this is ultimately also in the interest of the banks. DER SPIEGEL: Mr. Nagel, we thank you for this interview."
KI,Spiegel Online,2023-12-02,https://www.spiegel.de/ausland/israel-hamas-krieg-wie-das-israelische-militaer-kuenstliche-intelligenz-nutzt-a-d85a8b8a-d17e-4136-afc6-1f513f4be68c,Israel-Hamas-Krieg: Wie das israelische Militär künstliche Intelligenz nutzt - DER SPIEGEL,"Das KI-System »The Gospel« schlägt Angriffsziele zur Bombardierung im Gazastreifen vor. Israels Militär behauptet, zivile Kollateralschäden damit zu begrenzen. Doch Experten zweifeln an der Darstellung. Israel hat laut Militärangaben in den ersten 35 Tagen des Krieges 15.000 Ziele im Gazastreifen angegriffen – eine Zahl, die deutlich höher ist als bei früheren Militäroperationen in dem dicht besiedelten Küstengebiet. Zum Vergleich: Im Krieg von 2014, der 51 Tage dauerte, griffen die israelischen Streitkräfte (IDF) zwischen 5000 und 6000 Ziele an. Ein aktueller Bericht des »Guardian« legt nun nahe, welch große Rolle künstlicher Intelligenz bei der Auswahl der Ziele zukommt – und welche Risiken womöglich damit einhergehen. Experten sehen den KI-Einsatz im Krieg demnach als militärisch wegweisend, aber auch äußerst gefährlich an. Und mit den neuerlichen Angriffen im Gazastreifen wächst die Sorge über zivile Opfer. Nach Angaben des von der Hamas kontrollierten Gesundheitsministeriums sind seit dem 7. Oktober bereits mehr als 15.000 Menschen im Gazastreifen ums Leben gekommen. Von 50 Angriffszielen im Jahr zu 100 am Tag Wie die IDF die Ziele im Gazastreifen auswählt, die bombardiert werden, versucht die »Guardian«-Recherche zu beleuchten. Demnach nutzt die Armee ein KI-System namens »The Gospel« zur Lokalisierung von Zielen. Anfang November erklärte die IDF, mehr als 12.000 Angriffsziele im Gazastreifen identifiziert zu haben. »The Gospel« spielte dabei wohl eine erhebliche Rolle: Konnten zuvor etwa 50 Ziele im Jahr im Gazastreifen ausgemacht werden, sind es mittlerweile 100 Ziele an nur einem Tag. Die IDF schreibt denn auch auf ihrer Website, dass es im Krieg gegen die Hamas ein KI-gestütztes System namens »Habsora« (»The Gospel«) verwendet, um »Ziele in einem schnellen Tempo zu erstellen«. Mehrere Quellen, die mit den Angriffszielfindungs-Prozessen der IDF vertraut sind, sagten laut »Guardian«, »The Gospel« werde verwendet, um automatische Empfehlungen für Angriffe auf Ziele wie die Privatwohnungen von möglichen Hamas- oder Islamischer-Dschihad -Aktivisten auszugeben. In den vergangenen Jahren hat die IDF laut dem Bericht eine Datenbank aufgebaut, die Quellen zufolge zwischen 30.000 und 40.000 mutmaßliche Kämpfer umfasst. Systeme wie »The Gospel« hätten eine entscheidende Rolle bei der Erstellung der Listen von Personen gespielt, die zur Tötung zugelassen sind. Welche Art von Daten in »The Gospel« genau einfließen, ist nicht bekannt. Experten äußerten gegenüber dem »Guardian« jedoch, dass KI-basierte Systeme zur Entscheidungsunterstützung bei der Zielerfassung in der Regel große Mengen an Informationen aus einer Reihe von Quellen analysieren würden. Dazu zählen etwa Drohnenaufnahmen, abgehörte Kommunikation und Überwachungskameradaten. Ampel für den Kollateralschaden Ein IDF-Mann, der bei früheren Operationen im Gazastreifen an Entscheidungen über Zielpersonen mitgewirkt hat, erklärt in dem Bericht, das israelische Militär hätte zuvor keine Häuser von unbedeutenderen Hamas-Mitgliedern bombardiert. Das habe sich im aktuellen Krieg geändert. Die Häuser von mutmaßlichen Hamas-Aktivisten würden nun unabhängig von ihrem Rang ins Visier genommen. »Das sind eine Menge Häuser«, sagt er laut »Guardian«. »Hamas-Mitglieder, die nicht wirklich etwas bedeuten, leben im ganzen Gazastreifen verteilt. Also markieren sie die Häuser, bombardieren sie und töten alle Bewohner.« Der IDF zufolge führt die Zieldivision »präzise Angriffe auf Infrastrukturen, die mit der Hamas in Verbindung stehen, durch und fügt dabei dem Feind großen und Nichtkombattanten nur minimalen Schaden zu«. Die Präzision der von KI empfohlenen Angriffe wurde in mehreren Berichten in israelischen Medien hervorgehoben. Die Tageszeitung »Yedioth Ahronoth« berichtete, dass die Einheit »so weit wie möglich sicherstellt, dass keine unbeteiligten Zivilisten zu Schaden kommen«. Eine frühere hochrangige israelische Militärquelle sagte dem »Guardian«, dass die Einsatzkräfte eine »sehr genaue« Messung der Zahl der Zivilisten verwenden, die ein Gebäude kurz vor einem Angriff verlassen. »Wir verwenden einen Algorithmus, um zu bewerten, wie viele Zivilisten noch übrig sind. Er zeigt uns grün, gelb oder rot an, wie eine Ampel.« Experten zweifeln an geringerem zivilen Schaden durch KI Experten für künstliche Intelligenz und bewaffnete Konflikte äußerten sich im »Guardian« jedoch skeptisch gegenüber der Behauptung, dass KI-basierte Systeme den Schaden für die Zivilbevölkerung verringern, indem sie eine genauere Zielerfassung fördern. Es gebe kaum empirische Daten, die die Behauptungen stützen. Weiterhin sehen sie den Einsatz von KI zur Ausgabe militärischer Zielen als äußerst gefährlich an. Auch wenn Menschen in den Entscheidungsprozess vor einem Beschuss eingebunden seien, bestehe die Gefahr, sich zu sehr auf die KI-Daten zu verlassen. Mehrere Quellen berichteten dem »Guardian«, bei der Genehmigung eines Angriffs auf Privathäuser von Personen, die als Hamas- oder Islamischer-Dschihad-Aktivisten identifiziert wurden, haben die Zielforscher im Voraus gewusst, wie viele Zivilisten voraussichtlich getötet werden würden. Für jedes Ziel gebe es eine Datei mit einem Kollateralschadenwert. Ein ehemaliger US-Sicherheitsberater des Weißen Hauses, der mit dem Einsatz autonomer Systeme durch das US-Militär vertraut ist, sagte über die KI-Nutzung der IDF: »Andere Staaten werden zusehen und lernen«. Der Krieg zwischen Israel und der Hamas sei ein »wichtiger Moment, wenn die IDF KI in signifikanter Weise einsetzt, um Entscheidungen zu treffen, die Leben oder Tod bedeuten«."
